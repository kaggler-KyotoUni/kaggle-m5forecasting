{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_flow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYJV7LmzSEds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Google Colab: ランタイムはTPU推奨\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import os \n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxUFjobHltme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08d81de8-a459-4486-9618-1fefa0d7006b"
      },
      "source": [
        "import tensorflow as tf \n",
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ActKZC7JSKo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIR = \"./drive/My Drive/kaggle/m5-forecasting/datas\"\n",
        "\n",
        "def read_data():\n",
        "    cal = pd.read_csv(f\"{INPUT_DIR}calendar.csv\")\n",
        "    stv = pd.read_csv(f\"{INPUT_DIR}sales_train_validation.csv\")\n",
        "    ste = pd.read_csv(f\"{INPUT_DIR}sales_train_evaluation.csv\")\n",
        "    ss = pd.read_csv(f\"{INPUT_DIR}sample_submission.csv\")\n",
        "    sellp = pd.read_csv(f\"{INPUT_DIR}sell_prices.csv\")\n",
        "    \n",
        "    return cal, stv, ste, ss, sellp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLnkGO4jSL-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    \"\"\"\n",
        "    目的：メモリサイズの削減\n",
        "    df: メモリを削減したい DataFrame (pandas.DataFrame)\n",
        "    verbose: 実行時に、メモリ削減の情報を出力するかどうかを指定(bool)\n",
        "\n",
        "    ■ 基本思想\n",
        "    【前提知識】\n",
        "    pandas で作成したデータフレームのうち数値データは、特に dtype を指定しない場合\n",
        "    int64 または float64 でデータを作成するので、\n",
        "    実際のデータよりもこの型が大きいと余計なメモリサイズを確保してしまう。\n",
        "\n",
        "    【処理内容】\n",
        "    (1) 入力された DataFrame の column の型を全てチェック(for loop)\n",
        "    (2) その型が大きい数値データ(int16~int64, float16~float64)ならば、\n",
        "        そのデータフレームの最大値・最小値をチェック。\n",
        "        現在処理中のカラムを、上記の最大値・最小値を表せる必要最低限の型に変換する。\n",
        "        int と floatに分けて処理。\n",
        "\n",
        "    ────────────────────────────────────────────────────────────────────────\n",
        "    【変更履歴】\n",
        "    2020/06/06:\n",
        "    ■ 35行目\n",
        "    ifのネストが深かったので、リファクタ。\n",
        "    Early Continueを入れたので可読性が向上(したはず)。\n",
        "\n",
        "    ■ 46行目・71行目(置き換え・追加)\n",
        "    説明変数(関数?)で置き換え。\n",
        "    columnのtypeがintであるか否かを判定する関数を噛ませている。\n",
        "    (返り値はbool値)\n",
        "    \"\"\"\n",
        "\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    # main loop    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "\n",
        "        if col_type not in numerics: \n",
        "            continue # Early continue if column type is not numeric\n",
        "        \n",
        "        c_min = df[col].min()\n",
        "        c_max = df[col].max()\n",
        "\n",
        "        if IsInt(col_type):\n",
        "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                df[col] = df[col].astype(np.int8)\n",
        "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                df[col] = df[col].astype(np.int16)\n",
        "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                df[col] = df[col].astype(np.int32)\n",
        "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                df[col] = df[col].astype(np.int64)  \n",
        "        else:\n",
        "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                df[col] = df[col].astype(np.float16)\n",
        "            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                df[col] = df[col].astype(np.float32)\n",
        "            else:\n",
        "                df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    if verbose: \n",
        "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def IsInt(col_type):\n",
        "    return str(col_type)[:3] == 'int'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX1MThqFSZQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_ITEMS = 30490\n",
        "DATA_PATH = \"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oao-RhcxSb1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "zipからデータ読み出し。\n",
        "展開しないのでディスク容量も圧迫せず済む\n",
        "\"\"\"\n",
        "def train_data_from_csv_generator(num=NUM_ITEMS, datapath=DATA_PATH):\n",
        "    with zipfile.ZipFile(datapath) as myzip:\n",
        "        filelist = myzip.namelist()\n",
        "\n",
        "        for i, f_name in enumerate(filelist):\n",
        "\n",
        "            if i == 0:\n",
        "                continue\n",
        "\n",
        "            if i > num:\n",
        "                break\n",
        "\n",
        "            df = pd.read_csv(myzip.extract(f_name))\n",
        "            df = reduce_mem_usage(df, verbose=False)\n",
        "            df = df.fillna(0)\n",
        "            array = df.values\n",
        "            yield array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWoS4GiQSe4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "ジェネレータを使わないときはこれを用いる。\n",
        "※ 全部使うとメモリに乗りきらないので非推奨\n",
        "\"\"\"\n",
        "def CreateTrainingData(timesteps=28, delay=1, num_samples=30490):\n",
        "    x_shape = next(train_data_from_csv_generator(num=1)).shape\n",
        "\n",
        "    train_generator = train_data_from_csv_generator(num=num_samples)\n",
        "\n",
        "    len_sequence, num_features = x_shape\n",
        "    sample_batchsize = len_sequence-timesteps+1 - delay\n",
        "\n",
        "    X_train = np.zeros((sample_batchsize*num_samples, timesteps, num_features))\n",
        "    Y_train = np.zeros((sample_batchsize*num_samples, timesteps, 1))\n",
        "\n",
        "    for i, array in enumerate(train_generator):\n",
        "        for j in range(sample_batchsize - timesteps + 1 -delay):\n",
        "            X_train[i*sample_batchsize+j, 0: timesteps] = array[j:j+timesteps]\n",
        "            Y_train[i*sample_batchsize+j, 0: timesteps] = array[j+timesteps:j+2*timesteps , num_features-1].reshape(timesteps, 1)\n",
        "\n",
        "    return X_train, Y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h4xfpLvShJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing, metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM,Dropout\n",
        "from keras.layers import RepeatVector,TimeDistributed, BatchNormalization\n",
        "from numpy import array\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "#import utils_paths\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "\"\"\"\n",
        "仮のモデル\n",
        "ハイパーパラメータを引数にとれるよう改造すべき？\n",
        "※ チューニングができるように\n",
        "\"\"\"\n",
        "def build_model():\n",
        "    timesteps = 28\n",
        "    delay = 1\n",
        "\n",
        "    n_out_seq_length = 28\n",
        "    num_y = 1\n",
        "\n",
        "    train_generator = train_data_from_csv_generator(num=1) \n",
        "    x_shape = next(train_generator).shape\n",
        "\n",
        "    len_sequence, num_features = x_shape\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(LSTM(128, activation='relu', batch_input_shape=(None, timesteps, num_features), return_sequences=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(RepeatVector(28))\n",
        "    model.add(LSTM(32, activation='relu', return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.1))  \n",
        "    model.add(TimeDistributed(Dense(delay, activation=\"relu\")))   # num_y means the shape of y,in some problem(like translate), it can be many.\n",
        "                                                #In that case, you should set the  activation= 'softmax'\n",
        "    \n",
        "    #RMSpropOptimizer = RMSprop(lr=0.001, clipvalue=0.5)\n",
        "    #model.compile(optimizer=RMSpropOptimizer, loss='mean_squared_error', metrics=[\"accuracy\"])\n",
        "    model.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G0fcqThTEhP",
        "colab_type": "code",
        "outputId": "5b731973-e3cf-442c-b779-015bd20a8868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128)               73216     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 28, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 28, 32)            20608     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 32)            128       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 28, 32)            0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 28, 1)             33        \n",
            "=================================================================\n",
            "Total params: 94,497\n",
            "Trainable params: 94,177\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw5dNX9qTHjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import Sequence\n",
        "from keras.models import Sequential\n",
        "\n",
        "\"\"\"\n",
        "model.fit_generatorを使うためのユーザ定義関数\n",
        "※ generator を使わないとメモリが死ぬ\n",
        "\"\"\"\n",
        "class ReccurentTrainGenerator(Sequence):\n",
        "    def _resetindices(self):\n",
        "        \"\"\"\n",
        "        バッチ生成用のインデックスをランダムに出力\n",
        "        \"\"\"\n",
        "        self.num_called = 0\n",
        "\n",
        "        all_idx = np.random.permutation(np.arange(self.num_batches))\n",
        "        remain_idx = np.random.choice(np.arange(self.num_batches),\n",
        "                                      size=(self.steps_per_epoch*self.batch_size-len(all_idx)),\n",
        "                                      replace=False)\n",
        "        \n",
        "        self.indices = np.hstack([all_idx, remain_idx]).reshape(self.steps_per_epoch, self.batch_size)\n",
        "\n",
        "    def __init__(self, InputTensor, batch_size, InputSteps=28, OutputSteps=28, delay=1, normalize_factor=None):\n",
        "        \"\"\"\n",
        "        【入力】\n",
        "        InputTensor: 入力データ(説明変数) データ数(\"HOBBIES_1_...\"などに対応) × データ点数(時系列方向のデータ数) × 特徴量数 のndarray\n",
        "                     ※ 正解ラベルも、この時系列データからとるのでこれだけ入力すればOK \n",
        "        batch_size: バッチサイズ(例えば、timestepが5として、時刻0~4までのデータ、1~5までのデータ、...、10~14までのデータ、\n",
        "                                をひとまとめにして1データとみなすとする。RNNの場合はこのサイズがバッチサイズに対応する。)\n",
        "        InputSteps: リカレント層に食わせるデータを、何ステップ前までのデータにするか\n",
        "        OutputSteps: リカレント層からの出力(予測ステップ数)の設定値\n",
        "        delay: 目的変数をどの程度遅らせるか？(予測ステップのスタート位置をどの程度後ろにずらすか)\n",
        "        normalize_factor: 正規化する際のスケーリングをどの程度にするか\n",
        "        \"\"\"\n",
        "        self.train_tensor = InputTensor \n",
        "\n",
        "        # 各種パラメータ\n",
        "        self.num_datas = InputTensor.shape[0]\n",
        "        self.len_sequence = InputTensor.shape[1]\n",
        "        self.num_features = InputTensor.shape[2]\n",
        "        self.batch_size = batch_size\n",
        "        self.input_steps = InputSteps\n",
        "        self.output_steps = OutputSteps\n",
        "        self.delay = delay\n",
        "\n",
        "        # 現在のエポックでバッチ生成の対象となっているデータ系列\n",
        "        self.now_data = InputTensor[0]\n",
        "\n",
        "        # 各データ系列に対し、バッチサイズいくつ作れるか計算するのに必要な値\n",
        "        self.len_requied_per_batch = InputSteps + (batch_size-1) + (delay-1) + OutputSteps # 訓練データと正解データを作るために必要なサイズ \n",
        "        self.num_batches = self.len_sequence - self.len_requied_per_batch + 1              # 作れるバッチの数\n",
        "\n",
        "        # 1エポック当たりのステップ数\n",
        "        self.steps_per_epoch = int(np.ceil(self.len_sequence / float(batch_size)))\n",
        "        \n",
        "        # バッチ生成用の乱数初期化\n",
        "        self._resetindices()\n",
        "\n",
        "        # データ取得用インデックス生成\n",
        "        self.data_idx = self._reset_dataset_indices(self.num_datas)\n",
        "        self.num_epoch = 0\n",
        "\n",
        "        self.normalize_factor = normalize_factor\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        1エポックあたりのステップ数をリターン\n",
        "        \"\"\"\n",
        "        return self.steps_per_epoch\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        データをバッチにまとめて出力\n",
        "        \"\"\"\n",
        "        indices_temp = self.indices[idx] # indices は (steps_per_epoch, batchsize)の array\n",
        "\n",
        "        batch_x = np.array([self.now_data[i:i+self.input_steps] for i in indices_temp])\n",
        "        batch_y = np.array([self.now_data[i+self.input_steps+(self.delay-1):i+self.input_steps+(self.delay-1)+self.output_steps, -1] for i in indices_temp]).reshape(self.batch_size, self.output_steps, 1)\n",
        "\n",
        "        if self.num_called == (self.steps_per_epoch-1):\n",
        "            self._resetindices()\n",
        "        else:\n",
        "            self.num_called += 1\n",
        "\n",
        "        if self.normalize_factor:\n",
        "            batch_x = batch_x / self.normalize_factor\n",
        "            batch_y = batch_y / self.normalize_factor\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"\n",
        "        Epoch 終了ごとにデータセットを入れ替える\n",
        "        (データセット：\"HOBBIES_1_...\"などに対応)\n",
        "        \"\"\"\n",
        "        if self.num_epoch == self.num_datas:\n",
        "            self.num_epoch = 0\n",
        "            self.data_idx = self._reset_dataset_indices(self.num_datas)\n",
        "        else:\n",
        "            self.num_epoch += 1\n",
        "        \n",
        "        next_data_idx = self.data_idx[self.num_epoch]\n",
        "        self.now_data = self.train_tensor[next_data_idx]\n",
        "\n",
        "\n",
        "    def _reset_dataset_indices(self, num_datas):\n",
        "        \"\"\"\n",
        "        Epoch毎に入れ替えるデータのインデックスをランダムにするためのメソッド\n",
        "        \"\"\"\n",
        "        return np.random.permutation(np.arange(num_datas))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb8ik8H2USIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Generatorに食わせるためのトレーニングデータ(ndarray)作成関数\n",
        "一度作って np.saveで保存すれば使う必要なし(この関数の実行は時間かかる)\n",
        "\"\"\"\n",
        "def CreateTrainingTensor(num=30490):\n",
        "    tg = train_data_from_csv_generator(num=1)\n",
        "    shape = next(tg).shape\n",
        "    X_train = np.zeros((num, shape[0], shape[1]))\n",
        "\n",
        "    train_generator = train_data_from_csv_generator(num=num)\n",
        "\n",
        "    for i, array in enumerate(train_generator):\n",
        "        if i/1000 == i//1000:\n",
        "            print(i)\n",
        "\n",
        "        X_train[i] = array\n",
        "\n",
        "    return X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quPs4QymUico",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 作成と保存の例\n",
        "# X_train = CreateTrainingTensor()\n",
        "# X_train = CreateTrainingTensor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK57IM-bUp6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 読みだしは基本こっちで\n",
        "X_train = np.load(INPUT_DIR + \"/TrainingTensor.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvbeoqf6UrtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_max = np.max(X_train)\n",
        "\n",
        "RTG = ReccurentTrainGenerator(InputTensor=X_train[:-100], batch_size=128, InputSteps=28, normalize_factor=X_max)\n",
        "Validation_RTG = ReccurentTrainGenerator(X_train[:-100], batch_size=128, InputSteps=28, normalize_factor=X_max)\n",
        "# トレーニングデータの一部をバリデーション用にする"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZvJwlKvU0QY",
        "colab_type": "code",
        "outputId": "ed6a06b3-4c66-4a32-ab89-2f34b466ebfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        " \n",
        "# Early-stopping: patienceはもう少し大きくとる？\n",
        "early_stopping = EarlyStopping(patience=5, verbose=1) \n",
        "\n",
        "history = model.fit_generator(RTG, epochs=500, verbose=1, validation_data=Validation_RTG, callbacks=[early_stopping])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 278ms/step - loss: 5.2515e-04 - accuracy: 0.6719 - val_loss: 3.5139e-08 - val_accuracy: 0.6721\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 1.3748e-06 - accuracy: 0.6720 - val_loss: 3.5619e-08 - val_accuracy: 0.6717\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 6.1179e-07 - accuracy: 0.6719 - val_loss: 3.5379e-08 - val_accuracy: 0.6718\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 3.2946e-07 - accuracy: 0.6718 - val_loss: 3.5109e-08 - val_accuracy: 0.6719\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 1.0600e-07 - accuracy: 0.6721 - val_loss: 3.5860e-08 - val_accuracy: 0.6719\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 181ms/step - loss: 4.2529e-06 - accuracy: 0.6718 - val_loss: 3.5229e-08 - val_accuracy: 0.6719\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 175ms/step - loss: 2.3316e-07 - accuracy: 0.6723 - val_loss: 3.5199e-08 - val_accuracy: 0.6719\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 176ms/step - loss: 4.8319e-07 - accuracy: 0.6725 - val_loss: 3.5379e-08 - val_accuracy: 0.6716\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 176ms/step - loss: 1.0930e-07 - accuracy: 0.6724 - val_loss: 3.5079e-08 - val_accuracy: 0.6722\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 1.7133e-07 - accuracy: 0.6719 - val_loss: 3.4808e-08 - val_accuracy: 0.6722\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 6.2450e-08 - accuracy: 0.6721 - val_loss: 3.5619e-08 - val_accuracy: 0.6721\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 5.2905e-08 - accuracy: 0.6720 - val_loss: 3.4598e-08 - val_accuracy: 0.6726\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 5.4576e-08 - accuracy: 0.6720 - val_loss: 3.5860e-08 - val_accuracy: 0.6719\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 4.0691e-08 - accuracy: 0.6720 - val_loss: 3.5169e-08 - val_accuracy: 0.6719\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 6.6957e-08 - accuracy: 0.6717 - val_loss: 3.5319e-08 - val_accuracy: 0.6719\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 174ms/step - loss: 9.8043e-08 - accuracy: 0.6719 - val_loss: 3.5589e-08 - val_accuracy: 0.6720\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 175ms/step - loss: 9.0630e-08 - accuracy: 0.6719 - val_loss: 3.5349e-08 - val_accuracy: 0.6722\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65slhPeiU4VU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習結果の保存\n",
        "model_json_str = model.to_json()\n",
        "open('LSTM_test_model.json', 'w').write(model_json_str)\n",
        "model.save_weights('LSTM_test_weights.h5');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbE6cHwMVQwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "提出用データの入力作成関数\n",
        "(これも結果をnp.saveで保存してしまえば使う必要なし)\n",
        "\"\"\"\n",
        "def GenerateInputForPrediction(num_samples=30490):\n",
        "    TIMESTEPS = 28\n",
        "\n",
        "    train_generator = train_data_from_csv_generator(num=1) \n",
        "    x_shape = next(train_generator).shape\n",
        "    num_features = x_shape[1]\n",
        "\n",
        "    #X_test = np.zeros((num_samples, TIMESTEPS, num_features))\n",
        "\n",
        "    train_generator = train_data_from_csv_generator(num=num_samples)\n",
        "\n",
        "    for i, array in enumerate(train_generator):\n",
        "        #X_test[i] = array[-TIMESTEPS:]\n",
        "        yield array[-TIMESTEPS:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxRnBIxTVk0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# テストデータ作成と保存\n",
        "\n",
        "# X_test_generator = GenerateInputForPrediction()\n",
        "# X_test = np.zeros((30490, 28, 14))\n",
        "# for i, array in enumerate(X_test_generator):\n",
        "#     if i / 1000 == i //1000:\n",
        "#         print(i)\n",
        "#     X_test[i] = array \n",
        "# np.save(INPUT_DIR + \"/test_data.npy\", X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfYd3a5yVD71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# テストデータの読み出し\n",
        "X_test = np.load(INPUT_DIR + \"/test_data.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOziodsIWG23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erRT0TiUWKL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "予測結果のndarrayを提出形式のcsvに変換する関数\n",
        "\"\"\"\n",
        "\n",
        "INPUT_DIR = \"./drive/My Drive/kaggle/m5-forecasting/datas\"\n",
        "\n",
        "def CreateSubmissionCSV(prediction, save_path=INPUT_DIR):\n",
        "    # Create Prediction DataFrame\n",
        "    prediction = np.rint(prediction)\n",
        "    prediction = prediction.astype(\"int\")\n",
        "    pred_df = pd.DataFrame(prediction.reshape(30490, 28))\n",
        "\n",
        "    # Get \"id\" columns (id の情報だけまとめたファイルを作成した方が軽いはず -> 未実装)\n",
        "    stv = pd.read_csv(INPUT_DIR + \"/sales_train_validation.csv\")\n",
        "    ste = pd.read_csv(INPUT_DIR + \"/sales_train_evaluation.csv\")\n",
        "\n",
        "    # Rename Index & Columns\n",
        "    pred_df.index = list(ste[\"id\"])\n",
        "    pred_df.columns = [f'F{i}' for i in range(1, 28 + 1)]\n",
        "\n",
        "    # Set index label \"id\"\n",
        "    pred_df = pred_df.reset_index()\n",
        "    pred_df = pred_df.rename(columns={\"index\": \"id\"})\n",
        "    pred_df = pred_df.set_index(\"id\")\n",
        "\n",
        "    # Create \"Validation\" DataFrame\n",
        "    validation_df = ste[[\"id\"] +  [\"d_\" + str(i) for i in range(1914, 1942)]]\n",
        "\n",
        "    # Rename columns & set index \"id\"\n",
        "    validation_df = validation_df.set_index(\"id\")\n",
        "    validation_df = validation_df.rename(columns={\"d_\" + str(i + 1913): \"F\" + str(i) for i in range(1, 29)})\n",
        "    validation_df.index = stv[\"id\"]\n",
        "\n",
        "    # Create Submission DataFrame (shape = (60980, 28))\n",
        "    submission_df = pd.concat([validation_df, pred_df], axis=0)\n",
        "    submission_df.to_csv(save_path + \"/submission.csv\")\n",
        "\n",
        "    # For Debug\n",
        "\n",
        "    print(submission_df.shape)\n",
        "    return submission_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8VFL3XAWMkr",
        "colab_type": "code",
        "outputId": "a383e9da-89fb-4889-99a3-4dcbe7b13968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test_max = np.max(X_test)\n",
        "sub_df = CreateSubmissionCSV(prediction / X_test_max)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60980, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_V9NWimWh1u",
        "colab_type": "code",
        "outputId": "570a8ea3-61ea-4d56-a947-4907eb4a957c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "sub_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "      <th>F20</th>\n",
              "      <th>F21</th>\n",
              "      <th>F22</th>\n",
              "      <th>F23</th>\n",
              "      <th>F24</th>\n",
              "      <th>F25</th>\n",
              "      <th>F26</th>\n",
              "      <th>F27</th>\n",
              "      <th>F28</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HOBBIES_1_001_CA_1_validation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HOBBIES_1_002_CA_1_validation</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HOBBIES_1_003_CA_1_validation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HOBBIES_1_004_CA_1_validation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HOBBIES_1_005_CA_1_validation</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOODS_3_823_WI_3_evaluation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOODS_3_824_WI_3_evaluation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOODS_3_825_WI_3_evaluation</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOODS_3_826_WI_3_evaluation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOODS_3_827_WI_3_evaluation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60980 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                               F1  F2  F3  F4  F5  ...  F24  F25  F26  F27  F28\n",
              "id                                                 ...                         \n",
              "HOBBIES_1_001_CA_1_validation   0   0   0   2   0  ...    0    3    3    0    1\n",
              "HOBBIES_1_002_CA_1_validation   0   1   0   0   0  ...    0    0    0    0    0\n",
              "HOBBIES_1_003_CA_1_validation   0   0   1   1   0  ...    0    2    3    0    1\n",
              "HOBBIES_1_004_CA_1_validation   0   0   1   2   4  ...    1    3    0    2    6\n",
              "HOBBIES_1_005_CA_1_validation   1   0   2   3   1  ...    0    0    2    1    0\n",
              "...                            ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...\n",
              "FOODS_3_823_WI_3_evaluation     0   0   0   0   0  ...    0    0    2    4    0\n",
              "FOODS_3_824_WI_3_evaluation     0   0   0   0   0  ...   22   22   22   23   23\n",
              "FOODS_3_825_WI_3_evaluation     0   1   1   0   0  ...    4    4    4    4    4\n",
              "FOODS_3_826_WI_3_evaluation     0   0   0   0   0  ...    5    6    7    7    8\n",
              "FOODS_3_827_WI_3_evaluation     0   0   0   0   0  ...    1    0    1    2    0\n",
              "\n",
              "[60980 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGDV9rruInNi",
        "colab_type": "text"
      },
      "source": [
        "# クロスバリデーションのためのテスト"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4rRER08Irl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データ読み出し\n",
        "X_train = np.load(INPUT_DIR + \"/TrainingTensor.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTFTDLF_IyLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=5)\n",
        "CV_gen = kfold.split(X_train[:1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9_sYZyGKLLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32170509-99cc-4545-f8ac-8442065a22b0"
      },
      "source": [
        "next(CV_gen)[0].shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ykC58xKbeL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e5aaff7-7ff3-49bc-c686-0966676b42bd"
      },
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        "\n",
        "History = []\n",
        "\n",
        "# 1000サンプルでクロスバリデーションテスト\n",
        "for train_cv_idx, valid_cv_idx in kfold.split(X_train[:1000]):\n",
        "    X_CV_train_gen = ReccurentTrainGenerator(X_train[train_cv_idx], batch_size=128)\n",
        "    X_CV_valid_gen = ReccurentTrainGenerator(X_train[valid_cv_idx], batch_size=128)\n",
        "\n",
        "    model = build_model() #カテゴリごとのモデルを作る時も、同様にfor文内で再度モデルをビルドすればよいかもしれない。\n",
        " \n",
        "    # Early-stopping: patienceはもう少し大きくとる？\n",
        "    early_stopping = EarlyStopping(patience=5, verbose=1) \n",
        "\n",
        "    history = model.fit_generator(X_CV_train_gen, epochs=500, verbose=1, validation_data=X_CV_valid_gen, callbacks=[early_stopping])\n",
        "    History.append(history)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 267ms/step - loss: 0.8040 - accuracy: 0.5544 - val_loss: 10.0985 - val_accuracy: 0.5779\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.5521 - accuracy: 0.5825 - val_loss: 1.1749 - val_accuracy: 0.6210\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.4165 - accuracy: 0.6120 - val_loss: 0.3679 - val_accuracy: 0.6615\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3896 - accuracy: 0.6306 - val_loss: 0.3818 - val_accuracy: 0.6478\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3621 - accuracy: 0.6375 - val_loss: 0.3018 - val_accuracy: 0.6588\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 172ms/step - loss: 0.3832 - accuracy: 0.6403 - val_loss: 0.3224 - val_accuracy: 0.6685\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3340 - accuracy: 0.6336 - val_loss: 0.3281 - val_accuracy: 0.6709\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.3362 - accuracy: 0.6560 - val_loss: 0.3251 - val_accuracy: 0.6679\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3437 - accuracy: 0.6231 - val_loss: 0.3229 - val_accuracy: 0.6713\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 172ms/step - loss: 0.3318 - accuracy: 0.6390 - val_loss: 0.3299 - val_accuracy: 0.6717\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 255ms/step - loss: 0.8765 - accuracy: 0.5712 - val_loss: 15.0246 - val_accuracy: 0.4696\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 179ms/step - loss: 0.5896 - accuracy: 0.6037 - val_loss: 14.4073 - val_accuracy: 0.6007\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 175ms/step - loss: 0.4964 - accuracy: 0.5975 - val_loss: 58.3458 - val_accuracy: 0.2181\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.4304 - accuracy: 0.6217 - val_loss: 103.5754 - val_accuracy: 0.1335\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3860 - accuracy: 0.6233 - val_loss: 426.5581 - val_accuracy: 0.0103\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3503 - accuracy: 0.6391 - val_loss: 37.9847 - val_accuracy: 0.0654\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3739 - accuracy: 0.6470 - val_loss: 3.0560 - val_accuracy: 0.6356\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 172ms/step - loss: 0.3561 - accuracy: 0.6513 - val_loss: 0.3472 - val_accuracy: 0.6534\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3561 - accuracy: 0.6349 - val_loss: 3017.0039 - val_accuracy: 0.1157\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3638 - accuracy: 0.6333 - val_loss: 1.7743 - val_accuracy: 0.6454\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3445 - accuracy: 0.6411 - val_loss: 105.0615 - val_accuracy: 0.6290\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3381 - accuracy: 0.6502 - val_loss: 28.9752 - val_accuracy: 0.3971\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3424 - accuracy: 0.6565 - val_loss: 1.5330 - val_accuracy: 0.4625\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 235ms/step - loss: 0.5521 - accuracy: 0.5547 - val_loss: 414.1978 - val_accuracy: 0.5798\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.4356 - accuracy: 0.5841 - val_loss: 344.3774 - val_accuracy: 0.5938\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.4158 - accuracy: 0.6206 - val_loss: 20.4017 - val_accuracy: 0.6567\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3562 - accuracy: 0.6315 - val_loss: 0.8471 - val_accuracy: 0.6258\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3382 - accuracy: 0.6461 - val_loss: 0.3446 - val_accuracy: 0.6636\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3385 - accuracy: 0.6413 - val_loss: 7.5342 - val_accuracy: 0.6153\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3188 - accuracy: 0.6471 - val_loss: 0.3259 - val_accuracy: 0.6704\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.3170 - accuracy: 0.6525 - val_loss: 0.3222 - val_accuracy: 0.6612\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.3470 - accuracy: 0.6232 - val_loss: 3.8538 - val_accuracy: 0.6327\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.3431 - accuracy: 0.6327 - val_loss: 0.3164 - val_accuracy: 0.6677\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3382 - accuracy: 0.6217 - val_loss: 0.3312 - val_accuracy: 0.6288\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3521 - accuracy: 0.5974 - val_loss: 4.9830 - val_accuracy: 0.1142\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.3158 - accuracy: 0.6471 - val_loss: 0.3364 - val_accuracy: 0.6701\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 179ms/step - loss: 0.3126 - accuracy: 0.6383 - val_loss: 0.3270 - val_accuracy: 0.6722\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 179ms/step - loss: 0.3100 - accuracy: 0.6452 - val_loss: 0.3278 - val_accuracy: 0.6722\n",
            "Epoch 00015: early stopping\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 245ms/step - loss: 0.4226 - accuracy: 0.5755 - val_loss: 66.7638 - val_accuracy: 0.3989\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3554 - accuracy: 0.6173 - val_loss: 7.1341 - val_accuracy: 0.4144\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.3213 - accuracy: 0.6243 - val_loss: 4.2603 - val_accuracy: 0.6435\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 172ms/step - loss: 0.3071 - accuracy: 0.6340 - val_loss: 9.1688 - val_accuracy: 0.6365\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3130 - accuracy: 0.6408 - val_loss: 0.3156 - val_accuracy: 0.6719\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3114 - accuracy: 0.6194 - val_loss: 0.4358 - val_accuracy: 0.6703\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.2953 - accuracy: 0.6417 - val_loss: 0.3329 - val_accuracy: 0.6720\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 175ms/step - loss: 0.3058 - accuracy: 0.6254 - val_loss: 0.3223 - val_accuracy: 0.6722\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.2847 - accuracy: 0.6536 - val_loss: 0.3276 - val_accuracy: 0.6719\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.2969 - accuracy: 0.6429 - val_loss: 0.3318 - val_accuracy: 0.6720\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 237ms/step - loss: 1.8882 - accuracy: 0.5733 - val_loss: 5381.3350 - val_accuracy: 0.0927\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 1.1680 - accuracy: 0.5896 - val_loss: 10.9150 - val_accuracy: 0.3441\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.8784 - accuracy: 0.5879 - val_loss: 0.3210 - val_accuracy: 0.6724\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.7578 - accuracy: 0.6076 - val_loss: 0.3225 - val_accuracy: 0.6723\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.6373 - accuracy: 0.6242 - val_loss: 0.2387 - val_accuracy: 0.6720\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.5998 - accuracy: 0.6258 - val_loss: 0.3523 - val_accuracy: 0.4784\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.5964 - accuracy: 0.6271 - val_loss: 0.3604 - val_accuracy: 0.6364\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.4213 - accuracy: 0.6338 - val_loss: 0.6267 - val_accuracy: 0.3883\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3630 - accuracy: 0.6472 - val_loss: 1.3587 - val_accuracy: 0.4473\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3329 - accuracy: 0.6566 - val_loss: 2.4125 - val_accuracy: 0.4633\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raV2ubGxNPts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b59a4f39-8e39-456d-c050-ec2efd8424d0"
      },
      "source": [
        "History"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.callbacks.callbacks.History at 0x7fb21e27c390>,\n",
              " <keras.callbacks.callbacks.History at 0x7fb227f65dd8>,\n",
              " <keras.callbacks.callbacks.History at 0x7fb227b23f98>,\n",
              " <keras.callbacks.callbacks.History at 0x7fb21cc6b860>,\n",
              " <keras.callbacks.callbacks.History at 0x7fb21d3eab00>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSaX0grCN4Hl",
        "colab_type": "text"
      },
      "source": [
        "# Loss を自作する(RMSSEをLossとして学習する)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Imw2Ac4N1-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}