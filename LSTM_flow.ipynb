{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_flow.ipynb","provenance":[],"mount_file_id":"1Nj78KKCloC9B5DoydNH2qhxaO-EctSYd","authorship_tag":"ABX9TyNJATSPx6B7y0+qYChH+nSh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"NYJV7LmzSEds","colab_type":"code","colab":{}},"source":["\"\"\"\n","Google Colab: ランタイムはTPU推奨\n","\"\"\"\n","\n","import pandas as pd \n","import numpy as np \n","import matplotlib.pyplot as plt \n","import os \n","import zipfile"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ActKZC7JSKo6","colab_type":"code","colab":{}},"source":["INPUT_DIR = \"./drive/My Drive/kaggle/m5-forecasting/datas\"\n","\n","def read_data():\n","    cal = pd.read_csv(f\"{INPUT_DIR}calendar.csv\")\n","    stv = pd.read_csv(f\"{INPUT_DIR}sales_train_validation.csv\")\n","    ste = pd.read_csv(f\"{INPUT_DIR}sales_train_evaluation.csv\")\n","    ss = pd.read_csv(f\"{INPUT_DIR}sample_submission.csv\")\n","    sellp = pd.read_csv(f\"{INPUT_DIR}sell_prices.csv\")\n","    \n","    return cal, stv, ste, ss, sellp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mLnkGO4jSL-Q","colab_type":"code","colab":{}},"source":["def reduce_mem_usage(df, verbose=True):\n","    \"\"\"\n","    目的：メモリサイズの削減\n","    df: メモリを削減したい DataFrame (pandas.DataFrame)\n","    verbose: 実行時に、メモリ削減の情報を出力するかどうかを指定(bool)\n","\n","    ■ 基本思想\n","    【前提知識】\n","    pandas で作成したデータフレームのうち数値データは、特に dtype を指定しない場合\n","    int64 または float64 でデータを作成するので、\n","    実際のデータよりもこの型が大きいと余計なメモリサイズを確保してしまう。\n","\n","    【処理内容】\n","    (1) 入力された DataFrame の column の型を全てチェック(for loop)\n","    (2) その型が大きい数値データ(int16~int64, float16~float64)ならば、\n","        そのデータフレームの最大値・最小値をチェック。\n","        現在処理中のカラムを、上記の最大値・最小値を表せる必要最低限の型に変換する。\n","        int と floatに分けて処理。\n","\n","    ────────────────────────────────────────────────────────────────────────\n","    【変更履歴】\n","    2020/06/06:\n","    ■ 35行目\n","    ifのネストが深かったので、リファクタ。\n","    Early Continueを入れたので可読性が向上(したはず)。\n","\n","    ■ 46行目・71行目(置き換え・追加)\n","    説明変数(関数?)で置き換え。\n","    columnのtypeがintであるか否かを判定する関数を噛ませている。\n","    (返り値はbool値)\n","    \"\"\"\n","\n","    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n","    start_mem = df.memory_usage().sum() / 1024**2\n","\n","    # main loop    \n","    for col in df.columns:\n","        col_type = df[col].dtypes\n","\n","        if col_type not in numerics: \n","            continue # Early continue if column type is not numeric\n","        \n","        c_min = df[col].min()\n","        c_max = df[col].max()\n","\n","        if IsInt(col_type):\n","            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                df[col] = df[col].astype(np.int8)\n","            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                df[col] = df[col].astype(np.int16)\n","            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                df[col] = df[col].astype(np.int32)\n","            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                df[col] = df[col].astype(np.int64)  \n","        else:\n","            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                df[col] = df[col].astype(np.float16)\n","            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                df[col] = df[col].astype(np.float32)\n","            else:\n","                df[col] = df[col].astype(np.float64)\n","\n","    end_mem = df.memory_usage().sum() / 1024**2\n","\n","    if verbose: \n","        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n","\n","    return df\n","\n","\n","def IsInt(col_type):\n","    return str(col_type)[:3] == 'int'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iX1MThqFSZQP","colab_type":"code","colab":{}},"source":["NUM_ITEMS = 30490\n","DATA_PATH = \"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas.zip\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oao-RhcxSb1A","colab_type":"code","colab":{}},"source":["\"\"\"\n","zipからデータ読み出し。\n","展開しないのでディスク容量も圧迫せず済む\n","\"\"\"\n","def train_data_from_csv_generator(num=NUM_ITEMS, datapath=DATA_PATH):\n","    with zipfile.ZipFile(datapath) as myzip:\n","        filelist = myzip.namelist()\n","\n","        for i, f_name in enumerate(filelist):\n","\n","            if i == 0:\n","                continue\n","\n","            if i > num:\n","                break\n","\n","            df = pd.read_csv(myzip.extract(f_name))\n","            df = reduce_mem_usage(df, verbose=False)\n","            df = df.fillna(0)\n","            array = df.values\n","            yield array"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWoS4GiQSe4v","colab_type":"code","colab":{}},"source":["\"\"\"\n","ジェネレータを使わないときはこれを用いる。\n","※ 全部使うとメモリに乗りきらないので非推奨\n","\"\"\"\n","def CreateTrainingData(timesteps=28, delay=1, num_samples=30490):\n","    x_shape = next(train_data_from_csv_generator(num=1)).shape\n","\n","    train_generator = train_data_from_csv_generator(num=num_samples)\n","\n","    len_sequence, num_features = x_shape\n","    sample_batchsize = len_sequence-timesteps+1 - delay\n","\n","    X_train = np.zeros((sample_batchsize*num_samples, timesteps, num_features))\n","    Y_train = np.zeros((sample_batchsize*num_samples, timesteps, 1))\n","\n","    for i, array in enumerate(train_generator):\n","        for j in range(sample_batchsize - timesteps + 1 -delay):\n","            X_train[i*sample_batchsize+j, 0: timesteps] = array[j:j+timesteps]\n","            Y_train[i*sample_batchsize+j, 0: timesteps] = array[j+timesteps:j+2*timesteps , num_features-1].reshape(timesteps, 1)\n","\n","    return X_train, Y_train"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6h4xfpLvShJo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b3c42684-a25d-477a-a4f0-07e333c9198c","executionInfo":{"status":"ok","timestamp":1592011805382,"user_tz":-540,"elapsed":2628,"user":{"displayName":"芋田総之","photoUrl":"","userId":"06994139843960550178"}}},"source":["from sklearn import preprocessing, metrics\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM,Dropout\n","from keras.layers import RepeatVector,TimeDistributed, BatchNormalization\n","from numpy import array\n","from keras.models import Sequential, load_model\n","from keras.optimizers import Adam, RMSprop\n","#import utils_paths\n","import re\n","from tqdm import tqdm\n","import os\n","\n","\"\"\"\n","仮のモデル\n","ハイパーパラメータを引数にとれるよう改造すべき？\n","※ チューニングができるように\n","\"\"\"\n","def build_model():\n","    timesteps = 28\n","    delay = 1\n","\n","    n_out_seq_length = 28\n","    num_y = 1\n","\n","    train_generator = train_data_from_csv_generator(num=1) \n","    x_shape = next(train_generator).shape\n","\n","    len_sequence, num_features = x_shape\n","\n","    model = Sequential()\n","\n","    model.add(LSTM(128, activation='relu', batch_input_shape=(None, timesteps, num_features), return_sequences=False))\n","    model.add(BatchNormalization())\n","    model.add(RepeatVector(28))\n","    model.add(LSTM(32, activation='relu', return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.1))  \n","    model.add(TimeDistributed(Dense(delay, activation=\"relu\")))   # num_y means the shape of y,in some problem(like translate), it can be many.\n","                                                #In that case, you should set the  activation= 'softmax'\n","    \n","    #RMSpropOptimizer = RMSprop(lr=0.001, clipvalue=0.5)\n","    #model.compile(optimizer=RMSpropOptimizer, loss='mean_squared_error', metrics=[\"accuracy\"])\n","    model.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=[\"accuracy\"])\n","\n","\n","    return model"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_G0fcqThTEhP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":404},"outputId":"3f72860a-af74-4693-ee98-7d27d0b8984d","executionInfo":{"status":"ok","timestamp":1592011853045,"user_tz":-540,"elapsed":2732,"user":{"displayName":"芋田総之","photoUrl":"","userId":"06994139843960550178"}}},"source":["model = build_model()\n","model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_1 (LSTM)                (None, 128)               73216     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 128)               512       \n","_________________________________________________________________\n","repeat_vector_1 (RepeatVecto (None, 28, 128)           0         \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 28, 32)            20608     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 28, 32)            128       \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 28, 32)            0         \n","_________________________________________________________________\n","time_distributed_1 (TimeDist (None, 28, 1)             33        \n","=================================================================\n","Total params: 94,497\n","Trainable params: 94,177\n","Non-trainable params: 320\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fw5dNX9qTHjA","colab_type":"code","colab":{}},"source":["from keras.utils import Sequence\n","from keras.models import Sequential\n","\n","\"\"\"\n","model.fit_generatorを使うためのユーザ定義関数\n","※ generator を使わないとメモリが死ぬ\n","\"\"\"\n","class ReccurentTrainGenerator(Sequence):\n","    def _resetindices(self):\n","        \"\"\"\n","        バッチ生成用のインデックスをランダムに出力\n","        \"\"\"\n","        self.num_called = 0\n","\n","        all_idx = np.random.permutation(np.arange(self.num_batches))\n","        remain_idx = np.random.choice(np.arange(self.num_batches),\n","                                      size=(self.steps_per_epoch*self.batch_size-len(all_idx)),\n","                                      replace=False)\n","        \n","        self.indices = np.hstack([all_idx, remain_idx]).reshape(self.steps_per_epoch, self.batch_size)\n","\n","    def __init__(self, InputTensor, batch_size, InputSteps=28, OutputSteps=28, delay=1, normalize_factor=None):\n","        \"\"\"\n","        【入力】\n","        InputTensor: 入力データ(説明変数) データ数(\"HOBBIES_1_...\"などに対応) × データ点数(時系列方向のデータ数) × 特徴量数 のndarray\n","                     ※ 正解ラベルも、この時系列データからとるのでこれだけ入力すればOK \n","        batch_size: バッチサイズ(例えば、timestepが5として、時刻0~4までのデータ、1~5までのデータ、...、10~14までのデータ、\n","                                をひとまとめにして1データとみなすとする。RNNの場合はこのサイズがバッチサイズに対応する。)\n","        InputSteps: リカレント層に食わせるデータを、何ステップ前までのデータにするか\n","        OutputSteps: リカレント層からの出力(予測ステップ数)の設定値\n","        delay: 目的変数をどの程度遅らせるか？(予測ステップのスタート位置をどの程度後ろにずらすか)\n","        normalize_factor: 正規化する際のスケーリングをどの程度にするか\n","        \"\"\"\n","        self.train_tensor = InputTensor \n","\n","        # 各種パラメータ\n","        self.num_datas = InputTensor.shape[0]\n","        self.len_sequence = InputTensor.shape[1]\n","        self.num_features = InputTensor.shape[2]\n","        self.batch_size = batch_size\n","        self.input_steps = InputSteps\n","        self.output_steps = OutputSteps\n","        self.delay = delay\n","\n","        # 現在のエポックでバッチ生成の対象となっているデータ系列\n","        self.now_data = InputTensor[0]\n","\n","        # 各データ系列に対し、バッチサイズいくつ作れるか計算するのに必要な値\n","        self.len_requied_per_batch = InputSteps + (batch_size-1) + (delay-1) + OutputSteps # 訓練データと正解データを作るために必要なサイズ \n","        self.num_batches = self.len_sequence - self.len_requied_per_batch + 1              # 作れるバッチの数\n","\n","        # 1エポック当たりのステップ数\n","        self.steps_per_epoch = int(np.ceil(self.len_sequence / float(batch_size)))\n","        \n","        # バッチ生成用の乱数初期化\n","        self._resetindices()\n","\n","        # データ取得用インデックス生成\n","        self.data_idx = self._reset_dataset_indices(self.num_datas)\n","        self.num_epoch = 0\n","\n","        self.normalize_factor = normalize_factor\n","\n","\n","    def __len__(self):\n","        \"\"\"\n","        1エポックあたりのステップ数をリターン\n","        \"\"\"\n","        return self.steps_per_epoch\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        データをバッチにまとめて出力\n","        \"\"\"\n","        indices_temp = self.indices[idx] # indices は (steps_per_epoch, batchsize)の array\n","\n","        batch_x = np.array([self.now_data[i:i+self.input_steps] for i in indices_temp])\n","        batch_y = np.array([self.now_data[i+self.input_steps+(self.delay-1):i+self.input_steps+(self.delay-1)+self.output_steps, -1] for i in indices_temp]).reshape(self.batch_size, self.output_steps, 1)\n","\n","        if self.num_called == (self.steps_per_epoch-1):\n","            self._resetindices()\n","        else:\n","            self.num_called += 1\n","\n","        if self.normalize_factor:\n","            batch_x = batch_x / self.normalize_factor\n","            batch_y = batch_y / self.normalize_factor\n","\n","        return batch_x, batch_y\n","\n","    def on_epoch_end(self):\n","        \"\"\"\n","        Epoch 終了ごとにデータセットを入れ替える\n","        (データセット：\"HOBBIES_1_...\"などに対応)\n","        \"\"\"\n","        if self.num_epoch == self.num_datas:\n","            self.num_epoch = 0\n","            self.data_idx = self._reset_dataset_indices(self.num_datas)\n","        else:\n","            self.num_epoch += 1\n","        \n","        next_data_idx = self.data_idx[self.num_epoch]\n","        self.now_data = self.train_tensor[next_data_idx]\n","\n","\n","    def _reset_dataset_indices(self, num_datas):\n","        \"\"\"\n","        Epoch毎に入れ替えるデータのインデックスをランダムにするためのメソッド\n","        \"\"\"\n","        return np.random.permutation(np.arange(num_datas))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rb8ik8H2USIc","colab_type":"code","colab":{}},"source":["\"\"\"\n","Generatorに食わせるためのトレーニングデータ(ndarray)作成関数\n","一度作って np.saveで保存すれば使う必要なし(この関数の実行は時間かかる)\n","\"\"\"\n","def CreateTrainingTensor(num=30490):\n","    tg = train_data_from_csv_generator(num=1)\n","    shape = next(tg).shape\n","    X_train = np.zeros((num, shape[0], shape[1]))\n","\n","    train_generator = train_data_from_csv_generator(num=num)\n","\n","    for i, array in enumerate(train_generator):\n","        if i/1000 == i//1000:\n","            print(i)\n","\n","        X_train[i] = array\n","\n","    return X_train"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"quPs4QymUico","colab_type":"code","colab":{}},"source":["# 作成と保存の例\n","# X_train = CreateTrainingTensor()\n","# X_train = CreateTrainingTensor()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WK57IM-bUp6G","colab_type":"code","colab":{}},"source":["# 読みだしは基本こっちで\n","X_train = np.load(INPUT_DIR + \"/TrainingTensor.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xvbeoqf6UrtN","colab_type":"code","colab":{}},"source":["X_max = np.max(X_train)\n","\n","RTG = ReccurentTrainGenerator(InputTensor=X_train[:-100], batch_size=128, InputSteps=28, normalize_factor=X_max)\n","Validation_RTG = ReccurentTrainGenerator(X_train[:-100], batch_size=128, InputSteps=28, normalize_factor=X_max)\n","# トレーニングデータの一部をバリデーション用にする"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZvJwlKvU0QY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":633},"outputId":"ed6a06b3-4c66-4a32-ab89-2f34b466ebfa","executionInfo":{"status":"ok","timestamp":1592012618486,"user_tz":-540,"elapsed":51068,"user":{"displayName":"芋田総之","photoUrl":"","userId":"06994139843960550178"}}},"source":["from keras.callbacks import EarlyStopping \n"," \n","# Early-stopping: patienceはもう少し大きくとる？\n","early_stopping = EarlyStopping(patience=5, verbose=1) \n","\n","history = model.fit_generator(RTG, epochs=500, verbose=1, validation_data=Validation_RTG, callbacks=[early_stopping])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n","16/16 [==============================] - 4s 278ms/step - loss: 5.2515e-04 - accuracy: 0.6719 - val_loss: 3.5139e-08 - val_accuracy: 0.6721\n","Epoch 2/500\n","16/16 [==============================] - 3s 170ms/step - loss: 1.3748e-06 - accuracy: 0.6720 - val_loss: 3.5619e-08 - val_accuracy: 0.6717\n","Epoch 3/500\n","16/16 [==============================] - 3s 171ms/step - loss: 6.1179e-07 - accuracy: 0.6719 - val_loss: 3.5379e-08 - val_accuracy: 0.6718\n","Epoch 4/500\n","16/16 [==============================] - 3s 171ms/step - loss: 3.2946e-07 - accuracy: 0.6718 - val_loss: 3.5109e-08 - val_accuracy: 0.6719\n","Epoch 5/500\n","16/16 [==============================] - 3s 171ms/step - loss: 1.0600e-07 - accuracy: 0.6721 - val_loss: 3.5860e-08 - val_accuracy: 0.6719\n","Epoch 6/500\n","16/16 [==============================] - 3s 181ms/step - loss: 4.2529e-06 - accuracy: 0.6718 - val_loss: 3.5229e-08 - val_accuracy: 0.6719\n","Epoch 7/500\n","16/16 [==============================] - 3s 175ms/step - loss: 2.3316e-07 - accuracy: 0.6723 - val_loss: 3.5199e-08 - val_accuracy: 0.6719\n","Epoch 8/500\n","16/16 [==============================] - 3s 176ms/step - loss: 4.8319e-07 - accuracy: 0.6725 - val_loss: 3.5379e-08 - val_accuracy: 0.6716\n","Epoch 9/500\n","16/16 [==============================] - 3s 176ms/step - loss: 1.0930e-07 - accuracy: 0.6724 - val_loss: 3.5079e-08 - val_accuracy: 0.6722\n","Epoch 10/500\n","16/16 [==============================] - 3s 168ms/step - loss: 1.7133e-07 - accuracy: 0.6719 - val_loss: 3.4808e-08 - val_accuracy: 0.6722\n","Epoch 11/500\n","16/16 [==============================] - 3s 169ms/step - loss: 6.2450e-08 - accuracy: 0.6721 - val_loss: 3.5619e-08 - val_accuracy: 0.6721\n","Epoch 12/500\n","16/16 [==============================] - 3s 167ms/step - loss: 5.2905e-08 - accuracy: 0.6720 - val_loss: 3.4598e-08 - val_accuracy: 0.6726\n","Epoch 13/500\n","16/16 [==============================] - 3s 169ms/step - loss: 5.4576e-08 - accuracy: 0.6720 - val_loss: 3.5860e-08 - val_accuracy: 0.6719\n","Epoch 14/500\n","16/16 [==============================] - 3s 169ms/step - loss: 4.0691e-08 - accuracy: 0.6720 - val_loss: 3.5169e-08 - val_accuracy: 0.6719\n","Epoch 15/500\n","16/16 [==============================] - 3s 169ms/step - loss: 6.6957e-08 - accuracy: 0.6717 - val_loss: 3.5319e-08 - val_accuracy: 0.6719\n","Epoch 16/500\n","16/16 [==============================] - 3s 174ms/step - loss: 9.8043e-08 - accuracy: 0.6719 - val_loss: 3.5589e-08 - val_accuracy: 0.6720\n","Epoch 17/500\n","16/16 [==============================] - 3s 175ms/step - loss: 9.0630e-08 - accuracy: 0.6719 - val_loss: 3.5349e-08 - val_accuracy: 0.6722\n","Epoch 00017: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"65slhPeiU4VU","colab_type":"code","colab":{}},"source":["# 学習結果の保存\n","model_json_str = model.to_json()\n","open('LSTM_test_model.json', 'w').write(model_json_str)\n","model.save_weights('LSTM_test_weights.h5');"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbE6cHwMVQwp","colab_type":"code","colab":{}},"source":["\"\"\"\n","提出用データの入力作成関数\n","(これも結果をnp.saveで保存してしまえば使う必要なし)\n","\"\"\"\n","def GenerateInputForPrediction(num_samples=30490):\n","    TIMESTEPS = 28\n","\n","    train_generator = train_data_from_csv_generator(num=1) \n","    x_shape = next(train_generator).shape\n","    num_features = x_shape[1]\n","\n","    #X_test = np.zeros((num_samples, TIMESTEPS, num_features))\n","\n","    train_generator = train_data_from_csv_generator(num=num_samples)\n","\n","    for i, array in enumerate(train_generator):\n","        #X_test[i] = array[-TIMESTEPS:]\n","        yield array[-TIMESTEPS:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AxRnBIxTVk0Z","colab_type":"code","colab":{}},"source":["# テストデータ作成と保存\n","\n","# X_test_generator = GenerateInputForPrediction()\n","# X_test = np.zeros((30490, 28, 14))\n","# for i, array in enumerate(X_test_generator):\n","#     if i / 1000 == i //1000:\n","#         print(i)\n","#     X_test[i] = array \n","# np.save(INPUT_DIR + \"/test_data.npy\", X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gfYd3a5yVD71","colab_type":"code","colab":{}},"source":["# テストデータの読み出し\n","X_test = np.load(INPUT_DIR + \"/test_data.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GOziodsIWG23","colab_type":"code","colab":{}},"source":["prediction = model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"erRT0TiUWKL3","colab_type":"code","colab":{}},"source":["\"\"\"\n","予測結果のndarrayを提出形式のcsvに変換する関数\n","\"\"\"\n","\n","INPUT_DIR = \"./drive/My Drive/kaggle/m5-forecasting/datas\"\n","\n","def CreateSubmissionCSV(prediction, save_path=INPUT_DIR):\n","    # Create Prediction DataFrame\n","    prediction = np.rint(prediction)\n","    prediction = prediction.astype(\"int\")\n","    pred_df = pd.DataFrame(prediction.reshape(30490, 28))\n","\n","    # Get \"id\" columns (id の情報だけまとめたファイルを作成した方が軽いはず -> 未実装)\n","    stv = pd.read_csv(INPUT_DIR + \"/sales_train_validation.csv\")\n","    ste = pd.read_csv(INPUT_DIR + \"/sales_train_evaluation.csv\")\n","\n","    # Rename Index & Columns\n","    pred_df.index = list(ste[\"id\"])\n","    pred_df.columns = [f'F{i}' for i in range(1, 28 + 1)]\n","\n","    # Set index label \"id\"\n","    pred_df = pred_df.reset_index()\n","    pred_df = pred_df.rename(columns={\"index\": \"id\"})\n","    pred_df = pred_df.set_index(\"id\")\n","\n","    # Create \"Validation\" DataFrame\n","    validation_df = ste[[\"id\"] +  [\"d_\" + str(i) for i in range(1914, 1942)]]\n","\n","    # Rename columns & set index \"id\"\n","    validation_df = validation_df.set_index(\"id\")\n","    validation_df = validation_df.rename(columns={\"d_\" + str(i + 1913): \"F\" + str(i) for i in range(1, 29)})\n","    validation_df.index = stv[\"id\"]\n","\n","    # Create Submission DataFrame (shape = (60980, 28))\n","    submission_df = pd.concat([validation_df, pred_df], axis=0)\n","    submission_df.to_csv(save_path + \"/submission.csv\")\n","\n","    # For Debug\n","\n","    print(submission_df.shape)\n","    return submission_df\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u8VFL3XAWMkr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a383e9da-89fb-4889-99a3-4dcbe7b13968","executionInfo":{"status":"ok","timestamp":1592012748931,"user_tz":-540,"elapsed":15572,"user":{"displayName":"芋田総之","photoUrl":"","userId":"06994139843960550178"}}},"source":["X_test_max = np.max(X_test)\n","sub_df = CreateSubmissionCSV(prediction / X_test_max)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["(60980, 28)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K_V9NWimWh1u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":451},"outputId":"570a8ea3-61ea-4d56-a947-4907eb4a957c","executionInfo":{"status":"ok","timestamp":1592012764285,"user_tz":-540,"elapsed":468,"user":{"displayName":"芋田総之","photoUrl":"","userId":"06994139843960550178"}}},"source":["sub_df"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>F1</th>\n","      <th>F2</th>\n","      <th>F3</th>\n","      <th>F4</th>\n","      <th>F5</th>\n","      <th>F6</th>\n","      <th>F7</th>\n","      <th>F8</th>\n","      <th>F9</th>\n","      <th>F10</th>\n","      <th>F11</th>\n","      <th>F12</th>\n","      <th>F13</th>\n","      <th>F14</th>\n","      <th>F15</th>\n","      <th>F16</th>\n","      <th>F17</th>\n","      <th>F18</th>\n","      <th>F19</th>\n","      <th>F20</th>\n","      <th>F21</th>\n","      <th>F22</th>\n","      <th>F23</th>\n","      <th>F24</th>\n","      <th>F25</th>\n","      <th>F26</th>\n","      <th>F27</th>\n","      <th>F28</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>HOBBIES_1_001_CA_1_validation</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>HOBBIES_1_002_CA_1_validation</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>HOBBIES_1_003_CA_1_validation</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>HOBBIES_1_004_CA_1_validation</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>HOBBIES_1_005_CA_1_validation</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>FOODS_3_823_WI_3_evaluation</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>FOODS_3_824_WI_3_evaluation</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>9</td>\n","      <td>11</td>\n","      <td>13</td>\n","      <td>15</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>22</td>\n","      <td>22</td>\n","      <td>22</td>\n","      <td>22</td>\n","      <td>22</td>\n","      <td>23</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>FOODS_3_825_WI_3_evaluation</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>FOODS_3_826_WI_3_evaluation</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>FOODS_3_827_WI_3_evaluation</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>60980 rows × 28 columns</p>\n","</div>"],"text/plain":["                               F1  F2  F3  F4  F5  ...  F24  F25  F26  F27  F28\n","id                                                 ...                         \n","HOBBIES_1_001_CA_1_validation   0   0   0   2   0  ...    0    3    3    0    1\n","HOBBIES_1_002_CA_1_validation   0   1   0   0   0  ...    0    0    0    0    0\n","HOBBIES_1_003_CA_1_validation   0   0   1   1   0  ...    0    2    3    0    1\n","HOBBIES_1_004_CA_1_validation   0   0   1   2   4  ...    1    3    0    2    6\n","HOBBIES_1_005_CA_1_validation   1   0   2   3   1  ...    0    0    2    1    0\n","...                            ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...\n","FOODS_3_823_WI_3_evaluation     0   0   0   0   0  ...    0    0    2    4    0\n","FOODS_3_824_WI_3_evaluation     0   0   0   0   0  ...   22   22   22   23   23\n","FOODS_3_825_WI_3_evaluation     0   1   1   0   0  ...    4    4    4    4    4\n","FOODS_3_826_WI_3_evaluation     0   0   0   0   0  ...    5    6    7    7    8\n","FOODS_3_827_WI_3_evaluation     0   0   0   0   0  ...    1    0    1    2    0\n","\n","[60980 rows x 28 columns]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"kOLKm-lTWvJ3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}