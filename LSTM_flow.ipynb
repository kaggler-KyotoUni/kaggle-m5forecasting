{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_flow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Nj78KKCloC9B5DoydNH2qhxaO-EctSYd",
      "authorship_tag": "ABX9TyP49zEUcX7LIobaRyWUhImO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaggler-KyotoUni/kaggle-m5forecasting/blob/potedo_branch/LSTM_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlY0Lhaz8XQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Google Colab: ランタイムはTPU推奨\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import os \n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxUFjobHltme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66576f6e-2250-40bf-e0dd-90d8a9aa81eb"
      },
      "source": [
        "import tensorflow as tf \n",
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ActKZC7JSKo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIR = \"./drive/My Drive/kaggle/m5-forecasting/datas\"\n",
        "\n",
        "def read_data():\n",
        "    cal = pd.read_csv(f\"{INPUT_DIR}calendar.csv\")\n",
        "    stv = pd.read_csv(f\"{INPUT_DIR}sales_train_validation.csv\")\n",
        "    ste = pd.read_csv(f\"{INPUT_DIR}sales_train_evaluation.csv\")\n",
        "    ss = pd.read_csv(f\"{INPUT_DIR}sample_submission.csv\")\n",
        "    sellp = pd.read_csv(f\"{INPUT_DIR}sell_prices.csv\")\n",
        "    \n",
        "    return cal, stv, ste, ss, sellp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLnkGO4jSL-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    \"\"\"\n",
        "    目的：メモリサイズの削減\n",
        "    df: メモリを削減したい DataFrame (pandas.DataFrame)\n",
        "    verbose: 実行時に、メモリ削減の情報を出力するかどうかを指定(bool)\n",
        "\n",
        "    ■ 基本思想\n",
        "    【前提知識】\n",
        "    pandas で作成したデータフレームのうち数値データは、特に dtype を指定しない場合\n",
        "    int64 または float64 でデータを作成するので、\n",
        "    実際のデータよりもこの型が大きいと余計なメモリサイズを確保してしまう。\n",
        "\n",
        "    【処理内容】\n",
        "    (1) 入力された DataFrame の column の型を全てチェック(for loop)\n",
        "    (2) その型が大きい数値データ(int16~int64, float16~float64)ならば、\n",
        "        そのデータフレームの最大値・最小値をチェック。\n",
        "        現在処理中のカラムを、上記の最大値・最小値を表せる必要最低限の型に変換する。\n",
        "        int と floatに分けて処理。\n",
        "\n",
        "    ────────────────────────────────────────────────────────────────────────\n",
        "    【変更履歴】\n",
        "    2020/06/06:\n",
        "    ■ 35行目\n",
        "    ifのネストが深かったので、リファクタ。\n",
        "    Early Continueを入れたので可読性が向上(したはず)。\n",
        "\n",
        "    ■ 46行目・71行目(置き換え・追加)\n",
        "    説明変数(関数?)で置き換え。\n",
        "    columnのtypeがintであるか否かを判定する関数を噛ませている。\n",
        "    (返り値はbool値)\n",
        "    \"\"\"\n",
        "\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    # main loop    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "\n",
        "        if col_type not in numerics: \n",
        "            continue # Early continue if column type is not numeric\n",
        "        \n",
        "        c_min = df[col].min()\n",
        "        c_max = df[col].max()\n",
        "\n",
        "        if IsInt(col_type):\n",
        "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                df[col] = df[col].astype(np.int8)\n",
        "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                df[col] = df[col].astype(np.int16)\n",
        "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                df[col] = df[col].astype(np.int32)\n",
        "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                df[col] = df[col].astype(np.int64)  \n",
        "        else:\n",
        "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                df[col] = df[col].astype(np.float16)\n",
        "            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                df[col] = df[col].astype(np.float32)\n",
        "            else:\n",
        "                df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    if verbose: \n",
        "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def IsInt(col_type):\n",
        "    return str(col_type)[:3] == 'int'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX1MThqFSZQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_ITEMS = 30490\n",
        "DATA_PATH = \"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oao-RhcxSb1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "zipからデータ読み出し。\n",
        "展開しないのでディスク容量も圧迫せず済む\n",
        "\"\"\"\n",
        "def train_data_from_csv_generator(num=NUM_ITEMS, datapath=DATA_PATH):\n",
        "    with zipfile.ZipFile(datapath) as myzip:\n",
        "        filelist = myzip.namelist()\n",
        "\n",
        "        for i, f_name in enumerate(filelist):\n",
        "\n",
        "            if i == 0:\n",
        "                continue\n",
        "\n",
        "            if i > num:\n",
        "                break\n",
        "\n",
        "            df = pd.read_csv(myzip.extract(f_name))\n",
        "            df = reduce_mem_usage(df, verbose=False)\n",
        "            df = df.fillna(0)\n",
        "            array = df.values\n",
        "            yield array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWoS4GiQSe4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "ジェネレータを使わないときはこれを用いる。\n",
        "※ 全部使うとメモリに乗りきらないので非推奨\n",
        "\"\"\"\n",
        "def CreateTrainingData(timesteps=28, delay=1, num_samples=30490):\n",
        "    x_shape = next(train_data_from_csv_generator(num=1)).shape\n",
        "\n",
        "    train_generator = train_data_from_csv_generator(num=num_samples)\n",
        "\n",
        "    len_sequence, num_features = x_shape\n",
        "    sample_batchsize = len_sequence-timesteps+1 - delay\n",
        "\n",
        "    X_train = np.zeros((sample_batchsize*num_samples, timesteps, num_features))\n",
        "    Y_train = np.zeros((sample_batchsize*num_samples, timesteps, 1))\n",
        "\n",
        "    for i, array in enumerate(train_generator):\n",
        "        for j in range(sample_batchsize - timesteps + 1 -delay):\n",
        "            X_train[i*sample_batchsize+j, 0: timesteps] = array[j:j+timesteps]\n",
        "            Y_train[i*sample_batchsize+j, 0: timesteps] = array[j+timesteps:j+2*timesteps , num_features-1].reshape(timesteps, 1)\n",
        "\n",
        "    return X_train, Y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h4xfpLvShJo",
        "colab_type": "code",
        "outputId": "48367f4e-f250-4189-a4f0-ef4f5d3fe379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn import preprocessing, metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM,Dropout\n",
        "from keras.layers import RepeatVector,TimeDistributed, BatchNormalization\n",
        "from numpy import array\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "#import utils_paths\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "\"\"\"\n",
        "仮のモデル\n",
        "ハイパーパラメータを引数にとれるよう改造すべき？\n",
        "※ チューニングができるように\n",
        "\"\"\"\n",
        "def build_model():\n",
        "    timesteps = 28\n",
        "    delay = 1\n",
        "\n",
        "    n_out_seq_length = 28\n",
        "    num_y = 1\n",
        "\n",
        "    train_generator = train_data_from_csv_generator(num=1) \n",
        "    x_shape = next(train_generator).shape\n",
        "\n",
        "    len_sequence, num_features = x_shape\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(LSTM(128, activation='relu', batch_input_shape=(None, timesteps, num_features), return_sequences=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(RepeatVector(28))\n",
        "    model.add(LSTM(32, activation='relu', return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.1))  \n",
        "    model.add(TimeDistributed(Dense(delay, activation=\"relu\")))   # num_y means the shape of y,in some problem(like translate), it can be many.\n",
        "                                                #In that case, you should set the  activation= 'softmax'\n",
        "    \n",
        "    #RMSpropOptimizer = RMSprop(lr=0.001, clipvalue=0.5)\n",
        "    #model.compile(optimizer=RMSpropOptimizer, loss='mean_squared_error', metrics=[\"accuracy\"])\n",
        "    model.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G0fcqThTEhP",
        "colab_type": "code",
        "outputId": "5b731973-e3cf-442c-b779-015bd20a8868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128)               73216     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 28, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 28, 32)            20608     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 32)            128       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 28, 32)            0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 28, 1)             33        \n",
            "=================================================================\n",
            "Total params: 94,497\n",
            "Trainable params: 94,177\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw5dNX9qTHjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import Sequence\n",
        "from keras.models import Sequential\n",
        "\n",
        "\"\"\"\n",
        "model.fit_generatorを使うためのユーザ定義関数\n",
        "※ generator を使わないとメモリが死ぬ\n",
        "\"\"\"\n",
        "class ReccurentTrainGenerator(Sequence):\n",
        "    def _resetindices(self):\n",
        "        \"\"\"\n",
        "        バッチ生成用のインデックスをランダムに出力\n",
        "        \"\"\"\n",
        "        self.num_called = 0\n",
        "\n",
        "        all_idx = np.random.permutation(np.arange(self.num_batches))\n",
        "        remain_idx = np.random.choice(np.arange(self.num_batches),\n",
        "                                      size=(self.steps_per_epoch*self.batch_size-len(all_idx)),\n",
        "                                      replace=False)\n",
        "        \n",
        "        self.indices = np.hstack([all_idx, remain_idx]).reshape(self.steps_per_epoch, self.batch_size)\n",
        "\n",
        "    def __init__(self, InputTensor, batch_size, InputSteps=28, OutputSteps=28, delay=1, normalize_factor=None):\n",
        "        \"\"\"\n",
        "        【入力】\n",
        "        InputTensor: 入力データ(説明変数) データ数(\"HOBBIES_1_...\"などに対応) × データ点数(時系列方向のデータ数) × 特徴量数 のndarray\n",
        "                     ※ 正解ラベルも、この時系列データからとるのでこれだけ入力すればOK \n",
        "        batch_size: バッチサイズ(例えば、timestepが5として、時刻0~4までのデータ、1~5までのデータ、...、10~14までのデータ、\n",
        "                                をひとまとめにして1データとみなすとする。RNNの場合はこのサイズがバッチサイズに対応する。)\n",
        "        InputSteps: リカレント層に食わせるデータを、何ステップ前までのデータにするか\n",
        "        OutputSteps: リカレント層からの出力(予測ステップ数)の設定値\n",
        "        delay: 目的変数をどの程度遅らせるか？(予測ステップのスタート位置をどの程度後ろにずらすか)\n",
        "        normalize_factor: 正規化する際のスケーリングをどの程度にするか\n",
        "        \"\"\"\n",
        "        self.train_tensor = InputTensor \n",
        "\n",
        "        # 各種パラメータ\n",
        "        self.num_datas = InputTensor.shape[0]\n",
        "        self.len_sequence = InputTensor.shape[1]\n",
        "        self.num_features = InputTensor.shape[2]\n",
        "        self.batch_size = batch_size\n",
        "        self.input_steps = InputSteps\n",
        "        self.output_steps = OutputSteps\n",
        "        self.delay = delay\n",
        "\n",
        "        # 現在のエポックでバッチ生成の対象となっているデータ系列\n",
        "        self.now_data = InputTensor[0]\n",
        "\n",
        "        # 各データ系列に対し、バッチサイズいくつ作れるか計算するのに必要な値\n",
        "        self.len_requied_per_batch = InputSteps + (batch_size-1) + (delay-1) + OutputSteps # 訓練データと正解データを作るために必要なサイズ \n",
        "        self.num_batches = self.len_sequence - self.len_requied_per_batch + 1              # 作れるバッチの数\n",
        "\n",
        "        # 1エポック当たりのステップ数\n",
        "        self.steps_per_epoch = int(np.ceil(self.len_sequence / float(batch_size)))\n",
        "        \n",
        "        # バッチ生成用の乱数初期化\n",
        "        self._resetindices()\n",
        "\n",
        "        # データ取得用インデックス生成\n",
        "        self.data_idx = self._reset_dataset_indices(self.num_datas)\n",
        "        self.num_epoch = 0\n",
        "\n",
        "        self.normalize_factor = normalize_factor\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        1エポックあたりのステップ数をリターン\n",
        "        \"\"\"\n",
        "        return self.steps_per_epoch\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        データをバッチにまとめて出力\n",
        "        \"\"\"\n",
        "        indices_temp = self.indices[idx] # indices は (steps_per_epoch, batchsize)の array\n",
        "\n",
        "        batch_x = np.array([self.now_data[i:i+self.input_steps] for i in indices_temp])\n",
        "        batch_y = np.array([self.now_data[i+self.input_steps+(self.delay-1):i+self.input_steps+(self.delay-1)+self.output_steps, -1] for i in indices_temp]).reshape(self.batch_size, self.output_steps, 1)\n",
        "\n",
        "        if self.num_called == (self.steps_per_epoch-1):\n",
        "            self._resetindices()\n",
        "        else:\n",
        "            self.num_called += 1\n",
        "\n",
        "        if self.normalize_factor:\n",
        "            batch_x = batch_x / self.normalize_factor\n",
        "            batch_y = batch_y / self.normalize_factor\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"\n",
        "        Epoch 終了ごとにデータセットを入れ替える\n",
        "        (データセット：\"HOBBIES_1_...\"などに対応)\n",
        "        \"\"\"\n",
        "        if self.num_epoch == self.num_datas:\n",
        "            self.num_epoch = 0\n",
        "            self.data_idx = self._reset_dataset_indices(self.num_datas)\n",
        "        else:\n",
        "            self.num_epoch += 1\n",
        "        \n",
        "        next_data_idx = self.data_idx[self.num_epoch]\n",
        "        self.now_data = self.train_tensor[next_data_idx]\n",
        "\n",
        "\n",
        "    def _reset_dataset_indices(self, num_datas):\n",
        "        \"\"\"\n",
        "        Epoch毎に入れ替えるデータのインデックスをランダムにするためのメソッド\n",
        "        \"\"\"\n",
        "        return np.random.permutation(np.arange(num_datas))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb8ik8H2USIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Generatorに食わせるためのトレーニングデータ(ndarray)作成関数\n",
        "一度作って np.saveで保存すれば使う必要なし(この関数の実行は時間かかる)\n",
        "\"\"\"\n",
        "def CreateTrainingTensor(num=30490):\n",
        "    tg = train_data_from_csv_generator(num=1)\n",
        "    shape = next(tg).shape\n",
        "    X_train = np.zeros((num, shape[0], shape[1]))\n",
        "\n",
        "    train_generator = train_data_from_csv_generator(num=num)\n",
        "\n",
        "    for i, array in enumerate(train_generator):\n",
        "        if i/1000 == i//1000:\n",
        "            print(i)\n",
        "\n",
        "        X_train[i] = array\n",
        "\n",
        "    return X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quPs4QymUico",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 作成と保存の例\n",
        "# X_train = CreateTrainingTensor()\n",
        "# X_train = CreateTrainingTensor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK57IM-bUp6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 読みだしは基本こっちで\n",
        "X_train = np.load(INPUT_DIR + \"/TrainingTensor.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvbeoqf6UrtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_max = np.max(X_train)\n",
        "\n",
        "RTG = ReccurentTrainGenerator(InputTensor=X_train[:-100], batch_size=128, InputSteps=28, normalize_factor=X_max)\n",
        "Validation_RTG = ReccurentTrainGenerator(X_train[:-100], batch_size=128, InputSteps=28, normalize_factor=X_max)\n",
        "# トレーニングデータの一部をバリデーション用にする"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZvJwlKvU0QY",
        "colab_type": "code",
        "outputId": "ed6a06b3-4c66-4a32-ab89-2f34b466ebfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        " \n",
        "# Early-stopping: patienceはもう少し大きくとる？\n",
        "early_stopping = EarlyStopping(patience=5, verbose=1) \n",
        "\n",
        "history = model.fit_generator(RTG, epochs=500, verbose=1, validation_data=Validation_RTG, callbacks=[early_stopping])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 278ms/step - loss: 5.2515e-04 - accuracy: 0.6719 - val_loss: 3.5139e-08 - val_accuracy: 0.6721\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 1.3748e-06 - accuracy: 0.6720 - val_loss: 3.5619e-08 - val_accuracy: 0.6717\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 6.1179e-07 - accuracy: 0.6719 - val_loss: 3.5379e-08 - val_accuracy: 0.6718\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 3.2946e-07 - accuracy: 0.6718 - val_loss: 3.5109e-08 - val_accuracy: 0.6719\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 1.0600e-07 - accuracy: 0.6721 - val_loss: 3.5860e-08 - val_accuracy: 0.6719\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 181ms/step - loss: 4.2529e-06 - accuracy: 0.6718 - val_loss: 3.5229e-08 - val_accuracy: 0.6719\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 175ms/step - loss: 2.3316e-07 - accuracy: 0.6723 - val_loss: 3.5199e-08 - val_accuracy: 0.6719\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 176ms/step - loss: 4.8319e-07 - accuracy: 0.6725 - val_loss: 3.5379e-08 - val_accuracy: 0.6716\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 176ms/step - loss: 1.0930e-07 - accuracy: 0.6724 - val_loss: 3.5079e-08 - val_accuracy: 0.6722\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 1.7133e-07 - accuracy: 0.6719 - val_loss: 3.4808e-08 - val_accuracy: 0.6722\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 6.2450e-08 - accuracy: 0.6721 - val_loss: 3.5619e-08 - val_accuracy: 0.6721\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 5.2905e-08 - accuracy: 0.6720 - val_loss: 3.4598e-08 - val_accuracy: 0.6726\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 5.4576e-08 - accuracy: 0.6720 - val_loss: 3.5860e-08 - val_accuracy: 0.6719\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 4.0691e-08 - accuracy: 0.6720 - val_loss: 3.5169e-08 - val_accuracy: 0.6719\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 6.6957e-08 - accuracy: 0.6717 - val_loss: 3.5319e-08 - val_accuracy: 0.6719\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 174ms/step - loss: 9.8043e-08 - accuracy: 0.6719 - val_loss: 3.5589e-08 - val_accuracy: 0.6720\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 175ms/step - loss: 9.0630e-08 - accuracy: 0.6719 - val_loss: 3.5349e-08 - val_accuracy: 0.6722\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65slhPeiU4VU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習結果の保存\n",
        "model_json_str = model.to_json()\n",
        "open('LSTM_test_model.json', 'w').write(model_json_str)\n",
        "model.save_weights('LSTM_test_weights.h5');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbE6cHwMVQwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "提出用データの入力作成関数\n",
        "(これも結果をnp.saveで保存してしまえば使う必要なし)\n",
        "\"\"\"\n",
        "def GenerateInputForPrediction(num_samples=30490):\n",
        "    TIMESTEPS = 28\n",
        "\n",
        "    train_generator = train_data_from_csv_generator(num=1) \n",
        "    x_shape = next(train_generator).shape\n",
        "    num_features = x_shape[1]\n",
        "\n",
        "    #X_test = np.zeros((num_samples, TIMESTEPS, num_features))\n",
        "\n",
        "    train_generator = train_data_from_csv_generator(num=num_samples)\n",
        "\n",
        "    for i, array in enumerate(train_generator):\n",
        "        #X_test[i] = array[-TIMESTEPS:]\n",
        "        yield array[-TIMESTEPS:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxRnBIxTVk0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# テストデータ作成と保存\n",
        "\n",
        "# X_test_generator = GenerateInputForPrediction()\n",
        "# X_test = np.zeros((30490, 28, 14))\n",
        "# for i, array in enumerate(X_test_generator):\n",
        "#     if i / 1000 == i //1000:\n",
        "#         print(i)\n",
        "#     X_test[i] = array \n",
        "# np.save(INPUT_DIR + \"/test_data.npy\", X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfYd3a5yVD71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# テストデータの読み出し\n",
        "X_test = np.load(INPUT_DIR + \"/test_data.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOziodsIWG23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erRT0TiUWKL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "予測結果のndarrayを提出形式のcsvに変換する関数\n",
        "\"\"\"\n",
        "\n",
        "INPUT_DIR = \"./drive/My Drive/kaggle/m5-forecasting/datas\"\n",
        "\n",
        "def CreateSubmissionCSV(prediction, save_path=INPUT_DIR):\n",
        "    # Create Prediction DataFrame\n",
        "    prediction = np.rint(prediction)\n",
        "    prediction = prediction.astype(\"int\")\n",
        "    pred_df = pd.DataFrame(prediction.reshape(30490, 28))\n",
        "\n",
        "    # Get \"id\" columns (id の情報だけまとめたファイルを作成した方が軽いはず -> 未実装)\n",
        "    stv = pd.read_csv(INPUT_DIR + \"/sales_train_validation.csv\")\n",
        "    ste = pd.read_csv(INPUT_DIR + \"/sales_train_evaluation.csv\")\n",
        "\n",
        "    # Rename Index & Columns\n",
        "    pred_df.index = list(ste[\"id\"])\n",
        "    pred_df.columns = [f'F{i}' for i in range(1, 28 + 1)]\n",
        "\n",
        "    # Set index label \"id\"\n",
        "    pred_df = pred_df.reset_index()\n",
        "    pred_df = pred_df.rename(columns={\"index\": \"id\"})\n",
        "    pred_df = pred_df.set_index(\"id\")\n",
        "\n",
        "    # Create \"Validation\" DataFrame\n",
        "    validation_df = ste[[\"id\"] +  [\"d_\" + str(i) for i in range(1914, 1942)]]\n",
        "\n",
        "    # Rename columns & set index \"id\"\n",
        "    validation_df = validation_df.set_index(\"id\")\n",
        "    validation_df = validation_df.rename(columns={\"d_\" + str(i + 1913): \"F\" + str(i) for i in range(1, 29)})\n",
        "    validation_df.index = stv[\"id\"]\n",
        "\n",
        "    # Create Submission DataFrame (shape = (60980, 28))\n",
        "    submission_df = pd.concat([validation_df, pred_df], axis=0)\n",
        "    submission_df.to_csv(save_path + \"/submission.csv\")\n",
        "\n",
        "    # For Debug\n",
        "\n",
        "    print(submission_df.shape)\n",
        "    return submission_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8VFL3XAWMkr",
        "colab_type": "code",
        "outputId": "a383e9da-89fb-4889-99a3-4dcbe7b13968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test_max = np.max(X_test)\n",
        "sub_df = CreateSubmissionCSV(prediction / X_test_max)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60980, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_V9NWimWh1u",
        "colab_type": "code",
        "outputId": "570a8ea3-61ea-4d56-a947-4907eb4a957c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "sub_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "      <th>F20</th>\n",
              "      <th>F21</th>\n",
              "      <th>F22</th>\n",
              "      <th>F23</th>\n",
              "      <th>F24</th>\n",
              "      <th>F25</th>\n",
              "      <th>F26</th>\n",
              "      <th>F27</th>\n",
              "      <th>F28</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HOBBIES_1_001_CA_1_validation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HOBBIES_1_002_CA_1_validation</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HOBBIES_1_003_CA_1_validation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HOBBIES_1_004_CA_1_validation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HOBBIES_1_005_CA_1_validation</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOODS_3_823_WI_3_evaluation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOODS_3_824_WI_3_evaluation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOODS_3_825_WI_3_evaluation</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOODS_3_826_WI_3_evaluation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOODS_3_827_WI_3_evaluation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60980 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                               F1  F2  F3  F4  F5  ...  F24  F25  F26  F27  F28\n",
              "id                                                 ...                         \n",
              "HOBBIES_1_001_CA_1_validation   0   0   0   2   0  ...    0    3    3    0    1\n",
              "HOBBIES_1_002_CA_1_validation   0   1   0   0   0  ...    0    0    0    0    0\n",
              "HOBBIES_1_003_CA_1_validation   0   0   1   1   0  ...    0    2    3    0    1\n",
              "HOBBIES_1_004_CA_1_validation   0   0   1   2   4  ...    1    3    0    2    6\n",
              "HOBBIES_1_005_CA_1_validation   1   0   2   3   1  ...    0    0    2    1    0\n",
              "...                            ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...\n",
              "FOODS_3_823_WI_3_evaluation     0   0   0   0   0  ...    0    0    2    4    0\n",
              "FOODS_3_824_WI_3_evaluation     0   0   0   0   0  ...   22   22   22   23   23\n",
              "FOODS_3_825_WI_3_evaluation     0   1   1   0   0  ...    4    4    4    4    4\n",
              "FOODS_3_826_WI_3_evaluation     0   0   0   0   0  ...    5    6    7    7    8\n",
              "FOODS_3_827_WI_3_evaluation     0   0   0   0   0  ...    1    0    1    2    0\n",
              "\n",
              "[60980 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGDV9rruInNi",
        "colab_type": "text"
      },
      "source": [
        "# クロスバリデーションのためのテスト"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4rRER08Irl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データ読み出し\n",
        "X_train = np.load(INPUT_DIR + \"/TrainingTensor.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTFTDLF_IyLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=5)\n",
        "CV_gen = kfold.split(X_train[:1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9_sYZyGKLLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf5b5917-706d-4557-8de8-96cc4369dd33"
      },
      "source": [
        "next(CV_gen)[0].shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ykC58xKbeL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c24b5f4c-a92e-453f-b7d4-4ea8a52c94e7"
      },
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        "\n",
        "History = []\n",
        "\n",
        "# 1000サンプルでクロスバリデーションテスト\n",
        "for train_cv_idx, valid_cv_idx in kfold.split(X_train[:1000]):\n",
        "    X_CV_train_gen = ReccurentTrainGenerator(X_train[train_cv_idx], batch_size=128)\n",
        "    X_CV_valid_gen = ReccurentTrainGenerator(X_train[valid_cv_idx], batch_size=128)\n",
        "\n",
        "    model = build_model() #カテゴリごとのモデルを作る時も、同様にfor文内で再度モデルをビルドすればよいかもしれない。\n",
        " \n",
        "    # Early-stopping: patienceはもう少し大きくとる？\n",
        "    early_stopping = EarlyStopping(patience=5, verbose=1) \n",
        "\n",
        "    history = model.fit_generator(X_CV_train_gen, epochs=500, verbose=1, validation_data=X_CV_valid_gen, callbacks=[early_stopping])\n",
        "    History.append(history)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 272ms/step - loss: 0.4942 - accuracy: 0.5703 - val_loss: 12.5325 - val_accuracy: 0.4849\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3649 - accuracy: 0.6107 - val_loss: 0.3896 - val_accuracy: 0.6683\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3396 - accuracy: 0.6123 - val_loss: 553.0335 - val_accuracy: 0.6341\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3302 - accuracy: 0.6275 - val_loss: 0.7468 - val_accuracy: 0.6242\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3171 - accuracy: 0.6379 - val_loss: 0.3511 - val_accuracy: 0.6716\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3155 - accuracy: 0.6313 - val_loss: 0.7788 - val_accuracy: 0.6646\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3047 - accuracy: 0.6464 - val_loss: 0.3733 - val_accuracy: 0.6095\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3033 - accuracy: 0.6456 - val_loss: 0.3270 - val_accuracy: 0.6722\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3162 - accuracy: 0.6120 - val_loss: 0.3306 - val_accuracy: 0.6717\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3191 - accuracy: 0.6228 - val_loss: 0.2937 - val_accuracy: 0.6722\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.2881 - accuracy: 0.6493 - val_loss: 0.2907 - val_accuracy: 0.6718\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.2861 - accuracy: 0.6417 - val_loss: 0.2906 - val_accuracy: 0.6717\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3039 - accuracy: 0.6266 - val_loss: 0.3165 - val_accuracy: 0.6723\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.2767 - accuracy: 0.6461 - val_loss: 0.3175 - val_accuracy: 0.6721\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.2878 - accuracy: 0.6462 - val_loss: 0.3239 - val_accuracy: 0.6724\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.2746 - accuracy: 0.6397 - val_loss: 0.3256 - val_accuracy: 0.6724\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.2698 - accuracy: 0.6144 - val_loss: 0.3297 - val_accuracy: 0.6717\n",
            "Epoch 00017: early stopping\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 238ms/step - loss: 0.4938 - accuracy: 0.5815 - val_loss: 37.4200 - val_accuracy: 0.4073\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3447 - accuracy: 0.6248 - val_loss: 18.7204 - val_accuracy: 0.5436\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.3426 - accuracy: 0.6344 - val_loss: 0.3257 - val_accuracy: 0.6665\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.3200 - accuracy: 0.6344 - val_loss: 0.3257 - val_accuracy: 0.6719\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.3052 - accuracy: 0.6261 - val_loss: 0.3037 - val_accuracy: 0.6656\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.3158 - accuracy: 0.6252 - val_loss: 13.4833 - val_accuracy: 0.5428\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.3020 - accuracy: 0.6509 - val_loss: 0.3210 - val_accuracy: 0.6553\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.3027 - accuracy: 0.6310 - val_loss: 0.2378 - val_accuracy: 0.6716\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3181 - accuracy: 0.6162 - val_loss: 0.3275 - val_accuracy: 0.6721\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.3078 - accuracy: 0.6342 - val_loss: 0.3306 - val_accuracy: 0.6718\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3129 - accuracy: 0.6274 - val_loss: 0.3295 - val_accuracy: 0.6718\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.2957 - accuracy: 0.6276 - val_loss: 0.3270 - val_accuracy: 0.6722\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.2992 - accuracy: 0.6470 - val_loss: 0.3253 - val_accuracy: 0.6723\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 241ms/step - loss: 0.5968 - accuracy: 0.5722 - val_loss: 193.6136 - val_accuracy: 0.2846\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.4377 - accuracy: 0.6135 - val_loss: 0.4397 - val_accuracy: 0.6633\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3635 - accuracy: 0.6271 - val_loss: 0.4301 - val_accuracy: 0.6425\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3446 - accuracy: 0.6289 - val_loss: 2.9882 - val_accuracy: 0.4172\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.3531 - accuracy: 0.6282 - val_loss: 2.3598 - val_accuracy: 0.6220\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3485 - accuracy: 0.6341 - val_loss: 8.8077 - val_accuracy: 0.1938\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3381 - accuracy: 0.6336 - val_loss: 23.6127 - val_accuracy: 0.0369\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3262 - accuracy: 0.6463 - val_loss: 76.1985 - val_accuracy: 0.5404\n",
            "Epoch 00008: early stopping\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 236ms/step - loss: 1.1783 - accuracy: 0.5755 - val_loss: 62.7545 - val_accuracy: 0.4098\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.8475 - accuracy: 0.5982 - val_loss: 64.8589 - val_accuracy: 0.2253\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.6777 - accuracy: 0.6190 - val_loss: 8.0432 - val_accuracy: 0.5300\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.4745 - accuracy: 0.6285 - val_loss: 0.4657 - val_accuracy: 0.6605\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.4835 - accuracy: 0.6298 - val_loss: 6.2059 - val_accuracy: 0.5301\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.4552 - accuracy: 0.6354 - val_loss: 4.1453 - val_accuracy: 0.5451\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3899 - accuracy: 0.6399 - val_loss: 0.4650 - val_accuracy: 0.6122\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.4420 - accuracy: 0.6426 - val_loss: 2.5235 - val_accuracy: 0.5957\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.4065 - accuracy: 0.6393 - val_loss: 0.4000 - val_accuracy: 0.6065\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.3729 - accuracy: 0.6548 - val_loss: 0.3327 - val_accuracy: 0.6693\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 176ms/step - loss: 0.4087 - accuracy: 0.6496 - val_loss: 0.4267 - val_accuracy: 0.6502\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 176ms/step - loss: 0.3674 - accuracy: 0.6541 - val_loss: 0.2823 - val_accuracy: 0.5902\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3704 - accuracy: 0.6610 - val_loss: 0.3256 - val_accuracy: 0.6723\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.3682 - accuracy: 0.6536 - val_loss: 0.3378 - val_accuracy: 0.6700\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 176ms/step - loss: 0.3588 - accuracy: 0.6576 - val_loss: 0.4813 - val_accuracy: 0.6559\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 175ms/step - loss: 0.3387 - accuracy: 0.6615 - val_loss: 0.3198 - val_accuracy: 0.6723\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 174ms/step - loss: 0.3445 - accuracy: 0.6571 - val_loss: 0.3312 - val_accuracy: 0.6720\n",
            "Epoch 00017: early stopping\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 242ms/step - loss: 0.7951 - accuracy: 0.5710 - val_loss: 2.4229 - val_accuracy: 0.5153\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.5184 - accuracy: 0.5872 - val_loss: 0.3049 - val_accuracy: 0.6718\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.3990 - accuracy: 0.6088 - val_loss: 0.3651 - val_accuracy: 0.6653\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.3559 - accuracy: 0.6329 - val_loss: 0.3558 - val_accuracy: 0.6668\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3356 - accuracy: 0.6346 - val_loss: 0.2540 - val_accuracy: 0.6465\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3418 - accuracy: 0.6397 - val_loss: 0.2868 - val_accuracy: 0.6717\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3270 - accuracy: 0.6410 - val_loss: 0.3245 - val_accuracy: 0.6723\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.3285 - accuracy: 0.6350 - val_loss: 0.3554 - val_accuracy: 0.5458\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3206 - accuracy: 0.6438 - val_loss: 0.7719 - val_accuracy: 0.4229\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.3016 - accuracy: 0.6515 - val_loss: 4.3436 - val_accuracy: 0.0532\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raV2ubGxNPts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a9e80cee-bc20-4dd7-992b-806df8735879"
      },
      "source": [
        "History"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.callbacks.callbacks.History at 0x7f604d6e6c50>,\n",
              " <keras.callbacks.callbacks.History at 0x7f604d30ca20>,\n",
              " <keras.callbacks.callbacks.History at 0x7f604cf0a7f0>,\n",
              " <keras.callbacks.callbacks.History at 0x7f6043614dd8>,\n",
              " <keras.callbacks.callbacks.History at 0x7f604320ecf8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlIaRqSz2akk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30942bdd-b02e-4c6d-f635-f72ed10f02d2"
      },
      "source": [
        "History[0].history"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.57034737,\n",
              "  0.6107003,\n",
              "  0.6122872,\n",
              "  0.62749374,\n",
              "  0.637922,\n",
              "  0.63126045,\n",
              "  0.64643204,\n",
              "  0.64556015,\n",
              "  0.6120257,\n",
              "  0.62276787,\n",
              "  0.6492745,\n",
              "  0.6417411,\n",
              "  0.6265869,\n",
              "  0.6461007,\n",
              "  0.64624023,\n",
              "  0.6397182,\n",
              "  0.6143624],\n",
              " 'loss': [0.494242025539279,\n",
              "  0.36485074646770954,\n",
              "  0.3396125864237547,\n",
              "  0.3301929496228695,\n",
              "  0.31714816577732563,\n",
              "  0.31546652875840664,\n",
              "  0.3046710081398487,\n",
              "  0.3033412732183933,\n",
              "  0.3161908984184265,\n",
              "  0.3191160410642624,\n",
              "  0.2881226111203432,\n",
              "  0.28610892593860626,\n",
              "  0.30391204357147217,\n",
              "  0.27669483609497547,\n",
              "  0.28784034959971905,\n",
              "  0.2746207006275654,\n",
              "  0.26982585340738297],\n",
              " 'val_accuracy': [0.48486328125,\n",
              "  0.6683174967765808,\n",
              "  0.6340680718421936,\n",
              "  0.6241978406906128,\n",
              "  0.6715959906578064,\n",
              "  0.6645682454109192,\n",
              "  0.6095145344734192,\n",
              "  0.6722237467765808,\n",
              "  0.6717005968093872,\n",
              "  0.6721714735031128,\n",
              "  0.6718401312828064,\n",
              "  0.6717005968093872,\n",
              "  0.6723109483718872,\n",
              "  0.6720842719078064,\n",
              "  0.6724156141281128,\n",
              "  0.67236328125,\n",
              "  0.6716831922531128],\n",
              " 'val_loss': [12.532462120056152,\n",
              "  0.389602929353714,\n",
              "  553.0335083007812,\n",
              "  0.7467711567878723,\n",
              "  0.3511177599430084,\n",
              "  0.7788005471229553,\n",
              "  0.3732623755931854,\n",
              "  0.3270089328289032,\n",
              "  0.330556184053421,\n",
              "  0.29370221495628357,\n",
              "  0.29070037603378296,\n",
              "  0.290618360042572,\n",
              "  0.316451758146286,\n",
              "  0.3174732029438019,\n",
              "  0.3239397406578064,\n",
              "  0.3256138265132904,\n",
              "  0.32973018288612366]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmVGSoCB3rQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "21477faf-fa39-479e-d60e-0da6f48dd16d"
      },
      "source": [
        "History[0].history[\"val_loss\"]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12.532462120056152,\n",
              " 0.389602929353714,\n",
              " 553.0335083007812,\n",
              " 0.7467711567878723,\n",
              " 0.3511177599430084,\n",
              " 0.7788005471229553,\n",
              " 0.3732623755931854,\n",
              " 0.3270089328289032,\n",
              " 0.330556184053421,\n",
              " 0.29370221495628357,\n",
              " 0.29070037603378296,\n",
              " 0.290618360042572,\n",
              " 0.316451758146286,\n",
              " 0.3174732029438019,\n",
              " 0.3239397406578064,\n",
              " 0.3256138265132904,\n",
              " 0.32973018288612366]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiB0PI97xTOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(hyperparameters, iteration):\n",
        "    \"\"\"Objective function for grid and random search. Returns\n",
        "       the cross validation score from a set of hyperparameters.\"\"\"\n",
        "    # Number of estimators will be found using early stopping\n",
        "    if 'n_estimators' in hyperparameters.keys():\n",
        "        del hyperparameters['n_estimators']\n",
        "     # Perform n_folds cross validation\n",
        "    cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, \n",
        "                        early_stopping_rounds = 100, metrics = 'auc', seed = 42)\n",
        "    # results to retun\n",
        "    score = cv_results['auc-mean'][-1]\n",
        "    estimators = len(cv_results['auc-mean'])\n",
        "    hyperparameters['n_estimators'] = estimators \n",
        "    return [score, hyperparameters, iteration]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unbawZ29y16t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def objective(hyperparameters, X_train):\n",
        "    \"\"\"\n",
        "    hyperparameters:\n",
        "    LSTM units\n",
        "    LSTM activation\n",
        "\n",
        "    # ハイパーパラメータは、build_modelの引数に渡す。\n",
        "    後ほど実装。(今は引数なし)\n",
        "\n",
        "    \"\"\"\n",
        "    batch_size = 128\n",
        "    epochs = 500\n",
        "\n",
        "    \n",
        "    kfold = KFold(n_splits=5)\n",
        "    History = []\n",
        "\n",
        "    for train_cv_idx, valid_cv_idx in kfold.split(X_train):\n",
        "\n",
        "        X_CV_train_gen = ReccurentTrainGenerator(X_train[train_cv_idx], batch_size=batch_size)\n",
        "        X_CV_valid_gen = ReccurentTrainGenerator(X_train[valid_cv_idx], batch_size=batch_size)\n",
        "\n",
        "        model = build_model() # 引数にハイパーパラメータを入れられるようにする\n",
        "\n",
        "        early_stopping = EarlyStopping(patience=5, verbose=1) \n",
        "\n",
        "        history = model.fit_generator(X_CV_train_gen, epochs=epochs, verbose=1, validation_data=X_CV_valid_gen, callbacks=[early_stopping])\n",
        "        History.append(history)\n",
        "\n",
        "    scores = [History[i].history[\"val_loss\"][-1] for i in range(len(History))]\n",
        "    mean_score = np.mean(scores)\n",
        "\n",
        "    return mean_score\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwvdoOdd30Z1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae2dfadc-076c-466f-8484-2844b611ccf4"
      },
      "source": [
        "mean_score = objective(\"hyperparameters\", X_train[:1000])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 245ms/step - loss: 0.4873 - accuracy: 0.5721 - val_loss: 2.4192 - val_accuracy: 0.6165\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.3866 - accuracy: 0.5984 - val_loss: 6.4519 - val_accuracy: 0.5566\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.3658 - accuracy: 0.6076 - val_loss: 0.3284 - val_accuracy: 0.6708\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 174ms/step - loss: 0.3135 - accuracy: 0.6369 - val_loss: 13.5748 - val_accuracy: 0.6592\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3102 - accuracy: 0.6405 - val_loss: 9.2438 - val_accuracy: 0.6471\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 172ms/step - loss: 0.3023 - accuracy: 0.6500 - val_loss: 0.3998 - val_accuracy: 0.6643\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 174ms/step - loss: 0.3018 - accuracy: 0.6486 - val_loss: 13.7566 - val_accuracy: 0.2931\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.2825 - accuracy: 0.6483 - val_loss: 21.2023 - val_accuracy: 0.2047\n",
            "Epoch 00008: early stopping\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 264ms/step - loss: 1.1919 - accuracy: 0.5670 - val_loss: 0.3295 - val_accuracy: 0.6718\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.8209 - accuracy: 0.5833 - val_loss: 36.9045 - val_accuracy: 0.1251\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.5539 - accuracy: 0.6102 - val_loss: 1.0206 - val_accuracy: 0.6170\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.4308 - accuracy: 0.6218 - val_loss: 0.6525 - val_accuracy: 0.5869\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.4866 - accuracy: 0.6164 - val_loss: 33.6981 - val_accuracy: 0.4435\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 172ms/step - loss: 0.4411 - accuracy: 0.6435 - val_loss: 0.3271 - val_accuracy: 0.6678\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.4043 - accuracy: 0.6451 - val_loss: 0.3574 - val_accuracy: 0.6474\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.4022 - accuracy: 0.6244 - val_loss: 0.3232 - val_accuracy: 0.6718\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3489 - accuracy: 0.6450 - val_loss: 0.3204 - val_accuracy: 0.6720\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.3185 - accuracy: 0.6573 - val_loss: 0.3148 - val_accuracy: 0.6726\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3233 - accuracy: 0.6564 - val_loss: 0.3195 - val_accuracy: 0.6721\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3115 - accuracy: 0.6606 - val_loss: 0.3217 - val_accuracy: 0.6719\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 172ms/step - loss: 0.3223 - accuracy: 0.6505 - val_loss: 0.3163 - val_accuracy: 0.6721\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3144 - accuracy: 0.6517 - val_loss: 1.4429 - val_accuracy: 0.5017\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3057 - accuracy: 0.6572 - val_loss: 0.4482 - val_accuracy: 0.6137\n",
            "Epoch 00015: early stopping\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 261ms/step - loss: 0.9952 - accuracy: 0.5500 - val_loss: 500.5342 - val_accuracy: 0.3443\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.6693 - accuracy: 0.5863 - val_loss: 22.1057 - val_accuracy: 0.5311\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.4965 - accuracy: 0.6122 - val_loss: 0.5957 - val_accuracy: 0.6056\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.4349 - accuracy: 0.6257 - val_loss: 315.3819 - val_accuracy: 0.4254\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.5016 - accuracy: 0.6135 - val_loss: 0.3287 - val_accuracy: 0.6720\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3955 - accuracy: 0.6299 - val_loss: 0.3215 - val_accuracy: 0.6624\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3667 - accuracy: 0.6319 - val_loss: 0.3651 - val_accuracy: 0.6585\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 172ms/step - loss: 0.3616 - accuracy: 0.6368 - val_loss: 0.3283 - val_accuracy: 0.6635\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3632 - accuracy: 0.6293 - val_loss: 0.3304 - val_accuracy: 0.6662\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3573 - accuracy: 0.6494 - val_loss: 0.3275 - val_accuracy: 0.6719\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3508 - accuracy: 0.6519 - val_loss: 0.3304 - val_accuracy: 0.6302\n",
            "Epoch 00011: early stopping\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 245ms/step - loss: 0.5601 - accuracy: 0.5679 - val_loss: 40.3292 - val_accuracy: 0.5133\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.4548 - accuracy: 0.5811 - val_loss: 10.5865 - val_accuracy: 0.0778\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.4031 - accuracy: 0.6128 - val_loss: 1.4918 - val_accuracy: 0.4012\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.3739 - accuracy: 0.6205 - val_loss: 1.6726 - val_accuracy: 0.6232\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.3716 - accuracy: 0.6041 - val_loss: 16.6399 - val_accuracy: 0.5980\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 172ms/step - loss: 0.3443 - accuracy: 0.6319 - val_loss: 0.3256 - val_accuracy: 0.6722\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.3377 - accuracy: 0.6265 - val_loss: 0.3329 - val_accuracy: 0.6718\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 180ms/step - loss: 0.3114 - accuracy: 0.6503 - val_loss: 0.3276 - val_accuracy: 0.6722\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 174ms/step - loss: 0.3053 - accuracy: 0.6507 - val_loss: 0.3265 - val_accuracy: 0.6725\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.3185 - accuracy: 0.6578 - val_loss: 214.8456 - val_accuracy: 0.5856\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.3283 - accuracy: 0.6610 - val_loss: 0.7390 - val_accuracy: 0.6673\n",
            "Epoch 00011: early stopping\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 244ms/step - loss: 0.5973 - accuracy: 0.6044 - val_loss: 41.1299 - val_accuracy: 0.4581\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.4594 - accuracy: 0.6154 - val_loss: 0.3304 - val_accuracy: 0.6720\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3912 - accuracy: 0.6417 - val_loss: 0.3323 - val_accuracy: 0.6719\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3737 - accuracy: 0.6468 - val_loss: 0.3259 - val_accuracy: 0.6721\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.3368 - accuracy: 0.6501 - val_loss: 0.3299 - val_accuracy: 0.6714\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 174ms/step - loss: 0.3583 - accuracy: 0.6484 - val_loss: 0.3245 - val_accuracy: 0.6719\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 176ms/step - loss: 0.3423 - accuracy: 0.6483 - val_loss: 12.3522 - val_accuracy: 0.4011\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 177ms/step - loss: 0.3333 - accuracy: 0.6451 - val_loss: 0.4280 - val_accuracy: 0.6651\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 174ms/step - loss: 0.3309 - accuracy: 0.6418 - val_loss: 0.2893 - val_accuracy: 0.6718\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.2965 - accuracy: 0.6458 - val_loss: 1.0327 - val_accuracy: 0.2992\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.3042 - accuracy: 0.6476 - val_loss: 1.1348 - val_accuracy: 0.2504\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.2980 - accuracy: 0.6323 - val_loss: 2.9355 - val_accuracy: 0.1555\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.3072 - accuracy: 0.6238 - val_loss: 5.5749 - val_accuracy: 0.1591\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.3084 - accuracy: 0.6249 - val_loss: 3.8773 - val_accuracy: 0.1847\n",
            "Epoch 00014: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI2lFd4N5gBO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aeaaf8b7-a139-47bc-ca97-2b8ac034346d"
      },
      "source": [
        "mean_score"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.3194280624389645"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSaX0grCN4Hl",
        "colab_type": "text"
      },
      "source": [
        "# Loss を自作する(RMSSEをLossとして学習する)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Imw2Ac4N1-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}