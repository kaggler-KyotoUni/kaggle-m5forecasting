{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureCreation_For_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1mJs9d9G9vQ866wPPFiFdcPvpto6UnD1I",
      "authorship_tag": "ABX9TyOdYiQNVAGzEnpQBNSR2mbd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaggler-KyotoUni/kaggle-m5forecasting/blob/potedo_branch/FeatureCreation_For_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq7j6-Ba649p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import os \n",
        "from itertools import cycle\n",
        "color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7YD3eY4AvAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIR = \"./drive/My Drive/kaggle/m5-forecasting/datas\"\n",
        "\n",
        "def read_data():\n",
        "    cal = pd.read_csv(f\"{INPUT_DIR}/calendar.csv\")\n",
        "    stv = pd.read_csv(f\"{INPUT_DIR}/sales_train_validation.csv\")\n",
        "    ste = pd.read_csv(f\"{INPUT_DIR}/sales_train_evaluation.csv\")\n",
        "    ss = pd.read_csv(f\"{INPUT_DIR}/sample_submission.csv\")\n",
        "    sellp = pd.read_csv(f\"{INPUT_DIR}/sell_prices.csv\")\n",
        "    \n",
        "    return cal, stv, ste, ss, sellp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C2uBW94Awel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    \"\"\"\n",
        "    目的：メモリサイズの削減\n",
        "    df: メモリを削減したい DataFrame (pandas.DataFrame)\n",
        "    verbose: 実行時に、メモリ削減の情報を出力するかどうかを指定(bool)\n",
        "\n",
        "    ■ 基本思想\n",
        "    【前提知識】\n",
        "    pandas で作成したデータフレームのうち数値データは、特に dtype を指定しない場合\n",
        "    int64 または float64 でデータを作成するので、\n",
        "    実際のデータよりもこの型が大きいと余計なメモリサイズを確保してしまう。\n",
        "\n",
        "    【処理内容】\n",
        "    (1) 入力された DataFrame の column の型を全てチェック(for loop)\n",
        "    (2) その型が大きい数値データ(int16~int64, float16~float64)ならば、\n",
        "        そのデータフレームの最大値・最小値をチェック。\n",
        "        現在処理中のカラムを、上記の最大値・最小値を表せる必要最低限の型に変換する。\n",
        "        int と floatに分けて処理。\n",
        "\n",
        "    ────────────────────────────────────────────────────────────────────────\n",
        "    【変更履歴】\n",
        "    2020/06/06:\n",
        "    ■ 35行目\n",
        "    ifのネストが深かったので、リファクタ。\n",
        "    Early Continueを入れたので可読性が向上(したはず)。\n",
        "\n",
        "    ■ 46行目・71行目(置き換え・追加)\n",
        "    説明変数(関数?)で置き換え。\n",
        "    columnのtypeがintであるか否かを判定する関数を噛ませている。\n",
        "    (返り値はbool値)\n",
        "    \"\"\"\n",
        "\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    # main loop    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "\n",
        "        if col_type not in numerics: \n",
        "            continue # Early continue if column type is not numeric\n",
        "        \n",
        "        c_min = df[col].min()\n",
        "        c_max = df[col].max()\n",
        "\n",
        "        if IsInt(col_type):\n",
        "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                df[col] = df[col].astype(np.int8)\n",
        "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                df[col] = df[col].astype(np.int16)\n",
        "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                df[col] = df[col].astype(np.int32)\n",
        "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                df[col] = df[col].astype(np.int64)  \n",
        "        else:\n",
        "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                df[col] = df[col].astype(np.float16)\n",
        "            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                df[col] = df[col].astype(np.float32)\n",
        "            else:\n",
        "                df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    if verbose: \n",
        "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def IsInt(col_type):\n",
        "    return str(col_type)[:3] == 'int'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxiWVbUQBAyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cal, stv, ste, ss, sellp = read_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARN1fnaNBCQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "605e9966-fddc-4167-e271-f9b8a976108e"
      },
      "source": [
        "dfs = [cal, stv, ste, ss, sellp]\n",
        "for df in dfs:\n",
        "    df = reduce_mem_usage(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
            "Mem. usage decreased to 95.00 Mb (78.7% reduction)\n",
            "Mem. usage decreased to 96.13 Mb (78.8% reduction)\n",
            "Mem. usage decreased to  2.09 Mb (84.5% reduction)\n",
            "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGPgg7SVgdko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_sales = ste\n",
        "calendar = cal\n",
        "sell_prices = pd.read_csv(f\"{INPUT_DIR}/sell_prices.csv\")\n",
        "# pd.pivot() を使うときに、メモリサイズを削減したものだとエラーになる模様。なので再度読み直し。対応策はないのか？\n",
        "submission_file = ss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ76dAGqhkZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform(data):\n",
        "    \n",
        "    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
        "    for feature in nan_features:\n",
        "        data[feature].fillna('unknown', inplace = True)\n",
        "        \n",
        "    cat = ['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']\n",
        "    for feature in cat:\n",
        "        data[feature] = pd.get_dummies(data[feature])\n",
        "    \n",
        "    return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1COf0qoixLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "days = range(1, 1970)\n",
        "time_series_columns = [f'd_{i}' for i in days]\n",
        "\n",
        "event_snap_columns = ['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']\n",
        "\n",
        "transfer_cal = pd.DataFrame(calendar[event_snap_columns].values.T,\n",
        "                            index=event_snap_columns,\n",
        "                            columns=time_series_columns)\n",
        "transfer_cal = transfer_cal.fillna(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwD7OAXMixq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "8d77e40c-93ba-4b55-f7a8-5afc539cc94b"
      },
      "source": [
        "\"\"\"\n",
        "※注意※\n",
        "\n",
        "ここで、使用メモリを減らすためにcalenderの範囲が減らされている。\n",
        "増やすと単純に精度向上が可能？\n",
        "-> もしフルに使うと、ローカルのメモリが死ぬ\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "calendar['date'] = pd.to_datetime(calendar['date'])\n",
        "#calendar = calendar[calendar['date']>= '2014-3-15']  #reduce memory\n",
        "#calendar = calendar[calendar[\"date\"] <= \"2016-05-22\"] #eliminate evaluate date\n",
        "#使うデータを少なくします -> TrainingDataのステップ数が800になるよう設定\n",
        "calendar= transform(calendar)\n",
        "# Attempts to convert events into time series data.\n",
        "transfer_cal = pd.DataFrame(calendar[event_snap_columns + [\"date\", \"d\"]].values.T,\n",
        "                            index=event_snap_columns + [\"date\", \"d\"])\n",
        "transfer_cal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>1929</th>\n",
              "      <th>1930</th>\n",
              "      <th>1931</th>\n",
              "      <th>1932</th>\n",
              "      <th>1933</th>\n",
              "      <th>1934</th>\n",
              "      <th>1935</th>\n",
              "      <th>1936</th>\n",
              "      <th>1937</th>\n",
              "      <th>1938</th>\n",
              "      <th>1939</th>\n",
              "      <th>1940</th>\n",
              "      <th>1941</th>\n",
              "      <th>1942</th>\n",
              "      <th>1943</th>\n",
              "      <th>1944</th>\n",
              "      <th>1945</th>\n",
              "      <th>1946</th>\n",
              "      <th>1947</th>\n",
              "      <th>1948</th>\n",
              "      <th>1949</th>\n",
              "      <th>1950</th>\n",
              "      <th>1951</th>\n",
              "      <th>1952</th>\n",
              "      <th>1953</th>\n",
              "      <th>1954</th>\n",
              "      <th>1955</th>\n",
              "      <th>1956</th>\n",
              "      <th>1957</th>\n",
              "      <th>1958</th>\n",
              "      <th>1959</th>\n",
              "      <th>1960</th>\n",
              "      <th>1961</th>\n",
              "      <th>1962</th>\n",
              "      <th>1963</th>\n",
              "      <th>1964</th>\n",
              "      <th>1965</th>\n",
              "      <th>1966</th>\n",
              "      <th>1967</th>\n",
              "      <th>1968</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>event_name_1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>event_type_1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>event_name_2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>event_type_2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>snap_CA</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>snap_TX</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>snap_WI</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>2011-01-29 00:00:00</td>\n",
              "      <td>2011-01-30 00:00:00</td>\n",
              "      <td>2011-01-31 00:00:00</td>\n",
              "      <td>2011-02-01 00:00:00</td>\n",
              "      <td>2011-02-02 00:00:00</td>\n",
              "      <td>2011-02-03 00:00:00</td>\n",
              "      <td>2011-02-04 00:00:00</td>\n",
              "      <td>2011-02-05 00:00:00</td>\n",
              "      <td>2011-02-06 00:00:00</td>\n",
              "      <td>2011-02-07 00:00:00</td>\n",
              "      <td>2011-02-08 00:00:00</td>\n",
              "      <td>2011-02-09 00:00:00</td>\n",
              "      <td>2011-02-10 00:00:00</td>\n",
              "      <td>2011-02-11 00:00:00</td>\n",
              "      <td>2011-02-12 00:00:00</td>\n",
              "      <td>2011-02-13 00:00:00</td>\n",
              "      <td>2011-02-14 00:00:00</td>\n",
              "      <td>2011-02-15 00:00:00</td>\n",
              "      <td>2011-02-16 00:00:00</td>\n",
              "      <td>2011-02-17 00:00:00</td>\n",
              "      <td>2011-02-18 00:00:00</td>\n",
              "      <td>2011-02-19 00:00:00</td>\n",
              "      <td>2011-02-20 00:00:00</td>\n",
              "      <td>2011-02-21 00:00:00</td>\n",
              "      <td>2011-02-22 00:00:00</td>\n",
              "      <td>2011-02-23 00:00:00</td>\n",
              "      <td>2011-02-24 00:00:00</td>\n",
              "      <td>2011-02-25 00:00:00</td>\n",
              "      <td>2011-02-26 00:00:00</td>\n",
              "      <td>2011-02-27 00:00:00</td>\n",
              "      <td>2011-02-28 00:00:00</td>\n",
              "      <td>2011-03-01 00:00:00</td>\n",
              "      <td>2011-03-02 00:00:00</td>\n",
              "      <td>2011-03-03 00:00:00</td>\n",
              "      <td>2011-03-04 00:00:00</td>\n",
              "      <td>2011-03-05 00:00:00</td>\n",
              "      <td>2011-03-06 00:00:00</td>\n",
              "      <td>2011-03-07 00:00:00</td>\n",
              "      <td>2011-03-08 00:00:00</td>\n",
              "      <td>2011-03-09 00:00:00</td>\n",
              "      <td>...</td>\n",
              "      <td>2016-05-11 00:00:00</td>\n",
              "      <td>2016-05-12 00:00:00</td>\n",
              "      <td>2016-05-13 00:00:00</td>\n",
              "      <td>2016-05-14 00:00:00</td>\n",
              "      <td>2016-05-15 00:00:00</td>\n",
              "      <td>2016-05-16 00:00:00</td>\n",
              "      <td>2016-05-17 00:00:00</td>\n",
              "      <td>2016-05-18 00:00:00</td>\n",
              "      <td>2016-05-19 00:00:00</td>\n",
              "      <td>2016-05-20 00:00:00</td>\n",
              "      <td>2016-05-21 00:00:00</td>\n",
              "      <td>2016-05-22 00:00:00</td>\n",
              "      <td>2016-05-23 00:00:00</td>\n",
              "      <td>2016-05-24 00:00:00</td>\n",
              "      <td>2016-05-25 00:00:00</td>\n",
              "      <td>2016-05-26 00:00:00</td>\n",
              "      <td>2016-05-27 00:00:00</td>\n",
              "      <td>2016-05-28 00:00:00</td>\n",
              "      <td>2016-05-29 00:00:00</td>\n",
              "      <td>2016-05-30 00:00:00</td>\n",
              "      <td>2016-05-31 00:00:00</td>\n",
              "      <td>2016-06-01 00:00:00</td>\n",
              "      <td>2016-06-02 00:00:00</td>\n",
              "      <td>2016-06-03 00:00:00</td>\n",
              "      <td>2016-06-04 00:00:00</td>\n",
              "      <td>2016-06-05 00:00:00</td>\n",
              "      <td>2016-06-06 00:00:00</td>\n",
              "      <td>2016-06-07 00:00:00</td>\n",
              "      <td>2016-06-08 00:00:00</td>\n",
              "      <td>2016-06-09 00:00:00</td>\n",
              "      <td>2016-06-10 00:00:00</td>\n",
              "      <td>2016-06-11 00:00:00</td>\n",
              "      <td>2016-06-12 00:00:00</td>\n",
              "      <td>2016-06-13 00:00:00</td>\n",
              "      <td>2016-06-14 00:00:00</td>\n",
              "      <td>2016-06-15 00:00:00</td>\n",
              "      <td>2016-06-16 00:00:00</td>\n",
              "      <td>2016-06-17 00:00:00</td>\n",
              "      <td>2016-06-18 00:00:00</td>\n",
              "      <td>2016-06-19 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d</th>\n",
              "      <td>d_1</td>\n",
              "      <td>d_2</td>\n",
              "      <td>d_3</td>\n",
              "      <td>d_4</td>\n",
              "      <td>d_5</td>\n",
              "      <td>d_6</td>\n",
              "      <td>d_7</td>\n",
              "      <td>d_8</td>\n",
              "      <td>d_9</td>\n",
              "      <td>d_10</td>\n",
              "      <td>d_11</td>\n",
              "      <td>d_12</td>\n",
              "      <td>d_13</td>\n",
              "      <td>d_14</td>\n",
              "      <td>d_15</td>\n",
              "      <td>d_16</td>\n",
              "      <td>d_17</td>\n",
              "      <td>d_18</td>\n",
              "      <td>d_19</td>\n",
              "      <td>d_20</td>\n",
              "      <td>d_21</td>\n",
              "      <td>d_22</td>\n",
              "      <td>d_23</td>\n",
              "      <td>d_24</td>\n",
              "      <td>d_25</td>\n",
              "      <td>d_26</td>\n",
              "      <td>d_27</td>\n",
              "      <td>d_28</td>\n",
              "      <td>d_29</td>\n",
              "      <td>d_30</td>\n",
              "      <td>d_31</td>\n",
              "      <td>d_32</td>\n",
              "      <td>d_33</td>\n",
              "      <td>d_34</td>\n",
              "      <td>d_35</td>\n",
              "      <td>d_36</td>\n",
              "      <td>d_37</td>\n",
              "      <td>d_38</td>\n",
              "      <td>d_39</td>\n",
              "      <td>d_40</td>\n",
              "      <td>...</td>\n",
              "      <td>d_1930</td>\n",
              "      <td>d_1931</td>\n",
              "      <td>d_1932</td>\n",
              "      <td>d_1933</td>\n",
              "      <td>d_1934</td>\n",
              "      <td>d_1935</td>\n",
              "      <td>d_1936</td>\n",
              "      <td>d_1937</td>\n",
              "      <td>d_1938</td>\n",
              "      <td>d_1939</td>\n",
              "      <td>d_1940</td>\n",
              "      <td>d_1941</td>\n",
              "      <td>d_1942</td>\n",
              "      <td>d_1943</td>\n",
              "      <td>d_1944</td>\n",
              "      <td>d_1945</td>\n",
              "      <td>d_1946</td>\n",
              "      <td>d_1947</td>\n",
              "      <td>d_1948</td>\n",
              "      <td>d_1949</td>\n",
              "      <td>d_1950</td>\n",
              "      <td>d_1951</td>\n",
              "      <td>d_1952</td>\n",
              "      <td>d_1953</td>\n",
              "      <td>d_1954</td>\n",
              "      <td>d_1955</td>\n",
              "      <td>d_1956</td>\n",
              "      <td>d_1957</td>\n",
              "      <td>d_1958</td>\n",
              "      <td>d_1959</td>\n",
              "      <td>d_1960</td>\n",
              "      <td>d_1961</td>\n",
              "      <td>d_1962</td>\n",
              "      <td>d_1963</td>\n",
              "      <td>d_1964</td>\n",
              "      <td>d_1965</td>\n",
              "      <td>d_1966</td>\n",
              "      <td>d_1967</td>\n",
              "      <td>d_1968</td>\n",
              "      <td>d_1969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9 rows × 1969 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                0  ...                 1968\n",
              "event_name_1                    0  ...                    0\n",
              "event_type_1                    0  ...                    0\n",
              "event_name_2                    0  ...                    0\n",
              "event_type_2                    0  ...                    1\n",
              "snap_CA                         1  ...                    1\n",
              "snap_TX                         1  ...                    1\n",
              "snap_WI                         1  ...                    1\n",
              "date          2011-01-29 00:00:00  ...  2016-06-19 00:00:00\n",
              "d                             d_1  ...               d_1969\n",
              "\n",
              "[9 rows x 1969 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i7Dh9_Di1Kc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "4d77754a-a3bb-415a-ab2d-fcab53c166d5"
      },
      "source": [
        "calendar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>weekday</th>\n",
              "      <th>wday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>d</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-30</td>\n",
              "      <td>11101</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-31</td>\n",
              "      <td>11101</td>\n",
              "      <td>Monday</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-02-01</td>\n",
              "      <td>11101</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-02-02</td>\n",
              "      <td>11101</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>2016-06-15</td>\n",
              "      <td>11620</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>d_1965</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1965</th>\n",
              "      <td>2016-06-16</td>\n",
              "      <td>11620</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>d_1966</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>2016-06-17</td>\n",
              "      <td>11620</td>\n",
              "      <td>Friday</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>d_1967</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1967</th>\n",
              "      <td>2016-06-18</td>\n",
              "      <td>11621</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>d_1968</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1968</th>\n",
              "      <td>2016-06-19</td>\n",
              "      <td>11621</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>d_1969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1969 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  wm_yr_wk    weekday  ...  snap_CA  snap_TX  snap_WI\n",
              "0    2011-01-29     11101   Saturday  ...        1        1        1\n",
              "1    2011-01-30     11101     Sunday  ...        1        1        1\n",
              "2    2011-01-31     11101     Monday  ...        1        1        1\n",
              "3    2011-02-01     11101    Tuesday  ...        0        0        1\n",
              "4    2011-02-02     11101  Wednesday  ...        0        1        0\n",
              "...         ...       ...        ...  ...      ...      ...      ...\n",
              "1964 2016-06-15     11620  Wednesday  ...        1        0        0\n",
              "1965 2016-06-16     11620   Thursday  ...        1        1        1\n",
              "1966 2016-06-17     11620     Friday  ...        1        1        1\n",
              "1967 2016-06-18     11621   Saturday  ...        1        1        1\n",
              "1968 2016-06-19     11621     Sunday  ...        1        1        1\n",
              "\n",
              "[1969 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OtzZyiEjFf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "e03d68df-6005-40e3-e069-ab41bbe5c320"
      },
      "source": [
        "pd.get_dummies(stv[\"cat_id\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FOODS</th>\n",
              "      <th>HOBBIES</th>\n",
              "      <th>HOUSEHOLD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       FOODS  HOBBIES  HOUSEHOLD\n",
              "0          0        1          0\n",
              "1          0        1          0\n",
              "2          0        1          0\n",
              "3          0        1          0\n",
              "4          0        1          0\n",
              "...      ...      ...        ...\n",
              "30485      1        0          0\n",
              "30486      1        0          0\n",
              "30487      1        0          0\n",
              "30488      1        0          0\n",
              "30489      1        0          0\n",
              "\n",
              "[30490 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFayF3ZBjdT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "b1e54f56-a922-4992-9e22-f797d1775786"
      },
      "source": [
        "pd.get_dummies(stv[\"store_id\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CA_1</th>\n",
              "      <th>CA_2</th>\n",
              "      <th>CA_3</th>\n",
              "      <th>CA_4</th>\n",
              "      <th>TX_1</th>\n",
              "      <th>TX_2</th>\n",
              "      <th>TX_3</th>\n",
              "      <th>WI_1</th>\n",
              "      <th>WI_2</th>\n",
              "      <th>WI_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       CA_1  CA_2  CA_3  CA_4  TX_1  TX_2  TX_3  WI_1  WI_2  WI_3\n",
              "0         1     0     0     0     0     0     0     0     0     0\n",
              "1         1     0     0     0     0     0     0     0     0     0\n",
              "2         1     0     0     0     0     0     0     0     0     0\n",
              "3         1     0     0     0     0     0     0     0     0     0\n",
              "4         1     0     0     0     0     0     0     0     0     0\n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
              "30485     0     0     0     0     0     0     0     0     0     1\n",
              "30486     0     0     0     0     0     0     0     0     0     1\n",
              "30487     0     0     0     0     0     0     0     0     0     1\n",
              "30488     0     0     0     0     0     0     0     0     0     1\n",
              "30489     0     0     0     0     0     0     0     0     0     1\n",
              "\n",
              "[30490 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO1fp4q5jv5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "3eded4a5-f958-4071-de5d-7b27ef0e9431"
      },
      "source": [
        "stv.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1874</th>\n",
              "      <th>d_1875</th>\n",
              "      <th>d_1876</th>\n",
              "      <th>d_1877</th>\n",
              "      <th>d_1878</th>\n",
              "      <th>d_1879</th>\n",
              "      <th>d_1880</th>\n",
              "      <th>d_1881</th>\n",
              "      <th>d_1882</th>\n",
              "      <th>d_1883</th>\n",
              "      <th>d_1884</th>\n",
              "      <th>d_1885</th>\n",
              "      <th>d_1886</th>\n",
              "      <th>d_1887</th>\n",
              "      <th>d_1888</th>\n",
              "      <th>d_1889</th>\n",
              "      <th>d_1890</th>\n",
              "      <th>d_1891</th>\n",
              "      <th>d_1892</th>\n",
              "      <th>d_1893</th>\n",
              "      <th>d_1894</th>\n",
              "      <th>d_1895</th>\n",
              "      <th>d_1896</th>\n",
              "      <th>d_1897</th>\n",
              "      <th>d_1898</th>\n",
              "      <th>d_1899</th>\n",
              "      <th>d_1900</th>\n",
              "      <th>d_1901</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1919 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id        item_id  ... d_1912 d_1913\n",
              "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  ...      1      1\n",
              "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  ...      0      0\n",
              "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  ...      1      1\n",
              "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  ...      7      2\n",
              "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  ...      2      4\n",
              "\n",
              "[5 rows x 1919 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9SdeEmjjz5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "45a4332f-6f71-45f1-a4c6-9d4387de3cc1"
      },
      "source": [
        "pd.get_dummies(stv[\"dept_id\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FOODS_1</th>\n",
              "      <th>FOODS_2</th>\n",
              "      <th>FOODS_3</th>\n",
              "      <th>HOBBIES_1</th>\n",
              "      <th>HOBBIES_2</th>\n",
              "      <th>HOUSEHOLD_1</th>\n",
              "      <th>HOUSEHOLD_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       FOODS_1  FOODS_2  FOODS_3  ...  HOBBIES_2  HOUSEHOLD_1  HOUSEHOLD_2\n",
              "0            0        0        0  ...          0            0            0\n",
              "1            0        0        0  ...          0            0            0\n",
              "2            0        0        0  ...          0            0            0\n",
              "3            0        0        0  ...          0            0            0\n",
              "4            0        0        0  ...          0            0            0\n",
              "...        ...      ...      ...  ...        ...          ...          ...\n",
              "30485        0        0        1  ...          0            0            0\n",
              "30486        0        0        1  ...          0            0            0\n",
              "30487        0        0        1  ...          0            0            0\n",
              "30488        0        0        1  ...          0            0            0\n",
              "30489        0        0        1  ...          0            0            0\n",
              "\n",
              "[30490 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFC_nBookAfT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "5319f154-c05d-444a-9612-50d1ce97a866"
      },
      "source": [
        "pd.get_dummies(stv[\"item_id\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FOODS_1_001</th>\n",
              "      <th>FOODS_1_002</th>\n",
              "      <th>FOODS_1_003</th>\n",
              "      <th>FOODS_1_004</th>\n",
              "      <th>FOODS_1_005</th>\n",
              "      <th>FOODS_1_006</th>\n",
              "      <th>FOODS_1_008</th>\n",
              "      <th>FOODS_1_009</th>\n",
              "      <th>FOODS_1_010</th>\n",
              "      <th>FOODS_1_011</th>\n",
              "      <th>FOODS_1_012</th>\n",
              "      <th>FOODS_1_013</th>\n",
              "      <th>FOODS_1_014</th>\n",
              "      <th>FOODS_1_015</th>\n",
              "      <th>FOODS_1_016</th>\n",
              "      <th>FOODS_1_017</th>\n",
              "      <th>FOODS_1_018</th>\n",
              "      <th>FOODS_1_019</th>\n",
              "      <th>FOODS_1_020</th>\n",
              "      <th>FOODS_1_021</th>\n",
              "      <th>FOODS_1_022</th>\n",
              "      <th>FOODS_1_023</th>\n",
              "      <th>FOODS_1_024</th>\n",
              "      <th>FOODS_1_025</th>\n",
              "      <th>FOODS_1_026</th>\n",
              "      <th>FOODS_1_027</th>\n",
              "      <th>FOODS_1_028</th>\n",
              "      <th>FOODS_1_029</th>\n",
              "      <th>FOODS_1_030</th>\n",
              "      <th>FOODS_1_031</th>\n",
              "      <th>FOODS_1_032</th>\n",
              "      <th>FOODS_1_033</th>\n",
              "      <th>FOODS_1_034</th>\n",
              "      <th>FOODS_1_035</th>\n",
              "      <th>FOODS_1_036</th>\n",
              "      <th>FOODS_1_037</th>\n",
              "      <th>FOODS_1_038</th>\n",
              "      <th>FOODS_1_039</th>\n",
              "      <th>FOODS_1_040</th>\n",
              "      <th>FOODS_1_041</th>\n",
              "      <th>...</th>\n",
              "      <th>HOUSEHOLD_2_477</th>\n",
              "      <th>HOUSEHOLD_2_478</th>\n",
              "      <th>HOUSEHOLD_2_479</th>\n",
              "      <th>HOUSEHOLD_2_480</th>\n",
              "      <th>HOUSEHOLD_2_481</th>\n",
              "      <th>HOUSEHOLD_2_482</th>\n",
              "      <th>HOUSEHOLD_2_483</th>\n",
              "      <th>HOUSEHOLD_2_484</th>\n",
              "      <th>HOUSEHOLD_2_485</th>\n",
              "      <th>HOUSEHOLD_2_486</th>\n",
              "      <th>HOUSEHOLD_2_487</th>\n",
              "      <th>HOUSEHOLD_2_488</th>\n",
              "      <th>HOUSEHOLD_2_489</th>\n",
              "      <th>HOUSEHOLD_2_490</th>\n",
              "      <th>HOUSEHOLD_2_491</th>\n",
              "      <th>HOUSEHOLD_2_492</th>\n",
              "      <th>HOUSEHOLD_2_493</th>\n",
              "      <th>HOUSEHOLD_2_494</th>\n",
              "      <th>HOUSEHOLD_2_495</th>\n",
              "      <th>HOUSEHOLD_2_496</th>\n",
              "      <th>HOUSEHOLD_2_497</th>\n",
              "      <th>HOUSEHOLD_2_498</th>\n",
              "      <th>HOUSEHOLD_2_499</th>\n",
              "      <th>HOUSEHOLD_2_500</th>\n",
              "      <th>HOUSEHOLD_2_501</th>\n",
              "      <th>HOUSEHOLD_2_502</th>\n",
              "      <th>HOUSEHOLD_2_503</th>\n",
              "      <th>HOUSEHOLD_2_504</th>\n",
              "      <th>HOUSEHOLD_2_505</th>\n",
              "      <th>HOUSEHOLD_2_506</th>\n",
              "      <th>HOUSEHOLD_2_507</th>\n",
              "      <th>HOUSEHOLD_2_508</th>\n",
              "      <th>HOUSEHOLD_2_509</th>\n",
              "      <th>HOUSEHOLD_2_510</th>\n",
              "      <th>HOUSEHOLD_2_511</th>\n",
              "      <th>HOUSEHOLD_2_512</th>\n",
              "      <th>HOUSEHOLD_2_513</th>\n",
              "      <th>HOUSEHOLD_2_514</th>\n",
              "      <th>HOUSEHOLD_2_515</th>\n",
              "      <th>HOUSEHOLD_2_516</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 3049 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       FOODS_1_001  FOODS_1_002  ...  HOUSEHOLD_2_515  HOUSEHOLD_2_516\n",
              "0                0            0  ...                0                0\n",
              "1                0            0  ...                0                0\n",
              "2                0            0  ...                0                0\n",
              "3                0            0  ...                0                0\n",
              "4                0            0  ...                0                0\n",
              "...            ...          ...  ...              ...              ...\n",
              "30485            0            0  ...                0                0\n",
              "30486            0            0  ...                0                0\n",
              "30487            0            0  ...                0                0\n",
              "30488            0            0  ...                0                0\n",
              "30489            0            0  ...                0                0\n",
              "\n",
              "[30490 rows x 3049 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhVxo6Q0kEt1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "39779469-8ac5-4ed1-cf5f-4435c2d36faf"
      },
      "source": [
        "pd.get_dummies(stv[\"state_id\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CA</th>\n",
              "      <th>TX</th>\n",
              "      <th>WI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       CA  TX  WI\n",
              "0       1   0   0\n",
              "1       1   0   0\n",
              "2       1   0   0\n",
              "3       1   0   0\n",
              "4       1   0   0\n",
              "...    ..  ..  ..\n",
              "30485   0   0   1\n",
              "30486   0   0   1\n",
              "30487   0   0   1\n",
              "30488   0   0   1\n",
              "30489   0   0   1\n",
              "\n",
              "[30490 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Af-U1yP6sEF",
        "colab_type": "text"
      },
      "source": [
        "# エンコーディングの方針\n",
        "item_id はラベルエンコーディングしてEmbedding layerにぶち込む -> 余裕があれば最後にやる。最初はこの特徴量をそもそも入れない。<br />\n",
        "ほかのやつはone-hot encodingにする。<br />\n",
        "<br />\n",
        "ジェネレータも、圧縮ファイルから随時読み込む形に書き換える。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6QWoiWu7C3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calendar = cal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HVqhsT28x4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "28895df3-d97a-4d86-d8b2-b593dc395235"
      },
      "source": [
        "required_columns = [\"d\", \"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]\n",
        "calendar[required_columns].max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "d               d_999\n",
              "event_name_1        1\n",
              "event_name_2        1\n",
              "event_type_1        1\n",
              "event_type_2        1\n",
              "snap_CA             1\n",
              "snap_TX             1\n",
              "snap_WI             1\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAIj_R4P9R0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5065513-40b2-4998-ff79-da3dde7950af"
      },
      "source": [
        "cal[\"event_name_1\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTjZvJ1Q9qzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one-hot encodingしたものがあった\n",
        "cal = pd.read_csv(f\"{INPUT_DIR}/cal_dummies.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ9wXkxZ97_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "a36ef3ff-5767-4f45-a507-a898fcbd807f"
      },
      "source": [
        "cal.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>date</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>weekday</th>\n",
              "      <th>wday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>d</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_name_1_Chanukah End</th>\n",
              "      <th>event_name_1_Christmas</th>\n",
              "      <th>event_name_1_Cinco De Mayo</th>\n",
              "      <th>event_name_1_ColumbusDay</th>\n",
              "      <th>event_name_1_Easter</th>\n",
              "      <th>event_name_1_Eid al-Fitr</th>\n",
              "      <th>event_name_1_EidAlAdha</th>\n",
              "      <th>event_name_1_Father's day</th>\n",
              "      <th>event_name_1_Halloween</th>\n",
              "      <th>event_name_1_IndependenceDay</th>\n",
              "      <th>event_name_1_LaborDay</th>\n",
              "      <th>event_name_1_LentStart</th>\n",
              "      <th>event_name_1_LentWeek2</th>\n",
              "      <th>event_name_1_MartinLutherKingDay</th>\n",
              "      <th>event_name_1_MemorialDay</th>\n",
              "      <th>event_name_1_Mother's day</th>\n",
              "      <th>event_name_1_NBAFinalsEnd</th>\n",
              "      <th>event_name_1_NBAFinalsStart</th>\n",
              "      <th>event_name_1_NewYear</th>\n",
              "      <th>event_name_1_OrthodoxChristmas</th>\n",
              "      <th>event_name_1_OrthodoxEaster</th>\n",
              "      <th>event_name_1_Pesach End</th>\n",
              "      <th>event_name_1_PresidentsDay</th>\n",
              "      <th>event_name_1_Purim End</th>\n",
              "      <th>event_name_1_Ramadan starts</th>\n",
              "      <th>event_name_1_StPatricksDay</th>\n",
              "      <th>event_name_1_SuperBowl</th>\n",
              "      <th>event_name_1_Thanksgiving</th>\n",
              "      <th>event_name_1_ValentinesDay</th>\n",
              "      <th>event_name_1_VeteransDay</th>\n",
              "      <th>event_type_1_Cultural</th>\n",
              "      <th>event_type_1_National</th>\n",
              "      <th>event_type_1_Religious</th>\n",
              "      <th>event_type_1_Sporting</th>\n",
              "      <th>event_name_2_Cinco De Mayo</th>\n",
              "      <th>event_name_2_Easter</th>\n",
              "      <th>event_name_2_Father's day</th>\n",
              "      <th>event_name_2_OrthodoxEaster</th>\n",
              "      <th>event_type_2_Cultural</th>\n",
              "      <th>event_type_2_Religious</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-30</td>\n",
              "      <td>11101</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-31</td>\n",
              "      <td>11101</td>\n",
              "      <td>Monday</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-02-01</td>\n",
              "      <td>11101</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-02-02</td>\n",
              "      <td>11101</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0        date  ...  event_type_2_Cultural event_type_2_Religious\n",
              "0           0  2011-01-29  ...                      0                      0\n",
              "1           1  2011-01-30  ...                      0                      0\n",
              "2           2  2011-01-31  ...                      0                      0\n",
              "3           3  2011-02-01  ...                      0                      0\n",
              "4           4  2011-02-02  ...                      0                      0\n",
              "\n",
              "[5 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsEAFrbu_mrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cal = cal.drop(columns=[\"Unnamed: 0\", \"date\", \"wm_yr_wk\", \"weekday\", \"wday\", \"month\", \"year\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrjte5UrAFd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "zipからデータ読み出し。\n",
        "展開しないのでディスク容量も圧迫せず済む\n",
        "\"\"\"\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "NUM_ITEMS = 30490\n",
        "DATA_PATH = \"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas.zip\"\n",
        "\n",
        "def df_csv_generator(num=NUM_ITEMS, datapath=DATA_PATH):\n",
        "    with zipfile.ZipFile(datapath) as myzip:\n",
        "        filelist = myzip.namelist()\n",
        "\n",
        "        for i, f_name in enumerate(filelist):\n",
        "\n",
        "            if i == 0:\n",
        "                continue\n",
        "\n",
        "            if i > num:\n",
        "                break\n",
        "\n",
        "            df = pd.read_csv(myzip.extract(f_name, \"./extract_dir\"))\n",
        "            df = reduce_mem_usage(df, verbose=False)\n",
        "            df = df.fillna(0)\n",
        "            shutil.rmtree(\"./extract_dir\")\n",
        "            yield df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlR3glO6BBr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfg = df_csv_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw7Wj15VBINb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "c4727670-fa0b-4aa8-d444-224dd4f02c89"
      },
      "source": [
        "next(dfg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>sale</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>3.480469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1965</th>\n",
              "      <td>3.480469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>3.480469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1967</th>\n",
              "      <td>3.480469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1968</th>\n",
              "      <td>3.480469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1969 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         price  sale  item_id  dept_id  ...  event_type_2  snap_CA  snap_TX  snap_WI\n",
              "0     0.000000   0.0   1447.0      3.0  ...             2        0        0        0\n",
              "1     0.000000   0.0   1447.0      3.0  ...             2        0        0        0\n",
              "2     0.000000   0.0   1447.0      3.0  ...             2        0        0        0\n",
              "3     0.000000   0.0   1447.0      3.0  ...             2        1        1        0\n",
              "4     0.000000   0.0   1447.0      3.0  ...             2        1        0        1\n",
              "...        ...   ...      ...      ...  ...           ...      ...      ...      ...\n",
              "1964  3.480469   0.0   1447.0      3.0  ...             2        0        1        1\n",
              "1965  3.480469   0.0   1447.0      3.0  ...             2        0        0        0\n",
              "1966  3.480469   0.0   1447.0      3.0  ...             2        0        0        0\n",
              "1967  3.480469   0.0   1447.0      3.0  ...             2        0        0        0\n",
              "1968  3.480469   0.0   1447.0      3.0  ...             0        0        0        0\n",
              "\n",
              "[1969 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95umL7cYBJXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "0aad4d76-4c86-48d7-c379-f1b5ac66e355"
      },
      "source": [
        "drop_columns = [\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]\n",
        "test_df.drop(columns=drop_columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>sale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1965</th>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1967</th>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1968</th>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1969 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         price  sale\n",
              "0     0.000000   0.0\n",
              "1     0.000000   0.0\n",
              "2     0.000000   0.0\n",
              "3     0.000000   0.0\n",
              "4     0.000000   0.0\n",
              "...        ...   ...\n",
              "1964  8.382812   0.0\n",
              "1965  8.382812   0.0\n",
              "1966  8.382812   0.0\n",
              "1967  8.382812   0.0\n",
              "1968  8.382812   0.0\n",
              "\n",
              "[1969 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Safb0gCBDkTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "cfd14441-d272-477e-b970-88cc3346b872"
      },
      "source": [
        "pd.concat([cal.drop(columns=[\"d\"]), test_df.drop(columns=drop_columns)], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_name_1_Chanukah End</th>\n",
              "      <th>event_name_1_Christmas</th>\n",
              "      <th>event_name_1_Cinco De Mayo</th>\n",
              "      <th>event_name_1_ColumbusDay</th>\n",
              "      <th>event_name_1_Easter</th>\n",
              "      <th>event_name_1_Eid al-Fitr</th>\n",
              "      <th>event_name_1_EidAlAdha</th>\n",
              "      <th>event_name_1_Father's day</th>\n",
              "      <th>event_name_1_Halloween</th>\n",
              "      <th>event_name_1_IndependenceDay</th>\n",
              "      <th>event_name_1_LaborDay</th>\n",
              "      <th>event_name_1_LentStart</th>\n",
              "      <th>event_name_1_LentWeek2</th>\n",
              "      <th>event_name_1_MartinLutherKingDay</th>\n",
              "      <th>event_name_1_MemorialDay</th>\n",
              "      <th>event_name_1_Mother's day</th>\n",
              "      <th>event_name_1_NBAFinalsEnd</th>\n",
              "      <th>event_name_1_NBAFinalsStart</th>\n",
              "      <th>event_name_1_NewYear</th>\n",
              "      <th>event_name_1_OrthodoxChristmas</th>\n",
              "      <th>event_name_1_OrthodoxEaster</th>\n",
              "      <th>event_name_1_Pesach End</th>\n",
              "      <th>event_name_1_PresidentsDay</th>\n",
              "      <th>event_name_1_Purim End</th>\n",
              "      <th>event_name_1_Ramadan starts</th>\n",
              "      <th>event_name_1_StPatricksDay</th>\n",
              "      <th>event_name_1_SuperBowl</th>\n",
              "      <th>event_name_1_Thanksgiving</th>\n",
              "      <th>event_name_1_ValentinesDay</th>\n",
              "      <th>event_name_1_VeteransDay</th>\n",
              "      <th>event_type_1_Cultural</th>\n",
              "      <th>event_type_1_National</th>\n",
              "      <th>event_type_1_Religious</th>\n",
              "      <th>event_type_1_Sporting</th>\n",
              "      <th>event_name_2_Cinco De Mayo</th>\n",
              "      <th>event_name_2_Easter</th>\n",
              "      <th>event_name_2_Father's day</th>\n",
              "      <th>event_name_2_OrthodoxEaster</th>\n",
              "      <th>event_type_2_Cultural</th>\n",
              "      <th>event_type_2_Religious</th>\n",
              "      <th>price</th>\n",
              "      <th>sale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1965</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1967</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1968</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1969 rows × 45 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      snap_CA  snap_TX  snap_WI  ...  event_type_2_Religious     price  sale\n",
              "0           0        0        0  ...                       0  0.000000   0.0\n",
              "1           0        0        0  ...                       0  0.000000   0.0\n",
              "2           0        0        0  ...                       0  0.000000   0.0\n",
              "3           1        1        0  ...                       0  0.000000   0.0\n",
              "4           1        0        1  ...                       0  0.000000   0.0\n",
              "...       ...      ...      ...  ...                     ...       ...   ...\n",
              "1964        0        1        1  ...                       0  8.382812   0.0\n",
              "1965        0        0        0  ...                       0  8.382812   0.0\n",
              "1966        0        0        0  ...                       0  8.382812   0.0\n",
              "1967        0        0        0  ...                       0  8.382812   0.0\n",
              "1968        0        0        0  ...                       0  8.382812   0.0\n",
              "\n",
              "[1969 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kadHHGoaD6AR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "a6611888-6c31-46c8-b4e7-8c2545f57591"
      },
      "source": [
        "ste = ste.rename(columns={\"id\": \"total_id\"})\n",
        "mod_ste = ste.drop(columns=[\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"])\n",
        "mod_ste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>d_35</th>\n",
              "      <th>d_36</th>\n",
              "      <th>d_37</th>\n",
              "      <th>d_38</th>\n",
              "      <th>d_39</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "      <th>d_1914</th>\n",
              "      <th>d_1915</th>\n",
              "      <th>d_1916</th>\n",
              "      <th>d_1917</th>\n",
              "      <th>d_1918</th>\n",
              "      <th>d_1919</th>\n",
              "      <th>d_1920</th>\n",
              "      <th>d_1921</th>\n",
              "      <th>d_1922</th>\n",
              "      <th>d_1923</th>\n",
              "      <th>d_1924</th>\n",
              "      <th>d_1925</th>\n",
              "      <th>d_1926</th>\n",
              "      <th>d_1927</th>\n",
              "      <th>d_1928</th>\n",
              "      <th>d_1929</th>\n",
              "      <th>d_1930</th>\n",
              "      <th>d_1931</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 1942 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            total_id  d_1  d_2  ...  d_1939  d_1940  d_1941\n",
              "0      HOBBIES_1_001_CA_1_evaluation    0    0  ...       3       0       1\n",
              "1      HOBBIES_1_002_CA_1_evaluation    0    0  ...       0       0       0\n",
              "2      HOBBIES_1_003_CA_1_evaluation    0    0  ...       3       0       1\n",
              "3      HOBBIES_1_004_CA_1_evaluation    0    0  ...       0       2       6\n",
              "4      HOBBIES_1_005_CA_1_evaluation    0    0  ...       2       1       0\n",
              "...                              ...  ...  ...  ...     ...     ...     ...\n",
              "30485    FOODS_3_823_WI_3_evaluation    0    0  ...       0       1       1\n",
              "30486    FOODS_3_824_WI_3_evaluation    0    0  ...       0       1       0\n",
              "30487    FOODS_3_825_WI_3_evaluation    0    6  ...       1       0       2\n",
              "30488    FOODS_3_826_WI_3_evaluation    0    0  ...       1       1       0\n",
              "30489    FOODS_3_827_WI_3_evaluation    0    0  ...       2       5       1\n",
              "\n",
              "[30490 rows x 1942 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LVbYumGE8YD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 各商品の属性(食品、地域など)を記載したデータフレーム作成(item_idだけ除外)\n",
        "ste = ste.rename(columns={\"id\": \"total_id\"})\n",
        "mod_ste = ste.drop(columns=[\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"])\n",
        "item_attribute_df = pd.DataFrame(ste[\"total_id\"])\n",
        "\n",
        "dummy_list = [\"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n",
        "for col in dummy_list:\n",
        "    item_attribute_df = pd.concat([item_attribute_df, pd.get_dummies(ste[col])], axis=1)\n",
        "\n",
        "item_cat_df = item_attribute_df.drop(columns=[\"total_id\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sByzCosyHY6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "dd873484-61fd-439e-fd39-7608758399b0"
      },
      "source": [
        "item_cat_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FOODS_1</th>\n",
              "      <th>FOODS_2</th>\n",
              "      <th>FOODS_3</th>\n",
              "      <th>HOBBIES_1</th>\n",
              "      <th>HOBBIES_2</th>\n",
              "      <th>HOUSEHOLD_1</th>\n",
              "      <th>HOUSEHOLD_2</th>\n",
              "      <th>FOODS</th>\n",
              "      <th>HOBBIES</th>\n",
              "      <th>HOUSEHOLD</th>\n",
              "      <th>CA_1</th>\n",
              "      <th>CA_2</th>\n",
              "      <th>CA_3</th>\n",
              "      <th>CA_4</th>\n",
              "      <th>TX_1</th>\n",
              "      <th>TX_2</th>\n",
              "      <th>TX_3</th>\n",
              "      <th>WI_1</th>\n",
              "      <th>WI_2</th>\n",
              "      <th>WI_3</th>\n",
              "      <th>CA</th>\n",
              "      <th>TX</th>\n",
              "      <th>WI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       FOODS_1  FOODS_2  FOODS_3  HOBBIES_1  HOBBIES_2  ...  WI_2  WI_3  CA  TX  WI\n",
              "0            0        0        0          1          0  ...     0     0   1   0   0\n",
              "1            0        0        0          1          0  ...     0     0   1   0   0\n",
              "2            0        0        0          1          0  ...     0     0   1   0   0\n",
              "3            0        0        0          1          0  ...     0     0   1   0   0\n",
              "4            0        0        0          1          0  ...     0     0   1   0   0\n",
              "...        ...      ...      ...        ...        ...  ...   ...   ...  ..  ..  ..\n",
              "30485        0        0        1          0          0  ...     0     1   0   0   1\n",
              "30486        0        0        1          0          0  ...     0     1   0   0   1\n",
              "30487        0        0        1          0          0  ...     0     1   0   0   1\n",
              "30488        0        0        1          0          0  ...     0     1   0   0   1\n",
              "30489        0        0        1          0          0  ...     0     1   0   0   1\n",
              "\n",
              "[30490 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rZAufskFQ-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attribute_df_generator(item_cat_df):\n",
        "    for i in range(item_cat_df.shape[0]):\n",
        "        yield item_cat_df.loc[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_MTK1gWHkGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "857e0a0f-cf6a-4a4e-b586-39fcc5402f73"
      },
      "source": [
        "atg = attribute_df_generator(item_cat_df)\n",
        "(next(atg).values * np.ones((1969, 1))).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1969, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aisRLcGsHl4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop_columns = [\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]\n",
        "ste_days = ste.drop(columns=[\"total_id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"])\n",
        "\n",
        "def train_df_generator(item_cat_df, cat, ste_days ,num=30490):\n",
        "    dfg = df_csv_generator()\n",
        "    adg = attribute_df_generator(item_cat_df)\n",
        "    mv_avg_df_7 = ste_days.transpose().rolling(7).mean().fillna(0).reset_index(drop=True)\n",
        "    mv_avg_df_30 = ste_days.transpose().rolling(30).mean().fillna(0).reset_index(drop=True)\n",
        "\n",
        "    for i, df in enumerate(dfg):\n",
        "        if i >= num:\n",
        "            break\n",
        "        tmp_df = df.drop(columns=drop_columns)\n",
        "        tmp_cat_df = pd.DataFrame((next(adg).values * np.ones((1941, 1))).astype(int))\n",
        "        tmp_moving_average_df = ste_days\n",
        "        ret_df = pd.concat([cal.drop(columns=[\"d\"])[:-28], tmp_cat_df, mv_avg_df_7[i], mv_avg_df_30[i], tmp_df[:-28]], axis=1)\n",
        "        yield ret_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lNar2TSKB9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tdg = train_df_generator(item_cat_df, cal, ste_days, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvzasvWxKKBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e5e8961-ac87-4127-830e-14cb391d4640"
      },
      "source": [
        "next(tdg).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1941, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c33Y8vmaaS7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "a5715a66-28d1-4186-a7a5-4a21ab7836bc"
      },
      "source": [
        "next(tdg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_name_1_Chanukah End</th>\n",
              "      <th>event_name_1_Christmas</th>\n",
              "      <th>event_name_1_Cinco De Mayo</th>\n",
              "      <th>event_name_1_ColumbusDay</th>\n",
              "      <th>event_name_1_Easter</th>\n",
              "      <th>event_name_1_Eid al-Fitr</th>\n",
              "      <th>event_name_1_EidAlAdha</th>\n",
              "      <th>event_name_1_Father's day</th>\n",
              "      <th>event_name_1_Halloween</th>\n",
              "      <th>event_name_1_IndependenceDay</th>\n",
              "      <th>event_name_1_LaborDay</th>\n",
              "      <th>event_name_1_LentStart</th>\n",
              "      <th>event_name_1_LentWeek2</th>\n",
              "      <th>event_name_1_MartinLutherKingDay</th>\n",
              "      <th>event_name_1_MemorialDay</th>\n",
              "      <th>event_name_1_Mother's day</th>\n",
              "      <th>event_name_1_NBAFinalsEnd</th>\n",
              "      <th>event_name_1_NBAFinalsStart</th>\n",
              "      <th>event_name_1_NewYear</th>\n",
              "      <th>event_name_1_OrthodoxChristmas</th>\n",
              "      <th>event_name_1_OrthodoxEaster</th>\n",
              "      <th>event_name_1_Pesach End</th>\n",
              "      <th>event_name_1_PresidentsDay</th>\n",
              "      <th>event_name_1_Purim End</th>\n",
              "      <th>event_name_1_Ramadan starts</th>\n",
              "      <th>event_name_1_StPatricksDay</th>\n",
              "      <th>event_name_1_SuperBowl</th>\n",
              "      <th>event_name_1_Thanksgiving</th>\n",
              "      <th>event_name_1_ValentinesDay</th>\n",
              "      <th>event_name_1_VeteransDay</th>\n",
              "      <th>event_type_1_Cultural</th>\n",
              "      <th>event_type_1_National</th>\n",
              "      <th>event_type_1_Religious</th>\n",
              "      <th>event_type_1_Sporting</th>\n",
              "      <th>event_name_2_Cinco De Mayo</th>\n",
              "      <th>event_name_2_Easter</th>\n",
              "      <th>event_name_2_Father's day</th>\n",
              "      <th>event_name_2_OrthodoxEaster</th>\n",
              "      <th>event_type_2_Cultural</th>\n",
              "      <th>event_type_2_Religious</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>1</th>\n",
              "      <th>price</th>\n",
              "      <th>sale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1936</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1937</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1938</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1939</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1940</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1941 rows × 69 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      snap_CA  snap_TX  snap_WI  ...         1     price  sale\n",
              "0           0        0        0  ...  0.000000  0.000000   0.0\n",
              "1           0        0        0  ...  0.000000  0.000000   0.0\n",
              "2           0        0        0  ...  0.000000  0.000000   0.0\n",
              "3           1        1        0  ...  0.000000  0.000000   0.0\n",
              "4           1        0        1  ...  0.000000  0.000000   0.0\n",
              "...       ...      ...      ...  ...       ...       ...   ...\n",
              "1936        0        0        0  ...  0.714286  3.970703   0.0\n",
              "1937        0        0        0  ...  0.714286  3.970703   0.0\n",
              "1938        0        0        0  ...  0.714286  3.970703   0.0\n",
              "1939        0        0        0  ...  0.571429  3.970703   0.0\n",
              "1940        0        0        0  ...  0.285714  3.970703   0.0\n",
              "\n",
              "[1941 rows x 69 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0qnx2wfZz4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "abb4bb0a-bf70-4f50-f8fc-a6c98d86edf6"
      },
      "source": [
        "mv_avg_df_7 = ste_days.transpose().rolling(7).mean().fillna(0)\n",
        "mv_avg_df_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>30450</th>\n",
              "      <th>30451</th>\n",
              "      <th>30452</th>\n",
              "      <th>30453</th>\n",
              "      <th>30454</th>\n",
              "      <th>30455</th>\n",
              "      <th>30456</th>\n",
              "      <th>30457</th>\n",
              "      <th>30458</th>\n",
              "      <th>30459</th>\n",
              "      <th>30460</th>\n",
              "      <th>30461</th>\n",
              "      <th>30462</th>\n",
              "      <th>30463</th>\n",
              "      <th>30464</th>\n",
              "      <th>30465</th>\n",
              "      <th>30466</th>\n",
              "      <th>30467</th>\n",
              "      <th>30468</th>\n",
              "      <th>30469</th>\n",
              "      <th>30470</th>\n",
              "      <th>30471</th>\n",
              "      <th>30472</th>\n",
              "      <th>30473</th>\n",
              "      <th>30474</th>\n",
              "      <th>30475</th>\n",
              "      <th>30476</th>\n",
              "      <th>30477</th>\n",
              "      <th>30478</th>\n",
              "      <th>30479</th>\n",
              "      <th>30480</th>\n",
              "      <th>30481</th>\n",
              "      <th>30482</th>\n",
              "      <th>30483</th>\n",
              "      <th>30484</th>\n",
              "      <th>30485</th>\n",
              "      <th>30486</th>\n",
              "      <th>30487</th>\n",
              "      <th>30488</th>\n",
              "      <th>30489</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d_1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1937</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>11.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>5.142857</td>\n",
              "      <td>8.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>10.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>3.285714</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1938</th>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>5.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>...</td>\n",
              "      <td>4.285714</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>10.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.571429</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1939</th>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>3.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>8.285714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>7.285714</td>\n",
              "      <td>3.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>26.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1940</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>10.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>5.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>4.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>8.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>6.714286</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>24.142857</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1941</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>13.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>4.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>6.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>...</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>7.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>7.142857</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>25.571429</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>2.714286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1941 rows × 30490 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2      ...     30487     30488     30489\n",
              "d_1     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "d_2     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "d_3     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "d_4     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "d_5     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "...          ...       ...       ...  ...       ...       ...       ...\n",
              "d_1937  0.857143  0.714286  0.428571  ...  0.714286  2.000000  1.714286\n",
              "d_1938  1.285714  0.714286  0.714286  ...  0.571429  2.000000  2.000000\n",
              "d_1939  1.428571  0.714286  1.000000  ...  0.714286  2.000000  2.142857\n",
              "d_1940  0.857143  0.571429  1.000000  ...  0.714286  2.000000  2.571429\n",
              "d_1941  1.000000  0.285714  0.857143  ...  0.857143  1.857143  2.714286\n",
              "\n",
              "[1941 rows x 30490 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCol-d6YaBPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "3bb755bc-f046-4361-f14b-59a46226ba3d"
      },
      "source": [
        "mv_avg_df_7[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "d_1       0.000000\n",
              "d_2       0.000000\n",
              "d_3       0.000000\n",
              "d_4       0.000000\n",
              "d_5       0.000000\n",
              "            ...   \n",
              "d_1937    0.857143\n",
              "d_1938    1.285714\n",
              "d_1939    1.428571\n",
              "d_1940    0.857143\n",
              "d_1941    1.000000\n",
              "Name: 0, Length: 1941, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQkfIue1YHyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c285ad80-a3e7-4713-8a7e-d83d7317afff"
      },
      "source": [
        "dfg = df_csv_generator()\n",
        "next(dfg).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1969, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFGohfr5YoI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "23edaabc-d3ae-4980-f59e-7e9896d54863"
      },
      "source": [
        "ste_days.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>d_35</th>\n",
              "      <th>d_36</th>\n",
              "      <th>d_37</th>\n",
              "      <th>d_38</th>\n",
              "      <th>d_39</th>\n",
              "      <th>d_40</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "      <th>d_1914</th>\n",
              "      <th>d_1915</th>\n",
              "      <th>d_1916</th>\n",
              "      <th>d_1917</th>\n",
              "      <th>d_1918</th>\n",
              "      <th>d_1919</th>\n",
              "      <th>d_1920</th>\n",
              "      <th>d_1921</th>\n",
              "      <th>d_1922</th>\n",
              "      <th>d_1923</th>\n",
              "      <th>d_1924</th>\n",
              "      <th>d_1925</th>\n",
              "      <th>d_1926</th>\n",
              "      <th>d_1927</th>\n",
              "      <th>d_1928</th>\n",
              "      <th>d_1929</th>\n",
              "      <th>d_1930</th>\n",
              "      <th>d_1931</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1941 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   d_1  d_2  d_3  d_4  d_5  d_6  ...  d_1936  d_1937  d_1938  d_1939  d_1940  d_1941\n",
              "0    0    0    0    0    0    0  ...       0       0       3       3       0       1\n",
              "1    0    0    0    0    0    0  ...       1       0       0       0       0       0\n",
              "2    0    0    0    0    0    0  ...       0       0       2       3       0       1\n",
              "3    0    0    0    0    0    0  ...       0       1       3       0       2       6\n",
              "4    0    0    0    0    0    0  ...       1       0       0       2       1       0\n",
              "\n",
              "[5 rows x 1941 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrB_N4bfY7li",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "87a00494-a858-4dc8-bf62-dc3233bb6c58"
      },
      "source": [
        "cal[:-28]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_name_1_Chanukah End</th>\n",
              "      <th>event_name_1_Christmas</th>\n",
              "      <th>event_name_1_Cinco De Mayo</th>\n",
              "      <th>event_name_1_ColumbusDay</th>\n",
              "      <th>event_name_1_Easter</th>\n",
              "      <th>event_name_1_Eid al-Fitr</th>\n",
              "      <th>event_name_1_EidAlAdha</th>\n",
              "      <th>event_name_1_Father's day</th>\n",
              "      <th>event_name_1_Halloween</th>\n",
              "      <th>event_name_1_IndependenceDay</th>\n",
              "      <th>event_name_1_LaborDay</th>\n",
              "      <th>event_name_1_LentStart</th>\n",
              "      <th>event_name_1_LentWeek2</th>\n",
              "      <th>event_name_1_MartinLutherKingDay</th>\n",
              "      <th>event_name_1_MemorialDay</th>\n",
              "      <th>event_name_1_Mother's day</th>\n",
              "      <th>event_name_1_NBAFinalsEnd</th>\n",
              "      <th>event_name_1_NBAFinalsStart</th>\n",
              "      <th>event_name_1_NewYear</th>\n",
              "      <th>event_name_1_OrthodoxChristmas</th>\n",
              "      <th>event_name_1_OrthodoxEaster</th>\n",
              "      <th>event_name_1_Pesach End</th>\n",
              "      <th>event_name_1_PresidentsDay</th>\n",
              "      <th>event_name_1_Purim End</th>\n",
              "      <th>event_name_1_Ramadan starts</th>\n",
              "      <th>event_name_1_StPatricksDay</th>\n",
              "      <th>event_name_1_SuperBowl</th>\n",
              "      <th>event_name_1_Thanksgiving</th>\n",
              "      <th>event_name_1_ValentinesDay</th>\n",
              "      <th>event_name_1_VeteransDay</th>\n",
              "      <th>event_type_1_Cultural</th>\n",
              "      <th>event_type_1_National</th>\n",
              "      <th>event_type_1_Religious</th>\n",
              "      <th>event_type_1_Sporting</th>\n",
              "      <th>event_name_2_Cinco De Mayo</th>\n",
              "      <th>event_name_2_Easter</th>\n",
              "      <th>event_name_2_Father's day</th>\n",
              "      <th>event_name_2_OrthodoxEaster</th>\n",
              "      <th>event_type_2_Cultural</th>\n",
              "      <th>event_type_2_Religious</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d_2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d_3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d_4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d_5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1936</th>\n",
              "      <td>d_1937</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1937</th>\n",
              "      <td>d_1938</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1938</th>\n",
              "      <td>d_1939</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1939</th>\n",
              "      <td>d_1940</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1940</th>\n",
              "      <td>d_1941</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1941 rows × 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           d  snap_CA  ...  event_type_2_Cultural  event_type_2_Religious\n",
              "0        d_1        0  ...                      0                       0\n",
              "1        d_2        0  ...                      0                       0\n",
              "2        d_3        0  ...                      0                       0\n",
              "3        d_4        1  ...                      0                       0\n",
              "4        d_5        1  ...                      0                       0\n",
              "...      ...      ...  ...                    ...                     ...\n",
              "1936  d_1937        0  ...                      0                       0\n",
              "1937  d_1938        0  ...                      0                       0\n",
              "1938  d_1939        0  ...                      0                       0\n",
              "1939  d_1940        0  ...                      0                       0\n",
              "1940  d_1941        0  ...                      0                       0\n",
              "\n",
              "[1941 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLI7FW6-NEiZ",
        "colab_type": "text"
      },
      "source": [
        "# 20/06/19 移動平均のカラムを追加\n",
        "1週間と1ヶ月(30日)の平均を見る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4KCQ7ffNWkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "eef72bc3-560d-4e29-e4b3-41e20c129e4e"
      },
      "source": [
        "ste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "      <th>d_1914</th>\n",
              "      <th>d_1915</th>\n",
              "      <th>d_1916</th>\n",
              "      <th>d_1917</th>\n",
              "      <th>d_1918</th>\n",
              "      <th>d_1919</th>\n",
              "      <th>d_1920</th>\n",
              "      <th>d_1921</th>\n",
              "      <th>d_1922</th>\n",
              "      <th>d_1923</th>\n",
              "      <th>d_1924</th>\n",
              "      <th>d_1925</th>\n",
              "      <th>d_1926</th>\n",
              "      <th>d_1927</th>\n",
              "      <th>d_1928</th>\n",
              "      <th>d_1929</th>\n",
              "      <th>d_1930</th>\n",
              "      <th>d_1931</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
              "      <td>FOODS_3_823</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
              "      <td>FOODS_3_824</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
              "      <td>FOODS_3_825</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
              "      <td>FOODS_3_826</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
              "      <td>FOODS_3_827</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 1947 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  id        item_id  ... d_1940 d_1941\n",
              "0      HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  ...      0      1\n",
              "1      HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  ...      0      0\n",
              "2      HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  ...      0      1\n",
              "3      HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  ...      2      6\n",
              "4      HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  ...      1      0\n",
              "...                              ...            ...  ...    ...    ...\n",
              "30485    FOODS_3_823_WI_3_evaluation    FOODS_3_823  ...      1      1\n",
              "30486    FOODS_3_824_WI_3_evaluation    FOODS_3_824  ...      1      0\n",
              "30487    FOODS_3_825_WI_3_evaluation    FOODS_3_825  ...      0      2\n",
              "30488    FOODS_3_826_WI_3_evaluation    FOODS_3_826  ...      1      0\n",
              "30489    FOODS_3_827_WI_3_evaluation    FOODS_3_827  ...      5      1\n",
              "\n",
              "[30490 rows x 1947 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74DTudKaNb-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "75621836-3b5f-48db-d379-03101511de0a"
      },
      "source": [
        "# 移動平均テスト\n",
        "ste.drop(columns=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]).loc[0].rolling(7).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "d_1            NaN\n",
              "d_2            NaN\n",
              "d_3            NaN\n",
              "d_4            NaN\n",
              "d_5            NaN\n",
              "            ...   \n",
              "d_1937    0.857143\n",
              "d_1938    1.285714\n",
              "d_1939    1.428571\n",
              "d_1940    0.857143\n",
              "d_1941    1.000000\n",
              "Name: 0, Length: 1941, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOUYgwZxOZ_u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "c3a4ca7a-11f4-45c3-d998-709205959209"
      },
      "source": [
        "ste_id = ste[\"id\"]\n",
        "ste_days = ste.drop(columns=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"])\n",
        "ste_days"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>d_35</th>\n",
              "      <th>d_36</th>\n",
              "      <th>d_37</th>\n",
              "      <th>d_38</th>\n",
              "      <th>d_39</th>\n",
              "      <th>d_40</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "      <th>d_1914</th>\n",
              "      <th>d_1915</th>\n",
              "      <th>d_1916</th>\n",
              "      <th>d_1917</th>\n",
              "      <th>d_1918</th>\n",
              "      <th>d_1919</th>\n",
              "      <th>d_1920</th>\n",
              "      <th>d_1921</th>\n",
              "      <th>d_1922</th>\n",
              "      <th>d_1923</th>\n",
              "      <th>d_1924</th>\n",
              "      <th>d_1925</th>\n",
              "      <th>d_1926</th>\n",
              "      <th>d_1927</th>\n",
              "      <th>d_1928</th>\n",
              "      <th>d_1929</th>\n",
              "      <th>d_1930</th>\n",
              "      <th>d_1931</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 1941 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       d_1  d_2  d_3  d_4  d_5  ...  d_1937  d_1938  d_1939  d_1940  d_1941\n",
              "0        0    0    0    0    0  ...       0       3       3       0       1\n",
              "1        0    0    0    0    0  ...       0       0       0       0       0\n",
              "2        0    0    0    0    0  ...       0       2       3       0       1\n",
              "3        0    0    0    0    0  ...       1       3       0       2       6\n",
              "4        0    0    0    0    0  ...       0       0       2       1       0\n",
              "...    ...  ...  ...  ...  ...  ...     ...     ...     ...     ...     ...\n",
              "30485    0    0    2    2    0  ...       1       0       0       1       1\n",
              "30486    0    0    0    0    0  ...       0       1       0       1       0\n",
              "30487    0    6    0    2    2  ...       1       0       1       0       2\n",
              "30488    0    0    0    0    0  ...       0       1       1       1       0\n",
              "30489    0    0    0    0    0  ...       0       2       2       5       1\n",
              "\n",
              "[30490 rows x 1941 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU9cjhTbVLXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "3a2463e6-0f27-4147-c4c9-1a7490bc245b"
      },
      "source": [
        "ste_days.transpose().rolling(7).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>30450</th>\n",
              "      <th>30451</th>\n",
              "      <th>30452</th>\n",
              "      <th>30453</th>\n",
              "      <th>30454</th>\n",
              "      <th>30455</th>\n",
              "      <th>30456</th>\n",
              "      <th>30457</th>\n",
              "      <th>30458</th>\n",
              "      <th>30459</th>\n",
              "      <th>30460</th>\n",
              "      <th>30461</th>\n",
              "      <th>30462</th>\n",
              "      <th>30463</th>\n",
              "      <th>30464</th>\n",
              "      <th>30465</th>\n",
              "      <th>30466</th>\n",
              "      <th>30467</th>\n",
              "      <th>30468</th>\n",
              "      <th>30469</th>\n",
              "      <th>30470</th>\n",
              "      <th>30471</th>\n",
              "      <th>30472</th>\n",
              "      <th>30473</th>\n",
              "      <th>30474</th>\n",
              "      <th>30475</th>\n",
              "      <th>30476</th>\n",
              "      <th>30477</th>\n",
              "      <th>30478</th>\n",
              "      <th>30479</th>\n",
              "      <th>30480</th>\n",
              "      <th>30481</th>\n",
              "      <th>30482</th>\n",
              "      <th>30483</th>\n",
              "      <th>30484</th>\n",
              "      <th>30485</th>\n",
              "      <th>30486</th>\n",
              "      <th>30487</th>\n",
              "      <th>30488</th>\n",
              "      <th>30489</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d_1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1937</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>11.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>5.142857</td>\n",
              "      <td>8.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>10.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>3.285714</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1938</th>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>5.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>...</td>\n",
              "      <td>4.285714</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>10.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.571429</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1939</th>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>3.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>8.285714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>7.285714</td>\n",
              "      <td>3.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>26.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1940</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>10.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>5.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>4.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>8.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>6.714286</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>24.142857</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1941</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>13.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>4.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>6.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>...</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>7.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>7.142857</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>25.571429</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>2.714286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1941 rows × 30490 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2      ...     30487     30488     30489\n",
              "d_1          NaN       NaN       NaN  ...       NaN       NaN       NaN\n",
              "d_2          NaN       NaN       NaN  ...       NaN       NaN       NaN\n",
              "d_3          NaN       NaN       NaN  ...       NaN       NaN       NaN\n",
              "d_4          NaN       NaN       NaN  ...       NaN       NaN       NaN\n",
              "d_5          NaN       NaN       NaN  ...       NaN       NaN       NaN\n",
              "...          ...       ...       ...  ...       ...       ...       ...\n",
              "d_1937  0.857143  0.714286  0.428571  ...  0.714286  2.000000  1.714286\n",
              "d_1938  1.285714  0.714286  0.714286  ...  0.571429  2.000000  2.000000\n",
              "d_1939  1.428571  0.714286  1.000000  ...  0.714286  2.000000  2.142857\n",
              "d_1940  0.857143  0.571429  1.000000  ...  0.714286  2.000000  2.571429\n",
              "d_1941  1.000000  0.285714  0.857143  ...  0.857143  1.857143  2.714286\n",
              "\n",
              "[1941 rows x 30490 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_BW0ap_V5vG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "41793038-37d4-4f7e-bfa2-ce4a6715b669"
      },
      "source": [
        "ste_days.transpose().rolling(7).mean()[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "d_1            NaN\n",
              "d_2            NaN\n",
              "d_3            NaN\n",
              "d_4            NaN\n",
              "d_5            NaN\n",
              "            ...   \n",
              "d_1937    0.714286\n",
              "d_1938    0.714286\n",
              "d_1939    0.714286\n",
              "d_1940    0.571429\n",
              "d_1941    0.285714\n",
              "Name: 1, Length: 1941, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPfAGk5_OtZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d1ab2c16-e62b-4f59-f379-2213d8e425e2"
      },
      "source": [
        "\"\"\"for i in range(len(ste_days)):\n",
        "    if i // 1000 == i / 1000:\n",
        "        print(i)\n",
        "    tmp_df = ste_days.loc[i].rolling(7).mean()\n",
        "    tmp_df = tmp_df.fillna(0)\n",
        "    if i == 0:\n",
        "        moving_average_df = tmp_df.transpose()\n",
        "    else:\n",
        "        moving_average_df = pd.concat([moving_average_df, tmp_df.transpose()], axis=1) \n",
        "\n",
        "ジェネレータでやった方がよさげ        \n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-8cbda1737e07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mste_days\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3550\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3552\u001b[0m             \u001b[0;31m# may need to box a datelike-scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;31m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36miget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    363\u001b[0m         )\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17nfglVbQadA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "7e69cd72-ab35-40cf-99e7-3bdc8e6c7eac"
      },
      "source": [
        "# 10個分でテスト\n",
        "moving_average_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d_1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1937</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>11.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1938</th>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>5.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1939</th>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1940</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>10.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1941</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>13.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1941 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0         1         2  ...          7         8         9\n",
              "d_1     0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000\n",
              "d_2     0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000\n",
              "d_3     0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000\n",
              "d_4     0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000\n",
              "d_5     0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000\n",
              "...          ...       ...       ...  ...        ...       ...       ...\n",
              "d_1937  0.857143  0.714286  0.428571  ...  11.428571  0.142857  0.714286\n",
              "d_1938  1.285714  0.714286  0.714286  ...   5.285714  0.142857  0.714286\n",
              "d_1939  1.428571  0.714286  1.000000  ...   4.428571  0.000000  0.714286\n",
              "d_1940  0.857143  0.571429  1.000000  ...  10.142857  0.142857  0.714286\n",
              "d_1941  1.000000  0.285714  0.857143  ...  13.857143  0.142857  0.714286\n",
              "\n",
              "[1941 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg8FLgdYKqSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1CuMRznK7iA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba74675c-bf3e-4787-d3d6-b6b9c50e7308"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkGgdpfkK-B2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a27075f2-4dcf-4084-b96d-9da808ea730e"
      },
      "source": [
        "os.path.isdir(\"./training_datas\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rba6L0nXnUf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"./training_datas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQMBiNd9LTC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "15d98221-178d-462d-808d-eb0d81cede9f"
      },
      "source": [
        "\"\"\"\n",
        "保存名は \n",
        "df.to_pickle(OUTPUT_PATH + \"train_data\" + str(i) + \".zip\")ではなく\n",
        "df.to_pickle(OUTPUT_PATH + \"train_data\" + [idカラムの名前] + \".zip\")とできるようにした方が良いかもしれない。\n",
        "\"\"\"\n",
        "\n",
        "OUTPUT_PATH = \"./training_datas/\"\n",
        "tdg = train_df_generator(item_cat_df, cal, ste_days)\n",
        "shape_list = []\n",
        "for i, df in enumerate(tdg):\n",
        "     if i / 1000 == i // 1000:\n",
        "         print(i)\n",
        "     #df.to_csv(OUTPUT_PATH + \"train_data\" + str(i) + \".csv\", index=False, compression=\"zip\")\n",
        "     df.to_pickle(OUTPUT_PATH + \"train_data\" + str(i) + \".zip\")\n",
        "     shape_list.append(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG8kEeVpnivv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "048c3085-b5fc-4615-edab-17148ec3b44f"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with zipfile.ZipFile(\"./training_datas/train_data0.zip\") as zip:\n",
        "    for info in zip.infolist():\n",
        "        if info.is_dir():\n",
        "            continue\n",
        "        data = pickle.loads(zip.read(info.filename))\n",
        "        print(\"\\n\", data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...         0     price  sale\n",
            "0           0        0        0  ...  0.000000  0.000000   0.0\n",
            "1           0        0        0  ...  0.000000  0.000000   0.0\n",
            "2           0        0        0  ...  0.000000  0.000000   0.0\n",
            "3           1        1        0  ...  0.000000  0.000000   0.0\n",
            "4           1        0        1  ...  0.000000  0.000000   0.0\n",
            "...       ...      ...      ...  ...       ...       ...   ...\n",
            "1936        0        0        0  ...  1.100000  8.382812   0.0\n",
            "1937        0        0        0  ...  1.166667  8.382812   3.0\n",
            "1938        0        0        0  ...  1.233333  8.382812   3.0\n",
            "1939        0        0        0  ...  1.133333  8.382812   0.0\n",
            "1940        0        0        0  ...  1.166667  8.382812   1.0\n",
            "\n",
            "[1941 rows x 70 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DdIqabDohUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "listdir = os.listdir(\"./training_datas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZsIcLiyosgv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "3d3e8fd9-0704-4963-d372-e06b75bd905f"
      },
      "source": [
        "# 以下二つは、作成したpickleファイルからジェネレートする際に必要\n",
        "\n",
        "listdir.sort()\n",
        "listdir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_data0.zip',\n",
              " 'train_data1.zip',\n",
              " 'train_data2.zip',\n",
              " 'train_data3.zip',\n",
              " 'train_data4.zip',\n",
              " 'train_data5.zip',\n",
              " 'train_data6.zip',\n",
              " 'train_data7.zip',\n",
              " 'train_data8.zip',\n",
              " 'train_data9.zip']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqR8XOJdpBST",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c5dfbdb-c9e2-4b0d-d51e-73d833a652b4"
      },
      "source": [
        "for i in range(len(listdir)):\n",
        "    with zipfile.ZipFile(\"./training_datas/\" + listdir[i]) as zip:\n",
        "        for info in zip.infolist():\n",
        "            if info.is_dir():\n",
        "                continue\n",
        "            data = pickle.loads(zip.read(info.filename))\n",
        "            print(\"\\n\", data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  8.382812   0.0\n",
            "1965        0        0        0  ...   0  8.382812   0.0\n",
            "1966        0        0        0  ...   0  8.382812   0.0\n",
            "1967        0        0        0  ...   0  8.382812   0.0\n",
            "1968        0        0        0  ...   0  8.382812   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  3.970703   0.0\n",
            "1965        0        0        0  ...   0  3.970703   0.0\n",
            "1966        0        0        0  ...   0  3.970703   0.0\n",
            "1967        0        0        0  ...   0  3.970703   0.0\n",
            "1968        0        0        0  ...   0  3.970703   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  3.480469   0.0\n",
            "1965        0        0        0  ...   0  3.480469   0.0\n",
            "1966        0        0        0  ...   0  3.480469   0.0\n",
            "1967        0        0        0  ...   0  3.480469   0.0\n",
            "1968        0        0        0  ...   0  3.480469   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  6.441406   0.0\n",
            "1           0        0        0  ...   0  6.441406   0.0\n",
            "2           0        0        0  ...   0  6.441406   1.0\n",
            "3           1        1        0  ...   0  6.441406   3.0\n",
            "4           1        0        1  ...   0  6.441406   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  6.679688   0.0\n",
            "1965        0        0        0  ...   0  6.679688   0.0\n",
            "1966        0        0        0  ...   0  6.679688   0.0\n",
            "1967        0        0        0  ...   0  6.679688   0.0\n",
            "1968        0        0        0  ...   0  6.679688   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  1.969727   0.0\n",
            "1965        0        0        0  ...   0  1.969727   0.0\n",
            "1966        0        0        0  ...   0  1.969727   0.0\n",
            "1967        0        0        0  ...   0  1.969727   0.0\n",
            "1968        0        0        0  ...   0  1.969727   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  2.980469   0.0\n",
            "1965        0        0        0  ...   0  2.980469   0.0\n",
            "1966        0        0        0  ...   0  2.980469   0.0\n",
            "1967        0        0        0  ...   0  2.980469   0.0\n",
            "1968        0        0        0  ...   0  2.980469   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22    price  sale\n",
            "0           0        0        0  ...   0  0.00000   0.0\n",
            "1           0        0        0  ...   0  0.00000   0.0\n",
            "2           0        0        0  ...   0  0.00000   0.0\n",
            "3           1        1        0  ...   0  0.00000   0.0\n",
            "4           1        0        1  ...   0  0.00000   0.0\n",
            "...       ...      ...      ...  ...  ..      ...   ...\n",
            "1964        0        1        1  ...   0  4.96875   0.0\n",
            "1965        0        0        0  ...   0  4.96875   0.0\n",
            "1966        0        0        0  ...   0  4.96875   0.0\n",
            "1967        0        0        0  ...   0  4.96875   0.0\n",
            "1968        0        0        0  ...   0  4.96875   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  7.941406   0.0\n",
            "1965        0        0        0  ...   0  7.941406   0.0\n",
            "1966        0        0        0  ...   0  7.941406   0.0\n",
            "1967        0        0        0  ...   0  7.941406   0.0\n",
            "1968        0        0        0  ...   0  7.941406   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  3.720703   0.0\n",
            "1965        0        0        0  ...   0  3.720703   0.0\n",
            "1966        0        0        0  ...   0  3.720703   0.0\n",
            "1967        0        0        0  ...   0  3.720703   0.0\n",
            "1968        0        0        0  ...   0  3.720703   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  5.269531   0.0\n",
            "1965        0        0        0  ...   0  5.269531   0.0\n",
            "1966        0        0        0  ...   0  5.269531   0.0\n",
            "1967        0        0        0  ...   0  5.269531   0.0\n",
            "1968        0        0        0  ...   0  5.269531   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-5s0i6aRno8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "850ab82c-78dd-44e1-90f9-93046a3200f9"
      },
      "source": [
        "!zip -r training_datas.zip ./training_datas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "  adding: training_datas/train_data22586.zip (stored 0%)\n",
            "  adding: training_datas/train_data4114.zip (stored 0%)\n",
            "  adding: training_datas/train_data28298.zip (stored 0%)\n",
            "  adding: training_datas/train_data21834.zip (stored 0%)\n",
            "  adding: training_datas/train_data30159.zip (stored 0%)\n",
            "  adding: training_datas/train_data27591.zip (stored 0%)\n",
            "  adding: training_datas/train_data19314.zip (stored 0%)\n",
            "  adding: training_datas/train_data24863.zip (stored 0%)\n",
            "  adding: training_datas/train_data20693.zip (stored 0%)\n",
            "  adding: training_datas/train_data16423.zip (stored 0%)\n",
            "  adding: training_datas/train_data2086.zip (stored 0%)\n",
            "  adding: training_datas/train_data14186.zip (stored 0%)\n",
            "  adding: training_datas/train_data5602.zip (stored 0%)\n",
            "  adding: training_datas/train_data9052.zip (stored 0%)\n",
            "  adding: training_datas/train_data15380.zip (stored 0%)\n",
            "  adding: training_datas/train_data10922.zip (stored 0%)\n",
            "  adding: training_datas/train_data7026.zip (stored 0%)\n",
            "  adding: training_datas/train_data8418.zip (stored 0%)\n",
            "  adding: training_datas/train_data16488.zip (stored 0%)\n",
            "  adding: training_datas/train_data1763.zip (stored 0%)\n",
            "  adding: training_datas/train_data27281.zip (stored 0%)\n",
            "  adding: training_datas/train_data252.zip (stored 0%)\n",
            "  adding: training_datas/train_data6375.zip (stored 0%)\n",
            "  adding: training_datas/train_data26715.zip (stored 0%)\n",
            "  adding: training_datas/train_data2131.zip (stored 0%)\n",
            "  adding: training_datas/train_data1374.zip (stored 0%)\n",
            "  adding: training_datas/train_data2741.zip (stored 0%)\n",
            "  adding: training_datas/train_data5359.zip (stored 0%)\n",
            "  adding: training_datas/train_data3816.zip (stored 0%)\n",
            "  adding: training_datas/train_data821.zip (stored 0%)\n",
            "  adding: training_datas/train_data19134.zip (stored 0%)\n",
            "  adding: training_datas/train_data23632.zip (stored 0%)\n",
            "  adding: training_datas/train_data435.zip (stored 0%)\n",
            "  adding: training_datas/train_data15519.zip (stored 0%)\n",
            "  adding: training_datas/train_data23645.zip (stored 0%)\n",
            "  adding: training_datas/train_data22981.zip (stored 0%)\n",
            "  adding: training_datas/train_data15199.zip (stored 0%)\n",
            "  adding: training_datas/train_data25939.zip (stored 0%)\n",
            "  adding: training_datas/train_data5234.zip (stored 0%)\n",
            "  adding: training_datas/train_data28420.zip (stored 0%)\n",
            "  adding: training_datas/train_data4113.zip (stored 0%)\n",
            "  adding: training_datas/train_data24443.zip (stored 0%)\n",
            "  adding: training_datas/train_data30467.zip (stored 0%)\n",
            "  adding: training_datas/train_data18116.zip (stored 0%)\n",
            "  adding: training_datas/train_data20478.zip (stored 0%)\n",
            "  adding: training_datas/train_data25491.zip (stored 0%)\n",
            "  adding: training_datas/train_data13406.zip (stored 0%)\n",
            "  adding: training_datas/train_data24513.zip (stored 0%)\n",
            "  adding: training_datas/train_data1999.zip (stored 0%)\n",
            "  adding: training_datas/train_data23669.zip (stored 0%)\n",
            "  adding: training_datas/train_data10201.zip (stored 0%)\n",
            "  adding: training_datas/train_data28786.zip (stored 0%)\n",
            "  adding: training_datas/train_data5837.zip (stored 0%)\n",
            "  adding: training_datas/train_data14992.zip (stored 0%)\n",
            "  adding: training_datas/train_data22506.zip (stored 0%)\n",
            "  adding: training_datas/train_data15974.zip (stored 0%)\n",
            "  adding: training_datas/train_data28741.zip (stored 0%)\n",
            "  adding: training_datas/train_data25498.zip (stored 0%)\n",
            "  adding: training_datas/train_data22509.zip (stored 0%)\n",
            "  adding: training_datas/train_data15640.zip (stored 0%)\n",
            "  adding: training_datas/train_data13594.zip (stored 0%)\n",
            "  adding: training_datas/train_data4074.zip (stored 0%)\n",
            "  adding: training_datas/train_data24277.zip (stored 0%)\n",
            "  adding: training_datas/train_data304.zip (stored 0%)\n",
            "  adding: training_datas/train_data8514.zip (stored 0%)\n",
            "  adding: training_datas/train_data19999.zip (stored 0%)\n",
            "  adding: training_datas/train_data13254.zip (stored 0%)\n",
            "  adding: training_datas/train_data25154.zip (stored 0%)\n",
            "  adding: training_datas/train_data18783.zip (stored 0%)\n",
            "  adding: training_datas/train_data13290.zip (stored 0%)\n",
            "  adding: training_datas/train_data24569.zip (stored 0%)\n",
            "  adding: training_datas/train_data5435.zip (stored 0%)\n",
            "  adding: training_datas/train_data19872.zip (stored 0%)\n",
            "  adding: training_datas/train_data11349.zip (stored 0%)\n",
            "  adding: training_datas/train_data9169.zip (stored 0%)\n",
            "  adding: training_datas/train_data19200.zip (stored 0%)\n",
            "  adding: training_datas/train_data11995.zip (stored 0%)\n",
            "  adding: training_datas/train_data14449.zip (stored 0%)\n",
            "  adding: training_datas/train_data3375.zip (stored 0%)\n",
            "  adding: training_datas/train_data12001.zip (stored 0%)\n",
            "  adding: training_datas/train_data14741.zip (stored 0%)\n",
            "  adding: training_datas/train_data14099.zip (stored 0%)\n",
            "  adding: training_datas/train_data16977.zip (stored 0%)\n",
            "  adding: training_datas/train_data1679.zip (stored 0%)\n",
            "  adding: training_datas/train_data17311.zip (stored 0%)\n",
            "  adding: training_datas/train_data18591.zip (stored 0%)\n",
            "  adding: training_datas/train_data11743.zip (stored 0%)\n",
            "  adding: training_datas/train_data7454.zip (stored 0%)\n",
            "  adding: training_datas/train_data18996.zip (stored 0%)\n",
            "  adding: training_datas/train_data10795.zip (stored 0%)\n",
            "  adding: training_datas/train_data23049.zip (stored 0%)\n",
            "  adding: training_datas/train_data11167.zip (stored 0%)\n",
            "  adding: training_datas/train_data2942.zip (stored 0%)\n",
            "  adding: training_datas/train_data881.zip (stored 0%)\n",
            "  adding: training_datas/train_data4190.zip (stored 0%)\n",
            "  adding: training_datas/train_data28832.zip (stored 0%)\n",
            "  adding: training_datas/train_data17125.zip (stored 0%)\n",
            "  adding: training_datas/train_data22763.zip (stored 0%)\n",
            "  adding: training_datas/train_data25336.zip (stored 0%)\n",
            "  adding: training_datas/train_data8087.zip (stored 0%)\n",
            "  adding: training_datas/train_data7669.zip (stored 0%)\n",
            "  adding: training_datas/train_data10084.zip (stored 0%)\n",
            "  adding: training_datas/train_data1798.zip (stored 0%)\n",
            "  adding: training_datas/train_data7096.zip (stored 0%)\n",
            "  adding: training_datas/train_data20311.zip (stored 0%)\n",
            "  adding: training_datas/train_data15744.zip (stored 0%)\n",
            "  adding: training_datas/train_data14400.zip (stored 0%)\n",
            "  adding: training_datas/train_data9405.zip (stored 0%)\n",
            "  adding: training_datas/train_data7009.zip (stored 0%)\n",
            "  adding: training_datas/train_data9818.zip (stored 0%)\n",
            "  adding: training_datas/train_data1904.zip (stored 0%)\n",
            "  adding: training_datas/train_data22548.zip (stored 0%)\n",
            "  adding: training_datas/train_data6536.zip (stored 0%)\n",
            "  adding: training_datas/train_data15782.zip (stored 0%)\n",
            "  adding: training_datas/train_data3605.zip (stored 0%)\n",
            "  adding: training_datas/train_data5122.zip (stored 0%)\n",
            "  adding: training_datas/train_data7522.zip (stored 0%)\n",
            "  adding: training_datas/train_data3183.zip (stored 0%)\n",
            "  adding: training_datas/train_data3795.zip (stored 0%)\n",
            "  adding: training_datas/train_data8580.zip (stored 0%)\n",
            "  adding: training_datas/train_data28216.zip (stored 0%)\n",
            "  adding: training_datas/train_data15262.zip (stored 0%)\n",
            "  adding: training_datas/train_data9958.zip (stored 0%)\n",
            "  adding: training_datas/train_data17442.zip (stored 0%)\n",
            "  adding: training_datas/train_data15675.zip (stored 0%)\n",
            "  adding: training_datas/train_data7402.zip (stored 0%)\n",
            "  adding: training_datas/train_data14900.zip (stored 0%)\n",
            "  adding: training_datas/train_data17399.zip (stored 0%)\n",
            "  adding: training_datas/train_data20862.zip (stored 0%)\n",
            "  adding: training_datas/train_data21078.zip (stored 0%)\n",
            "  adding: training_datas/train_data14999.zip (stored 0%)\n",
            "  adding: training_datas/train_data20109.zip (stored 0%)\n",
            "  adding: training_datas/train_data7450.zip (stored 0%)\n",
            "  adding: training_datas/train_data30129.zip (stored 0%)\n",
            "  adding: training_datas/train_data6161.zip (stored 0%)\n",
            "  adding: training_datas/train_data9573.zip (stored 0%)\n",
            "  adding: training_datas/train_data20733.zip (stored 0%)\n",
            "  adding: training_datas/train_data12147.zip (stored 0%)\n",
            "  adding: training_datas/train_data5622.zip (stored 0%)\n",
            "  adding: training_datas/train_data26338.zip (stored 0%)\n",
            "  adding: training_datas/train_data13642.zip (stored 0%)\n",
            "  adding: training_datas/train_data1183.zip (stored 0%)\n",
            "  adding: training_datas/train_data28082.zip (stored 0%)\n",
            "  adding: training_datas/train_data21312.zip (stored 0%)\n",
            "  adding: training_datas/train_data24042.zip (stored 0%)\n",
            "  adding: training_datas/train_data7726.zip (stored 0%)\n",
            "  adding: training_datas/train_data24485.zip (stored 0%)\n",
            "  adding: training_datas/train_data20207.zip (stored 0%)\n",
            "  adding: training_datas/train_data19957.zip (stored 0%)\n",
            "  adding: training_datas/train_data15494.zip (stored 0%)\n",
            "  adding: training_datas/train_data24920.zip (stored 0%)\n",
            "  adding: training_datas/train_data1341.zip (stored 0%)\n",
            "  adding: training_datas/train_data5109.zip (stored 0%)\n",
            "  adding: training_datas/train_data25963.zip (stored 0%)\n",
            "  adding: training_datas/train_data8880.zip (stored 0%)\n",
            "  adding: training_datas/train_data22186.zip (stored 0%)\n",
            "  adding: training_datas/train_data38.zip (stored 0%)\n",
            "  adding: training_datas/train_data8887.zip (stored 0%)\n",
            "  adding: training_datas/train_data18700.zip (stored 0%)\n",
            "  adding: training_datas/train_data3140.zip (stored 0%)\n",
            "  adding: training_datas/train_data25365.zip (stored 0%)\n",
            "  adding: training_datas/train_data2478.zip (stored 0%)\n",
            "  adding: training_datas/train_data3849.zip (stored 0%)\n",
            "  adding: training_datas/train_data19026.zip (stored 0%)\n",
            "  adding: training_datas/train_data19565.zip (stored 0%)\n",
            "  adding: training_datas/train_data22089.zip (stored 0%)\n",
            "  adding: training_datas/train_data94.zip (stored 0%)\n",
            "  adding: training_datas/train_data823.zip (stored 0%)\n",
            "  adding: training_datas/train_data27065.zip (stored 0%)\n",
            "  adding: training_datas/train_data23637.zip (stored 0%)\n",
            "  adding: training_datas/train_data1326.zip (stored 0%)\n",
            "  adding: training_datas/train_data322.zip (stored 0%)\n",
            "  adding: training_datas/train_data25404.zip (stored 0%)\n",
            "  adding: training_datas/train_data12204.zip (stored 0%)\n",
            "  adding: training_datas/train_data13144.zip (stored 0%)\n",
            "  adding: training_datas/train_data13020.zip (stored 0%)\n",
            "  adding: training_datas/train_data1995.zip (stored 0%)\n",
            "  adding: training_datas/train_data15305.zip (stored 0%)\n",
            "  adding: training_datas/train_data29019.zip (stored 0%)\n",
            "  adding: training_datas/train_data22769.zip (stored 0%)\n",
            "  adding: training_datas/train_data11313.zip (stored 0%)\n",
            "  adding: training_datas/train_data21405.zip (stored 0%)\n",
            "  adding: training_datas/train_data7517.zip (stored 0%)\n",
            "  adding: training_datas/train_data1791.zip (stored 0%)\n",
            "  adding: training_datas/train_data18908.zip (stored 0%)\n",
            "  adding: training_datas/train_data21199.zip (stored 0%)\n",
            "  adding: training_datas/train_data14487.zip (stored 0%)\n",
            "  adding: training_datas/train_data16769.zip (stored 0%)\n",
            "  adding: training_datas/train_data601.zip (stored 0%)\n",
            "  adding: training_datas/train_data6776.zip (stored 0%)\n",
            "  adding: training_datas/train_data25094.zip (stored 0%)\n",
            "  adding: training_datas/train_data18906.zip (stored 0%)\n",
            "  adding: training_datas/train_data5858.zip (stored 0%)\n",
            "  adding: training_datas/train_data6340.zip (stored 0%)\n",
            "  adding: training_datas/train_data21285.zip (stored 0%)\n",
            "  adding: training_datas/train_data27252.zip (stored 0%)\n",
            "  adding: training_datas/train_data11117.zip (stored 0%)\n",
            "  adding: training_datas/train_data22656.zip (stored 0%)\n",
            "  adding: training_datas/train_data12673.zip (stored 0%)\n",
            "  adding: training_datas/train_data26986.zip (stored 0%)\n",
            "  adding: training_datas/train_data3937.zip (stored 0%)\n",
            "  adding: training_datas/train_data9923.zip (stored 0%)\n",
            "  adding: training_datas/train_data28848.zip (stored 0%)\n",
            "  adding: training_datas/train_data29324.zip (stored 0%)\n",
            "  adding: training_datas/train_data6688.zip (stored 0%)\n",
            "  adding: training_datas/train_data11716.zip (stored 0%)\n",
            "  adding: training_datas/train_data6182.zip (stored 0%)\n",
            "  adding: training_datas/train_data16964.zip (stored 0%)\n",
            "  adding: training_datas/train_data23231.zip (stored 0%)\n",
            "  adding: training_datas/train_data13731.zip (stored 0%)\n",
            "  adding: training_datas/train_data3908.zip (stored 0%)\n",
            "  adding: training_datas/train_data21473.zip (stored 0%)\n",
            "  adding: training_datas/train_data1880.zip (stored 0%)\n",
            "  adding: training_datas/train_data22756.zip (stored 0%)\n",
            "  adding: training_datas/train_data30021.zip (stored 0%)\n",
            "  adding: training_datas/train_data13794.zip (stored 0%)\n",
            "  adding: training_datas/train_data23440.zip (stored 0%)\n",
            "  adding: training_datas/train_data3236.zip (stored 0%)\n",
            "  adding: training_datas/train_data26233.zip (stored 0%)\n",
            "  adding: training_datas/train_data7024.zip (stored 0%)\n",
            "  adding: training_datas/train_data10348.zip (stored 0%)\n",
            "  adding: training_datas/train_data2806.zip (stored 0%)\n",
            "  adding: training_datas/train_data24088.zip (stored 0%)\n",
            "  adding: training_datas/train_data27509.zip (stored 0%)\n",
            "  adding: training_datas/train_data17747.zip (stored 0%)\n",
            "  adding: training_datas/train_data24098.zip (stored 0%)\n",
            "  adding: training_datas/train_data29330.zip (stored 0%)\n",
            "  adding: training_datas/train_data1529.zip (stored 0%)\n",
            "  adding: training_datas/train_data24007.zip (stored 0%)\n",
            "  adding: training_datas/train_data16503.zip (stored 0%)\n",
            "  adding: training_datas/train_data16551.zip (stored 0%)\n",
            "  adding: training_datas/train_data16035.zip (stored 0%)\n",
            "  adding: training_datas/train_data11518.zip (stored 0%)\n",
            "  adding: training_datas/train_data29651.zip (stored 0%)\n",
            "  adding: training_datas/train_data18407.zip (stored 0%)\n",
            "  adding: training_datas/train_data27365.zip (stored 0%)\n",
            "  adding: training_datas/train_data11508.zip (stored 0%)\n",
            "  adding: training_datas/train_data3655.zip (stored 0%)\n",
            "  adding: training_datas/train_data19527.zip (stored 0%)\n",
            "  adding: training_datas/train_data9555.zip (stored 0%)\n",
            "  adding: training_datas/train_data23644.zip (stored 0%)\n",
            "  adding: training_datas/train_data24464.zip (stored 0%)\n",
            "  adding: training_datas/train_data12125.zip (stored 0%)\n",
            "  adding: training_datas/train_data14136.zip (stored 0%)\n",
            "  adding: training_datas/train_data23918.zip (stored 0%)\n",
            "  adding: training_datas/train_data6187.zip (stored 0%)\n",
            "  adding: training_datas/train_data21659.zip (stored 0%)\n",
            "  adding: training_datas/train_data13644.zip (stored 0%)\n",
            "  adding: training_datas/train_data5395.zip (stored 0%)\n",
            "  adding: training_datas/train_data7393.zip (stored 0%)\n",
            "  adding: training_datas/train_data2230.zip (stored 0%)\n",
            "  adding: training_datas/train_data15132.zip (stored 0%)\n",
            "  adding: training_datas/train_data4084.zip (stored 0%)\n",
            "  adding: training_datas/train_data26821.zip (stored 0%)\n",
            "  adding: training_datas/train_data14758.zip (stored 0%)\n",
            "  adding: training_datas/train_data3029.zip (stored 0%)\n",
            "  adding: training_datas/train_data16738.zip (stored 0%)\n",
            "  adding: training_datas/train_data1524.zip (stored 0%)\n",
            "  adding: training_datas/train_data1035.zip (stored 0%)\n",
            "  adding: training_datas/train_data14067.zip (stored 0%)\n",
            "  adding: training_datas/train_data1737.zip (stored 0%)\n",
            "  adding: training_datas/train_data27248.zip (stored 0%)\n",
            "  adding: training_datas/train_data15755.zip (stored 0%)\n",
            "  adding: training_datas/train_data7381.zip (stored 0%)\n",
            "  adding: training_datas/train_data13362.zip (stored 0%)\n",
            "  adding: training_datas/train_data18916.zip (stored 0%)\n",
            "  adding: training_datas/train_data21390.zip (stored 0%)\n",
            "  adding: training_datas/train_data13160.zip (stored 0%)\n",
            "  adding: training_datas/train_data25831.zip (stored 0%)\n",
            "  adding: training_datas/train_data15855.zip (stored 0%)\n",
            "  adding: training_datas/train_data16395.zip (stored 0%)\n",
            "  adding: training_datas/train_data20015.zip (stored 0%)\n",
            "  adding: training_datas/train_data22392.zip (stored 0%)\n",
            "  adding: training_datas/train_data28952.zip (stored 0%)\n",
            "  adding: training_datas/train_data542.zip (stored 0%)\n",
            "  adding: training_datas/train_data29681.zip (stored 0%)\n",
            "  adding: training_datas/train_data12313.zip (stored 0%)\n",
            "  adding: training_datas/train_data15241.zip (stored 0%)\n",
            "  adding: training_datas/train_data27060.zip (stored 0%)\n",
            "  adding: training_datas/train_data28477.zip (stored 0%)\n",
            "  adding: training_datas/train_data8599.zip (stored 0%)\n",
            "  adding: training_datas/train_data19350.zip (stored 0%)\n",
            "  adding: training_datas/train_data14492.zip (stored 0%)\n",
            "  adding: training_datas/train_data15954.zip (stored 0%)\n",
            "  adding: training_datas/train_data22885.zip (stored 0%)\n",
            "  adding: training_datas/train_data16484.zip (stored 0%)\n",
            "  adding: training_datas/train_data5741.zip (stored 0%)\n",
            "  adding: training_datas/train_data12944.zip (stored 0%)\n",
            "  adding: training_datas/train_data23054.zip (stored 0%)\n",
            "  adding: training_datas/train_data18001.zip (stored 0%)\n",
            "  adding: training_datas/train_data20626.zip (stored 0%)\n",
            "  adding: training_datas/train_data25636.zip (stored 0%)\n",
            "  adding: training_datas/train_data24739.zip (stored 0%)\n",
            "  adding: training_datas/train_data10572.zip (stored 0%)\n",
            "  adding: training_datas/train_data15699.zip (stored 0%)\n",
            "  adding: training_datas/train_data16358.zip (stored 0%)\n",
            "  adding: training_datas/train_data4667.zip (stored 0%)\n",
            "  adding: training_datas/train_data25069.zip (stored 0%)\n",
            "  adding: training_datas/train_data3123.zip (stored 0%)\n",
            "  adding: training_datas/train_data3985.zip (stored 0%)\n",
            "  adding: training_datas/train_data3869.zip (stored 0%)\n",
            "  adding: training_datas/train_data5428.zip (stored 0%)\n",
            "  adding: training_datas/train_data16575.zip (stored 0%)\n",
            "  adding: training_datas/train_data20644.zip (stored 0%)\n",
            "  adding: training_datas/train_data25160.zip (stored 0%)\n",
            "  adding: training_datas/train_data3789.zip (stored 0%)\n",
            "  adding: training_datas/train_data23842.zip (stored 0%)\n",
            "  adding: training_datas/train_data1273.zip (stored 0%)\n",
            "  adding: training_datas/train_data12370.zip (stored 0%)\n",
            "  adding: training_datas/train_data9920.zip (stored 0%)\n",
            "  adding: training_datas/train_data13323.zip (stored 0%)\n",
            "  adding: training_datas/train_data13669.zip (stored 0%)\n",
            "  adding: training_datas/train_data17225.zip (stored 0%)\n",
            "  adding: training_datas/train_data26583.zip (stored 0%)\n",
            "  adding: training_datas/train_data6849.zip (stored 0%)\n",
            "  adding: training_datas/train_data12385.zip (stored 0%)\n",
            "  adding: training_datas/train_data19612.zip (stored 0%)\n",
            "  adding: training_datas/train_data11047.zip (stored 0%)\n",
            "  adding: training_datas/train_data24428.zip (stored 0%)\n",
            "  adding: training_datas/train_data10203.zip (stored 0%)\n",
            "  adding: training_datas/train_data59.zip (stored 0%)\n",
            "  adding: training_datas/train_data14069.zip (stored 0%)\n",
            "  adding: training_datas/train_data9800.zip (stored 0%)\n",
            "  adding: training_datas/train_data11554.zip (stored 0%)\n",
            "  adding: training_datas/train_data24683.zip (stored 0%)\n",
            "  adding: training_datas/train_data21083.zip (stored 0%)\n",
            "  adding: training_datas/train_data29959.zip (stored 0%)\n",
            "  adding: training_datas/train_data29468.zip (stored 0%)\n",
            "  adding: training_datas/train_data28990.zip (stored 0%)\n",
            "  adding: training_datas/train_data15225.zip (stored 0%)\n",
            "  adding: training_datas/train_data11381.zip (stored 0%)\n",
            "  adding: training_datas/train_data25539.zip (stored 0%)\n",
            "  adding: training_datas/train_data4766.zip (stored 0%)\n",
            "  adding: training_datas/train_data7653.zip (stored 0%)\n",
            "  adding: training_datas/train_data5664.zip (stored 0%)\n",
            "  adding: training_datas/train_data28047.zip (stored 0%)\n",
            "  adding: training_datas/train_data7292.zip (stored 0%)\n",
            "  adding: training_datas/train_data28146.zip (stored 0%)\n",
            "  adding: training_datas/train_data19929.zip (stored 0%)\n",
            "  adding: training_datas/train_data27153.zip (stored 0%)\n",
            "  adding: training_datas/train_data11533.zip (stored 0%)\n",
            "  adding: training_datas/train_data27224.zip (stored 0%)\n",
            "  adding: training_datas/train_data21263.zip (stored 0%)\n",
            "  adding: training_datas/train_data3958.zip (stored 0%)\n",
            "  adding: training_datas/train_data20897.zip (stored 0%)\n",
            "  adding: training_datas/train_data2104.zip (stored 0%)\n",
            "  adding: training_datas/train_data29458.zip (stored 0%)\n",
            "  adding: training_datas/train_data16885.zip (stored 0%)\n",
            "  adding: training_datas/train_data26875.zip (stored 0%)\n",
            "  adding: training_datas/train_data8924.zip (stored 0%)\n",
            "  adding: training_datas/train_data18960.zip (stored 0%)\n",
            "  adding: training_datas/train_data13950.zip (stored 0%)\n",
            "  adding: training_datas/train_data15861.zip (stored 0%)\n",
            "  adding: training_datas/train_data22901.zip (stored 0%)\n",
            "  adding: training_datas/train_data5113.zip (stored 0%)\n",
            "  adding: training_datas/train_data3964.zip (stored 0%)\n",
            "  adding: training_datas/train_data29880.zip (stored 0%)\n",
            "  adding: training_datas/train_data706.zip (stored 0%)\n",
            "  adding: training_datas/train_data16524.zip (stored 0%)\n",
            "  adding: training_datas/train_data17193.zip (stored 0%)\n",
            "  adding: training_datas/train_data7286.zip (stored 0%)\n",
            "  adding: training_datas/train_data9021.zip (stored 0%)\n",
            "  adding: training_datas/train_data14803.zip (stored 0%)\n",
            "  adding: training_datas/train_data18766.zip (stored 0%)\n",
            "  adding: training_datas/train_data2609.zip (stored 0%)\n",
            "  adding: training_datas/train_data28654.zip (stored 0%)\n",
            "  adding: training_datas/train_data2692.zip (stored 0%)\n",
            "  adding: training_datas/train_data28325.zip (stored 0%)\n",
            "  adding: training_datas/train_data22227.zip (stored 0%)\n",
            "  adding: training_datas/train_data18929.zip (stored 0%)\n",
            "  adding: training_datas/train_data28327.zip (stored 0%)\n",
            "  adding: training_datas/train_data27466.zip (stored 0%)\n",
            "  adding: training_datas/train_data4656.zip (stored 0%)\n",
            "  adding: training_datas/train_data23545.zip (stored 0%)\n",
            "  adding: training_datas/train_data17431.zip (stored 0%)\n",
            "  adding: training_datas/train_data1191.zip (stored 0%)\n",
            "  adding: training_datas/train_data9663.zip (stored 0%)\n",
            "  adding: training_datas/train_data29861.zip (stored 0%)\n",
            "  adding: training_datas/train_data2295.zip (stored 0%)\n",
            "  adding: training_datas/train_data30242.zip (stored 0%)\n",
            "  adding: training_datas/train_data21112.zip (stored 0%)\n",
            "  adding: training_datas/train_data18925.zip (stored 0%)\n",
            "  adding: training_datas/train_data4343.zip (stored 0%)\n",
            "  adding: training_datas/train_data378.zip (stored 0%)\n",
            "  adding: training_datas/train_data26665.zip (stored 0%)\n",
            "  adding: training_datas/train_data15577.zip (stored 0%)\n",
            "  adding: training_datas/train_data22043.zip (stored 0%)\n",
            "  adding: training_datas/train_data15583.zip (stored 0%)\n",
            "  adding: training_datas/train_data6672.zip (stored 0%)\n",
            "  adding: training_datas/train_data2424.zip (stored 0%)\n",
            "  adding: training_datas/train_data24401.zip (stored 0%)\n",
            "  adding: training_datas/train_data14394.zip (stored 0%)\n",
            "  adding: training_datas/train_data29702.zip (stored 0%)\n",
            "  adding: training_datas/train_data4593.zip (stored 0%)\n",
            "  adding: training_datas/train_data24289.zip (stored 0%)\n",
            "  adding: training_datas/train_data20833.zip (stored 0%)\n",
            "  adding: training_datas/train_data3352.zip (stored 0%)\n",
            "  adding: training_datas/train_data21201.zip (stored 0%)\n",
            "  adding: training_datas/train_data5540.zip (stored 0%)\n",
            "  adding: training_datas/train_data13597.zip (stored 0%)\n",
            "  adding: training_datas/train_data20661.zip (stored 0%)\n",
            "  adding: training_datas/train_data19671.zip (stored 0%)\n",
            "  adding: training_datas/train_data22150.zip (stored 0%)\n",
            "  adding: training_datas/train_data16904.zip (stored 0%)\n",
            "  adding: training_datas/train_data7116.zip (stored 0%)\n",
            "  adding: training_datas/train_data28397.zip (stored 0%)\n",
            "  adding: training_datas/train_data3445.zip (stored 0%)\n",
            "  adding: training_datas/train_data2626.zip (stored 0%)\n",
            "  adding: training_datas/train_data20936.zip (stored 0%)\n",
            "  adding: training_datas/train_data15772.zip (stored 0%)\n",
            "  adding: training_datas/train_data27832.zip (stored 0%)\n",
            "  adding: training_datas/train_data20503.zip (stored 0%)\n",
            "  adding: training_datas/train_data14205.zip (stored 0%)\n",
            "  adding: training_datas/train_data17633.zip (stored 0%)\n",
            "  adding: training_datas/train_data5835.zip (stored 0%)\n",
            "  adding: training_datas/train_data26308.zip (stored 0%)\n",
            "  adding: training_datas/train_data5104.zip (stored 0%)\n",
            "  adding: training_datas/train_data5628.zip (stored 0%)\n",
            "  adding: training_datas/train_data5364.zip (stored 0%)\n",
            "  adding: training_datas/train_data1145.zip (stored 0%)\n",
            "  adding: training_datas/train_data9248.zip (stored 0%)\n",
            "  adding: training_datas/train_data5832.zip (stored 0%)\n",
            "  adding: training_datas/train_data1530.zip (stored 0%)\n",
            "  adding: training_datas/train_data10408.zip (stored 0%)\n",
            "  adding: training_datas/train_data17561.zip (stored 0%)\n",
            "  adding: training_datas/train_data23785.zip (stored 0%)\n",
            "  adding: training_datas/train_data15695.zip (stored 0%)\n",
            "  adding: training_datas/train_data477.zip (stored 0%)\n",
            "  adding: training_datas/train_data26431.zip (stored 0%)\n",
            "  adding: training_datas/train_data8107.zip (stored 0%)\n",
            "  adding: training_datas/train_data25561.zip (stored 0%)\n",
            "  adding: training_datas/train_data3159.zip (stored 0%)\n",
            "  adding: training_datas/train_data7288.zip (stored 0%)\n",
            "  adding: training_datas/train_data13685.zip (stored 0%)\n",
            "  adding: training_datas/train_data2270.zip (stored 0%)\n",
            "  adding: training_datas/train_data17002.zip (stored 0%)\n",
            "  adding: training_datas/train_data17437.zip (stored 0%)\n",
            "  adding: training_datas/train_data6719.zip (stored 0%)\n",
            "  adding: training_datas/train_data15918.zip (stored 0%)\n",
            "  adding: training_datas/train_data14886.zip (stored 0%)\n",
            "  adding: training_datas/train_data5975.zip (stored 0%)\n",
            "  adding: training_datas/train_data8393.zip (stored 0%)\n",
            "  adding: training_datas/train_data9725.zip (stored 0%)\n",
            "  adding: training_datas/train_data20930.zip (stored 0%)\n",
            "  adding: training_datas/train_data1988.zip (stored 0%)\n",
            "  adding: training_datas/train_data3693.zip (stored 0%)\n",
            "  adding: training_datas/train_data22074.zip (stored 0%)\n",
            "  adding: training_datas/train_data28458.zip (stored 0%)\n",
            "  adding: training_datas/train_data26957.zip (stored 0%)\n",
            "  adding: training_datas/train_data14525.zip (stored 0%)\n",
            "  adding: training_datas/train_data1869.zip (stored 0%)\n",
            "  adding: training_datas/train_data5371.zip (stored 0%)\n",
            "  adding: training_datas/train_data499.zip (stored 0%)\n",
            "  adding: training_datas/train_data9632.zip (stored 0%)\n",
            "  adding: training_datas/train_data2622.zip (stored 0%)\n",
            "  adding: training_datas/train_data7418.zip (stored 0%)\n",
            "  adding: training_datas/train_data3116.zip (stored 0%)\n",
            "  adding: training_datas/train_data17326.zip (stored 0%)\n",
            "  adding: training_datas/train_data8250.zip (stored 0%)\n",
            "  adding: training_datas/train_data16133.zip (stored 0%)\n",
            "  adding: training_datas/train_data8928.zip (stored 0%)\n",
            "  adding: training_datas/train_data11768.zip (stored 0%)\n",
            "  adding: training_datas/train_data12646.zip (stored 0%)\n",
            "  adding: training_datas/train_data15779.zip (stored 0%)\n",
            "  adding: training_datas/train_data25230.zip (stored 0%)\n",
            "  adding: training_datas/train_data5086.zip (stored 0%)\n",
            "  adding: training_datas/train_data25733.zip (stored 0%)\n",
            "  adding: training_datas/train_data28314.zip (stored 0%)\n",
            "  adding: training_datas/train_data4753.zip (stored 0%)\n",
            "  adding: training_datas/train_data13891.zip (stored 0%)\n",
            "  adding: training_datas/train_data1943.zip (stored 0%)\n",
            "  adding: training_datas/train_data26764.zip (stored 0%)\n",
            "  adding: training_datas/train_data15716.zip (stored 0%)\n",
            "  adding: training_datas/train_data29444.zip (stored 0%)\n",
            "  adding: training_datas/train_data23019.zip (stored 0%)\n",
            "  adding: training_datas/train_data23931.zip (stored 0%)\n",
            "  adding: training_datas/train_data20353.zip (stored 0%)\n",
            "  adding: training_datas/train_data5175.zip (stored 0%)\n",
            "  adding: training_datas/train_data6328.zip (stored 0%)\n",
            "  adding: training_datas/train_data5126.zip (stored 0%)\n",
            "  adding: training_datas/train_data28444.zip (stored 0%)\n",
            "  adding: training_datas/train_data11783.zip (stored 0%)\n",
            "  adding: training_datas/train_data24868.zip (stored 0%)\n",
            "  adding: training_datas/train_data4586.zip (stored 0%)\n",
            "  adding: training_datas/train_data22157.zip (stored 0%)\n",
            "  adding: training_datas/train_data23070.zip (stored 0%)\n",
            "  adding: training_datas/train_data13972.zip (stored 0%)\n",
            "  adding: training_datas/train_data15035.zip (stored 0%)\n",
            "  adding: training_datas/train_data13869.zip (stored 0%)\n",
            "  adding: training_datas/train_data29109.zip (stored 0%)\n",
            "  adding: training_datas/train_data23392.zip (stored 0%)\n",
            "  adding: training_datas/train_data30201.zip (stored 0%)\n",
            "  adding: training_datas/train_data26461.zip (stored 0%)\n",
            "  adding: training_datas/train_data10168.zip (stored 0%)\n",
            "  adding: training_datas/train_data26322.zip (stored 0%)\n",
            "  adding: training_datas/train_data28443.zip (stored 0%)\n",
            "  adding: training_datas/train_data29842.zip (stored 0%)\n",
            "  adding: training_datas/train_data27110.zip (stored 0%)\n",
            "  adding: training_datas/train_data5385.zip (stored 0%)\n",
            "  adding: training_datas/train_data6347.zip (stored 0%)\n",
            "  adding: training_datas/train_data17091.zip (stored 0%)\n",
            "  adding: training_datas/train_data28517.zip (stored 0%)\n",
            "  adding: training_datas/train_data13329.zip (stored 0%)\n",
            "  adding: training_datas/train_data14458.zip (stored 0%)\n",
            "  adding: training_datas/train_data10179.zip (stored 0%)\n",
            "  adding: training_datas/train_data16072.zip (stored 0%)\n",
            "  adding: training_datas/train_data4728.zip (stored 0%)\n",
            "  adding: training_datas/train_data2157.zip (stored 0%)\n",
            "  adding: training_datas/train_data10632.zip (stored 0%)\n",
            "  adding: training_datas/train_data17818.zip (stored 0%)\n",
            "  adding: training_datas/train_data10516.zip (stored 0%)\n",
            "  adding: training_datas/train_data28384.zip (stored 0%)\n",
            "  adding: training_datas/train_data11288.zip (stored 0%)\n",
            "  adding: training_datas/train_data822.zip (stored 0%)\n",
            "  adding: training_datas/train_data19186.zip (stored 0%)\n",
            "  adding: training_datas/train_data5292.zip (stored 0%)\n",
            "  adding: training_datas/train_data11532.zip (stored 0%)\n",
            "  adding: training_datas/train_data22834.zip (stored 0%)\n",
            "  adding: training_datas/train_data16750.zip (stored 0%)\n",
            "  adding: training_datas/train_data5143.zip (stored 0%)\n",
            "  adding: training_datas/train_data11462.zip (stored 0%)\n",
            "  adding: training_datas/train_data803.zip (stored 0%)\n",
            "  adding: training_datas/train_data10042.zip (stored 0%)\n",
            "  adding: training_datas/train_data210.zip (stored 0%)\n",
            "  adding: training_datas/train_data22414.zip (stored 0%)\n",
            "  adding: training_datas/train_data3647.zip (stored 0%)\n",
            "  adding: training_datas/train_data21620.zip (stored 0%)\n",
            "  adding: training_datas/train_data22269.zip (stored 0%)\n",
            "  adding: training_datas/train_data22011.zip (stored 0%)\n",
            "  adding: training_datas/train_data7867.zip (stored 0%)\n",
            "  adding: training_datas/train_data4163.zip (stored 0%)\n",
            "  adding: training_datas/train_data6131.zip (stored 0%)\n",
            "  adding: training_datas/train_data5580.zip (stored 0%)\n",
            "  adding: training_datas/train_data24823.zip (stored 0%)\n",
            "  adding: training_datas/train_data6943.zip (stored 0%)\n",
            "  adding: training_datas/train_data12118.zip (stored 0%)\n",
            "  adding: training_datas/train_data29196.zip (stored 0%)\n",
            "  adding: training_datas/train_data13142.zip (stored 0%)\n",
            "  adding: training_datas/train_data8866.zip (stored 0%)\n",
            "  adding: training_datas/train_data10736.zip (stored 0%)\n",
            "  adding: training_datas/train_data25592.zip (stored 0%)\n",
            "  adding: training_datas/train_data13322.zip (stored 0%)\n",
            "  adding: training_datas/train_data9989.zip (stored 0%)\n",
            "  adding: training_datas/train_data27431.zip (stored 0%)\n",
            "  adding: training_datas/train_data18178.zip (stored 0%)\n",
            "  adding: training_datas/train_data13676.zip (stored 0%)\n",
            "  adding: training_datas/train_data25554.zip (stored 0%)\n",
            "  adding: training_datas/train_data23973.zip (stored 0%)\n",
            "  adding: training_datas/train_data21489.zip (stored 0%)\n",
            "  adding: training_datas/train_data30332.zip (stored 0%)\n",
            "  adding: training_datas/train_data4352.zip (stored 0%)\n",
            "  adding: training_datas/train_data116.zip (stored 0%)\n",
            "  adding: training_datas/train_data6804.zip (stored 0%)\n",
            "  adding: training_datas/train_data13463.zip (stored 0%)\n",
            "  adding: training_datas/train_data27253.zip (stored 0%)\n",
            "  adding: training_datas/train_data19921.zip (stored 0%)\n",
            "  adding: training_datas/train_data14821.zip (stored 0%)\n",
            "  adding: training_datas/train_data8280.zip (stored 0%)\n",
            "  adding: training_datas/train_data8957.zip (stored 0%)\n",
            "  adding: training_datas/train_data21071.zip (stored 0%)\n",
            "  adding: training_datas/train_data26724.zip (stored 0%)\n",
            "  adding: training_datas/train_data27087.zip (stored 0%)\n",
            "  adding: training_datas/train_data2348.zip (stored 0%)\n",
            "  adding: training_datas/train_data19171.zip (stored 0%)\n",
            "  adding: training_datas/train_data20230.zip (stored 0%)\n",
            "  adding: training_datas/train_data20408.zip (stored 0%)\n",
            "  adding: training_datas/train_data22106.zip (stored 0%)\n",
            "  adding: training_datas/train_data9823.zip (stored 0%)\n",
            "  adding: training_datas/train_data22054.zip (stored 0%)\n",
            "  adding: training_datas/train_data6283.zip (stored 0%)\n",
            "  adding: training_datas/train_data5606.zip (stored 0%)\n",
            "  adding: training_datas/train_data8721.zip (stored 0%)\n",
            "  adding: training_datas/train_data26432.zip (stored 0%)\n",
            "  adding: training_datas/train_data20524.zip (stored 0%)\n",
            "  adding: training_datas/train_data3980.zip (stored 0%)\n",
            "  adding: training_datas/train_data11383.zip (stored 0%)\n",
            "  adding: training_datas/train_data8469.zip (stored 0%)\n",
            "  adding: training_datas/train_data16851.zip (stored 0%)\n",
            "  adding: training_datas/train_data21899.zip (stored 0%)\n",
            "  adding: training_datas/train_data12295.zip (stored 0%)\n",
            "  adding: training_datas/train_data9188.zip (stored 0%)\n",
            "  adding: training_datas/train_data11150.zip (stored 0%)\n",
            "  adding: training_datas/train_data21421.zip (stored 0%)\n",
            "  adding: training_datas/train_data12294.zip (stored 0%)\n",
            "  adding: training_datas/train_data17426.zip (stored 0%)\n",
            "  adding: training_datas/train_data3603.zip (stored 0%)\n",
            "  adding: training_datas/train_data1857.zip (stored 0%)\n",
            "  adding: training_datas/train_data11236.zip (stored 0%)\n",
            "  adding: training_datas/train_data5079.zip (stored 0%)\n",
            "  adding: training_datas/train_data446.zip (stored 0%)\n",
            "  adding: training_datas/train_data19935.zip (stored 0%)\n",
            "  adding: training_datas/train_data4928.zip (stored 0%)\n",
            "  adding: training_datas/train_data22940.zip (stored 0%)\n",
            "  adding: training_datas/train_data9343.zip (stored 0%)\n",
            "  adding: training_datas/train_data18406.zip (stored 0%)\n",
            "  adding: training_datas/train_data2300.zip (stored 0%)\n",
            "  adding: training_datas/train_data29933.zip (stored 0%)\n",
            "  adding: training_datas/train_data13461.zip (stored 0%)\n",
            "  adding: training_datas/train_data2284.zip (stored 0%)\n",
            "  adding: training_datas/train_data4893.zip (stored 0%)\n",
            "  adding: training_datas/train_data16405.zip (stored 0%)\n",
            "  adding: training_datas/train_data13250.zip (stored 0%)\n",
            "  adding: training_datas/train_data14423.zip (stored 0%)\n",
            "  adding: training_datas/train_data10820.zip (stored 0%)\n",
            "  adding: training_datas/train_data10383.zip (stored 0%)\n",
            "  adding: training_datas/train_data3073.zip (stored 0%)\n",
            "  adding: training_datas/train_data27785.zip (stored 0%)\n",
            "  adding: training_datas/train_data674.zip (stored 0%)\n",
            "  adding: training_datas/train_data15836.zip (stored 0%)\n",
            "  adding: training_datas/train_data21302.zip (stored 0%)\n",
            "  adding: training_datas/train_data4889.zip (stored 0%)\n",
            "  adding: training_datas/train_data12255.zip (stored 0%)\n",
            "  adding: training_datas/train_data8339.zip (stored 0%)\n",
            "  adding: training_datas/train_data11897.zip (stored 0%)\n",
            "  adding: training_datas/train_data7405.zip (stored 0%)\n",
            "  adding: training_datas/train_data23948.zip (stored 0%)\n",
            "  adding: training_datas/train_data25406.zip (stored 0%)\n",
            "  adding: training_datas/train_data22580.zip (stored 0%)\n",
            "  adding: training_datas/train_data25165.zip (stored 0%)\n",
            "  adding: training_datas/train_data13619.zip (stored 0%)\n",
            "  adding: training_datas/train_data27063.zip (stored 0%)\n",
            "  adding: training_datas/train_data24175.zip (stored 0%)\n",
            "  adding: training_datas/train_data19152.zip (stored 0%)\n",
            "  adding: training_datas/train_data24789.zip (stored 0%)\n",
            "  adding: training_datas/train_data27132.zip (stored 0%)\n",
            "  adding: training_datas/train_data23758.zip (stored 0%)\n",
            "  adding: training_datas/train_data23346.zip (stored 0%)\n",
            "  adding: training_datas/train_data27229.zip (stored 0%)\n",
            "  adding: training_datas/train_data27653.zip (stored 0%)\n",
            "  adding: training_datas/train_data10892.zip (stored 0%)\n",
            "  adding: training_datas/train_data4300.zip (stored 0%)\n",
            "  adding: training_datas/train_data4980.zip (stored 0%)\n",
            "  adding: training_datas/train_data839.zip (stored 0%)\n",
            "  adding: training_datas/train_data29212.zip (stored 0%)\n",
            "  adding: training_datas/train_data21407.zip (stored 0%)\n",
            "  adding: training_datas/train_data3017.zip (stored 0%)\n",
            "  adding: training_datas/train_data27949.zip (stored 0%)\n",
            "  adding: training_datas/train_data12554.zip (stored 0%)\n",
            "  adding: training_datas/train_data27761.zip (stored 0%)\n",
            "  adding: training_datas/train_data5324.zip (stored 0%)\n",
            "  adding: training_datas/train_data20158.zip (stored 0%)\n",
            "  adding: training_datas/train_data13055.zip (stored 0%)\n",
            "  adding: training_datas/train_data25632.zip (stored 0%)\n",
            "  adding: training_datas/train_data14229.zip (stored 0%)\n",
            "  adding: training_datas/train_data27773.zip (stored 0%)\n",
            "  adding: training_datas/train_data21289.zip (stored 0%)\n",
            "  adding: training_datas/train_data20442.zip (stored 0%)\n",
            "  adding: training_datas/train_data12982.zip (stored 0%)\n",
            "  adding: training_datas/train_data1150.zip (stored 0%)\n",
            "  adding: training_datas/train_data14355.zip (stored 0%)\n",
            "  adding: training_datas/train_data27055.zip (stored 0%)\n",
            "  adding: training_datas/train_data19993.zip (stored 0%)\n",
            "  adding: training_datas/train_data28405.zip (stored 0%)\n",
            "  adding: training_datas/train_data21248.zip (stored 0%)\n",
            "  adding: training_datas/train_data10904.zip (stored 0%)\n",
            "  adding: training_datas/train_data25393.zip (stored 0%)\n",
            "  adding: training_datas/train_data760.zip (stored 0%)\n",
            "  adding: training_datas/train_data11189.zip (stored 0%)\n",
            "  adding: training_datas/train_data18982.zip (stored 0%)\n",
            "  adding: training_datas/train_data1650.zip (stored 0%)\n",
            "  adding: training_datas/train_data8667.zip (stored 0%)\n",
            "  adding: training_datas/train_data2757.zip (stored 0%)\n",
            "  adding: training_datas/train_data30433.zip (stored 0%)\n",
            "  adding: training_datas/train_data3224.zip (stored 0%)\n",
            "  adding: training_datas/train_data607.zip (stored 0%)\n",
            "  adding: training_datas/train_data621.zip (stored 0%)\n",
            "  adding: training_datas/train_data13656.zip (stored 0%)\n",
            "  adding: training_datas/train_data9350.zip (stored 0%)\n",
            "  adding: training_datas/train_data27415.zip (stored 0%)\n",
            "  adding: training_datas/train_data8775.zip (stored 0%)\n",
            "  adding: training_datas/train_data8710.zip (stored 0%)\n",
            "  adding: training_datas/train_data108.zip (stored 0%)\n",
            "  adding: training_datas/train_data6964.zip (stored 0%)\n",
            "  adding: training_datas/train_data5974.zip (stored 0%)\n",
            "  adding: training_datas/train_data14765.zip (stored 0%)\n",
            "  adding: training_datas/train_data14690.zip (stored 0%)\n",
            "  adding: training_datas/train_data12267.zip (stored 0%)\n",
            "  adding: training_datas/train_data24242.zip (stored 0%)\n",
            "  adding: training_datas/train_data28703.zip (stored 0%)\n",
            "  adding: training_datas/train_data2078.zip (stored 0%)\n",
            "  adding: training_datas/train_data19181.zip (stored 0%)\n",
            "  adding: training_datas/train_data28034.zip (stored 0%)\n",
            "  adding: training_datas/train_data1162.zip (stored 0%)\n",
            "  adding: training_datas/train_data18300.zip (stored 0%)\n",
            "  adding: training_datas/train_data19619.zip (stored 0%)\n",
            "  adding: training_datas/train_data27934.zip (stored 0%)\n",
            "  adding: training_datas/train_data24899.zip (stored 0%)\n",
            "  adding: training_datas/train_data11771.zip (stored 0%)\n",
            "  adding: training_datas/train_data24856.zip (stored 0%)\n",
            "  adding: training_datas/train_data7756.zip (stored 0%)\n",
            "  adding: training_datas/train_data17216.zip (stored 0%)\n",
            "  adding: training_datas/train_data15879.zip (stored 0%)\n",
            "  adding: training_datas/train_data21575.zip (stored 0%)\n",
            "  adding: training_datas/train_data7294.zip (stored 0%)\n",
            "  adding: training_datas/train_data27725.zip (stored 0%)\n",
            "  adding: training_datas/train_data23310.zip (stored 0%)\n",
            "  adding: training_datas/train_data16357.zip (stored 0%)\n",
            "  adding: training_datas/train_data5473.zip (stored 0%)\n",
            "  adding: training_datas/train_data8942.zip (stored 0%)\n",
            "  adding: training_datas/train_data27439.zip (stored 0%)\n",
            "  adding: training_datas/train_data5463.zip (stored 0%)\n",
            "  adding: training_datas/train_data26243.zip (stored 0%)\n",
            "  adding: training_datas/train_data20457.zip (stored 0%)\n",
            "  adding: training_datas/train_data11084.zip (stored 0%)\n",
            "  adding: training_datas/train_data13932.zip (stored 0%)\n",
            "  adding: training_datas/train_data2418.zip (stored 0%)\n",
            "  adding: training_datas/train_data27249.zip (stored 0%)\n",
            "  adding: training_datas/train_data4225.zip (stored 0%)\n",
            "  adding: training_datas/train_data15020.zip (stored 0%)\n",
            "  adding: training_datas/train_data10486.zip (stored 0%)\n",
            "  adding: training_datas/train_data20758.zip (stored 0%)\n",
            "  adding: training_datas/train_data27033.zip (stored 0%)\n",
            "  adding: training_datas/train_data20205.zip (stored 0%)\n",
            "  adding: training_datas/train_data22386.zip (stored 0%)\n",
            "  adding: training_datas/train_data6842.zip (stored 0%)\n",
            "  adding: training_datas/train_data21734.zip (stored 0%)\n",
            "  adding: training_datas/train_data30143.zip (stored 0%)\n",
            "  adding: training_datas/train_data9264.zip (stored 0%)\n",
            "  adding: training_datas/train_data19575.zip (stored 0%)\n",
            "  adding: training_datas/train_data27959.zip (stored 0%)\n",
            "  adding: training_datas/train_data29465.zip (stored 0%)\n",
            "  adding: training_datas/train_data21547.zip (stored 0%)\n",
            "  adding: training_datas/train_data28028.zip (stored 0%)\n",
            "  adding: training_datas/train_data1247.zip (stored 0%)\n",
            "  adding: training_datas/train_data5014.zip (stored 0%)\n",
            "  adding: training_datas/train_data20237.zip (stored 0%)\n",
            "  adding: training_datas/train_data26126.zip (stored 0%)\n",
            "  adding: training_datas/train_data4117.zip (stored 0%)\n",
            "  adding: training_datas/train_data7485.zip (stored 0%)\n",
            "  adding: training_datas/train_data15661.zip (stored 0%)\n",
            "  adding: training_datas/train_data12828.zip (stored 0%)\n",
            "  adding: training_datas/train_data7264.zip (stored 0%)\n",
            "  adding: training_datas/train_data21486.zip (stored 0%)\n",
            "  adding: training_datas/train_data5226.zip (stored 0%)\n",
            "  adding: training_datas/train_data10491.zip (stored 0%)\n",
            "  adding: training_datas/train_data4969.zip (stored 0%)\n",
            "  adding: training_datas/train_data20896.zip (stored 0%)\n",
            "  adding: training_datas/train_data9727.zip (stored 0%)\n",
            "  adding: training_datas/train_data23201.zip (stored 0%)\n",
            "  adding: training_datas/train_data11816.zip (stored 0%)\n",
            "  adding: training_datas/train_data28995.zip (stored 0%)\n",
            "  adding: training_datas/train_data14661.zip (stored 0%)\n",
            "  adding: training_datas/train_data6038.zip (stored 0%)\n",
            "  adding: training_datas/train_data9266.zip (stored 0%)\n",
            "  adding: training_datas/train_data24728.zip (stored 0%)\n",
            "  adding: training_datas/train_data1836.zip (stored 0%)\n",
            "  adding: training_datas/train_data24765.zip (stored 0%)\n",
            "  adding: training_datas/train_data4020.zip (stored 0%)\n",
            "  adding: training_datas/train_data11642.zip (stored 0%)\n",
            "  adding: training_datas/train_data8954.zip (stored 0%)\n",
            "  adding: training_datas/train_data10307.zip (stored 0%)\n",
            "  adding: training_datas/train_data29841.zip (stored 0%)\n",
            "  adding: training_datas/train_data25974.zip (stored 0%)\n",
            "  adding: training_datas/train_data18258.zip (stored 0%)\n",
            "  adding: training_datas/train_data17087.zip (stored 0%)\n",
            "  adding: training_datas/train_data7656.zip (stored 0%)\n",
            "  adding: training_datas/train_data17562.zip (stored 0%)\n",
            "  adding: training_datas/train_data27797.zip (stored 0%)\n",
            "  adding: training_datas/train_data9197.zip (stored 0%)\n",
            "  adding: training_datas/train_data11303.zip (stored 0%)\n",
            "  adding: training_datas/train_data20500.zip (stored 0%)\n",
            "  adding: training_datas/train_data30475.zip (stored 0%)\n",
            "  adding: training_datas/train_data13465.zip (stored 0%)\n",
            "  adding: training_datas/train_data21690.zip (stored 0%)\n",
            "  adding: training_datas/train_data21467.zip (stored 0%)\n",
            "  adding: training_datas/train_data10885.zip (stored 0%)\n",
            "  adding: training_datas/train_data30464.zip (stored 0%)\n",
            "  adding: training_datas/train_data6889.zip (stored 0%)\n",
            "  adding: training_datas/train_data14383.zip (stored 0%)\n",
            "  adding: training_datas/train_data10217.zip (stored 0%)\n",
            "  adding: training_datas/train_data5719.zip (stored 0%)\n",
            "  adding: training_datas/train_data7786.zip (stored 0%)\n",
            "  adding: training_datas/train_data22369.zip (stored 0%)\n",
            "  adding: training_datas/train_data10097.zip (stored 0%)\n",
            "  adding: training_datas/train_data14516.zip (stored 0%)\n",
            "  adding: training_datas/train_data20013.zip (stored 0%)\n",
            "  adding: training_datas/train_data19135.zip (stored 0%)\n",
            "  adding: training_datas/train_data2857.zip (stored 0%)\n",
            "  adding: training_datas/train_data17725.zip (stored 0%)\n",
            "  adding: training_datas/train_data10038.zip (stored 0%)\n",
            "  adding: training_datas/train_data24543.zip (stored 0%)\n",
            "  adding: training_datas/train_data28245.zip (stored 0%)\n",
            "  adding: training_datas/train_data21561.zip (stored 0%)\n",
            "  adding: training_datas/train_data13372.zip (stored 0%)\n",
            "  adding: training_datas/train_data30089.zip (stored 0%)\n",
            "  adding: training_datas/train_data14403.zip (stored 0%)\n",
            "  adding: training_datas/train_data20456.zip (stored 0%)\n",
            "  adding: training_datas/train_data26858.zip (stored 0%)\n",
            "  adding: training_datas/train_data28180.zip (stored 0%)\n",
            "  adding: training_datas/train_data23100.zip (stored 0%)\n",
            "  adding: training_datas/train_data20619.zip (stored 0%)\n",
            "  adding: training_datas/train_data29989.zip (stored 0%)\n",
            "  adding: training_datas/train_data20050.zip (stored 0%)\n",
            "  adding: training_datas/train_data5657.zip (stored 0%)\n",
            "  adding: training_datas/train_data11030.zip (stored 0%)\n",
            "  adding: training_datas/train_data6918.zip (stored 0%)\n",
            "  adding: training_datas/train_data10055.zip (stored 0%)\n",
            "  adding: training_datas/train_data7837.zip (stored 0%)\n",
            "  adding: training_datas/train_data22639.zip (stored 0%)\n",
            "  adding: training_datas/train_data14648.zip (stored 0%)\n",
            "  adding: training_datas/train_data4645.zip (stored 0%)\n",
            "  adding: training_datas/train_data21018.zip (stored 0%)\n",
            "  adding: training_datas/train_data27817.zip (stored 0%)\n",
            "  adding: training_datas/train_data4233.zip (stored 0%)\n",
            "  adding: training_datas/train_data5367.zip (stored 0%)\n",
            "  adding: training_datas/train_data18351.zip (stored 0%)\n",
            "  adding: training_datas/train_data13523.zip (stored 0%)\n",
            "  adding: training_datas/train_data4485.zip (stored 0%)\n",
            "  adding: training_datas/train_data19086.zip (stored 0%)\n",
            "  adding: training_datas/train_data22974.zip (stored 0%)\n",
            "  adding: training_datas/train_data8625.zip (stored 0%)\n",
            "  adding: training_datas/train_data10126.zip (stored 0%)\n",
            "  adding: training_datas/train_data9698.zip (stored 0%)\n",
            "  adding: training_datas/train_data11557.zip (stored 0%)\n",
            "  adding: training_datas/train_data29479.zip (stored 0%)\n",
            "  adding: training_datas/train_data7155.zip (stored 0%)\n",
            "  adding: training_datas/train_data7320.zip (stored 0%)\n",
            "  adding: training_datas/train_data21430.zip (stored 0%)\n",
            "  adding: training_datas/train_data7613.zip (stored 0%)\n",
            "  adding: training_datas/train_data2279.zip (stored 0%)\n",
            "  adding: training_datas/train_data1109.zip (stored 0%)\n",
            "  adding: training_datas/train_data18038.zip (stored 0%)\n",
            "  adding: training_datas/train_data8015.zip (stored 0%)\n",
            "  adding: training_datas/train_data16030.zip (stored 0%)\n",
            "  adding: training_datas/train_data4274.zip (stored 0%)\n",
            "  adding: training_datas/train_data12034.zip (stored 0%)\n",
            "  adding: training_datas/train_data7449.zip (stored 0%)\n",
            "  adding: training_datas/train_data28588.zip (stored 0%)\n",
            "  adding: training_datas/train_data8909.zip (stored 0%)\n",
            "  adding: training_datas/train_data11627.zip (stored 0%)\n",
            "  adding: training_datas/train_data4026.zip (stored 0%)\n",
            "  adding: training_datas/train_data23681.zip (stored 0%)\n",
            "  adding: training_datas/train_data20025.zip (stored 0%)\n",
            "  adding: training_datas/train_data4504.zip (stored 0%)\n",
            "  adding: training_datas/train_data21740.zip (stored 0%)\n",
            "  adding: training_datas/train_data26576.zip (stored 0%)\n",
            "  adding: training_datas/train_data2210.zip (stored 0%)\n",
            "  adding: training_datas/train_data7693.zip (stored 0%)\n",
            "  adding: training_datas/train_data2248.zip (stored 0%)\n",
            "  adding: training_datas/train_data4535.zip (stored 0%)\n",
            "  adding: training_datas/train_data25772.zip (stored 0%)\n",
            "  adding: training_datas/train_data18220.zip (stored 0%)\n",
            "  adding: training_datas/train_data2287.zip (stored 0%)\n",
            "  adding: training_datas/train_data13911.zip (stored 0%)\n",
            "  adding: training_datas/train_data6077.zip (stored 0%)\n",
            "  adding: training_datas/train_data25701.zip (stored 0%)\n",
            "  adding: training_datas/train_data16918.zip (stored 0%)\n",
            "  adding: training_datas/train_data19587.zip (stored 0%)\n",
            "  adding: training_datas/train_data2107.zip (stored 0%)\n",
            "  adding: training_datas/train_data12178.zip (stored 0%)\n",
            "  adding: training_datas/train_data21602.zip (stored 0%)\n",
            "  adding: training_datas/train_data14276.zip (stored 0%)\n",
            "  adding: training_datas/train_data10568.zip (stored 0%)\n",
            "  adding: training_datas/train_data20517.zip (stored 0%)\n",
            "  adding: training_datas/train_data2453.zip (stored 0%)\n",
            "  adding: training_datas/train_data10733.zip (stored 0%)\n",
            "  adding: training_datas/train_data13929.zip (stored 0%)\n",
            "  adding: training_datas/train_data11326.zip (stored 0%)\n",
            "  adding: training_datas/train_data20643.zip (stored 0%)\n",
            "  adding: training_datas/train_data9874.zip (stored 0%)\n",
            "  adding: training_datas/train_data17567.zip (stored 0%)\n",
            "  adding: training_datas/train_data1669.zip (stored 0%)\n",
            "  adding: training_datas/train_data22372.zip (stored 0%)\n",
            "  adding: training_datas/train_data19835.zip (stored 0%)\n",
            "  adding: training_datas/train_data6823.zip (stored 0%)\n",
            "  adding: training_datas/train_data29538.zip (stored 0%)\n",
            "  adding: training_datas/train_data18318.zip (stored 0%)\n",
            "  adding: training_datas/train_data14921.zip (stored 0%)\n",
            "  adding: training_datas/train_data13421.zip (stored 0%)\n",
            "  adding: training_datas/train_data20531.zip (stored 0%)\n",
            "  adding: training_datas/train_data5116.zip (stored 0%)\n",
            "  adding: training_datas/train_data17771.zip (stored 0%)\n",
            "  adding: training_datas/train_data12222.zip (stored 0%)\n",
            "  adding: training_datas/train_data14507.zip (stored 0%)\n",
            "  adding: training_datas/train_data5255.zip (stored 0%)\n",
            "  adding: training_datas/train_data5675.zip (stored 0%)\n",
            "  adding: training_datas/train_data564.zip (stored 0%)\n",
            "  adding: training_datas/train_data12356.zip (stored 0%)\n",
            "  adding: training_datas/train_data9386.zip (stored 0%)\n",
            "  adding: training_datas/train_data8325.zip (stored 0%)\n",
            "  adding: training_datas/train_data14356.zip (stored 0%)\n",
            "  adding: training_datas/train_data13788.zip (stored 0%)\n",
            "  adding: training_datas/train_data17934.zip (stored 0%)\n",
            "  adding: training_datas/train_data19289.zip (stored 0%)\n",
            "  adding: training_datas/train_data9422.zip (stored 0%)\n",
            "  adding: training_datas/train_data1623.zip (stored 0%)\n",
            "  adding: training_datas/train_data14093.zip (stored 0%)\n",
            "  adding: training_datas/train_data12234.zip (stored 0%)\n",
            "  adding: training_datas/train_data9050.zip (stored 0%)\n",
            "  adding: training_datas/train_data2422.zip (stored 0%)\n",
            "  adding: training_datas/train_data22739.zip (stored 0%)\n",
            "  adding: training_datas/train_data6307.zip (stored 0%)\n",
            "  adding: training_datas/train_data29268.zip (stored 0%)\n",
            "  adding: training_datas/train_data501.zip (stored 0%)\n",
            "  adding: training_datas/train_data21085.zip (stored 0%)\n",
            "  adding: training_datas/train_data26828.zip (stored 0%)\n",
            "  adding: training_datas/train_data30161.zip (stored 0%)\n",
            "  adding: training_datas/train_data29623.zip (stored 0%)\n",
            "  adding: training_datas/train_data14629.zip (stored 0%)\n",
            "  adding: training_datas/train_data11787.zip (stored 0%)\n",
            "  adding: training_datas/train_data19910.zip (stored 0%)\n",
            "  adding: training_datas/train_data21233.zip (stored 0%)\n",
            "  adding: training_datas/train_data17824.zip (stored 0%)\n",
            "  adding: training_datas/train_data12651.zip (stored 0%)\n",
            "  adding: training_datas/train_data8733.zip (stored 0%)\n",
            "  adding: training_datas/train_data15693.zip (stored 0%)\n",
            "  adding: training_datas/train_data29611.zip (stored 0%)\n",
            "  adding: training_datas/train_data4033.zip (stored 0%)\n",
            "  adding: training_datas/train_data27222.zip (stored 0%)\n",
            "  adding: training_datas/train_data7638.zip (stored 0%)\n",
            "  adding: training_datas/train_data8189.zip (stored 0%)\n",
            "  adding: training_datas/train_data13632.zip (stored 0%)\n",
            "  adding: training_datas/train_data1834.zip (stored 0%)\n",
            "  adding: training_datas/train_data27273.zip (stored 0%)\n",
            "  adding: training_datas/train_data4902.zip (stored 0%)\n",
            "  adding: training_datas/train_data2689.zip (stored 0%)\n",
            "  adding: training_datas/train_data24496.zip (stored 0%)\n",
            "  adding: training_datas/train_data5167.zip (stored 0%)\n",
            "  adding: training_datas/train_data19199.zip (stored 0%)\n",
            "  adding: training_datas/train_data7847.zip (stored 0%)\n",
            "  adding: training_datas/train_data12045.zip (stored 0%)\n",
            "  adding: training_datas/train_data178.zip (stored 0%)\n",
            "  adding: training_datas/train_data3624.zip (stored 0%)\n",
            "  adding: training_datas/train_data4390.zip (stored 0%)\n",
            "  adding: training_datas/train_data7215.zip (stored 0%)\n",
            "  adding: training_datas/train_data25932.zip (stored 0%)\n",
            "  adding: training_datas/train_data10759.zip (stored 0%)\n",
            "  adding: training_datas/train_data28258.zip (stored 0%)\n",
            "  adding: training_datas/train_data4511.zip (stored 0%)\n",
            "  adding: training_datas/train_data17017.zip (stored 0%)\n",
            "  adding: training_datas/train_data13529.zip (stored 0%)\n",
            "  adding: training_datas/train_data24723.zip (stored 0%)\n",
            "  adding: training_datas/train_data1429.zip (stored 0%)\n",
            "  adding: training_datas/train_data29817.zip (stored 0%)\n",
            "  adding: training_datas/train_data13890.zip (stored 0%)\n",
            "  adding: training_datas/train_data10489.zip (stored 0%)\n",
            "  adding: training_datas/train_data6280.zip (stored 0%)\n",
            "  adding: training_datas/train_data9413.zip (stored 0%)\n",
            "  adding: training_datas/train_data28847.zip (stored 0%)\n",
            "  adding: training_datas/train_data13493.zip (stored 0%)\n",
            "  adding: training_datas/train_data17040.zip (stored 0%)\n",
            "  adding: training_datas/train_data3841.zip (stored 0%)\n",
            "  adding: training_datas/train_data16428.zip (stored 0%)\n",
            "  adding: training_datas/train_data27335.zip (stored 0%)\n",
            "  adding: training_datas/train_data18213.zip (stored 0%)\n",
            "  adding: training_datas/train_data27552.zip (stored 0%)\n",
            "  adding: training_datas/train_data17085.zip (stored 0%)\n",
            "  adding: training_datas/train_data27708.zip (stored 0%)\n",
            "  adding: training_datas/train_data4729.zip (stored 0%)\n",
            "  adding: training_datas/train_data1324.zip (stored 0%)\n",
            "  adding: training_datas/train_data16640.zip (stored 0%)\n",
            "  adding: training_datas/train_data20611.zip (stored 0%)\n",
            "  adding: training_datas/train_data5570.zip (stored 0%)\n",
            "  adding: training_datas/train_data7052.zip (stored 0%)\n",
            "  adding: training_datas/train_data30033.zip (stored 0%)\n",
            "  adding: training_datas/train_data3822.zip (stored 0%)\n",
            "  adding: training_datas/train_data26064.zip (stored 0%)\n",
            "  adding: training_datas/train_data8630.zip (stored 0%)\n",
            "  adding: training_datas/train_data24453.zip (stored 0%)\n",
            "  adding: training_datas/train_data22794.zip (stored 0%)\n",
            "  adding: training_datas/train_data16169.zip (stored 0%)\n",
            "  adding: training_datas/train_data28304.zip (stored 0%)\n",
            "  adding: training_datas/train_data11067.zip (stored 0%)\n",
            "  adding: training_datas/train_data26657.zip (stored 0%)\n",
            "  adding: training_datas/train_data27779.zip (stored 0%)\n",
            "  adding: training_datas/train_data26956.zip (stored 0%)\n",
            "  adding: training_datas/train_data18127.zip (stored 0%)\n",
            "  adding: training_datas/train_data16509.zip (stored 0%)\n",
            "  adding: training_datas/train_data9868.zip (stored 0%)\n",
            "  adding: training_datas/train_data23208.zip (stored 0%)\n",
            "  adding: training_datas/train_data2129.zip (stored 0%)\n",
            "  adding: training_datas/train_data18037.zip (stored 0%)\n",
            "  adding: training_datas/train_data10205.zip (stored 0%)\n",
            "  adding: training_datas/train_data6078.zip (stored 0%)\n",
            "  adding: training_datas/train_data28661.zip (stored 0%)\n",
            "  adding: training_datas/train_data29661.zip (stored 0%)\n",
            "  adding: training_datas/train_data3121.zip (stored 0%)\n",
            "  adding: training_datas/train_data18699.zip (stored 0%)\n",
            "  adding: training_datas/train_data1043.zip (stored 0%)\n",
            "  adding: training_datas/train_data12929.zip (stored 0%)\n",
            "  adding: training_datas/train_data27814.zip (stored 0%)\n",
            "  adding: training_datas/train_data7255.zip (stored 0%)\n",
            "  adding: training_datas/train_data5046.zip (stored 0%)\n",
            "  adding: training_datas/train_data6061.zip (stored 0%)\n",
            "  adding: training_datas/train_data7919.zip (stored 0%)\n",
            "  adding: training_datas/train_data11672.zip (stored 0%)\n",
            "  adding: training_datas/train_data10369.zip (stored 0%)\n",
            "  adding: training_datas/train_data25787.zip (stored 0%)\n",
            "  adding: training_datas/train_data11276.zip (stored 0%)\n",
            "  adding: training_datas/train_data17001.zip (stored 0%)\n",
            "  adding: training_datas/train_data4502.zip (stored 0%)\n",
            "  adding: training_datas/train_data12343.zip (stored 0%)\n",
            "  adding: training_datas/train_data1861.zip (stored 0%)\n",
            "  adding: training_datas/train_data661.zip (stored 0%)\n",
            "  adding: training_datas/train_data25068.zip (stored 0%)\n",
            "  adding: training_datas/train_data22992.zip (stored 0%)\n",
            "  adding: training_datas/train_data1681.zip (stored 0%)\n",
            "  adding: training_datas/train_data8913.zip (stored 0%)\n",
            "  adding: training_datas/train_data19616.zip (stored 0%)\n",
            "  adding: training_datas/train_data13265.zip (stored 0%)\n",
            "  adding: training_datas/train_data15172.zip (stored 0%)\n",
            "  adding: training_datas/train_data3776.zip (stored 0%)\n",
            "  adding: training_datas/train_data14697.zip (stored 0%)\n",
            "  adding: training_datas/train_data1236.zip (stored 0%)\n",
            "  adding: training_datas/train_data15463.zip (stored 0%)\n",
            "  adding: training_datas/train_data2378.zip (stored 0%)\n",
            "  adding: training_datas/train_data5058.zip (stored 0%)\n",
            "  adding: training_datas/train_data4397.zip (stored 0%)\n",
            "  adding: training_datas/train_data3373.zip (stored 0%)\n",
            "  adding: training_datas/train_data26836.zip (stored 0%)\n",
            "  adding: training_datas/train_data28793.zip (stored 0%)\n",
            "  adding: training_datas/train_data4999.zip (stored 0%)\n",
            "  adding: training_datas/train_data6692.zip (stored 0%)\n",
            "  adding: training_datas/train_data8376.zip (stored 0%)\n",
            "  adding: training_datas/train_data4335.zip (stored 0%)\n",
            "  adding: training_datas/train_data3846.zip (stored 0%)\n",
            "  adding: training_datas/train_data11949.zip (stored 0%)\n",
            "  adding: training_datas/train_data22852.zip (stored 0%)\n",
            "  adding: training_datas/train_data9414.zip (stored 0%)\n",
            "  adding: training_datas/train_data7017.zip (stored 0%)\n",
            "  adding: training_datas/train_data23591.zip (stored 0%)\n",
            "  adding: training_datas/train_data4109.zip (stored 0%)\n",
            "  adding: training_datas/train_data15050.zip (stored 0%)\n",
            "  adding: training_datas/train_data28712.zip (stored 0%)\n",
            "  adding: training_datas/train_data19995.zip (stored 0%)\n",
            "  adding: training_datas/train_data7617.zip (stored 0%)\n",
            "  adding: training_datas/train_data9302.zip (stored 0%)\n",
            "  adding: training_datas/train_data11621.zip (stored 0%)\n",
            "  adding: training_datas/train_data22704.zip (stored 0%)\n",
            "  adding: training_datas/train_data5381.zip (stored 0%)\n",
            "  adding: training_datas/train_data25114.zip (stored 0%)\n",
            "  adding: training_datas/train_data25290.zip (stored 0%)\n",
            "  adding: training_datas/train_data24196.zip (stored 0%)\n",
            "  adding: training_datas/train_data16873.zip (stored 0%)\n",
            "  adding: training_datas/train_data4699.zip (stored 0%)\n",
            "  adding: training_datas/train_data3582.zip (stored 0%)\n",
            "  adding: training_datas/train_data22313.zip (stored 0%)\n",
            "  adding: training_datas/train_data3302.zip (stored 0%)\n",
            "  adding: training_datas/train_data18430.zip (stored 0%)\n",
            "  adding: training_datas/train_data26792.zip (stored 0%)\n",
            "  adding: training_datas/train_data21565.zip (stored 0%)\n",
            "  adding: training_datas/train_data12541.zip (stored 0%)\n",
            "  adding: training_datas/train_data30094.zip (stored 0%)\n",
            "  adding: training_datas/train_data20329.zip (stored 0%)\n",
            "  adding: training_datas/train_data9820.zip (stored 0%)\n",
            "  adding: training_datas/train_data20599.zip (stored 0%)\n",
            "  adding: training_datas/train_data19608.zip (stored 0%)\n",
            "  adding: training_datas/train_data26365.zip (stored 0%)\n",
            "  adding: training_datas/train_data24867.zip (stored 0%)\n",
            "  adding: training_datas/train_data5295.zip (stored 0%)\n",
            "  adding: training_datas/train_data10741.zip (stored 0%)\n",
            "  adding: training_datas/train_data23347.zip (stored 0%)\n",
            "  adding: training_datas/train_data3366.zip (stored 0%)\n",
            "  adding: training_datas/train_data11653.zip (stored 0%)\n",
            "  adding: training_datas/train_data8863.zip (stored 0%)\n",
            "  adding: training_datas/train_data8159.zip (stored 0%)\n",
            "  adding: training_datas/train_data3852.zip (stored 0%)\n",
            "  adding: training_datas/train_data19130.zip (stored 0%)\n",
            "  adding: training_datas/train_data28559.zip (stored 0%)\n",
            "  adding: training_datas/train_data9985.zip (stored 0%)\n",
            "  adding: training_datas/train_data8.zip (stored 0%)\n",
            "  adding: training_datas/train_data11965.zip (stored 0%)\n",
            "  adding: training_datas/train_data7694.zip (stored 0%)\n",
            "  adding: training_datas/train_data28909.zip (stored 0%)\n",
            "  adding: training_datas/train_data22458.zip (stored 0%)\n",
            "  adding: training_datas/train_data12297.zip (stored 0%)\n",
            "  adding: training_datas/train_data4447.zip (stored 0%)\n",
            "  adding: training_datas/train_data29550.zip (stored 0%)\n",
            "  adding: training_datas/train_data8445.zip (stored 0%)\n",
            "  adding: training_datas/train_data21542.zip (stored 0%)\n",
            "  adding: training_datas/train_data586.zip (stored 0%)\n",
            "  adding: training_datas/train_data2879.zip (stored 0%)\n",
            "  adding: training_datas/train_data17815.zip (stored 0%)\n",
            "  adding: training_datas/train_data17064.zip (stored 0%)\n",
            "  adding: training_datas/train_data14058.zip (stored 0%)\n",
            "  adding: training_datas/train_data16424.zip (stored 0%)\n",
            "  adding: training_datas/train_data28452.zip (stored 0%)\n",
            "  adding: training_datas/train_data8436.zip (stored 0%)\n",
            "  adding: training_datas/train_data19311.zip (stored 0%)\n",
            "  adding: training_datas/train_data2639.zip (stored 0%)\n",
            "  adding: training_datas/train_data5148.zip (stored 0%)\n",
            "  adding: training_datas/train_data4660.zip (stored 0%)\n",
            "  adding: training_datas/train_data16888.zip (stored 0%)\n",
            "  adding: training_datas/train_data4800.zip (stored 0%)\n",
            "  adding: training_datas/train_data15823.zip (stored 0%)\n",
            "  adding: training_datas/train_data29253.zip (stored 0%)\n",
            "  adding: training_datas/train_data29419.zip (stored 0%)\n",
            "  adding: training_datas/train_data24544.zip (stored 0%)\n",
            "  adding: training_datas/train_data11997.zip (stored 0%)\n",
            "  adding: training_datas/train_data16979.zip (stored 0%)\n",
            "  adding: training_datas/train_data25790.zip (stored 0%)\n",
            "  adding: training_datas/train_data1082.zip (stored 0%)\n",
            "  adding: training_datas/train_data12844.zip (stored 0%)\n",
            "  adding: training_datas/train_data20045.zip (stored 0%)\n",
            "  adding: training_datas/train_data25389.zip (stored 0%)\n",
            "  adding: training_datas/train_data11334.zip (stored 0%)\n",
            "  adding: training_datas/train_data9572.zip (stored 0%)\n",
            "  adding: training_datas/train_data24094.zip (stored 0%)\n",
            "  adding: training_datas/train_data28391.zip (stored 0%)\n",
            "  adding: training_datas/train_data6694.zip (stored 0%)\n",
            "  adding: training_datas/train_data22274.zip (stored 0%)\n",
            "  adding: training_datas/train_data13967.zip (stored 0%)\n",
            "  adding: training_datas/train_data1380.zip (stored 0%)\n",
            "  adding: training_datas/train_data10225.zip (stored 0%)\n",
            "  adding: training_datas/train_data23808.zip (stored 0%)\n",
            "  adding: training_datas/train_data16517.zip (stored 0%)\n",
            "  adding: training_datas/train_data9794.zip (stored 0%)\n",
            "  adding: training_datas/train_data6617.zip (stored 0%)\n",
            "  adding: training_datas/train_data5686.zip (stored 0%)\n",
            "  adding: training_datas/train_data9921.zip (stored 0%)\n",
            "  adding: training_datas/train_data1718.zip (stored 0%)\n",
            "  adding: training_datas/train_data7789.zip (stored 0%)\n",
            "  adding: training_datas/train_data18632.zip (stored 0%)\n",
            "  adding: training_datas/train_data11094.zip (stored 0%)\n",
            "  adding: training_datas/train_data26630.zip (stored 0%)\n",
            "  adding: training_datas/train_data18724.zip (stored 0%)\n",
            "  adding: training_datas/train_data28080.zip (stored 0%)\n",
            "  adding: training_datas/train_data23504.zip (stored 0%)\n",
            "  adding: training_datas/train_data15462.zip (stored 0%)\n",
            "  adding: training_datas/train_data27741.zip (stored 0%)\n",
            "  adding: training_datas/train_data29825.zip (stored 0%)\n",
            "  adding: training_datas/train_data7423.zip (stored 0%)\n",
            "  adding: training_datas/train_data17624.zip (stored 0%)\n",
            "  adding: training_datas/train_data26804.zip (stored 0%)\n",
            "  adding: training_datas/train_data11273.zip (stored 0%)\n",
            "  adding: training_datas/train_data904.zip (stored 0%)\n",
            "  adding: training_datas/train_data9971.zip (stored 0%)\n",
            "  adding: training_datas/train_data26962.zip (stored 0%)\n",
            "  adding: training_datas/train_data7242.zip (stored 0%)\n",
            "  adding: training_datas/train_data4445.zip (stored 0%)\n",
            "  adding: training_datas/train_data15569.zip (stored 0%)\n",
            "  adding: training_datas/train_data21896.zip (stored 0%)\n",
            "  adding: training_datas/train_data16478.zip (stored 0%)\n",
            "  adding: training_datas/train_data11286.zip (stored 0%)\n",
            "  adding: training_datas/train_data14949.zip (stored 0%)\n",
            "  adding: training_datas/train_data30035.zip (stored 0%)\n",
            "  adding: training_datas/train_data1354.zip (stored 0%)\n",
            "  adding: training_datas/train_data1164.zip (stored 0%)\n",
            "  adding: training_datas/train_data8806.zip (stored 0%)\n",
            "  adding: training_datas/train_data25558.zip (stored 0%)\n",
            "  adding: training_datas/train_data17392.zip (stored 0%)\n",
            "  adding: training_datas/train_data15715.zip (stored 0%)\n",
            "  adding: training_datas/train_data21901.zip (stored 0%)\n",
            "  adding: training_datas/train_data25504.zip (stored 0%)\n",
            "  adding: training_datas/train_data1022.zip (stored 0%)\n",
            "  adding: training_datas/train_data3372.zip (stored 0%)\n",
            "  adding: training_datas/train_data24685.zip (stored 0%)\n",
            "  adding: training_datas/train_data17398.zip (stored 0%)\n",
            "  adding: training_datas/train_data11985.zip (stored 0%)\n",
            "  adding: training_datas/train_data17947.zip (stored 0%)\n",
            "  adding: training_datas/train_data29162.zip (stored 0%)\n",
            "  adding: training_datas/train_data13330.zip (stored 0%)\n",
            "  adding: training_datas/train_data21632.zip (stored 0%)\n",
            "  adding: training_datas/train_data15476.zip (stored 0%)\n",
            "  adding: training_datas/train_data14870.zip (stored 0%)\n",
            "  adding: training_datas/train_data4885.zip (stored 0%)\n",
            "  adding: training_datas/train_data17621.zip (stored 0%)\n",
            "  adding: training_datas/train_data14120.zip (stored 0%)\n",
            "  adding: training_datas/train_data7923.zip (stored 0%)\n",
            "  adding: training_datas/train_data17498.zip (stored 0%)\n",
            "  adding: training_datas/train_data21000.zip (stored 0%)\n",
            "  adding: training_datas/train_data1786.zip (stored 0%)\n",
            "  adding: training_datas/train_data7090.zip (stored 0%)\n",
            "  adding: training_datas/train_data905.zip (stored 0%)\n",
            "  adding: training_datas/train_data13743.zip (stored 0%)\n",
            "  adding: training_datas/train_data12640.zip (stored 0%)\n",
            "  adding: training_datas/train_data295.zip (stored 0%)\n",
            "  adding: training_datas/train_data18788.zip (stored 0%)\n",
            "  adding: training_datas/train_data22159.zip (stored 0%)\n",
            "  adding: training_datas/train_data21594.zip (stored 0%)\n",
            "  adding: training_datas/train_data26359.zip (stored 0%)\n",
            "  adding: training_datas/train_data27735.zip (stored 0%)\n",
            "  adding: training_datas/train_data8612.zip (stored 0%)\n",
            "  adding: training_datas/train_data23978.zip (stored 0%)\n",
            "  adding: training_datas/train_data8487.zip (stored 0%)\n",
            "  adding: training_datas/train_data23829.zip (stored 0%)\n",
            "  adding: training_datas/train_data27513.zip (stored 0%)\n",
            "  adding: training_datas/train_data16950.zip (stored 0%)\n",
            "  adding: training_datas/train_data13180.zip (stored 0%)\n",
            "  adding: training_datas/train_data15995.zip (stored 0%)\n",
            "  adding: training_datas/train_data11153.zip (stored 0%)\n",
            "  adding: training_datas/train_data9539.zip (stored 0%)\n",
            "  adding: training_datas/train_data21118.zip (stored 0%)\n",
            "  adding: training_datas/train_data27679.zip (stored 0%)\n",
            "  adding: training_datas/train_data18986.zip (stored 0%)\n",
            "  adding: training_datas/train_data8113.zip (stored 0%)\n",
            "  adding: training_datas/train_data11923.zip (stored 0%)\n",
            "  adding: training_datas/train_data2420.zip (stored 0%)\n",
            "  adding: training_datas/train_data25335.zip (stored 0%)\n",
            "  adding: training_datas/train_data7413.zip (stored 0%)\n",
            "  adding: training_datas/train_data29972.zip (stored 0%)\n",
            "  adding: training_datas/train_data26619.zip (stored 0%)\n",
            "  adding: training_datas/train_data10337.zip (stored 0%)\n",
            "  adding: training_datas/train_data13426.zip (stored 0%)\n",
            "  adding: training_datas/train_data27532.zip (stored 0%)\n",
            "  adding: training_datas/train_data23422.zip (stored 0%)\n",
            "  adding: training_datas/train_data5662.zip (stored 0%)\n",
            "  adding: training_datas/train_data1403.zip (stored 0%)\n",
            "  adding: training_datas/train_data27094.zip (stored 0%)\n",
            "  adding: training_datas/train_data7284.zip (stored 0%)\n",
            "  adding: training_datas/train_data11847.zip (stored 0%)\n",
            "  adding: training_datas/train_data17942.zip (stored 0%)\n",
            "  adding: training_datas/train_data19813.zip (stored 0%)\n",
            "  adding: training_datas/train_data6730.zip (stored 0%)\n",
            "  adding: training_datas/train_data8204.zip (stored 0%)\n",
            "  adding: training_datas/train_data2507.zip (stored 0%)\n",
            "  adding: training_datas/train_data15601.zip (stored 0%)\n",
            "  adding: training_datas/train_data25136.zip (stored 0%)\n",
            "  adding: training_datas/train_data7792.zip (stored 0%)\n",
            "  adding: training_datas/train_data18358.zip (stored 0%)\n",
            "  adding: training_datas/train_data23381.zip (stored 0%)\n",
            "  adding: training_datas/train_data12008.zip (stored 0%)\n",
            "  adding: training_datas/train_data1783.zip (stored 0%)\n",
            "  adding: training_datas/train_data15455.zip (stored 0%)\n",
            "  adding: training_datas/train_data6317.zip (stored 0%)\n",
            "  adding: training_datas/train_data10934.zip (stored 0%)\n",
            "  adding: training_datas/train_data24970.zip (stored 0%)\n",
            "  adding: training_datas/train_data20603.zip (stored 0%)\n",
            "  adding: training_datas/train_data14018.zip (stored 0%)\n",
            "  adding: training_datas/train_data4780.zip (stored 0%)\n",
            "  adding: training_datas/train_data25035.zip (stored 0%)\n",
            "  adding: training_datas/train_data8718.zip (stored 0%)\n",
            "  adding: training_datas/train_data11352.zip (stored 0%)\n",
            "  adding: training_datas/train_data11434.zip (stored 0%)\n",
            "  adding: training_datas/train_data15047.zip (stored 0%)\n",
            "  adding: training_datas/train_data1225.zip (stored 0%)\n",
            "  adding: training_datas/train_data3643.zip (stored 0%)\n",
            "  adding: training_datas/train_data7173.zip (stored 0%)\n",
            "  adding: training_datas/train_data28073.zip (stored 0%)\n",
            "  adding: training_datas/train_data13280.zip (stored 0%)\n",
            "  adding: training_datas/train_data28980.zip (stored 0%)\n",
            "  adding: training_datas/train_data16625.zip (stored 0%)\n",
            "  adding: training_datas/train_data12761.zip (stored 0%)\n",
            "  adding: training_datas/train_data14441.zip (stored 0%)\n",
            "  adding: training_datas/train_data14195.zip (stored 0%)\n",
            "  adding: training_datas/train_data15594.zip (stored 0%)\n",
            "  adding: training_datas/train_data28417.zip (stored 0%)\n",
            "  adding: training_datas/train_data24053.zip (stored 0%)\n",
            "  adding: training_datas/train_data5538.zip (stored 0%)\n",
            "  adding: training_datas/train_data11069.zip (stored 0%)\n",
            "  adding: training_datas/train_data9855.zip (stored 0%)\n",
            "  adding: training_datas/train_data5401.zip (stored 0%)\n",
            "  adding: training_datas/train_data1212.zip (stored 0%)\n",
            "  adding: training_datas/train_data8802.zip (stored 0%)\n",
            "  adding: training_datas/train_data14681.zip (stored 0%)\n",
            "  adding: training_datas/train_data5252.zip (stored 0%)\n",
            "  adding: training_datas/train_data23059.zip (stored 0%)\n",
            "  adding: training_datas/train_data25150.zip (stored 0%)\n",
            "  adding: training_datas/train_data17290.zip (stored 0%)\n",
            "  adding: training_datas/train_data22065.zip (stored 0%)\n",
            "  adding: training_datas/train_data24066.zip (stored 0%)\n",
            "  adding: training_datas/train_data355.zip (stored 0%)\n",
            "  adding: training_datas/train_data24955.zip (stored 0%)\n",
            "  adding: training_datas/train_data23010.zip (stored 0%)\n",
            "  adding: training_datas/train_data5270.zip (stored 0%)\n",
            "  adding: training_datas/train_data26725.zip (stored 0%)\n",
            "  adding: training_datas/train_data20774.zip (stored 0%)\n",
            "  adding: training_datas/train_data2170.zip (stored 0%)\n",
            "  adding: training_datas/train_data28560.zip (stored 0%)\n",
            "  adding: training_datas/train_data9118.zip (stored 0%)\n",
            "  adding: training_datas/train_data16142.zip (stored 0%)\n",
            "  adding: training_datas/train_data29579.zip (stored 0%)\n",
            "  adding: training_datas/train_data9055.zip (stored 0%)\n",
            "  adding: training_datas/train_data21502.zip (stored 0%)\n",
            "  adding: training_datas/train_data26463.zip (stored 0%)\n",
            "  adding: training_datas/train_data23787.zip (stored 0%)\n",
            "  adding: training_datas/train_data7941.zip (stored 0%)\n",
            "  adding: training_datas/train_data6759.zip (stored 0%)\n",
            "  adding: training_datas/train_data4841.zip (stored 0%)\n",
            "  adding: training_datas/train_data20398.zip (stored 0%)\n",
            "  adding: training_datas/train_data556.zip (stored 0%)\n",
            "  adding: training_datas/train_data6472.zip (stored 0%)\n",
            "  adding: training_datas/train_data17170.zip (stored 0%)\n",
            "  adding: training_datas/train_data29969.zip (stored 0%)\n",
            "  adding: training_datas/train_data21256.zip (stored 0%)\n",
            "  adding: training_datas/train_data16694.zip (stored 0%)\n",
            "  adding: training_datas/train_data16628.zip (stored 0%)\n",
            "  adding: training_datas/train_data13183.zip (stored 0%)\n",
            "  adding: training_datas/train_data6308.zip (stored 0%)\n",
            "  adding: training_datas/train_data20798.zip (stored 0%)\n",
            "  adding: training_datas/train_data15360.zip (stored 0%)\n",
            "  adding: training_datas/train_data16994.zip (stored 0%)\n",
            "  adding: training_datas/train_data29673.zip (stored 0%)\n",
            "  adding: training_datas/train_data171.zip (stored 0%)\n",
            "  adding: training_datas/train_data26435.zip (stored 0%)\n",
            "  adding: training_datas/train_data25647.zip (stored 0%)\n",
            "  adding: training_datas/train_data25537.zip (stored 0%)\n",
            "  adding: training_datas/train_data23509.zip (stored 0%)\n",
            "  adding: training_datas/train_data7862.zip (stored 0%)\n",
            "  adding: training_datas/train_data22331.zip (stored 0%)\n",
            "  adding: training_datas/train_data28929.zip (stored 0%)\n",
            "  adding: training_datas/train_data13392.zip (stored 0%)\n",
            "  adding: training_datas/train_data9793.zip (stored 0%)\n",
            "  adding: training_datas/train_data28727.zip (stored 0%)\n",
            "  adding: training_datas/train_data6904.zip (stored 0%)\n",
            "  adding: training_datas/train_data1268.zip (stored 0%)\n",
            "  adding: training_datas/train_data5247.zip (stored 0%)\n",
            "  adding: training_datas/train_data9129.zip (stored 0%)\n",
            "  adding: training_datas/train_data21898.zip (stored 0%)\n",
            "  adding: training_datas/train_data25982.zip (stored 0%)\n",
            "  adding: training_datas/train_data13603.zip (stored 0%)\n",
            "  adding: training_datas/train_data13244.zip (stored 0%)\n",
            "  adding: training_datas/train_data20261.zip (stored 0%)\n",
            "  adding: training_datas/train_data24256.zip (stored 0%)\n",
            "  adding: training_datas/train_data6828.zip (stored 0%)\n",
            "  adding: training_datas/train_data18826.zip (stored 0%)\n",
            "  adding: training_datas/train_data18928.zip (stored 0%)\n",
            "  adding: training_datas/train_data12768.zip (stored 0%)\n",
            "  adding: training_datas/train_data9685.zip (stored 0%)\n",
            "  adding: training_datas/train_data13520.zip (stored 0%)\n",
            "  adding: training_datas/train_data8791.zip (stored 0%)\n",
            "  adding: training_datas/train_data11491.zip (stored 0%)\n",
            "  adding: training_datas/train_data8220.zip (stored 0%)\n",
            "  adding: training_datas/train_data27592.zip (stored 0%)\n",
            "  adding: training_datas/train_data23568.zip (stored 0%)\n",
            "  adding: training_datas/train_data28766.zip (stored 0%)\n",
            "  adding: training_datas/train_data13556.zip (stored 0%)\n",
            "  adding: training_datas/train_data5635.zip (stored 0%)\n",
            "  adding: training_datas/train_data18581.zip (stored 0%)\n",
            "  adding: training_datas/train_data10628.zip (stored 0%)\n",
            "  adding: training_datas/train_data5089.zip (stored 0%)\n",
            "  adding: training_datas/train_data3514.zip (stored 0%)\n",
            "  adding: training_datas/train_data15447.zip (stored 0%)\n",
            "  adding: training_datas/train_data15024.zip (stored 0%)\n",
            "  adding: training_datas/train_data10316.zip (stored 0%)\n",
            "  adding: training_datas/train_data20212.zip (stored 0%)\n",
            "  adding: training_datas/train_data21262.zip (stored 0%)\n",
            "  adding: training_datas/train_data28413.zip (stored 0%)\n",
            "  adding: training_datas/train_data1455.zip (stored 0%)\n",
            "  adding: training_datas/train_data17211.zip (stored 0%)\n",
            "  adding: training_datas/train_data25462.zip (stored 0%)\n",
            "  adding: training_datas/train_data7047.zip (stored 0%)\n",
            "  adding: training_datas/train_data10532.zip (stored 0%)\n",
            "  adding: training_datas/train_data23124.zip (stored 0%)\n",
            "  adding: training_datas/train_data12049.zip (stored 0%)\n",
            "  adding: training_datas/train_data9968.zip (stored 0%)\n",
            "  adding: training_datas/train_data22395.zip (stored 0%)\n",
            "  adding: training_datas/train_data7972.zip (stored 0%)\n",
            "  adding: training_datas/train_data16264.zip (stored 0%)\n",
            "  adding: training_datas/train_data1643.zip (stored 0%)\n",
            "  adding: training_datas/train_data6364.zip (stored 0%)\n",
            "  adding: training_datas/train_data15136.zip (stored 0%)\n",
            "  adding: training_datas/train_data16370.zip (stored 0%)\n",
            "  adding: training_datas/train_data12598.zip (stored 0%)\n",
            "  adding: training_datas/train_data852.zip (stored 0%)\n",
            "  adding: training_datas/train_data2677.zip (stored 0%)\n",
            "  adding: training_datas/train_data3399.zip (stored 0%)\n",
            "  adding: training_datas/train_data1355.zip (stored 0%)\n",
            "  adding: training_datas/train_data21506.zip (stored 0%)\n",
            "  adding: training_datas/train_data29301.zip (stored 0%)\n",
            "  adding: training_datas/train_data20719.zip (stored 0%)\n",
            "  adding: training_datas/train_data21880.zip (stored 0%)\n",
            "  adding: training_datas/train_data9959.zip (stored 0%)\n",
            "  adding: training_datas/train_data15309.zip (stored 0%)\n",
            "  adding: training_datas/train_data6066.zip (stored 0%)\n",
            "  adding: training_datas/train_data7167.zip (stored 0%)\n",
            "  adding: training_datas/train_data27362.zip (stored 0%)\n",
            "  adding: training_datas/train_data18068.zip (stored 0%)\n",
            "  adding: training_datas/train_data20234.zip (stored 0%)\n",
            "  adding: training_datas/train_data1985.zip (stored 0%)\n",
            "  adding: training_datas/train_data5839.zip (stored 0%)\n",
            "  adding: training_datas/train_data19547.zip (stored 0%)\n",
            "  adding: training_datas/train_data7905.zip (stored 0%)\n",
            "  adding: training_datas/train_data22955.zip (stored 0%)\n",
            "  adding: training_datas/train_data17285.zip (stored 0%)\n",
            "  adding: training_datas/train_data14382.zip (stored 0%)\n",
            "  adding: training_datas/train_data12394.zip (stored 0%)\n",
            "  adding: training_datas/train_data26089.zip (stored 0%)\n",
            "  adding: training_datas/train_data21946.zip (stored 0%)\n",
            "  adding: training_datas/train_data6253.zip (stored 0%)\n",
            "  adding: training_datas/train_data9932.zip (stored 0%)\n",
            "  adding: training_datas/train_data15108.zip (stored 0%)\n",
            "  adding: training_datas/train_data9624.zip (stored 0%)\n",
            "  adding: training_datas/train_data25586.zip (stored 0%)\n",
            "  adding: training_datas/train_data21607.zip (stored 0%)\n",
            "  adding: training_datas/train_data23789.zip (stored 0%)\n",
            "  adding: training_datas/train_data2049.zip (stored 0%)\n",
            "  adding: training_datas/train_data27082.zip (stored 0%)\n",
            "  adding: training_datas/train_data21960.zip (stored 0%)\n",
            "  adding: training_datas/train_data27041.zip (stored 0%)\n",
            "  adding: training_datas/train_data14625.zip (stored 0%)\n",
            "  adding: training_datas/train_data24203.zip (stored 0%)\n",
            "  adding: training_datas/train_data13061.zip (stored 0%)\n",
            "  adding: training_datas/train_data7920.zip (stored 0%)\n",
            "  adding: training_datas/train_data26931.zip (stored 0%)\n",
            "  adding: training_datas/train_data22796.zip (stored 0%)\n",
            "  adding: training_datas/train_data22050.zip (stored 0%)\n",
            "  adding: training_datas/train_data13599.zip (stored 0%)\n",
            "  adding: training_datas/train_data15765.zip (stored 0%)\n",
            "  adding: training_datas/train_data7201.zip (stored 0%)\n",
            "  adding: training_datas/train_data21588.zip (stored 0%)\n",
            "  adding: training_datas/train_data12030.zip (stored 0%)\n",
            "  adding: training_datas/train_data9211.zip (stored 0%)\n",
            "  adding: training_datas/train_data5332.zip (stored 0%)\n",
            "  adding: training_datas/train_data17271.zip (stored 0%)\n",
            "  adding: training_datas/train_data12938.zip (stored 0%)\n",
            "  adding: training_datas/train_data8111.zip (stored 0%)\n",
            "  adding: training_datas/train_data2251.zip (stored 0%)\n",
            "  adding: training_datas/train_data9711.zip (stored 0%)\n",
            "  adding: training_datas/train_data8375.zip (stored 0%)\n",
            "  adding: training_datas/train_data24987.zip (stored 0%)\n",
            "  adding: training_datas/train_data24211.zip (stored 0%)\n",
            "  adding: training_datas/train_data17768.zip (stored 0%)\n",
            "  adding: training_datas/train_data10570.zip (stored 0%)\n",
            "  adding: training_datas/train_data13293.zip (stored 0%)\n",
            "  adding: training_datas/train_data13159.zip (stored 0%)\n",
            "  adding: training_datas/train_data6354.zip (stored 0%)\n",
            "  adding: training_datas/train_data4083.zip (stored 0%)\n",
            "  adding: training_datas/train_data14411.zip (stored 0%)\n",
            "  adding: training_datas/train_data530.zip (stored 0%)\n",
            "  adding: training_datas/train_data26046.zip (stored 0%)\n",
            "  adding: training_datas/train_data13919.zip (stored 0%)\n",
            "  adding: training_datas/train_data29219.zip (stored 0%)\n",
            "  adding: training_datas/train_data23473.zip (stored 0%)\n",
            "  adding: training_datas/train_data25188.zip (stored 0%)\n",
            "  adding: training_datas/train_data27795.zip (stored 0%)\n",
            "  adding: training_datas/train_data28430.zip (stored 0%)\n",
            "  adding: training_datas/train_data8601.zip (stored 0%)\n",
            "  adding: training_datas/train_data27958.zip (stored 0%)\n",
            "  adding: training_datas/train_data23519.zip (stored 0%)\n",
            "  adding: training_datas/train_data6862.zip (stored 0%)\n",
            "  adding: training_datas/train_data21807.zip (stored 0%)\n",
            "  adding: training_datas/train_data26381.zip (stored 0%)\n",
            "  adding: training_datas/train_data18485.zip (stored 0%)\n",
            "  adding: training_datas/train_data18040.zip (stored 0%)\n",
            "  adding: training_datas/train_data21398.zip (stored 0%)\n",
            "  adding: training_datas/train_data14288.zip (stored 0%)\n",
            "  adding: training_datas/train_data7793.zip (stored 0%)\n",
            "  adding: training_datas/train_data5448.zip (stored 0%)\n",
            "  adding: training_datas/train_data16241.zip (stored 0%)\n",
            "  adding: training_datas/train_data29810.zip (stored 0%)\n",
            "  adding: training_datas/train_data25466.zip (stored 0%)\n",
            "  adding: training_datas/train_data21945.zip (stored 0%)\n",
            "  adding: training_datas/train_data30136.zip (stored 0%)\n",
            "  adding: training_datas/train_data9583.zip (stored 0%)\n",
            "  adding: training_datas/train_data13772.zip (stored 0%)\n",
            "  adding: training_datas/train_data5572.zip (stored 0%)\n",
            "  adding: training_datas/train_data20536.zip (stored 0%)\n",
            "  adding: training_datas/train_data5745.zip (stored 0%)\n",
            "  adding: training_datas/train_data11044.zip (stored 0%)\n",
            "  adding: training_datas/train_data25194.zip (stored 0%)\n",
            "  adding: training_datas/train_data28843.zip (stored 0%)\n",
            "  adding: training_datas/train_data9383.zip (stored 0%)\n",
            "  adding: training_datas/train_data14244.zip (stored 0%)\n",
            "  adding: training_datas/train_data1662.zip (stored 0%)\n",
            "  adding: training_datas/train_data25952.zip (stored 0%)\n",
            "  adding: training_datas/train_data25732.zip (stored 0%)\n",
            "  adding: training_datas/train_data12471.zip (stored 0%)\n",
            "  adding: training_datas/train_data23394.zip (stored 0%)\n",
            "  adding: training_datas/train_data6967.zip (stored 0%)\n",
            "  adding: training_datas/train_data23132.zip (stored 0%)\n",
            "  adding: training_datas/train_data17433.zip (stored 0%)\n",
            "  adding: training_datas/train_data8063.zip (stored 0%)\n",
            "  adding: training_datas/train_data24102.zip (stored 0%)\n",
            "  adding: training_datas/train_data23474.zip (stored 0%)\n",
            "  adding: training_datas/train_data11104.zip (stored 0%)\n",
            "  adding: training_datas/train_data4857.zip (stored 0%)\n",
            "  adding: training_datas/train_data29800.zip (stored 0%)\n",
            "  adding: training_datas/train_data12183.zip (stored 0%)\n",
            "  adding: training_datas/train_data22437.zip (stored 0%)\n",
            "  adding: training_datas/train_data24633.zip (stored 0%)\n",
            "  adding: training_datas/train_data26833.zip (stored 0%)\n",
            "  adding: training_datas/train_data10987.zip (stored 0%)\n",
            "  adding: training_datas/train_data8400.zip (stored 0%)\n",
            "  adding: training_datas/train_data2143.zip (stored 0%)\n",
            "  adding: training_datas/train_data2932.zip (stored 0%)\n",
            "  adding: training_datas/train_data24347.zip (stored 0%)\n",
            "  adding: training_datas/train_data1770.zip (stored 0%)\n",
            "  adding: training_datas/train_data23066.zip (stored 0%)\n",
            "  adding: training_datas/train_data14839.zip (stored 0%)\n",
            "  adding: training_datas/train_data15724.zip (stored 0%)\n",
            "  adding: training_datas/train_data18796.zip (stored 0%)\n",
            "  adding: training_datas/train_data18078.zip (stored 0%)\n",
            "  adding: training_datas/train_data7535.zip (stored 0%)\n",
            "  adding: training_datas/train_data2979.zip (stored 0%)\n",
            "  adding: training_datas/train_data22335.zip (stored 0%)\n",
            "  adding: training_datas/train_data24473.zip (stored 0%)\n",
            "  adding: training_datas/train_data16086.zip (stored 0%)\n",
            "  adding: training_datas/train_data6689.zip (stored 0%)\n",
            "  adding: training_datas/train_data5174.zip (stored 0%)\n",
            "  adding: training_datas/train_data30173.zip (stored 0%)\n",
            "  adding: training_datas/train_data4718.zip (stored 0%)\n",
            "  adding: training_datas/train_data9282.zip (stored 0%)\n",
            "  adding: training_datas/train_data492.zip (stored 0%)\n",
            "  adding: training_datas/train_data7655.zip (stored 0%)\n",
            "  adding: training_datas/train_data5624.zip (stored 0%)\n",
            "  adding: training_datas/train_data16946.zip (stored 0%)\n",
            "  adding: training_datas/train_data26951.zip (stored 0%)\n",
            "  adding: training_datas/train_data8053.zip (stored 0%)\n",
            "  adding: training_datas/train_data4989.zip (stored 0%)\n",
            "  adding: training_datas/train_data20513.zip (stored 0%)\n",
            "  adding: training_datas/train_data24150.zip (stored 0%)\n",
            "  adding: training_datas/train_data531.zip (stored 0%)\n",
            "  adding: training_datas/train_data11222.zip (stored 0%)\n",
            "  adding: training_datas/train_data29213.zip (stored 0%)\n",
            "  adding: training_datas/train_data17739.zip (stored 0%)\n",
            "  adding: training_datas/train_data11200.zip (stored 0%)\n",
            "  adding: training_datas/train_data23953.zip (stored 0%)\n",
            "  adding: training_datas/train_data23258.zip (stored 0%)\n",
            "  adding: training_datas/train_data18871.zip (stored 0%)\n",
            "  adding: training_datas/train_data16528.zip (stored 0%)\n",
            "  adding: training_datas/train_data15442.zip (stored 0%)\n",
            "  adding: training_datas/train_data22626.zip (stored 0%)\n",
            "  adding: training_datas/train_data16098.zip (stored 0%)\n",
            "  adding: training_datas/train_data19605.zip (stored 0%)\n",
            "  adding: training_datas/train_data20533.zip (stored 0%)\n",
            "  adding: training_datas/train_data1203.zip (stored 0%)\n",
            "  adding: training_datas/train_data25334.zip (stored 0%)\n",
            "  adding: training_datas/train_data23533.zip (stored 0%)\n",
            "  adding: training_datas/train_data2846.zip (stored 0%)\n",
            "  adding: training_datas/train_data9824.zip (stored 0%)\n",
            "  adding: training_datas/train_data2829.zip (stored 0%)\n",
            "  adding: training_datas/train_data9979.zip (stored 0%)\n",
            "  adding: training_datas/train_data3575.zip (stored 0%)\n",
            "  adding: training_datas/train_data4120.zip (stored 0%)\n",
            "  adding: training_datas/train_data16095.zip (stored 0%)\n",
            "  adding: training_datas/train_data1676.zip (stored 0%)\n",
            "  adding: training_datas/train_data20071.zip (stored 0%)\n",
            "  adding: training_datas/train_data1964.zip (stored 0%)\n",
            "  adding: training_datas/train_data2537.zip (stored 0%)\n",
            "  adding: training_datas/train_data16090.zip (stored 0%)\n",
            "  adding: training_datas/train_data72.zip (stored 0%)\n",
            "  adding: training_datas/train_data17872.zip (stored 0%)\n",
            "  adding: training_datas/train_data13125.zip (stored 0%)\n",
            "  adding: training_datas/train_data14444.zip (stored 0%)\n",
            "  adding: training_datas/train_data1221.zip (stored 0%)\n",
            "  adding: training_datas/train_data25236.zip (stored 0%)\n",
            "  adding: training_datas/train_data5900.zip (stored 0%)\n",
            "  adding: training_datas/train_data12280.zip (stored 0%)\n",
            "  adding: training_datas/train_data26372.zip (stored 0%)\n",
            "  adding: training_datas/train_data29942.zip (stored 0%)\n",
            "  adding: training_datas/train_data10813.zip (stored 0%)\n",
            "  adding: training_datas/train_data23955.zip (stored 0%)\n",
            "  adding: training_datas/train_data19356.zip (stored 0%)\n",
            "  adding: training_datas/train_data19482.zip (stored 0%)\n",
            "  adding: training_datas/train_data20444.zip (stored 0%)\n",
            "  adding: training_datas/train_data8423.zip (stored 0%)\n",
            "  adding: training_datas/train_data22655.zip (stored 0%)\n",
            "  adding: training_datas/train_data5592.zip (stored 0%)\n",
            "  adding: training_datas/train_data8240.zip (stored 0%)\n",
            "  adding: training_datas/train_data25943.zip (stored 0%)\n",
            "  adding: training_datas/train_data12139.zip (stored 0%)\n",
            "  adding: training_datas/train_data28819.zip (stored 0%)\n",
            "  adding: training_datas/train_data28001.zip (stored 0%)\n",
            "  adding: training_datas/train_data15493.zip (stored 0%)\n",
            "  adding: training_datas/train_data25223.zip (stored 0%)\n",
            "  adding: training_datas/train_data9277.zip (stored 0%)\n",
            "  adding: training_datas/train_data27588.zip (stored 0%)\n",
            "  adding: training_datas/train_data14180.zip (stored 0%)\n",
            "  adding: training_datas/train_data8097.zip (stored 0%)\n",
            "  adding: training_datas/train_data16879.zip (stored 0%)\n",
            "  adding: training_datas/train_data4910.zip (stored 0%)\n",
            "  adding: training_datas/train_data2536.zip (stored 0%)\n",
            "  adding: training_datas/train_data3684.zip (stored 0%)\n",
            "  adding: training_datas/train_data7435.zip (stored 0%)\n",
            "  adding: training_datas/train_data14770.zip (stored 0%)\n",
            "  adding: training_datas/train_data21646.zip (stored 0%)\n",
            "  adding: training_datas/train_data16229.zip (stored 0%)\n",
            "  adding: training_datas/train_data27545.zip (stored 0%)\n",
            "  adding: training_datas/train_data13168.zip (stored 0%)\n",
            "  adding: training_datas/train_data5614.zip (stored 0%)\n",
            "  adding: training_datas/train_data20031.zip (stored 0%)\n",
            "  adding: training_datas/train_data4079.zip (stored 0%)\n",
            "  adding: training_datas/train_data11644.zip (stored 0%)\n",
            "  adding: training_datas/train_data5406.zip (stored 0%)\n",
            "  adding: training_datas/train_data6949.zip (stored 0%)\n",
            "  adding: training_datas/train_data23801.zip (stored 0%)\n",
            "  adding: training_datas/train_data11232.zip (stored 0%)\n",
            "  adding: training_datas/train_data3076.zip (stored 0%)\n",
            "  adding: training_datas/train_data9403.zip (stored 0%)\n",
            "  adding: training_datas/train_data24913.zip (stored 0%)\n",
            "  adding: training_datas/train_data21103.zip (stored 0%)\n",
            "  adding: training_datas/train_data12470.zip (stored 0%)\n",
            "  adding: training_datas/train_data9900.zip (stored 0%)\n",
            "  adding: training_datas/train_data17220.zip (stored 0%)\n",
            "  adding: training_datas/train_data21611.zip (stored 0%)\n",
            "  adding: training_datas/train_data24261.zip (stored 0%)\n",
            "  adding: training_datas/train_data25016.zip (stored 0%)\n",
            "  adding: training_datas/train_data16699.zip (stored 0%)\n",
            "  adding: training_datas/train_data26044.zip (stored 0%)\n",
            "  adding: training_datas/train_data29223.zip (stored 0%)\n",
            "  adding: training_datas/train_data26379.zip (stored 0%)\n",
            "  adding: training_datas/train_data30186.zip (stored 0%)\n",
            "  adding: training_datas/train_data28850.zip (stored 0%)\n",
            "  adding: training_datas/train_data17767.zip (stored 0%)\n",
            "  adding: training_datas/train_data16985.zip (stored 0%)\n",
            "  adding: training_datas/train_data19247.zip (stored 0%)\n",
            "  adding: training_datas/train_data10986.zip (stored 0%)\n",
            "  adding: training_datas/train_data30092.zip (stored 0%)\n",
            "  adding: training_datas/train_data5505.zip (stored 0%)\n",
            "  adding: training_datas/train_data6998.zip (stored 0%)\n",
            "  adding: training_datas/train_data7074.zip (stored 0%)\n",
            "  adding: training_datas/train_data14576.zip (stored 0%)\n",
            "  adding: training_datas/train_data8743.zip (stored 0%)\n",
            "  adding: training_datas/train_data19385.zip (stored 0%)\n",
            "  adding: training_datas/train_data5688.zip (stored 0%)\n",
            "  adding: training_datas/train_data683.zip (stored 0%)\n",
            "  adding: training_datas/train_data6463.zip (stored 0%)\n",
            "  adding: training_datas/train_data1038.zip (stored 0%)\n",
            "  adding: training_datas/train_data7272.zip (stored 0%)\n",
            "  adding: training_datas/train_data5796.zip (stored 0%)\n",
            "  adding: training_datas/train_data10514.zip (stored 0%)\n",
            "  adding: training_datas/train_data7516.zip (stored 0%)\n",
            "  adding: training_datas/train_data5379.zip (stored 0%)\n",
            "  adding: training_datas/train_data22840.zip (stored 0%)\n",
            "  adding: training_datas/train_data4781.zip (stored 0%)\n",
            "  adding: training_datas/train_data30175.zip (stored 0%)\n",
            "  adding: training_datas/train_data19567.zip (stored 0%)\n",
            "  adding: training_datas/train_data27978.zip (stored 0%)\n",
            "  adding: training_datas/train_data27446.zip (stored 0%)\n",
            "  adding: training_datas/train_data14002.zip (stored 0%)\n",
            "  adding: training_datas/train_data5353.zip (stored 0%)\n",
            "  adding: training_datas/train_data6367.zip (stored 0%)\n",
            "  adding: training_datas/train_data4128.zip (stored 0%)\n",
            "  adding: training_datas/train_data17406.zip (stored 0%)\n",
            "  adding: training_datas/train_data24693.zip (stored 0%)\n",
            "  adding: training_datas/train_data29898.zip (stored 0%)\n",
            "  adding: training_datas/train_data11397.zip (stored 0%)\n",
            "  adding: training_datas/train_data23534.zip (stored 0%)\n",
            "  adding: training_datas/train_data10544.zip (stored 0%)\n",
            "  adding: training_datas/train_data4510.zip (stored 0%)\n",
            "  adding: training_datas/train_data1351.zip (stored 0%)\n",
            "  adding: training_datas/train_data21744.zip (stored 0%)\n",
            "  adding: training_datas/train_data17958.zip (stored 0%)\n",
            "  adding: training_datas/train_data8605.zip (stored 0%)\n",
            "  adding: training_datas/train_data8466.zip (stored 0%)\n",
            "  adding: training_datas/train_data12913.zip (stored 0%)\n",
            "  adding: training_datas/train_data15430.zip (stored 0%)\n",
            "  adding: training_datas/train_data26130.zip (stored 0%)\n",
            "  adding: training_datas/train_data17649.zip (stored 0%)\n",
            "  adding: training_datas/train_data15017.zip (stored 0%)\n",
            "  adding: training_datas/train_data11413.zip (stored 0%)\n",
            "  adding: training_datas/train_data17358.zip (stored 0%)\n",
            "  adding: training_datas/train_data11605.zip (stored 0%)\n",
            "  adding: training_datas/train_data5639.zip (stored 0%)\n",
            "  adding: training_datas/train_data1445.zip (stored 0%)\n",
            "  adding: training_datas/train_data5948.zip (stored 0%)\n",
            "  adding: training_datas/train_data1209.zip (stored 0%)\n",
            "  adding: training_datas/train_data27301.zip (stored 0%)\n",
            "  adding: training_datas/train_data16631.zip (stored 0%)\n",
            "  adding: training_datas/train_data23242.zip (stored 0%)\n",
            "  adding: training_datas/train_data11173.zip (stored 0%)\n",
            "  adding: training_datas/train_data12587.zip (stored 0%)\n",
            "  adding: training_datas/train_data8570.zip (stored 0%)\n",
            "  adding: training_datas/train_data10394.zip (stored 0%)\n",
            "  adding: training_datas/train_data17455.zip (stored 0%)\n",
            "  adding: training_datas/train_data766.zip (stored 0%)\n",
            "  adding: training_datas/train_data13309.zip (stored 0%)\n",
            "  adding: training_datas/train_data25797.zip (stored 0%)\n",
            "  adding: training_datas/train_data28144.zip (stored 0%)\n",
            "  adding: training_datas/train_data7379.zip (stored 0%)\n",
            "  adding: training_datas/train_data15656.zip (stored 0%)\n",
            "  adding: training_datas/train_data14070.zip (stored 0%)\n",
            "  adding: training_datas/train_data2222.zip (stored 0%)\n",
            "  adding: training_datas/train_data20118.zip (stored 0%)\n",
            "  adding: training_datas/train_data19716.zip (stored 0%)\n",
            "  adding: training_datas/train_data23359.zip (stored 0%)\n",
            "  adding: training_datas/train_data9398.zip (stored 0%)\n",
            "  adding: training_datas/train_data27931.zip (stored 0%)\n",
            "  adding: training_datas/train_data10333.zip (stored 0%)\n",
            "  adding: training_datas/train_data7426.zip (stored 0%)\n",
            "  adding: training_datas/train_data3966.zip (stored 0%)\n",
            "  adding: training_datas/train_data8995.zip (stored 0%)\n",
            "  adding: training_datas/train_data9977.zip (stored 0%)\n",
            "  adding: training_datas/train_data29064.zip (stored 0%)\n",
            "  adding: training_datas/train_data28111.zip (stored 0%)\n",
            "  adding: training_datas/train_data20273.zip (stored 0%)\n",
            "  adding: training_datas/train_data29472.zip (stored 0%)\n",
            "  adding: training_datas/train_data24417.zip (stored 0%)\n",
            "  adding: training_datas/train_data22306.zip (stored 0%)\n",
            "  adding: training_datas/train_data10200.zip (stored 0%)\n",
            "  adding: training_datas/train_data1348.zip (stored 0%)\n",
            "  adding: training_datas/train_data28039.zip (stored 0%)\n",
            "  adding: training_datas/train_data24658.zip (stored 0%)\n",
            "  adding: training_datas/train_data12275.zip (stored 0%)\n",
            "  adding: training_datas/train_data11799.zip (stored 0%)\n",
            "  adding: training_datas/train_data1789.zip (stored 0%)\n",
            "  adding: training_datas/train_data17534.zip (stored 0%)\n",
            "  adding: training_datas/train_data15347.zip (stored 0%)\n",
            "  adding: training_datas/train_data19449.zip (stored 0%)\n",
            "  adding: training_datas/train_data12718.zip (stored 0%)\n",
            "  adding: training_datas/train_data4092.zip (stored 0%)\n",
            "  adding: training_datas/train_data14277.zip (stored 0%)\n",
            "  adding: training_datas/train_data27447.zip (stored 0%)\n",
            "  adding: training_datas/train_data27576.zip (stored 0%)\n",
            "  adding: training_datas/train_data8922.zip (stored 0%)\n",
            "  adding: training_datas/train_data17716.zip (stored 0%)\n",
            "  adding: training_datas/train_data19692.zip (stored 0%)\n",
            "  adding: training_datas/train_data1210.zip (stored 0%)\n",
            "  adding: training_datas/train_data29712.zip (stored 0%)\n",
            "  adding: training_datas/train_data28586.zip (stored 0%)\n",
            "  adding: training_datas/train_data26192.zip (stored 0%)\n",
            "  adding: training_datas/train_data30421.zip (stored 0%)\n",
            "  adding: training_datas/train_data14521.zip (stored 0%)\n",
            "  adding: training_datas/train_data11126.zip (stored 0%)\n",
            "  adding: training_datas/train_data21802.zip (stored 0%)\n",
            "  adding: training_datas/train_data12715.zip (stored 0%)\n",
            "  adding: training_datas/train_data21183.zip (stored 0%)\n",
            "  adding: training_datas/train_data24704.zip (stored 0%)\n",
            "  adding: training_datas/train_data9692.zip (stored 0%)\n",
            "  adding: training_datas/train_data11612.zip (stored 0%)\n",
            "  adding: training_datas/train_data3710.zip (stored 0%)\n",
            "  adding: training_datas/train_data27308.zip (stored 0%)\n",
            "  adding: training_datas/train_data27848.zip (stored 0%)\n",
            "  adding: training_datas/train_data26690.zip (stored 0%)\n",
            "  adding: training_datas/train_data7232.zip (stored 0%)\n",
            "  adding: training_datas/train_data5384.zip (stored 0%)\n",
            "  adding: training_datas/train_data29622.zip (stored 0%)\n",
            "  adding: training_datas/train_data30040.zip (stored 0%)\n",
            "  adding: training_datas/train_data28360.zip (stored 0%)\n",
            "  adding: training_datas/train_data11043.zip (stored 0%)\n",
            "  adding: training_datas/train_data19218.zip (stored 0%)\n",
            "  adding: training_datas/train_data20738.zip (stored 0%)\n",
            "  adding: training_datas/train_data14412.zip (stored 0%)\n",
            "  adding: training_datas/train_data17843.zip (stored 0%)\n",
            "  adding: training_datas/train_data5138.zip (stored 0%)\n",
            "  adding: training_datas/train_data17547.zip (stored 0%)\n",
            "  adding: training_datas/train_data23158.zip (stored 0%)\n",
            "  adding: training_datas/train_data6574.zip (stored 0%)\n",
            "  adding: training_datas/train_data19939.zip (stored 0%)\n",
            "  adding: training_datas/train_data2680.zip (stored 0%)\n",
            "  adding: training_datas/train_data1745.zip (stored 0%)\n",
            "  adding: training_datas/train_data28635.zip (stored 0%)\n",
            "  adding: training_datas/train_data29146.zip (stored 0%)\n",
            "  adding: training_datas/train_data17488.zip (stored 0%)\n",
            "  adding: training_datas/train_data24535.zip (stored 0%)\n",
            "  adding: training_datas/train_data29077.zip (stored 0%)\n",
            "  adding: training_datas/train_data26817.zip (stored 0%)\n",
            "  adding: training_datas/train_data22931.zip (stored 0%)\n",
            "  adding: training_datas/train_data2972.zip (stored 0%)\n",
            "  adding: training_datas/train_data543.zip (stored 0%)\n",
            "  adding: training_datas/train_data29483.zip (stored 0%)\n",
            "  adding: training_datas/train_data17071.zip (stored 0%)\n",
            "  adding: training_datas/train_data7674.zip (stored 0%)\n",
            "  adding: training_datas/train_data14892.zip (stored 0%)\n",
            "  adding: training_datas/train_data18879.zip (stored 0%)\n",
            "  adding: training_datas/train_data4394.zip (stored 0%)\n",
            "  adding: training_datas/train_data16687.zip (stored 0%)\n",
            "  adding: training_datas/train_data4199.zip (stored 0%)\n",
            "  adding: training_datas/train_data2199.zip (stored 0%)\n",
            "  adding: training_datas/train_data24031.zip (stored 0%)\n",
            "  adding: training_datas/train_data11162.zip (stored 0%)\n",
            "  adding: training_datas/train_data9618.zip (stored 0%)\n",
            "  adding: training_datas/train_data24288.zip (stored 0%)\n",
            "  adding: training_datas/train_data12274.zip (stored 0%)\n",
            "  adding: training_datas/train_data14630.zip (stored 0%)\n",
            "  adding: training_datas/train_data5260.zip (stored 0%)\n",
            "  adding: training_datas/train_data19287.zip (stored 0%)\n",
            "  adding: training_datas/train_data11435.zip (stored 0%)\n",
            "  adding: training_datas/train_data4760.zip (stored 0%)\n",
            "  adding: training_datas/train_data16390.zip (stored 0%)\n",
            "  adding: training_datas/train_data14473.zip (stored 0%)\n",
            "  adding: training_datas/train_data3694.zip (stored 0%)\n",
            "  adding: training_datas/train_data11214.zip (stored 0%)\n",
            "  adding: training_datas/train_data23949.zip (stored 0%)\n",
            "  adding: training_datas/train_data13170.zip (stored 0%)\n",
            "  adding: training_datas/train_data12144.zip (stored 0%)\n",
            "  adding: training_datas/train_data8818.zip (stored 0%)\n",
            "  adding: training_datas/train_data26273.zip (stored 0%)\n",
            "  adding: training_datas/train_data22154.zip (stored 0%)\n",
            "  adding: training_datas/train_data4170.zip (stored 0%)\n",
            "  adding: training_datas/train_data29805.zip (stored 0%)\n",
            "  adding: training_datas/train_data2071.zip (stored 0%)\n",
            "  adding: training_datas/train_data14787.zip (stored 0%)\n",
            "  adding: training_datas/train_data9251.zip (stored 0%)\n",
            "  adding: training_datas/train_data8915.zip (stored 0%)\n",
            "  adding: training_datas/train_data22321.zip (stored 0%)\n",
            "  adding: training_datas/train_data18805.zip (stored 0%)\n",
            "  adding: training_datas/train_data3891.zip (stored 0%)\n",
            "  adding: training_datas/train_data19070.zip (stored 0%)\n",
            "  adding: training_datas/train_data7446.zip (stored 0%)\n",
            "  adding: training_datas/train_data14855.zip (stored 0%)\n",
            "  adding: training_datas/train_data198.zip (stored 0%)\n",
            "  adding: training_datas/train_data7120.zip (stored 0%)\n",
            "  adding: training_datas/train_data14698.zip (stored 0%)\n",
            "  adding: training_datas/train_data13939.zip (stored 0%)\n",
            "  adding: training_datas/train_data25282.zip (stored 0%)\n",
            "  adding: training_datas/train_data6125.zip (stored 0%)\n",
            "  adding: training_datas/train_data20843.zip (stored 0%)\n",
            "  adding: training_datas/train_data1794.zip (stored 0%)\n",
            "  adding: training_datas/train_data6590.zip (stored 0%)\n",
            "  adding: training_datas/train_data2203.zip (stored 0%)\n",
            "  adding: training_datas/train_data6417.zip (stored 0%)\n",
            "  adding: training_datas/train_data21603.zip (stored 0%)\n",
            "  adding: training_datas/train_data14230.zip (stored 0%)\n",
            "  adding: training_datas/train_data24533.zip (stored 0%)\n",
            "  adding: training_datas/train_data25649.zip (stored 0%)\n",
            "  adding: training_datas/train_data6994.zip (stored 0%)\n",
            "  adding: training_datas/train_data10031.zip (stored 0%)\n",
            "  adding: training_datas/train_data11828.zip (stored 0%)\n",
            "  adding: training_datas/train_data9789.zip (stored 0%)\n",
            "  adding: training_datas/train_data2488.zip (stored 0%)\n",
            "  adding: training_datas/train_data20694.zip (stored 0%)\n",
            "  adding: training_datas/train_data5611.zip (stored 0%)\n",
            "  adding: training_datas/train_data26302.zip (stored 0%)\n",
            "  adding: training_datas/train_data17370.zip (stored 0%)\n",
            "  adding: training_datas/train_data28924.zip (stored 0%)\n",
            "  adding: training_datas/train_data21324.zip (stored 0%)\n",
            "  adding: training_datas/train_data8967.zip (stored 0%)\n",
            "  adding: training_datas/train_data29398.zip (stored 0%)\n",
            "  adding: training_datas/train_data13185.zip (stored 0%)\n",
            "  adding: training_datas/train_data15520.zip (stored 0%)\n",
            "  adding: training_datas/train_data21051.zip (stored 0%)\n",
            "  adding: training_datas/train_data19442.zip (stored 0%)\n",
            "  adding: training_datas/train_data29762.zip (stored 0%)\n",
            "  adding: training_datas/train_data26047.zip (stored 0%)\n",
            "  adding: training_datas/train_data24398.zip (stored 0%)\n",
            "  adding: training_datas/train_data23191.zip (stored 0%)\n",
            "  adding: training_datas/train_data17519.zip (stored 0%)\n",
            "  adding: training_datas/train_data30337.zip (stored 0%)\n",
            "  adding: training_datas/train_data3257.zip (stored 0%)\n",
            "  adding: training_datas/train_data3052.zip (stored 0%)\n",
            "  adding: training_datas/train_data5999.zip (stored 0%)\n",
            "  adding: training_datas/train_data6326.zip (stored 0%)\n",
            "  adding: training_datas/train_data12925.zip (stored 0%)\n",
            "  adding: training_datas/train_data18540.zip (stored 0%)\n",
            "  adding: training_datas/train_data5845.zip (stored 0%)\n",
            "  adding: training_datas/train_data8677.zip (stored 0%)\n",
            "  adding: training_datas/train_data19439.zip (stored 0%)\n",
            "  adding: training_datas/train_data28557.zip (stored 0%)\n",
            "  adding: training_datas/train_data727.zip (stored 0%)\n",
            "  adding: training_datas/train_data23493.zip (stored 0%)\n",
            "  adding: training_datas/train_data26883.zip (stored 0%)\n",
            "  adding: training_datas/train_data8950.zip (stored 0%)\n",
            "  adding: training_datas/train_data6065.zip (stored 0%)\n",
            "  adding: training_datas/train_data15514.zip (stored 0%)\n",
            "  adding: training_datas/train_data18184.zip (stored 0%)\n",
            "  adding: training_datas/train_data18658.zip (stored 0%)\n",
            "  adding: training_datas/train_data16141.zip (stored 0%)\n",
            "  adding: training_datas/train_data28308.zip (stored 0%)\n",
            "  adding: training_datas/train_data21757.zip (stored 0%)\n",
            "  adding: training_datas/train_data29701.zip (stored 0%)\n",
            "  adding: training_datas/train_data5943.zip (stored 0%)\n",
            "  adding: training_datas/train_data23806.zip (stored 0%)\n",
            "  adding: training_datas/train_data98.zip (stored 0%)\n",
            "  adding: training_datas/train_data20108.zip (stored 0%)\n",
            "  adding: training_datas/train_data23696.zip (stored 0%)\n",
            "  adding: training_datas/train_data3254.zip (stored 0%)\n",
            "  adding: training_datas/train_data15771.zip (stored 0%)\n",
            "  adding: training_datas/train_data6309.zip (stored 0%)\n",
            "  adding: training_datas/train_data4600.zip (stored 0%)\n",
            "  adding: training_datas/train_data22793.zip (stored 0%)\n",
            "  adding: training_datas/train_data7234.zip (stored 0%)\n",
            "  adding: training_datas/train_data2452.zip (stored 0%)\n",
            "  adding: training_datas/train_data19182.zip (stored 0%)\n",
            "  adding: training_datas/train_data22396.zip (stored 0%)\n",
            "  adding: training_datas/train_data9116.zip (stored 0%)\n",
            "  adding: training_datas/train_data18336.zip (stored 0%)\n",
            "  adding: training_datas/train_data21566.zip (stored 0%)\n",
            "  adding: training_datas/train_data16469.zip (stored 0%)\n",
            "  adding: training_datas/train_data2029.zip (stored 0%)\n",
            "  adding: training_datas/train_data12386.zip (stored 0%)\n",
            "  adding: training_datas/train_data20468.zip (stored 0%)\n",
            "  adding: training_datas/train_data21627.zip (stored 0%)\n",
            "  adding: training_datas/train_data843.zip (stored 0%)\n",
            "  adding: training_datas/train_data30232.zip (stored 0%)\n",
            "  adding: training_datas/train_data22475.zip (stored 0%)\n",
            "  adding: training_datas/train_data22015.zip (stored 0%)\n",
            "  adding: training_datas/train_data23500.zip (stored 0%)\n",
            "  adding: training_datas/train_data11051.zip (stored 0%)\n",
            "  adding: training_datas/train_data14954.zip (stored 0%)\n",
            "  adding: training_datas/train_data17993.zip (stored 0%)\n",
            "  adding: training_datas/train_data2147.zip (stored 0%)\n",
            "  adding: training_datas/train_data2562.zip (stored 0%)\n",
            "  adding: training_datas/train_data20779.zip (stored 0%)\n",
            "  adding: training_datas/train_data204.zip (stored 0%)\n",
            "  adding: training_datas/train_data28866.zip (stored 0%)\n",
            "  adding: training_datas/train_data8026.zip (stored 0%)\n",
            "  adding: training_datas/train_data19346.zip (stored 0%)\n",
            "  adding: training_datas/train_data21014.zip (stored 0%)\n",
            "  adding: training_datas/train_data26814.zip (stored 0%)\n",
            "  adding: training_datas/train_data1132.zip (stored 0%)\n",
            "  adding: training_datas/train_data6501.zip (stored 0%)\n",
            "  adding: training_datas/train_data10015.zip (stored 0%)\n",
            "  adding: training_datas/train_data23959.zip (stored 0%)\n",
            "  adding: training_datas/train_data27965.zip (stored 0%)\n",
            "  adding: training_datas/train_data20084.zip (stored 0%)\n",
            "  adding: training_datas/train_data11704.zip (stored 0%)\n",
            "  adding: training_datas/train_data13700.zip (stored 0%)\n",
            "  adding: training_datas/train_data1631.zip (stored 0%)\n",
            "  adding: training_datas/train_data25844.zip (stored 0%)\n",
            "  adding: training_datas/train_data28495.zip (stored 0%)\n",
            "  adding: training_datas/train_data11055.zip (stored 0%)\n",
            "  adding: training_datas/train_data27985.zip (stored 0%)\n",
            "  adding: training_datas/train_data17730.zip (stored 0%)\n",
            "  adding: training_datas/train_data28679.zip (stored 0%)\n",
            "  adding: training_datas/train_data16559.zip (stored 0%)\n",
            "  adding: training_datas/train_data6183.zip (stored 0%)\n",
            "  adding: training_datas/train_data12931.zip (stored 0%)\n",
            "  adding: training_datas/train_data6336.zip (stored 0%)\n",
            "  adding: training_datas/train_data21140.zip (stored 0%)\n",
            "  adding: training_datas/train_data26034.zip (stored 0%)\n",
            "  adding: training_datas/train_data10575.zip (stored 0%)\n",
            "  adding: training_datas/train_data10530.zip (stored 0%)\n",
            "  adding: training_datas/train_data4451.zip (stored 0%)\n",
            "  adding: training_datas/train_data29957.zip (stored 0%)\n",
            "  adding: training_datas/train_data11025.zip (stored 0%)\n",
            "  adding: training_datas/train_data16936.zip (stored 0%)\n",
            "  adding: training_datas/train_data27633.zip (stored 0%)\n",
            "  adding: training_datas/train_data21260.zip (stored 0%)\n",
            "  adding: training_datas/train_data954.zip (stored 0%)\n",
            "  adding: training_datas/train_data12260.zip (stored 0%)\n",
            "  adding: training_datas/train_data8529.zip (stored 0%)\n",
            "  adding: training_datas/train_data28055.zip (stored 0%)\n",
            "  adding: training_datas/train_data9234.zip (stored 0%)\n",
            "  adding: training_datas/train_data1373.zip (stored 0%)\n",
            "  adding: training_datas/train_data23316.zip (stored 0%)\n",
            "  adding: training_datas/train_data2443.zip (stored 0%)\n",
            "  adding: training_datas/train_data24298.zip (stored 0%)\n",
            "  adding: training_datas/train_data18099.zip (stored 0%)\n",
            "  adding: training_datas/train_data7886.zip (stored 0%)\n",
            "  adding: training_datas/train_data19203.zip (stored 0%)\n",
            "  adding: training_datas/train_data28667.zip (stored 0%)\n",
            "  adding: training_datas/train_data6502.zip (stored 0%)\n",
            "  adding: training_datas/train_data8656.zip (stored 0%)\n",
            "  adding: training_datas/train_data9724.zip (stored 0%)\n",
            "  adding: training_datas/train_data23496.zip (stored 0%)\n",
            "  adding: training_datas/train_data15837.zip (stored 0%)\n",
            "  adding: training_datas/train_data20006.zip (stored 0%)\n",
            "  adding: training_datas/train_data20526.zip (stored 0%)\n",
            "  adding: training_datas/train_data4659.zip (stored 0%)\n",
            "  adding: training_datas/train_data16768.zip (stored 0%)\n",
            "  adding: training_datas/train_data30331.zip (stored 0%)\n",
            "  adding: training_datas/train_data22356.zip (stored 0%)\n",
            "  adding: training_datas/train_data20846.zip (stored 0%)\n",
            "  adding: training_datas/train_data20752.zip (stored 0%)\n",
            "  adding: training_datas/train_data15369.zip (stored 0%)\n",
            "  adding: training_datas/train_data27327.zip (stored 0%)\n",
            "  adding: training_datas/train_data11002.zip (stored 0%)\n",
            "  adding: training_datas/train_data4401.zip (stored 0%)\n",
            "  adding: training_datas/train_data17230.zip (stored 0%)\n",
            "  adding: training_datas/train_data6915.zip (stored 0%)\n",
            "  adding: training_datas/train_data27556.zip (stored 0%)\n",
            "  adding: training_datas/train_data1633.zip (stored 0%)\n",
            "  adding: training_datas/train_data19982.zip (stored 0%)\n",
            "  adding: training_datas/train_data12009.zip (stored 0%)\n",
            "  adding: training_datas/train_data27799.zip (stored 0%)\n",
            "  adding: training_datas/train_data17948.zip (stored 0%)\n",
            "  adding: training_datas/train_data9030.zip (stored 0%)\n",
            "  adding: training_datas/train_data6987.zip (stored 0%)\n",
            "  adding: training_datas/train_data3026.zip (stored 0%)\n",
            "  adding: training_datas/train_data13703.zip (stored 0%)\n",
            "  adding: training_datas/train_data936.zip (stored 0%)\n",
            "  adding: training_datas/train_data24700.zip (stored 0%)\n",
            "  adding: training_datas/train_data25811.zip (stored 0%)\n",
            "  adding: training_datas/train_data8407.zip (stored 0%)\n",
            "  adding: training_datas/train_data29986.zip (stored 0%)\n",
            "  adding: training_datas/train_data22972.zip (stored 0%)\n",
            "  adding: training_datas/train_data6049.zip (stored 0%)\n",
            "  adding: training_datas/train_data21674.zip (stored 0%)\n",
            "  adding: training_datas/train_data5695.zip (stored 0%)\n",
            "  adding: training_datas/train_data21994.zip (stored 0%)\n",
            "  adding: training_datas/train_data3745.zip (stored 0%)\n",
            "  adding: training_datas/train_data10151.zip (stored 0%)\n",
            "  adding: training_datas/train_data3398.zip (stored 0%)\n",
            "  adding: training_datas/train_data15044.zip (stored 0%)\n",
            "  adding: training_datas/train_data12869.zip (stored 0%)\n",
            "  adding: training_datas/train_data3775.zip (stored 0%)\n",
            "  adding: training_datas/train_data27597.zip (stored 0%)\n",
            "  adding: training_datas/train_data28307.zip (stored 0%)\n",
            "  adding: training_datas/train_data12513.zip (stored 0%)\n",
            "  adding: training_datas/train_data7703.zip (stored 0%)\n",
            "  adding: training_datas/train_data3946.zip (stored 0%)\n",
            "  adding: training_datas/train_data28004.zip (stored 0%)\n",
            "  adding: training_datas/train_data18313.zip (stored 0%)\n",
            "  adding: training_datas/train_data15586.zip (stored 0%)\n",
            "  adding: training_datas/train_data1545.zip (stored 0%)\n",
            "  adding: training_datas/train_data2100.zip (stored 0%)\n",
            "  adding: training_datas/train_data6264.zip (stored 0%)\n",
            "  adding: training_datas/train_data26204.zip (stored 0%)\n",
            "  adding: training_datas/train_data7070.zip (stored 0%)\n",
            "  adding: training_datas/train_data28235.zip (stored 0%)\n",
            "  adding: training_datas/train_data174.zip (stored 0%)\n",
            "  adding: training_datas/train_data495.zip (stored 0%)\n",
            "  adding: training_datas/train_data23142.zip (stored 0%)\n",
            "  adding: training_datas/train_data17655.zip (stored 0%)\n",
            "  adding: training_datas/train_data1731.zip (stored 0%)\n",
            "  adding: training_datas/train_data11548.zip (stored 0%)\n",
            "  adding: training_datas/train_data5810.zip (stored 0%)\n",
            "  adding: training_datas/train_data20002.zip (stored 0%)\n",
            "  adding: training_datas/train_data6311.zip (stored 0%)\n",
            "  adding: training_datas/train_data26818.zip (stored 0%)\n",
            "  adding: training_datas/train_data23554.zip (stored 0%)\n",
            "  adding: training_datas/train_data24352.zip (stored 0%)\n",
            "  adding: training_datas/train_data23832.zip (stored 0%)\n",
            "  adding: training_datas/train_data30056.zip (stored 0%)\n",
            "  adding: training_datas/train_data3577.zip (stored 0%)\n",
            "  adding: training_datas/train_data2904.zip (stored 0%)\n",
            "  adding: training_datas/train_data8017.zip (stored 0%)\n",
            "  adding: training_datas/train_data2325.zip (stored 0%)\n",
            "  adding: training_datas/train_data7127.zip (stored 0%)\n",
            "  adding: training_datas/train_data26112.zip (stored 0%)\n",
            "  adding: training_datas/train_data8234.zip (stored 0%)\n",
            "  adding: training_datas/train_data8892.zip (stored 0%)\n",
            "  adding: training_datas/train_data26173.zip (stored 0%)\n",
            "  adding: training_datas/train_data7192.zip (stored 0%)\n",
            "  adding: training_datas/train_data19801.zip (stored 0%)\n",
            "  adding: training_datas/train_data18434.zip (stored 0%)\n",
            "  adding: training_datas/train_data6951.zip (stored 0%)\n",
            "  adding: training_datas/train_data4255.zip (stored 0%)\n",
            "  adding: training_datas/train_data9567.zip (stored 0%)\n",
            "  adding: training_datas/train_data13145.zip (stored 0%)\n",
            "  adding: training_datas/train_data4080.zip (stored 0%)\n",
            "  adding: training_datas/train_data12916.zip (stored 0%)\n",
            "  adding: training_datas/train_data8195.zip (stored 0%)\n",
            "  adding: training_datas/train_data8160.zip (stored 0%)\n",
            "  adding: training_datas/train_data4432.zip (stored 0%)\n",
            "  adding: training_datas/train_data4423.zip (stored 0%)\n",
            "  adding: training_datas/train_data27108.zip (stored 0%)\n",
            "  adding: training_datas/train_data28331.zip (stored 0%)\n",
            "  adding: training_datas/train_data13521.zip (stored 0%)\n",
            "  adding: training_datas/train_data20900.zip (stored 0%)\n",
            "  adding: training_datas/train_data5791.zip (stored 0%)\n",
            "  adding: training_datas/train_data6993.zip (stored 0%)\n",
            "  adding: training_datas/train_data5413.zip (stored 0%)\n",
            "  adding: training_datas/train_data6825.zip (stored 0%)\n",
            "  adding: training_datas/train_data23452.zip (stored 0%)\n",
            "  adding: training_datas/train_data10186.zip (stored 0%)\n",
            "  adding: training_datas/train_data15707.zip (stored 0%)\n",
            "  adding: training_datas/train_data27397.zip (stored 0%)\n",
            "  adding: training_datas/train_data21124.zip (stored 0%)\n",
            "  adding: training_datas/train_data24745.zip (stored 0%)\n",
            "  adding: training_datas/train_data7445.zip (stored 0%)\n",
            "  adding: training_datas/train_data14289.zip (stored 0%)\n",
            "  adding: training_datas/train_data11460.zip (stored 0%)\n",
            "  adding: training_datas/train_data19535.zip (stored 0%)\n",
            "  adding: training_datas/train_data5806.zip (stored 0%)\n",
            "  adding: training_datas/train_data5001.zip (stored 0%)\n",
            "  adding: training_datas/train_data16533.zip (stored 0%)\n",
            "  adding: training_datas/train_data5800.zip (stored 0%)\n",
            "  adding: training_datas/train_data26826.zip (stored 0%)\n",
            "  adding: training_datas/train_data20149.zip (stored 0%)\n",
            "  adding: training_datas/train_data10625.zip (stored 0%)\n",
            "  adding: training_datas/train_data13666.zip (stored 0%)\n",
            "  adding: training_datas/train_data27344.zip (stored 0%)\n",
            "  adding: training_datas/train_data13252.zip (stored 0%)\n",
            "  adding: training_datas/train_data484.zip (stored 0%)\n",
            "  adding: training_datas/train_data27925.zip (stored 0%)\n",
            "  adding: training_datas/train_data8686.zip (stored 0%)\n",
            "  adding: training_datas/train_data23362.zip (stored 0%)\n",
            "  adding: training_datas/train_data5673.zip (stored 0%)\n",
            "  adding: training_datas/train_data3144.zip (stored 0%)\n",
            "  adding: training_datas/train_data26577.zip (stored 0%)\n",
            "  adding: training_datas/train_data8291.zip (stored 0%)\n",
            "  adding: training_datas/train_data5171.zip (stored 0%)\n",
            "  adding: training_datas/train_data5637.zip (stored 0%)\n",
            "  adding: training_datas/train_data23678.zip (stored 0%)\n",
            "  adding: training_datas/train_data28658.zip (stored 0%)\n",
            "  adding: training_datas/train_data10767.zip (stored 0%)\n",
            "  adding: training_datas/train_data28656.zip (stored 0%)\n",
            "  adding: training_datas/train_data9098.zip (stored 0%)\n",
            "  adding: training_datas/train_data29934.zip (stored 0%)\n",
            "  adding: training_datas/train_data14717.zip (stored 0%)\n",
            "  adding: training_datas/train_data17569.zip (stored 0%)\n",
            "  adding: training_datas/train_data6031.zip (stored 0%)\n",
            "  adding: training_datas/train_data29296.zip (stored 0%)\n",
            "  adding: training_datas/train_data4585.zip (stored 0%)\n",
            "  adding: training_datas/train_data17136.zip (stored 0%)\n",
            "  adding: training_datas/train_data2768.zip (stored 0%)\n",
            "  adding: training_datas/train_data25152.zip (stored 0%)\n",
            "  adding: training_datas/train_data3860.zip (stored 0%)\n",
            "  adding: training_datas/train_data5314.zip (stored 0%)\n",
            "  adding: training_datas/train_data14000.zip (stored 0%)\n",
            "  adding: training_datas/train_data24687.zip (stored 0%)\n",
            "  adding: training_datas/train_data28801.zip (stored 0%)\n",
            "  adding: training_datas/train_data3455.zip (stored 0%)\n",
            "  adding: training_datas/train_data12029.zip (stored 0%)\n",
            "  adding: training_datas/train_data26190.zip (stored 0%)\n",
            "  adding: training_datas/train_data5717.zip (stored 0%)\n",
            "  adding: training_datas/train_data19920.zip (stored 0%)\n",
            "  adding: training_datas/train_data259.zip (stored 0%)\n",
            "  adding: training_datas/train_data7969.zip (stored 0%)\n",
            "  adding: training_datas/train_data19106.zip (stored 0%)\n",
            "  adding: training_datas/train_data17883.zip (stored 0%)\n",
            "  adding: training_datas/train_data568.zip (stored 0%)\n",
            "  adding: training_datas/train_data8178.zip (stored 0%)\n",
            "  adding: training_datas/train_data3041.zip (stored 0%)\n",
            "  adding: training_datas/train_data19051.zip (stored 0%)\n",
            "  adding: training_datas/train_data23350.zip (stored 0%)\n",
            "  adding: training_datas/train_data2856.zip (stored 0%)\n",
            "  adding: training_datas/train_data22268.zip (stored 0%)\n",
            "  adding: training_datas/train_data25680.zip (stored 0%)\n",
            "  adding: training_datas/train_data23521.zip (stored 0%)\n",
            "  adding: training_datas/train_data29314.zip (stored 0%)\n",
            "  adding: training_datas/train_data26144.zip (stored 0%)\n",
            "  adding: training_datas/train_data6710.zip (stored 0%)\n",
            "  adding: training_datas/train_data1562.zip (stored 0%)\n",
            "  adding: training_datas/train_data5091.zip (stored 0%)\n",
            "  adding: training_datas/train_data25973.zip (stored 0%)\n",
            "  adding: training_datas/train_data20097.zip (stored 0%)\n",
            "  adding: training_datas/train_data11622.zip (stored 0%)\n",
            "  adding: training_datas/train_data2938.zip (stored 0%)\n",
            "  adding: training_datas/train_data28469.zip (stored 0%)\n",
            "  adding: training_datas/train_data29361.zip (stored 0%)\n",
            "  adding: training_datas/train_data6830.zip (stored 0%)\n",
            "  adding: training_datas/train_data18704.zip (stored 0%)\n",
            "  adding: training_datas/train_data29532.zip (stored 0%)\n",
            "  adding: training_datas/train_data8076.zip (stored 0%)\n",
            "  adding: training_datas/train_data2601.zip (stored 0%)\n",
            "  adding: training_datas/train_data17189.zip (stored 0%)\n",
            "  adding: training_datas/train_data18731.zip (stored 0%)\n",
            "  adding: training_datas/train_data2656.zip (stored 0%)\n",
            "  adding: training_datas/train_data23686.zip (stored 0%)\n",
            "  adding: training_datas/train_data25606.zip (stored 0%)\n",
            "  adding: training_datas/train_data12474.zip (stored 0%)\n",
            "  adding: training_datas/train_data22139.zip (stored 0%)\n",
            "  adding: training_datas/train_data15933.zip (stored 0%)\n",
            "  adding: training_datas/train_data21254.zip (stored 0%)\n",
            "  adding: training_datas/train_data5479.zip (stored 0%)\n",
            "  adding: training_datas/train_data14100.zip (stored 0%)\n",
            "  adding: training_datas/train_data23881.zip (stored 0%)\n",
            "  adding: training_datas/train_data2523.zip (stored 0%)\n",
            "  adding: training_datas/train_data4673.zip (stored 0%)\n",
            "  adding: training_datas/train_data1413.zip (stored 0%)\n",
            "  adding: training_datas/train_data7058.zip (stored 0%)\n",
            "  adding: training_datas/train_data12251.zip (stored 0%)\n",
            "  adding: training_datas/train_data5550.zip (stored 0%)\n",
            "  adding: training_datas/train_data10165.zip (stored 0%)\n",
            "  adding: training_datas/train_data22009.zip (stored 0%)\n",
            "  adding: training_datas/train_data15184.zip (stored 0%)\n",
            "  adding: training_datas/train_data185.zip (stored 0%)\n",
            "  adding: training_datas/train_data25284.zip (stored 0%)\n",
            "  adding: training_datas/train_data4306.zip (stored 0%)\n",
            "  adding: training_datas/train_data19552.zip (stored 0%)\n",
            "  adding: training_datas/train_data14357.zip (stored 0%)\n",
            "  adding: training_datas/train_data20821.zip (stored 0%)\n",
            "  adding: training_datas/train_data3074.zip (stored 0%)\n",
            "  adding: training_datas/train_data25163.zip (stored 0%)\n",
            "  adding: training_datas/train_data6316.zip (stored 0%)\n",
            "  adding: training_datas/train_data18158.zip (stored 0%)\n",
            "  adding: training_datas/train_data27389.zip (stored 0%)\n",
            "  adding: training_datas/train_data29741.zip (stored 0%)\n",
            "  adding: training_datas/train_data20782.zip (stored 0%)\n",
            "  adding: training_datas/train_data16377.zip (stored 0%)\n",
            "  adding: training_datas/train_data1295.zip (stored 0%)\n",
            "  adding: training_datas/train_data29809.zip (stored 0%)\n",
            "  adding: training_datas/train_data1761.zip (stored 0%)\n",
            "  adding: training_datas/train_data27254.zip (stored 0%)\n",
            "  adding: training_datas/train_data6213.zip (stored 0%)\n",
            "  adding: training_datas/train_data25330.zip (stored 0%)\n",
            "  adding: training_datas/train_data13823.zip (stored 0%)\n",
            "  adding: training_datas/train_data17330.zip (stored 0%)\n",
            "  adding: training_datas/train_data28354.zip (stored 0%)\n",
            "  adding: training_datas/train_data28373.zip (stored 0%)\n",
            "  adding: training_datas/train_data16644.zip (stored 0%)\n",
            "  adding: training_datas/train_data27150.zip (stored 0%)\n",
            "  adding: training_datas/train_data21917.zip (stored 0%)\n",
            "  adding: training_datas/train_data3189.zip (stored 0%)\n",
            "  adding: training_datas/train_data30124.zip (stored 0%)\n",
            "  adding: training_datas/train_data17491.zip (stored 0%)\n",
            "  adding: training_datas/train_data2495.zip (stored 0%)\n",
            "  adding: training_datas/train_data9362.zip (stored 0%)\n",
            "  adding: training_datas/train_data27214.zip (stored 0%)\n",
            "  adding: training_datas/train_data810.zip (stored 0%)\n",
            "  adding: training_datas/train_data7029.zip (stored 0%)\n",
            "  adding: training_datas/train_data5003.zip (stored 0%)\n",
            "  adding: training_datas/train_data16703.zip (stored 0%)\n",
            "  adding: training_datas/train_data4513.zip (stored 0%)\n",
            "  adding: training_datas/train_data14290.zip (stored 0%)\n",
            "  adding: training_datas/train_data28742.zip (stored 0%)\n",
            "  adding: training_datas/train_data20803.zip (stored 0%)\n",
            "  adding: training_datas/train_data19386.zip (stored 0%)\n",
            "  adding: training_datas/train_data22597.zip (stored 0%)\n",
            "  adding: training_datas/train_data6302.zip (stored 0%)\n",
            "  adding: training_datas/train_data942.zip (stored 0%)\n",
            "  adding: training_datas/train_data21593.zip (stored 0%)\n",
            "  adding: training_datas/train_data14730.zip (stored 0%)\n",
            "  adding: training_datas/train_data26890.zip (stored 0%)\n",
            "  adding: training_datas/train_data13365.zip (stored 0%)\n",
            "  adding: training_datas/train_data11161.zip (stored 0%)\n",
            "  adding: training_datas/train_data25563.zip (stored 0%)\n",
            "  adding: training_datas/train_data8705.zip (stored 0%)\n",
            "  adding: training_datas/train_data22415.zip (stored 0%)\n",
            "  adding: training_datas/train_data27131.zip (stored 0%)\n",
            "  adding: training_datas/train_data348.zip (stored 0%)\n",
            "  adding: training_datas/train_data29979.zip (stored 0%)\n",
            "  adding: training_datas/train_data25579.zip (stored 0%)\n",
            "  adding: training_datas/train_data17159.zip (stored 0%)\n",
            "  adding: training_datas/train_data23172.zip (stored 0%)\n",
            "  adding: training_datas/train_data549.zip (stored 0%)\n",
            "  adding: training_datas/train_data14816.zip (stored 0%)\n",
            "  adding: training_datas/train_data22539.zip (stored 0%)\n",
            "  adding: training_datas/train_data12811.zip (stored 0%)\n",
            "  adding: training_datas/train_data5567.zip (stored 0%)\n",
            "  adding: training_datas/train_data30299.zip (stored 0%)\n",
            "  adding: training_datas/train_data967.zip (stored 0%)\n",
            "  adding: training_datas/train_data29326.zip (stored 0%)\n",
            "  adding: training_datas/train_data25341.zip (stored 0%)\n",
            "  adding: training_datas/train_data30289.zip (stored 0%)\n",
            "  adding: training_datas/train_data21505.zip (stored 0%)\n",
            "  adding: training_datas/train_data24696.zip (stored 0%)\n",
            "  adding: training_datas/train_data29474.zip (stored 0%)\n",
            "  adding: training_datas/train_data27514.zip (stored 0%)\n",
            "  adding: training_datas/train_data17975.zip (stored 0%)\n",
            "  adding: training_datas/train_data23994.zip (stored 0%)\n",
            "  adding: training_datas/train_data30459.zip (stored 0%)\n",
            "  adding: training_datas/train_data24510.zip (stored 0%)\n",
            "  adding: training_datas/train_data26660.zip (stored 0%)\n",
            "  adding: training_datas/train_data16204.zip (stored 0%)\n",
            "  adding: training_datas/train_data5025.zip (stored 0%)\n",
            "  adding: training_datas/train_data258.zip (stored 0%)\n",
            "  adding: training_datas/train_data21828.zip (stored 0%)\n",
            "  adding: training_datas/train_data7719.zip (stored 0%)\n",
            "  adding: training_datas/train_data25716.zip (stored 0%)\n",
            "  adding: training_datas/train_data2558.zip (stored 0%)\n",
            "  adding: training_datas/train_data11614.zip (stored 0%)\n",
            "  adding: training_datas/train_data12641.zip (stored 0%)\n",
            "  adding: training_datas/train_data20558.zip (stored 0%)\n",
            "  adding: training_datas/train_data17373.zip (stored 0%)\n",
            "  adding: training_datas/train_data16829.zip (stored 0%)\n",
            "  adding: training_datas/train_data17857.zip (stored 0%)\n",
            "  adding: training_datas/train_data28569.zip (stored 0%)\n",
            "  adding: training_datas/train_data25286.zip (stored 0%)\n",
            "  adding: training_datas/train_data4206.zip (stored 0%)\n",
            "  adding: training_datas/train_data8035.zip (stored 0%)\n",
            "  adding: training_datas/train_data25168.zip (stored 0%)\n",
            "  adding: training_datas/train_data23451.zip (stored 0%)\n",
            "  adding: training_datas/train_data21016.zip (stored 0%)\n",
            "  adding: training_datas/train_data11473.zip (stored 0%)\n",
            "  adding: training_datas/train_data10747.zip (stored 0%)\n",
            "  adding: training_datas/train_data6657.zip (stored 0%)\n",
            "  adding: training_datas/train_data24664.zip (stored 0%)\n",
            "  adding: training_datas/train_data20662.zip (stored 0%)\n",
            "  adding: training_datas/train_data22565.zip (stored 0%)\n",
            "  adding: training_datas/train_data11278.zip (stored 0%)\n",
            "  adding: training_datas/train_data4259.zip (stored 0%)\n",
            "  adding: training_datas/train_data2623.zip (stored 0%)\n",
            "  adding: training_datas/train_data8916.zip (stored 0%)\n",
            "  adding: training_datas/train_data20210.zip (stored 0%)\n",
            "  adding: training_datas/train_data22727.zip (stored 0%)\n",
            "  adding: training_datas/train_data29667.zip (stored 0%)\n",
            "  adding: training_datas/train_data22999.zip (stored 0%)\n",
            "  adding: training_datas/train_data22760.zip (stored 0%)\n",
            "  adding: training_datas/train_data20963.zip (stored 0%)\n",
            "  adding: training_datas/train_data6241.zip (stored 0%)\n",
            "  adding: training_datas/train_data14973.zip (stored 0%)\n",
            "  adding: training_datas/train_data23713.zip (stored 0%)\n",
            "  adding: training_datas/train_data13274.zip (stored 0%)\n",
            "  adding: training_datas/train_data30395.zip (stored 0%)\n",
            "  adding: training_datas/train_data16338.zip (stored 0%)\n",
            "  adding: training_datas/train_data14190.zip (stored 0%)\n",
            "  adding: training_datas/train_data19885.zip (stored 0%)\n",
            "  adding: training_datas/train_data8312.zip (stored 0%)\n",
            "  adding: training_datas/train_data736.zip (stored 0%)\n",
            "  adding: training_datas/train_data28633.zip (stored 0%)\n",
            "  adding: training_datas/train_data11639.zip (stored 0%)\n",
            "  adding: training_datas/train_data963.zip (stored 0%)\n",
            "  adding: training_datas/train_data9879.zip (stored 0%)\n",
            "  adding: training_datas/train_data30487.zip (stored 0%)\n",
            "  adding: training_datas/train_data10178.zip (stored 0%)\n",
            "  adding: training_datas/train_data14875.zip (stored 0%)\n",
            "  adding: training_datas/train_data27913.zip (stored 0%)\n",
            "  adding: training_datas/train_data2020.zip (stored 0%)\n",
            "  adding: training_datas/train_data3734.zip (stored 0%)\n",
            "  adding: training_datas/train_data15714.zip (stored 0%)\n",
            "  adding: training_datas/train_data13887.zip (stored 0%)\n",
            "  adding: training_datas/train_data4280.zip (stored 0%)\n",
            "  adding: training_datas/train_data18310.zip (stored 0%)\n",
            "  adding: training_datas/train_data17777.zip (stored 0%)\n",
            "  adding: training_datas/train_data29983.zip (stored 0%)\n",
            "  adding: training_datas/train_data4248.zip (stored 0%)\n",
            "  adding: training_datas/train_data19004.zip (stored 0%)\n",
            "  adding: training_datas/train_data9726.zip (stored 0%)\n",
            "  adding: training_datas/train_data7745.zip (stored 0%)\n",
            "  adding: training_datas/train_data8907.zip (stored 0%)\n",
            "  adding: training_datas/train_data782.zip (stored 0%)\n",
            "  adding: training_datas/train_data3642.zip (stored 0%)\n",
            "  adding: training_datas/train_data22384.zip (stored 0%)\n",
            "  adding: training_datas/train_data7494.zip (stored 0%)\n",
            "  adding: training_datas/train_data7093.zip (stored 0%)\n",
            "  adding: training_datas/train_data23867.zip (stored 0%)\n",
            "  adding: training_datas/train_data11289.zip (stored 0%)\n",
            "  adding: training_datas/train_data14928.zip (stored 0%)\n",
            "  adding: training_datas/train_data18502.zip (stored 0%)\n",
            "  adding: training_datas/train_data19002.zip (stored 0%)\n",
            "  adding: training_datas/train_data18716.zip (stored 0%)\n",
            "  adding: training_datas/train_data18678.zip (stored 0%)\n",
            "  adding: training_datas/train_data26756.zip (stored 0%)\n",
            "  adding: training_datas/train_data17008.zip (stored 0%)\n",
            "  adding: training_datas/train_data22008.zip (stored 0%)\n",
            "  adding: training_datas/train_data11597.zip (stored 0%)\n",
            "  adding: training_datas/train_data7295.zip (stored 0%)\n",
            "  adding: training_datas/train_data28493.zip (stored 0%)\n",
            "  adding: training_datas/train_data17867.zip (stored 0%)\n",
            "  adding: training_datas/train_data15876.zip (stored 0%)\n",
            "  adding: training_datas/train_data15498.zip (stored 0%)\n",
            "  adding: training_datas/train_data3682.zip (stored 0%)\n",
            "  adding: training_datas/train_data9951.zip (stored 0%)\n",
            "  adding: training_datas/train_data26070.zip (stored 0%)\n",
            "  adding: training_datas/train_data21924.zip (stored 0%)\n",
            "  adding: training_datas/train_data19141.zip (stored 0%)\n",
            "  adding: training_datas/train_data13533.zip (stored 0%)\n",
            "  adding: training_datas/train_data16863.zip (stored 0%)\n",
            "  adding: training_datas/train_data15996.zip (stored 0%)\n",
            "  adding: training_datas/train_data24938.zip (stored 0%)\n",
            "  adding: training_datas/train_data6416.zip (stored 0%)\n",
            "  adding: training_datas/train_data11432.zip (stored 0%)\n",
            "  adding: training_datas/train_data5533.zip (stored 0%)\n",
            "  adding: training_datas/train_data9696.zip (stored 0%)\n",
            "  adding: training_datas/train_data12418.zip (stored 0%)\n",
            "  adding: training_datas/train_data26879.zip (stored 0%)\n",
            "  adding: training_datas/train_data6454.zip (stored 0%)\n",
            "  adding: training_datas/train_data19626.zip (stored 0%)\n",
            "  adding: training_datas/train_data7761.zip (stored 0%)\n",
            "  adding: training_datas/train_data8422.zip (stored 0%)\n",
            "  adding: training_datas/train_data16017.zip (stored 0%)\n",
            "  adding: training_datas/train_data10715.zip (stored 0%)\n",
            "  adding: training_datas/train_data2447.zip (stored 0%)\n",
            "  adding: training_datas/train_data13494.zip (stored 0%)\n",
            "  adding: training_datas/train_data4623.zip (stored 0%)\n",
            "  adding: training_datas/train_data24481.zip (stored 0%)\n",
            "  adding: training_datas/train_data3446.zip (stored 0%)\n",
            "  adding: training_datas/train_data20138.zip (stored 0%)\n",
            "  adding: training_datas/train_data25816.zip (stored 0%)\n",
            "  adding: training_datas/train_data4715.zip (stored 0%)\n",
            "  adding: training_datas/train_data28385.zip (stored 0%)\n",
            "  adding: training_datas/train_data12428.zip (stored 0%)\n",
            "  adding: training_datas/train_data18734.zip (stored 0%)\n",
            "  adding: training_datas/train_data13688.zip (stored 0%)\n",
            "  adding: training_datas/train_data16216.zip (stored 0%)\n",
            "  adding: training_datas/train_data26520.zip (stored 0%)\n",
            "  adding: training_datas/train_data12993.zip (stored 0%)\n",
            "  adding: training_datas/train_data25714.zip (stored 0%)\n",
            "  adding: training_datas/train_data13643.zip (stored 0%)\n",
            "  adding: training_datas/train_data1726.zip (stored 0%)\n",
            "  adding: training_datas/train_data12676.zip (stored 0%)\n",
            "  adding: training_datas/train_data18102.zip (stored 0%)\n",
            "  adding: training_datas/train_data5242.zip (stored 0%)\n",
            "  adding: training_datas/train_data30282.zip (stored 0%)\n",
            "  adding: training_datas/train_data18169.zip (stored 0%)\n",
            "  adding: training_datas/train_data22568.zip (stored 0%)\n",
            "  adding: training_datas/train_data22630.zip (stored 0%)\n",
            "  adding: training_datas/train_data9193.zip (stored 0%)\n",
            "  adding: training_datas/train_data4918.zip (stored 0%)\n",
            "  adding: training_datas/train_data24100.zip (stored 0%)\n",
            "  adding: training_datas/train_data11615.zip (stored 0%)\n",
            "  adding: training_datas/train_data28671.zip (stored 0%)\n",
            "  adding: training_datas/train_data22382.zip (stored 0%)\n",
            "  adding: training_datas/train_data7658.zip (stored 0%)\n",
            "  adding: training_datas/train_data29581.zip (stored 0%)\n",
            "  adding: training_datas/train_data15061.zip (stored 0%)\n",
            "  adding: training_datas/train_data1614.zip (stored 0%)\n",
            "  adding: training_datas/train_data5221.zip (stored 0%)\n",
            "  adding: training_datas/train_data16793.zip (stored 0%)\n",
            "  adding: training_datas/train_data15098.zip (stored 0%)\n",
            "  adding: training_datas/train_data12575.zip (stored 0%)\n",
            "  adding: training_datas/train_data2385.zip (stored 0%)\n",
            "  adding: training_datas/train_data13933.zip (stored 0%)\n",
            "  adding: training_datas/train_data8606.zip (stored 0%)\n",
            "  adding: training_datas/train_data12465.zip (stored 0%)\n",
            "  adding: training_datas/train_data11191.zip (stored 0%)\n",
            "  adding: training_datas/train_data5638.zip (stored 0%)\n",
            "  adding: training_datas/train_data27497.zip (stored 0%)\n",
            "  adding: training_datas/train_data12692.zip (stored 0%)\n",
            "  adding: training_datas/train_data5761.zip (stored 0%)\n",
            "  adding: training_datas/train_data12011.zip (stored 0%)\n",
            "  adding: training_datas/train_data23972.zip (stored 0%)\n",
            "  adding: training_datas/train_data26590.zip (stored 0%)\n",
            "  adding: training_datas/train_data23851.zip (stored 0%)\n",
            "  adding: training_datas/train_data25800.zip (stored 0%)\n",
            "  adding: training_datas/train_data5150.zip (stored 0%)\n",
            "  adding: training_datas/train_data6079.zip (stored 0%)\n",
            "  adding: training_datas/train_data8934.zip (stored 0%)\n",
            "  adding: training_datas/train_data27478.zip (stored 0%)\n",
            "  adding: training_datas/train_data16162.zip (stored 0%)\n",
            "  adding: training_datas/train_data1765.zip (stored 0%)\n",
            "  adding: training_datas/train_data9832.zip (stored 0%)\n",
            "  adding: training_datas/train_data27941.zip (stored 0%)\n",
            "  adding: training_datas/train_data23704.zip (stored 0%)\n",
            "  adding: training_datas/train_data9496.zip (stored 0%)\n",
            "  adding: training_datas/train_data27448.zip (stored 0%)\n",
            "  adding: training_datas/train_data9842.zip (stored 0%)\n",
            "  adding: training_datas/train_data8142.zip (stored 0%)\n",
            "  adding: training_datas/train_data27201.zip (stored 0%)\n",
            "  adding: training_datas/train_data17607.zip (stored 0%)\n",
            "  adding: training_datas/train_data16609.zip (stored 0%)\n",
            "  adding: training_datas/train_data3355.zip (stored 0%)\n",
            "  adding: training_datas/train_data24876.zip (stored 0%)\n",
            "  adding: training_datas/train_data29096.zip (stored 0%)\n",
            "  adding: training_datas/train_data19853.zip (stored 0%)\n",
            "  adding: training_datas/train_data8657.zip (stored 0%)\n",
            "  adding: training_datas/train_data9389.zip (stored 0%)\n",
            "  adding: training_datas/train_data463.zip (stored 0%)\n",
            "  adding: training_datas/train_data16000.zip (stored 0%)\n",
            "  adding: training_datas/train_data28606.zip (stored 0%)\n",
            "  adding: training_datas/train_data17344.zip (stored 0%)\n",
            "  adding: training_datas/train_data21678.zip (stored 0%)\n",
            "  adding: training_datas/train_data20583.zip (stored 0%)\n",
            "  adding: training_datas/train_data2541.zip (stored 0%)\n",
            "  adding: training_datas/train_data5386.zip (stored 0%)\n",
            "  adding: training_datas/train_data4399.zip (stored 0%)\n",
            "  adding: training_datas/train_data24077.zip (stored 0%)\n",
            "  adding: training_datas/train_data16865.zip (stored 0%)\n",
            "  adding: training_datas/train_data22137.zip (stored 0%)\n",
            "  adding: training_datas/train_data24627.zip (stored 0%)\n",
            "  adding: training_datas/train_data9975.zip (stored 0%)\n",
            "  adding: training_datas/train_data23454.zip (stored 0%)\n",
            "  adding: training_datas/train_data5076.zip (stored 0%)\n",
            "  adding: training_datas/train_data9821.zip (stored 0%)\n",
            "  adding: training_datas/train_data18350.zip (stored 0%)\n",
            "  adding: training_datas/train_data24436.zip (stored 0%)\n",
            "  adding: training_datas/train_data9365.zip (stored 0%)\n",
            "  adding: training_datas/train_data21947.zip (stored 0%)\n",
            "  adding: training_datas/train_data12622.zip (stored 0%)\n",
            "  adding: training_datas/train_data18206.zip (stored 0%)\n",
            "  adding: training_datas/train_data18556.zip (stored 0%)\n",
            "  adding: training_datas/train_data20304.zip (stored 0%)\n",
            "  adding: training_datas/train_data22557.zip (stored 0%)\n",
            "  adding: training_datas/train_data247.zip (stored 0%)\n",
            "  adding: training_datas/train_data14268.zip (stored 0%)\n",
            "  adding: training_datas/train_data12366.zip (stored 0%)\n",
            "  adding: training_datas/train_data20820.zip (stored 0%)\n",
            "  adding: training_datas/train_data24280.zip (stored 0%)\n",
            "  adding: training_datas/train_data21625.zip (stored 0%)\n",
            "  adding: training_datas/train_data245.zip (stored 0%)\n",
            "  adding: training_datas/train_data11906.zip (stored 0%)\n",
            "  adding: training_datas/train_data15560.zip (stored 0%)\n",
            "  adding: training_datas/train_data21117.zip (stored 0%)\n",
            "  adding: training_datas/train_data20559.zip (stored 0%)\n",
            "  adding: training_datas/train_data17115.zip (stored 0%)\n",
            "  adding: training_datas/train_data4310.zip (stored 0%)\n",
            "  adding: training_datas/train_data4022.zip (stored 0%)\n",
            "  adding: training_datas/train_data3909.zip (stored 0%)\n",
            "  adding: training_datas/train_data20866.zip (stored 0%)\n",
            "  adding: training_datas/train_data29963.zip (stored 0%)\n",
            "  adding: training_datas/train_data16068.zip (stored 0%)\n",
            "  adding: training_datas/train_data12974.zip (stored 0%)\n",
            "  adding: training_datas/train_data4126.zip (stored 0%)\n",
            "  adding: training_datas/train_data553.zip (stored 0%)\n",
            "  adding: training_datas/train_data9319.zip (stored 0%)\n",
            "  adding: training_datas/train_data17456.zip (stored 0%)\n",
            "  adding: training_datas/train_data6060.zip (stored 0%)\n",
            "  adding: training_datas/train_data21288.zip (stored 0%)\n",
            "  adding: training_datas/train_data1584.zip (stored 0%)\n",
            "  adding: training_datas/train_data24919.zip (stored 0%)\n",
            "  adding: training_datas/train_data12551.zip (stored 0%)\n",
            "  adding: training_datas/train_data5069.zip (stored 0%)\n",
            "  adding: training_datas/train_data28576.zip (stored 0%)\n",
            "  adding: training_datas/train_data10712.zip (stored 0%)\n",
            "  adding: training_datas/train_data434.zip (stored 0%)\n",
            "  adding: training_datas/train_data30479.zip (stored 0%)\n",
            "  adding: training_datas/train_data1148.zip (stored 0%)\n",
            "  adding: training_datas/train_data12924.zip (stored 0%)\n",
            "  adding: training_datas/train_data17881.zip (stored 0%)\n",
            "  adding: training_datas/train_data7112.zip (stored 0%)\n",
            "  adding: training_datas/train_data5362.zip (stored 0%)\n",
            "  adding: training_datas/train_data19704.zip (stored 0%)\n",
            "  adding: training_datas/train_data9881.zip (stored 0%)\n",
            "  adding: training_datas/train_data3617.zip (stored 0%)\n",
            "  adding: training_datas/train_data23911.zip (stored 0%)\n",
            "  adding: training_datas/train_data5751.zip (stored 0%)\n",
            "  adding: training_datas/train_data9608.zip (stored 0%)\n",
            "  adding: training_datas/train_data9703.zip (stored 0%)\n",
            "  adding: training_datas/train_data21969.zip (stored 0%)\n",
            "  adding: training_datas/train_data8511.zip (stored 0%)\n",
            "  adding: training_datas/train_data3876.zip (stored 0%)\n",
            "  adding: training_datas/train_data27987.zip (stored 0%)\n",
            "  adding: training_datas/train_data15041.zip (stored 0%)\n",
            "  adding: training_datas/train_data7600.zip (stored 0%)\n",
            "  adding: training_datas/train_data1126.zip (stored 0%)\n",
            "  adding: training_datas/train_data20048.zip (stored 0%)\n",
            "  adding: training_datas/train_data5147.zip (stored 0%)\n",
            "  adding: training_datas/train_data28248.zip (stored 0%)\n",
            "  adding: training_datas/train_data22051.zip (stored 0%)\n",
            "  adding: training_datas/train_data28087.zip (stored 0%)\n",
            "  adding: training_datas/train_data28531.zip (stored 0%)\n",
            "  adding: training_datas/train_data814.zip (stored 0%)\n",
            "  adding: training_datas/train_data19201.zip (stored 0%)\n",
            "  adding: training_datas/train_data8906.zip (stored 0%)\n",
            "  adding: training_datas/train_data15621.zip (stored 0%)\n",
            "  adding: training_datas/train_data3201.zip (stored 0%)\n",
            "  adding: training_datas/train_data16884.zip (stored 0%)\n",
            "  adding: training_datas/train_data25425.zip (stored 0%)\n",
            "  adding: training_datas/train_data24145.zip (stored 0%)\n",
            "  adding: training_datas/train_data2773.zip (stored 0%)\n",
            "  adding: training_datas/train_data26244.zip (stored 0%)\n",
            "  adding: training_datas/train_data24785.zip (stored 0%)\n",
            "  adding: training_datas/train_data23235.zip (stored 0%)\n",
            "  adding: training_datas/train_data10908.zip (stored 0%)\n",
            "  adding: training_datas/train_data9869.zip (stored 0%)\n",
            "  adding: training_datas/train_data14212.zip (stored 0%)\n",
            "  adding: training_datas/train_data12025.zip (stored 0%)\n",
            "  adding: training_datas/train_data1728.zip (stored 0%)\n",
            "  adding: training_datas/train_data25589.zip (stored 0%)\n",
            "  adding: training_datas/train_data19260.zip (stored 0%)\n",
            "  adding: training_datas/train_data8361.zip (stored 0%)\n",
            "  adding: training_datas/train_data26824.zip (stored 0%)\n",
            "  adding: training_datas/train_data4913.zip (stored 0%)\n",
            "  adding: training_datas/train_data4725.zip (stored 0%)\n",
            "  adding: training_datas/train_data28737.zip (stored 0%)\n",
            "  adding: training_datas/train_data16189.zip (stored 0%)\n",
            "  adding: training_datas/train_data11027.zip (stored 0%)\n",
            "  adding: training_datas/train_data3313.zip (stored 0%)\n",
            "  adding: training_datas/train_data28264.zip (stored 0%)\n",
            "  adding: training_datas/train_data13720.zip (stored 0%)\n",
            "  adding: training_datas/train_data24676.zip (stored 0%)\n",
            "  adding: training_datas/train_data29382.zip (stored 0%)\n",
            "  adding: training_datas/train_data12271.zip (stored 0%)\n",
            "  adding: training_datas/train_data24091.zip (stored 0%)\n",
            "  adding: training_datas/train_data20813.zip (stored 0%)\n",
            "  adding: training_datas/train_data12421.zip (stored 0%)\n",
            "  adding: training_datas/train_data14830.zip (stored 0%)\n",
            "  adding: training_datas/train_data20063.zip (stored 0%)\n",
            "  adding: training_datas/train_data8302.zip (stored 0%)\n",
            "  adding: training_datas/train_data3818.zip (stored 0%)\n",
            "  adding: training_datas/train_data6072.zip (stored 0%)\n",
            "  adding: training_datas/train_data3583.zip (stored 0%)\n",
            "  adding: training_datas/train_data29642.zip (stored 0%)\n",
            "  adding: training_datas/train_data27895.zip (stored 0%)\n",
            "  adding: training_datas/train_data10851.zip (stored 0%)\n",
            "  adding: training_datas/train_data2658.zip (stored 0%)\n",
            "  adding: training_datas/train_data7565.zip (stored 0%)\n",
            "  adding: training_datas/train_data1299.zip (stored 0%)\n",
            "  adding: training_datas/train_data1258.zip (stored 0%)\n",
            "  adding: training_datas/train_data23518.zip (stored 0%)\n",
            "  adding: training_datas/train_data14085.zip (stored 0%)\n",
            "  adding: training_datas/train_data24871.zip (stored 0%)\n",
            "  adding: training_datas/train_data22062.zip (stored 0%)\n",
            "  adding: training_datas/train_data14987.zip (stored 0%)\n",
            "  adding: training_datas/train_data17070.zip (stored 0%)\n",
            "  adding: training_datas/train_data23324.zip (stored 0%)\n",
            "  adding: training_datas/train_data5774.zip (stored 0%)\n",
            "  adding: training_datas/train_data20973.zip (stored 0%)\n",
            "  adding: training_datas/train_data840.zip (stored 0%)\n",
            "  adding: training_datas/train_data21091.zip (stored 0%)\n",
            "  adding: training_datas/train_data23935.zip (stored 0%)\n",
            "  adding: training_datas/train_data17949.zip (stored 0%)\n",
            "  adding: training_datas/train_data26703.zip (stored 0%)\n",
            "  adding: training_datas/train_data19637.zip (stored 0%)\n",
            "  adding: training_datas/train_data469.zip (stored 0%)\n",
            "  adding: training_datas/train_data22862.zip (stored 0%)\n",
            "  adding: training_datas/train_data5219.zip (stored 0%)\n",
            "  adding: training_datas/train_data1041.zip (stored 0%)\n",
            "  adding: training_datas/train_data30178.zip (stored 0%)\n",
            "  adding: training_datas/train_data4758.zip (stored 0%)\n",
            "  adding: training_datas/train_data16164.zip (stored 0%)\n",
            "  adding: training_datas/train_data14488.zip (stored 0%)\n",
            "  adding: training_datas/train_data28543.zip (stored 0%)\n",
            "  adding: training_datas/train_data5404.zip (stored 0%)\n",
            "  adding: training_datas/train_data13992.zip (stored 0%)\n",
            "  adding: training_datas/train_data15086.zip (stored 0%)\n",
            "  adding: training_datas/train_data15358.zip (stored 0%)\n",
            "  adding: training_datas/train_data15209.zip (stored 0%)\n",
            "  adding: training_datas/train_data10761.zip (stored 0%)\n",
            "  adding: training_datas/train_data28603.zip (stored 0%)\n",
            "  adding: training_datas/train_data20909.zip (stored 0%)\n",
            "  adding: training_datas/train_data19958.zip (stored 0%)\n",
            "  adding: training_datas/train_data9330.zip (stored 0%)\n",
            "  adding: training_datas/train_data16445.zip (stored 0%)\n",
            "  adding: training_datas/train_data17348.zip (stored 0%)\n",
            "  adding: training_datas/train_data4506.zip (stored 0%)\n",
            "  adding: training_datas/train_data17719.zip (stored 0%)\n",
            "  adding: training_datas/train_data25328.zip (stored 0%)\n",
            "  adding: training_datas/train_data25782.zip (stored 0%)\n",
            "  adding: training_datas/train_data17512.zip (stored 0%)\n",
            "  adding: training_datas/train_data602.zip (stored 0%)\n",
            "  adding: training_datas/train_data9854.zip (stored 0%)\n",
            "  adding: training_datas/train_data2740.zip (stored 0%)\n",
            "  adding: training_datas/train_data15680.zip (stored 0%)\n",
            "  adding: training_datas/train_data14443.zip (stored 0%)\n",
            "  adding: training_datas/train_data20167.zip (stored 0%)\n",
            "  adding: training_datas/train_data16682.zip (stored 0%)\n",
            "  adding: training_datas/train_data16760.zip (stored 0%)\n",
            "  adding: training_datas/train_data15412.zip (stored 0%)\n",
            "  adding: training_datas/train_data18576.zip (stored 0%)\n",
            "  adding: training_datas/train_data5044.zip (stored 0%)\n",
            "  adding: training_datas/train_data16779.zip (stored 0%)\n",
            "  adding: training_datas/train_data15068.zip (stored 0%)\n",
            "  adding: training_datas/train_data13850.zip (stored 0%)\n",
            "  adding: training_datas/train_data4396.zip (stored 0%)\n",
            "  adding: training_datas/train_data23468.zip (stored 0%)\n",
            "  adding: training_datas/train_data13797.zip (stored 0%)\n",
            "  adding: training_datas/train_data6199.zip (stored 0%)\n",
            "  adding: training_datas/train_data5469.zip (stored 0%)\n",
            "  adding: training_datas/train_data18623.zip (stored 0%)\n",
            "  adding: training_datas/train_data8615.zip (stored 0%)\n",
            "  adding: training_datas/train_data23624.zip (stored 0%)\n",
            "  adding: training_datas/train_data22037.zip (stored 0%)\n",
            "  adding: training_datas/train_data23546.zip (stored 0%)\n",
            "  adding: training_datas/train_data18671.zip (stored 0%)\n",
            "  adding: training_datas/train_data27546.zip (stored 0%)\n",
            "  adding: training_datas/train_data25945.zip (stored 0%)\n",
            "  adding: training_datas/train_data26300.zip (stored 0%)\n",
            "  adding: training_datas/train_data8264.zip (stored 0%)\n",
            "  adding: training_datas/train_data10719.zip (stored 0%)\n",
            "  adding: training_datas/train_data13941.zip (stored 0%)\n",
            "  adding: training_datas/train_data28644.zip (stored 0%)\n",
            "  adding: training_datas/train_data3602.zip (stored 0%)\n",
            "  adding: training_datas/train_data11078.zip (stored 0%)\n",
            "  adding: training_datas/train_data23849.zip (stored 0%)\n",
            "  adding: training_datas/train_data23348.zip (stored 0%)\n",
            "  adding: training_datas/train_data15598.zip (stored 0%)\n",
            "  adding: training_datas/train_data9999.zip (stored 0%)\n",
            "  adding: training_datas/train_data26798.zip (stored 0%)\n",
            "  adding: training_datas/train_data14873.zip (stored 0%)\n",
            "  adding: training_datas/train_data28252.zip (stored 0%)\n",
            "  adding: training_datas/train_data9517.zip (stored 0%)\n",
            "  adding: training_datas/train_data18250.zip (stored 0%)\n",
            "  adding: training_datas/train_data14527.zip (stored 0%)\n",
            "  adding: training_datas/train_data28227.zip (stored 0%)\n",
            "  adding: training_datas/train_data2913.zip (stored 0%)\n",
            "  adding: training_datas/train_data20484.zip (stored 0%)\n",
            "  adding: training_datas/train_data27660.zip (stored 0%)\n",
            "  adding: training_datas/train_data11155.zip (stored 0%)\n",
            "  adding: training_datas/train_data1261.zip (stored 0%)\n",
            "  adding: training_datas/train_data22279.zip (stored 0%)\n",
            "  adding: training_datas/train_data29820.zip (stored 0%)\n",
            "  adding: training_datas/train_data3100.zip (stored 0%)\n",
            "  adding: training_datas/train_data11781.zip (stored 0%)\n",
            "  adding: training_datas/train_data2786.zip (stored 0%)\n",
            "  adding: training_datas/train_data4710.zip (stored 0%)\n",
            "  adding: training_datas/train_data19075.zip (stored 0%)\n",
            "  adding: training_datas/train_data19745.zip (stored 0%)\n",
            "  adding: training_datas/train_data15312.zip (stored 0%)\n",
            "  adding: training_datas/train_data24721.zip (stored 0%)\n",
            "  adding: training_datas/train_data14192.zip (stored 0%)\n",
            "  adding: training_datas/train_data27977.zip (stored 0%)\n",
            "  adding: training_datas/train_data27889.zip (stored 0%)\n",
            "  adding: training_datas/train_data13117.zip (stored 0%)\n",
            "  adding: training_datas/train_data12668.zip (stored 0%)\n",
            "  adding: training_datas/train_data7848.zip (stored 0%)\n",
            "  adding: training_datas/train_data14144.zip (stored 0%)\n",
            "  adding: training_datas/train_data13595.zip (stored 0%)\n",
            "  adding: training_datas/train_data21195.zip (stored 0%)\n",
            "  adding: training_datas/train_data10957.zip (stored 0%)\n",
            "  adding: training_datas/train_data21869.zip (stored 0%)\n",
            "  adding: training_datas/train_data20098.zip (stored 0%)\n",
            "  adding: training_datas/train_data16940.zip (stored 0%)\n",
            "  adding: training_datas/train_data16875.zip (stored 0%)\n",
            "  adding: training_datas/train_data29966.zip (stored 0%)\n",
            "  adding: training_datas/train_data10313.zip (stored 0%)\n",
            "  adding: training_datas/train_data27438.zip (stored 0%)\n",
            "  adding: training_datas/train_data27561.zip (stored 0%)\n",
            "  adding: training_datas/train_data11134.zip (stored 0%)\n",
            "  adding: training_datas/train_data26324.zip (stored 0%)\n",
            "  adding: training_datas/train_data10312.zip (stored 0%)\n",
            "  adding: training_datas/train_data3186.zip (stored 0%)\n",
            "  adding: training_datas/train_data29684.zip (stored 0%)\n",
            "  adding: training_datas/train_data14108.zip (stored 0%)\n",
            "  adding: training_datas/train_data9090.zip (stored 0%)\n",
            "  adding: training_datas/train_data1670.zip (stored 0%)\n",
            "  adding: training_datas/train_data17080.zip (stored 0%)\n",
            "  adding: training_datas/train_data6159.zip (stored 0%)\n",
            "  adding: training_datas/train_data27062.zip (stored 0%)\n",
            "  adding: training_datas/train_data28545.zip (stored 0%)\n",
            "  adding: training_datas/train_data627.zip (stored 0%)\n",
            "  adding: training_datas/train_data27102.zip (stored 0%)\n",
            "  adding: training_datas/train_data25023.zip (stored 0%)\n",
            "  adding: training_datas/train_data24928.zip (stored 0%)\n",
            "  adding: training_datas/train_data7687.zip (stored 0%)\n",
            "  adding: training_datas/train_data4905.zip (stored 0%)\n",
            "  adding: training_datas/train_data8206.zip (stored 0%)\n",
            "  adding: training_datas/train_data11862.zip (stored 0%)\n",
            "  adding: training_datas/train_data737.zip (stored 0%)\n",
            "  adding: training_datas/train_data29700.zip (stored 0%)\n",
            "  adding: training_datas/train_data10020.zip (stored 0%)\n",
            "  adding: training_datas/train_data24342.zip (stored 0%)\n",
            "  adding: training_datas/train_data5100.zip (stored 0%)\n",
            "  adding: training_datas/train_data21883.zip (stored 0%)\n",
            "  adding: training_datas/train_data24005.zip (stored 0%)\n",
            "  adding: training_datas/train_data22782.zip (stored 0%)\n",
            "  adding: training_datas/train_data20415.zip (stored 0%)\n",
            "  adding: training_datas/train_data593.zip (stored 0%)\n",
            "  adding: training_datas/train_data22554.zip (stored 0%)\n",
            "  adding: training_datas/train_data11888.zip (stored 0%)\n",
            "  adding: training_datas/train_data16610.zip (stored 0%)\n",
            "  adding: training_datas/train_data7398.zip (stored 0%)\n",
            "  adding: training_datas/train_data28297.zip (stored 0%)\n",
            "  adding: training_datas/train_data23575.zip (stored 0%)\n",
            "  adding: training_datas/train_data22368.zip (stored 0%)\n",
            "  adding: training_datas/train_data13725.zip (stored 0%)\n",
            "  adding: training_datas/train_data7588.zip (stored 0%)\n",
            "  adding: training_datas/train_data16920.zip (stored 0%)\n",
            "  adding: training_datas/train_data20975.zip (stored 0%)\n",
            "  adding: training_datas/train_data25894.zip (stored 0%)\n",
            "  adding: training_datas/train_data28928.zip (stored 0%)\n",
            "  adding: training_datas/train_data12220.zip (stored 0%)\n",
            "  adding: training_datas/train_data24733.zip (stored 0%)\n",
            "  adding: training_datas/train_data26341.zip (stored 0%)\n",
            "  adding: training_datas/train_data9076.zip (stored 0%)\n",
            "  adding: training_datas/train_data10076.zip (stored 0%)\n",
            "  adding: training_datas/train_data25423.zip (stored 0%)\n",
            "  adding: training_datas/train_data29394.zip (stored 0%)\n",
            "  adding: training_datas/train_data22239.zip (stored 0%)\n",
            "  adding: training_datas/train_data15852.zip (stored 0%)\n",
            "  adding: training_datas/train_data24255.zip (stored 0%)\n",
            "  adding: training_datas/train_data300.zip (stored 0%)\n",
            "  adding: training_datas/train_data14399.zip (stored 0%)\n",
            "  adding: training_datas/train_data13358.zip (stored 0%)\n",
            "  adding: training_datas/train_data18117.zip (stored 0%)\n",
            "  adding: training_datas/train_data23412.zip (stored 0%)\n",
            "  adding: training_datas/train_data22659.zip (stored 0%)\n",
            "  adding: training_datas/train_data18877.zip (stored 0%)\n",
            "  adding: training_datas/train_data11837.zip (stored 0%)\n",
            "  adding: training_datas/train_data19406.zip (stored 0%)\n",
            "  adding: training_datas/train_data17195.zip (stored 0%)\n",
            "  adding: training_datas/train_data1310.zip (stored 0%)\n",
            "  adding: training_datas/train_data29646.zip (stored 0%)\n",
            "  adding: training_datas/train_data22822.zip (stored 0%)\n",
            "  adding: training_datas/train_data8860.zip (stored 0%)\n",
            "  adding: training_datas/train_data21404.zip (stored 0%)\n",
            "  adding: training_datas/train_data11635.zip (stored 0%)\n",
            "  adding: training_datas/train_data5202.zip (stored 0%)\n",
            "  adding: training_datas/train_data27020.zip (stored 0%)\n",
            "  adding: training_datas/train_data3708.zip (stored 0%)\n",
            "  adding: training_datas/train_data15282.zip (stored 0%)\n",
            "  adding: training_datas/train_data22587.zip (stored 0%)\n",
            "  adding: training_datas/train_data29903.zip (stored 0%)\n",
            "  adding: training_datas/train_data16274.zip (stored 0%)\n",
            "  adding: training_datas/train_data20088.zip (stored 0%)\n",
            "  adding: training_datas/train_data11964.zip (stored 0%)\n",
            "  adding: training_datas/train_data21703.zip (stored 0%)\n",
            "  adding: training_datas/train_data28243.zip (stored 0%)\n",
            "  adding: training_datas/train_data29243.zip (stored 0%)\n",
            "  adding: training_datas/train_data1471.zip (stored 0%)\n",
            "  adding: training_datas/train_data4069.zip (stored 0%)\n",
            "  adding: training_datas/train_data14645.zip (stored 0%)\n",
            "  adding: training_datas/train_data19401.zip (stored 0%)\n",
            "  adding: training_datas/train_data1412.zip (stored 0%)\n",
            "  adding: training_datas/train_data733.zip (stored 0%)\n",
            "  adding: training_datas/train_data8216.zip (stored 0%)\n",
            "  adding: training_datas/train_data9441.zip (stored 0%)\n",
            "  adding: training_datas/train_data24112.zip (stored 0%)\n",
            "  adding: training_datas/train_data9243.zip (stored 0%)\n",
            "  adding: training_datas/train_data23679.zip (stored 0%)\n",
            "  adding: training_datas/train_data6886.zip (stored 0%)\n",
            "  adding: training_datas/train_data1736.zip (stored 0%)\n",
            "  adding: training_datas/train_data23512.zip (stored 0%)\n",
            "  adding: training_datas/train_data28681.zip (stored 0%)\n",
            "  adding: training_datas/train_data9153.zip (stored 0%)\n",
            "  adding: training_datas/train_data19318.zip (stored 0%)\n",
            "  adding: training_datas/train_data10398.zip (stored 0%)\n",
            "  adding: training_datas/train_data4236.zip (stored 0%)\n",
            "  adding: training_datas/train_data17155.zip (stored 0%)\n",
            "  adding: training_datas/train_data12872.zip (stored 0%)\n",
            "  adding: training_datas/train_data20628.zip (stored 0%)\n",
            "  adding: training_datas/train_data2880.zip (stored 0%)\n",
            "  adding: training_datas/train_data26625.zip (stored 0%)\n",
            "  adding: training_datas/train_data17163.zip (stored 0%)\n",
            "  adding: training_datas/train_data18586.zip (stored 0%)\n",
            "  adding: training_datas/train_data24060.zip (stored 0%)\n",
            "  adding: training_datas/train_data24420.zip (stored 0%)\n",
            "  adding: training_datas/train_data795.zip (stored 0%)\n",
            "  adding: training_datas/train_data20608.zip (stored 0%)\n",
            "  adding: training_datas/train_data20112.zip (stored 0%)\n",
            "  adding: training_datas/train_data13856.zip (stored 0%)\n",
            "  adding: training_datas/train_data10662.zip (stored 0%)\n",
            "  adding: training_datas/train_data19737.zip (stored 0%)\n",
            "  adding: training_datas/train_data28400.zip (stored 0%)\n",
            "  adding: training_datas/train_data3539.zip (stored 0%)\n",
            "  adding: training_datas/train_data10680.zip (stored 0%)\n",
            "  adding: training_datas/train_data24519.zip (stored 0%)\n",
            "  adding: training_datas/train_data18424.zip (stored 0%)\n",
            "  adding: training_datas/train_data457.zip (stored 0%)\n",
            "  adding: training_datas/train_data5959.zip (stored 0%)\n",
            "  adding: training_datas/train_data3024.zip (stored 0%)\n",
            "  adding: training_datas/train_data10364.zip (stored 0%)\n",
            "  adding: training_datas/train_data20491.zip (stored 0%)\n",
            "  adding: training_datas/train_data18545.zip (stored 0%)\n",
            "  adding: training_datas/train_data5511.zip (stored 0%)\n",
            "  adding: training_datas/train_data26514.zip (stored 0%)\n",
            "  adding: training_datas/train_data19534.zip (stored 0%)\n",
            "  adding: training_datas/train_data27184.zip (stored 0%)\n",
            "  adding: training_datas/train_data29318.zip (stored 0%)\n",
            "  adding: training_datas/train_data28506.zip (stored 0%)\n",
            "  adding: training_datas/train_data14553.zip (stored 0%)\n",
            "  adding: training_datas/train_data13580.zip (stored 0%)\n",
            "  adding: training_datas/train_data2009.zip (stored 0%)\n",
            "  adding: training_datas/train_data27602.zip (stored 0%)\n",
            "  adding: training_datas/train_data9701.zip (stored 0%)\n",
            "  adding: training_datas/train_data23697.zip (stored 0%)\n",
            "  adding: training_datas/train_data20878.zip (stored 0%)\n",
            "  adding: training_datas/train_data25464.zip (stored 0%)\n",
            "  adding: training_datas/train_data8566.zip (stored 0%)\n",
            "  adding: training_datas/train_data24754.zip (stored 0%)\n",
            "  adding: training_datas/train_data13211.zip (stored 0%)\n",
            "  adding: training_datas/train_data17605.zip (stored 0%)\n",
            "  adding: training_datas/train_data3920.zip (stored 0%)\n",
            "  adding: training_datas/train_data1883.zip (stored 0%)\n",
            "  adding: training_datas/train_data28833.zip (stored 0%)\n",
            "  adding: training_datas/train_data20421.zip (stored 0%)\n",
            "  adding: training_datas/train_data490.zip (stored 0%)\n",
            "  adding: training_datas/train_data9494.zip (stored 0%)\n",
            "  adding: training_datas/train_data3947.zip (stored 0%)\n",
            "  adding: training_datas/train_data8759.zip (stored 0%)\n",
            "  adding: training_datas/train_data10917.zip (stored 0%)\n",
            "  adding: training_datas/train_data11712.zip (stored 0%)\n",
            "  adding: training_datas/train_data22600.zip (stored 0%)\n",
            "  adding: training_datas/train_data11691.zip (stored 0%)\n",
            "  adding: training_datas/train_data20606.zip (stored 0%)\n",
            "  adding: training_datas/train_data28066.zip (stored 0%)\n",
            "  adding: training_datas/train_data30169.zip (stored 0%)\n",
            "  adding: training_datas/train_data14262.zip (stored 0%)\n",
            "  adding: training_datas/train_data4347.zip (stored 0%)\n",
            "  adding: training_datas/train_data6285.zip (stored 0%)\n",
            "  adding: training_datas/train_data15350.zip (stored 0%)\n",
            "  adding: training_datas/train_data25528.zip (stored 0%)\n",
            "  adding: training_datas/train_data17000.zip (stored 0%)\n",
            "  adding: training_datas/train_data22219.zip (stored 0%)\n",
            "  adding: training_datas/train_data2596.zip (stored 0%)\n",
            "  adding: training_datas/train_data29170.zip (stored 0%)\n",
            "  adding: training_datas/train_data26069.zip (stored 0%)\n",
            "  adding: training_datas/train_data1625.zip (stored 0%)\n",
            "  adding: training_datas/train_data1078.zip (stored 0%)\n",
            "  adding: training_datas/train_data15985.zip (stored 0%)\n",
            "  adding: training_datas/train_data24960.zip (stored 0%)\n",
            "  adding: training_datas/train_data20014.zip (stored 0%)\n",
            "  adding: training_datas/train_data20861.zip (stored 0%)\n",
            "  adding: training_datas/train_data3904.zip (stored 0%)\n",
            "  adding: training_datas/train_data17546.zip (stored 0%)\n",
            "  adding: training_datas/train_data2780.zip (stored 0%)\n",
            "  adding: training_datas/train_data6157.zip (stored 0%)\n",
            "  adding: training_datas/train_data2197.zip (stored 0%)\n",
            "  adding: training_datas/train_data2465.zip (stored 0%)\n",
            "  adding: training_datas/train_data28698.zip (stored 0%)\n",
            "  adding: training_datas/train_data18268.zip (stored 0%)\n",
            "  adding: training_datas/train_data25497.zip (stored 0%)\n",
            "  adding: training_datas/train_data17995.zip (stored 0%)\n",
            "  adding: training_datas/train_data17489.zip (stored 0%)\n",
            "  adding: training_datas/train_data3630.zip (stored 0%)\n",
            "  adding: training_datas/train_data28353.zip (stored 0%)\n",
            "  adding: training_datas/train_data2908.zip (stored 0%)\n",
            "  adding: training_datas/train_data5981.zip (stored 0%)\n",
            "  adding: training_datas/train_data5370.zip (stored 0%)\n",
            "  adding: training_datas/train_data13092.zip (stored 0%)\n",
            "  adding: training_datas/train_data28732.zip (stored 0%)\n",
            "  adding: training_datas/train_data3715.zip (stored 0%)\n",
            "  adding: training_datas/train_data3462.zip (stored 0%)\n",
            "  adding: training_datas/train_data20232.zip (stored 0%)\n",
            "  adding: training_datas/train_data17825.zip (stored 0%)\n",
            "  adding: training_datas/train_data21370.zip (stored 0%)\n",
            "  adding: training_datas/train_data19984.zip (stored 0%)\n",
            "  adding: training_datas/train_data11994.zip (stored 0%)\n",
            "  adding: training_datas/train_data11546.zip (stored 0%)\n",
            "  adding: training_datas/train_data22516.zip (stored 0%)\n",
            "  adding: training_datas/train_data24293.zip (stored 0%)\n",
            "  adding: training_datas/train_data1143.zip (stored 0%)\n",
            "  adding: training_datas/train_data20069.zip (stored 0%)\n",
            "  adding: training_datas/train_data6598.zip (stored 0%)\n",
            "  adding: training_datas/train_data17811.zip (stored 0%)\n",
            "  adding: training_datas/train_data12690.zip (stored 0%)\n",
            "  adding: training_datas/train_data6489.zip (stored 0%)\n",
            "  adding: training_datas/train_data6272.zip (stored 0%)\n",
            "  adding: training_datas/train_data19031.zip (stored 0%)\n",
            "  adding: training_datas/train_data18872.zip (stored 0%)\n",
            "  adding: training_datas/train_data27657.zip (stored 0%)\n",
            "  adding: training_datas/train_data6513.zip (stored 0%)\n",
            "  adding: training_datas/train_data28617.zip (stored 0%)\n",
            "  adding: training_datas/train_data20344.zip (stored 0%)\n",
            "  adding: training_datas/train_data23057.zip (stored 0%)\n",
            "  adding: training_datas/train_data24912.zip (stored 0%)\n",
            "  adding: training_datas/train_data28233.zip (stored 0%)\n",
            "  adding: training_datas/train_data5880.zip (stored 0%)\n",
            "  adding: training_datas/train_data1243.zip (stored 0%)\n",
            "  adding: training_datas/train_data9190.zip (stored 0%)\n",
            "  adding: training_datas/train_data9966.zip (stored 0%)\n",
            "  adding: training_datas/train_data18075.zip (stored 0%)\n",
            "  adding: training_datas/train_data15702.zip (stored 0%)\n",
            "  adding: training_datas/train_data23730.zip (stored 0%)\n",
            "  adding: training_datas/train_data25859.zip (stored 0%)\n",
            "  adding: training_datas/train_data13946.zip (stored 0%)\n",
            "  adding: training_datas/train_data21679.zip (stored 0%)\n",
            "  adding: training_datas/train_data25656.zip (stored 0%)\n",
            "  adding: training_datas/train_data21180.zip (stored 0%)\n",
            "  adding: training_datas/train_data30176.zip (stored 0%)\n",
            "  adding: training_datas/train_data3202.zip (stored 0%)\n",
            "  adding: training_datas/train_data4414.zip (stored 0%)\n",
            "  adding: training_datas/train_data11031.zip (stored 0%)\n",
            "  adding: training_datas/train_data30389.zip (stored 0%)\n",
            "  adding: training_datas/train_data4104.zip (stored 0%)\n",
            "  adding: training_datas/train_data24521.zip (stored 0%)\n",
            "  adding: training_datas/train_data24045.zip (stored 0%)\n",
            "  adding: training_datas/train_data6366.zip (stored 0%)\n",
            "  adding: training_datas/train_data16972.zip (stored 0%)\n",
            "  adding: training_datas/train_data8071.zip (stored 0%)\n",
            "  adding: training_datas/train_data10370.zip (stored 0%)\n",
            "  adding: training_datas/train_data25552.zip (stored 0%)\n",
            "  adding: training_datas/train_data16762.zip (stored 0%)\n",
            "  adding: training_datas/train_data16899.zip (stored 0%)\n",
            "  adding: training_datas/train_data1502.zip (stored 0%)\n",
            "  adding: training_datas/train_data22330.zip (stored 0%)\n",
            "  adding: training_datas/train_data17873.zip (stored 0%)\n",
            "  adding: training_datas/train_data4739.zip (stored 0%)\n",
            "  adding: training_datas/train_data18463.zip (stored 0%)\n",
            "  adding: training_datas/train_data6946.zip (stored 0%)\n",
            "  adding: training_datas/train_data8614.zip (stored 0%)\n",
            "  adding: training_datas/train_data1682.zip (stored 0%)\n",
            "  adding: training_datas/train_data16244.zip (stored 0%)\n",
            "  adding: training_datas/train_data19381.zip (stored 0%)\n",
            "  adding: training_datas/train_data964.zip (stored 0%)\n",
            "  adding: training_datas/train_data23112.zip (stored 0%)\n",
            "  adding: training_datas/train_data8879.zip (stored 0%)\n",
            "  adding: training_datas/train_data12879.zip (stored 0%)\n",
            "  adding: training_datas/train_data12591.zip (stored 0%)\n",
            "  adding: training_datas/train_data15990.zip (stored 0%)\n",
            "  adding: training_datas/train_data7002.zip (stored 0%)\n",
            "  adding: training_datas/train_data10552.zip (stored 0%)\n",
            "  adding: training_datas/train_data27496.zip (stored 0%)\n",
            "  adding: training_datas/train_data1784.zip (stored 0%)\n",
            "  adding: training_datas/train_data7385.zip (stored 0%)\n",
            "  adding: training_datas/train_data27322.zip (stored 0%)\n",
            "  adding: training_datas/train_data4368.zip (stored 0%)\n",
            "  adding: training_datas/train_data2309.zip (stored 0%)\n",
            "  adding: training_datas/train_data28303.zip (stored 0%)\n",
            "  adding: training_datas/train_data28957.zip (stored 0%)\n",
            "  adding: training_datas/train_data19681.zip (stored 0%)\n",
            "  adding: training_datas/train_data13156.zip (stored 0%)\n",
            "  adding: training_datas/train_data18709.zip (stored 0%)\n",
            "  adding: training_datas/train_data11835.zip (stored 0%)\n",
            "  adding: training_datas/train_data14941.zip (stored 0%)\n",
            "  adding: training_datas/train_data11241.zip (stored 0%)\n",
            "  adding: training_datas/train_data23076.zip (stored 0%)\n",
            "  adding: training_datas/train_data14164.zip (stored 0%)\n",
            "  adding: training_datas/train_data15140.zip (stored 0%)\n",
            "  adding: training_datas/train_data11970.zip (stored 0%)\n",
            "  adding: training_datas/train_data21416.zip (stored 0%)\n",
            "  adding: training_datas/train_data747.zip (stored 0%)\n",
            "  adding: training_datas/train_data27157.zip (stored 0%)\n",
            "  adding: training_datas/train_data25640.zip (stored 0%)\n",
            "  adding: training_datas/train_data29813.zip (stored 0%)\n",
            "  adding: training_datas/train_data18592.zip (stored 0%)\n",
            "  adding: training_datas/train_data3777.zip (stored 0%)\n",
            "  adding: training_datas/train_data21175.zip (stored 0%)\n",
            "  adding: training_datas/train_data5521.zip (stored 0%)\n",
            "  adding: training_datas/train_data15441.zip (stored 0%)\n",
            "  adding: training_datas/train_data6295.zip (stored 0%)\n",
            "  adding: training_datas/train_data30434.zip (stored 0%)\n",
            "  adding: training_datas/train_data4323.zip (stored 0%)\n",
            "  adding: training_datas/train_data15589.zip (stored 0%)\n",
            "  adding: training_datas/train_data8742.zip (stored 0%)\n",
            "  adding: training_datas/train_data6476.zip (stored 0%)\n",
            "  adding: training_datas/train_data816.zip (stored 0%)\n",
            "  adding: training_datas/train_data29176.zip (stored 0%)\n",
            "  adding: training_datas/train_data21971.zip (stored 0%)\n",
            "  adding: training_datas/train_data6919.zip (stored 0%)\n",
            "  adding: training_datas/train_data13844.zip (stored 0%)\n",
            "  adding: training_datas/train_data10642.zip (stored 0%)\n",
            "  adding: training_datas/train_data17585.zip (stored 0%)\n",
            "  adding: training_datas/train_data4544.zip (stored 0%)\n",
            "  adding: training_datas/train_data6517.zip (stored 0%)\n",
            "  adding: training_datas/train_data19272.zip (stored 0%)\n",
            "  adding: training_datas/train_data14978.zip (stored 0%)\n",
            "  adding: training_datas/train_data6663.zip (stored 0%)\n",
            "  adding: training_datas/train_data1882.zip (stored 0%)\n",
            "  adding: training_datas/train_data23778.zip (stored 0%)\n",
            "  adding: training_datas/train_data18242.zip (stored 0%)\n",
            "  adding: training_datas/train_data17856.zip (stored 0%)\n",
            "  adding: training_datas/train_data19249.zip (stored 0%)\n",
            "  adding: training_datas/train_data22629.zip (stored 0%)\n",
            "  adding: training_datas/train_data29037.zip (stored 0%)\n",
            "  adding: training_datas/train_data13485.zip (stored 0%)\n",
            "  adding: training_datas/train_data22874.zip (stored 0%)\n",
            "  adding: training_datas/train_data10386.zip (stored 0%)\n",
            "  adding: training_datas/train_data22887.zip (stored 0%)\n",
            "  adding: training_datas/train_data21348.zip (stored 0%)\n",
            "  adding: training_datas/train_data226.zip (stored 0%)\n",
            "  adding: training_datas/train_data22477.zip (stored 0%)\n",
            "  adding: training_datas/train_data16996.zip (stored 0%)\n",
            "  adding: training_datas/train_data1970.zip (stored 0%)\n",
            "  adding: training_datas/train_data16655.zip (stored 0%)\n",
            "  adding: training_datas/train_data6667.zip (stored 0%)\n",
            "  adding: training_datas/train_data26306.zip (stored 0%)\n",
            "  adding: training_datas/train_data20759.zip (stored 0%)\n",
            "  adding: training_datas/train_data9208.zip (stored 0%)\n",
            "  adding: training_datas/train_data29373.zip (stored 0%)\n",
            "  adding: training_datas/train_data6711.zip (stored 0%)\n",
            "  adding: training_datas/train_data21518.zip (stored 0%)\n",
            "  adding: training_datas/train_data18792.zip (stored 0%)\n",
            "  adding: training_datas/train_data18938.zip (stored 0%)\n",
            "  adding: training_datas/train_data1206.zip (stored 0%)\n",
            "  adding: training_datas/train_data10012.zip (stored 0%)\n",
            "  adding: training_datas/train_data22085.zip (stored 0%)\n",
            "  adding: training_datas/train_data9762.zip (stored 0%)\n",
            "  adding: training_datas/train_data18837.zip (stored 0%)\n",
            "  adding: training_datas/train_data3746.zip (stored 0%)\n",
            "  adding: training_datas/train_data27051.zip (stored 0%)\n",
            "  adding: training_datas/train_data7196.zip (stored 0%)\n",
            "  adding: training_datas/train_data8984.zip (stored 0%)\n",
            "  adding: training_datas/train_data23498.zip (stored 0%)\n",
            "  adding: training_datas/train_data380.zip (stored 0%)\n",
            "  adding: training_datas/train_data23041.zip (stored 0%)\n",
            "  adding: training_datas/train_data28978.zip (stored 0%)\n",
            "  adding: training_datas/train_data22333.zip (stored 0%)\n",
            "  adding: training_datas/train_data1163.zip (stored 0%)\n",
            "  adding: training_datas/train_data8702.zip (stored 0%)\n",
            "  adding: training_datas/train_data11151.zip (stored 0%)\n",
            "  adding: training_datas/train_data11792.zip (stored 0%)\n",
            "  adding: training_datas/train_data28760.zip (stored 0%)\n",
            "  adding: training_datas/train_data21617.zip (stored 0%)\n",
            "  adding: training_datas/train_data22029.zip (stored 0%)\n",
            "  adding: training_datas/train_data27839.zip (stored 0%)\n",
            "  adding: training_datas/train_data9549.zip (stored 0%)\n",
            "  adding: training_datas/train_data19846.zip (stored 0%)\n",
            "  adding: training_datas/train_data20814.zip (stored 0%)\n",
            "  adding: training_datas/train_data21600.zip (stored 0%)\n",
            "  adding: training_datas/train_data7668.zip (stored 0%)\n",
            "  adding: training_datas/train_data19812.zip (stored 0%)\n",
            "  adding: training_datas/train_data14278.zip (stored 0%)\n",
            "  adding: training_datas/train_data1841.zip (stored 0%)\n",
            "  adding: training_datas/train_data3307.zip (stored 0%)\n",
            "  adding: training_datas/train_data21024.zip (stored 0%)\n",
            "  adding: training_datas/train_data26468.zip (stored 0%)\n",
            "  adding: training_datas/train_data19862.zip (stored 0%)\n",
            "  adding: training_datas/train_data10783.zip (stored 0%)\n",
            "  adding: training_datas/train_data13271.zip (stored 0%)\n",
            "  adding: training_datas/train_data20481.zip (stored 0%)\n",
            "  adding: training_datas/train_data22469.zip (stored 0%)\n",
            "  adding: training_datas/train_data12174.zip (stored 0%)\n",
            "  adding: training_datas/train_data14956.zip (stored 0%)\n",
            "  adding: training_datas/train_data2556.zip (stored 0%)\n",
            "  adding: training_datas/train_data18668.zip (stored 0%)\n",
            "  adding: training_datas/train_data14800.zip (stored 0%)\n",
            "  adding: training_datas/train_data15742.zip (stored 0%)\n",
            "  adding: training_datas/train_data9806.zip (stored 0%)\n",
            "  adding: training_datas/train_data12975.zip (stored 0%)\n",
            "  adding: training_datas/train_data21612.zip (stored 0%)\n",
            "  adding: training_datas/train_data11910.zip (stored 0%)\n",
            "  adding: training_datas/train_data24454.zip (stored 0%)\n",
            "  adding: training_datas/train_data6997.zip (stored 0%)\n",
            "  adding: training_datas/train_data19595.zip (stored 0%)\n",
            "  adding: training_datas/train_data6925.zip (stored 0%)\n",
            "  adding: training_datas/train_data10452.zip (stored 0%)\n",
            "  adding: training_datas/train_data15787.zip (stored 0%)\n",
            "  adding: training_datas/train_data23588.zip (stored 0%)\n",
            "  adding: training_datas/train_data16384.zip (stored 0%)\n",
            "  adding: training_datas/train_data6660.zip (stored 0%)\n",
            "  adding: training_datas/train_data24806.zip (stored 0%)\n",
            "  adding: training_datas/train_data18904.zip (stored 0%)\n",
            "  adding: training_datas/train_data3912.zip (stored 0%)\n",
            "  adding: training_datas/train_data14385.zip (stored 0%)\n",
            "  adding: training_datas/train_data21466.zip (stored 0%)\n",
            "  adding: training_datas/train_data13883.zip (stored 0%)\n",
            "  adding: training_datas/train_data20775.zip (stored 0%)\n",
            "  adding: training_datas/train_data20582.zip (stored 0%)\n",
            "  adding: training_datas/train_data27125.zip (stored 0%)\n",
            "  adding: training_datas/train_data10118.zip (stored 0%)\n",
            "  adding: training_datas/train_data4207.zip (stored 0%)\n",
            "  adding: training_datas/train_data24434.zip (stored 0%)\n",
            "  adding: training_datas/train_data7938.zip (stored 0%)\n",
            "  adding: training_datas/train_data11492.zip (stored 0%)\n",
            "  adding: training_datas/train_data28721.zip (stored 0%)\n",
            "  adding: training_datas/train_data24006.zip (stored 0%)\n",
            "  adding: training_datas/train_data12447.zip (stored 0%)\n",
            "  adding: training_datas/train_data29653.zip (stored 0%)\n",
            "  adding: training_datas/train_data27854.zip (stored 0%)\n",
            "  adding: training_datas/train_data6242.zip (stored 0%)\n",
            "  adding: training_datas/train_data15825.zip (stored 0%)\n",
            "  adding: training_datas/train_data18500.zip (stored 0%)\n",
            "  adding: training_datas/train_data3774.zip (stored 0%)\n",
            "  adding: training_datas/train_data14742.zip (stored 0%)\n",
            "  adding: training_datas/train_data10598.zip (stored 0%)\n",
            "  adding: training_datas/train_data25910.zip (stored 0%)\n",
            "  adding: training_datas/train_data27508.zip (stored 0%)\n",
            "  adding: training_datas/train_data28083.zip (stored 0%)\n",
            "  adding: training_datas/train_data27241.zip (stored 0%)\n",
            "  adding: training_datas/train_data9241.zip (stored 0%)\n",
            "  adding: training_datas/train_data22902.zip (stored 0%)\n",
            "  adding: training_datas/train_data433.zip (stored 0%)\n",
            "  adding: training_datas/train_data4071.zip (stored 0%)\n",
            "  adding: training_datas/train_data23538.zip (stored 0%)\n",
            "  adding: training_datas/train_data10766.zip (stored 0%)\n",
            "  adding: training_datas/train_data8041.zip (stored 0%)\n",
            "  adding: training_datas/train_data20294.zip (stored 0%)\n",
            "  adding: training_datas/train_data20734.zip (stored 0%)\n",
            "  adding: training_datas/train_data21133.zip (stored 0%)\n",
            "  adding: training_datas/train_data25766.zip (stored 0%)\n",
            "  adding: training_datas/train_data1735.zip (stored 0%)\n",
            "  adding: training_datas/train_data1339.zip (stored 0%)\n",
            "  adding: training_datas/train_data20841.zip (stored 0%)\n",
            "  adding: training_datas/train_data9380.zip (stored 0%)\n",
            "  adding: training_datas/train_data14860.zip (stored 0%)\n",
            "  adding: training_datas/train_data12390.zip (stored 0%)\n",
            "  adding: training_datas/train_data28584.zip (stored 0%)\n",
            "  adding: training_datas/train_data13671.zip (stored 0%)\n",
            "  adding: training_datas/train_data22354.zip (stored 0%)\n",
            "  adding: training_datas/train_data26580.zip (stored 0%)\n",
            "  adding: training_datas/train_data5994.zip (stored 0%)\n",
            "  adding: training_datas/train_data5763.zip (stored 0%)\n",
            "  adding: training_datas/train_data15488.zip (stored 0%)\n",
            "  adding: training_datas/train_data2522.zip (stored 0%)\n",
            "  adding: training_datas/train_data11038.zip (stored 0%)\n",
            "  adding: training_datas/train_data29770.zip (stored 0%)\n",
            "  adding: training_datas/train_data2299.zip (stored 0%)\n",
            "  adding: training_datas/train_data24304.zip (stored 0%)\n",
            "  adding: training_datas/train_data17152.zip (stored 0%)\n",
            "  adding: training_datas/train_data16376.zip (stored 0%)\n",
            "  adding: training_datas/train_data6385.zip (stored 0%)\n",
            "  adding: training_datas/train_data20347.zip (stored 0%)\n",
            "  adding: training_datas/train_data25333.zip (stored 0%)\n",
            "  adding: training_datas/train_data16808.zip (stored 0%)\n",
            "  adding: training_datas/train_data28497.zip (stored 0%)\n",
            "  adding: training_datas/train_data17154.zip (stored 0%)\n",
            "  adding: training_datas/train_data12396.zip (stored 0%)\n",
            "  adding: training_datas/train_data28214.zip (stored 0%)\n",
            "  adding: training_datas/train_data9656.zip (stored 0%)\n",
            "  adding: training_datas/train_data3481.zip (stored 0%)\n",
            "  adding: training_datas/train_data4868.zip (stored 0%)\n",
            "  adding: training_datas/train_data16121.zip (stored 0%)\n",
            "  adding: training_datas/train_data10615.zip (stored 0%)\n",
            "  adding: training_datas/train_data10053.zip (stored 0%)\n",
            "  adding: training_datas/train_data30303.zip (stored 0%)\n",
            "  adding: training_datas/train_data9798.zip (stored 0%)\n",
            "  adding: training_datas/train_data5935.zip (stored 0%)\n",
            "  adding: training_datas/train_data14996.zip (stored 0%)\n",
            "  adding: training_datas/train_data26800.zip (stored 0%)\n",
            "  adding: training_datas/train_data10036.zip (stored 0%)\n",
            "  adding: training_datas/train_data10969.zip (stored 0%)\n",
            "  adding: training_datas/train_data30432.zip (stored 0%)\n",
            "  adding: training_datas/train_data11119.zip (stored 0%)\n",
            "  adding: training_datas/train_data27477.zip (stored 0%)\n",
            "  adding: training_datas/train_data1961.zip (stored 0%)\n",
            "  adding: training_datas/train_data15121.zip (stored 0%)\n",
            "  adding: training_datas/train_data5578.zip (stored 0%)\n",
            "  adding: training_datas/train_data27791.zip (stored 0%)\n",
            "  adding: training_datas/train_data20795.zip (stored 0%)\n",
            "  adding: training_datas/train_data22895.zip (stored 0%)\n",
            "  adding: training_datas/train_data22729.zip (stored 0%)\n",
            "  adding: training_datas/train_data8091.zip (stored 0%)\n",
            "  adding: training_datas/train_data8303.zip (stored 0%)\n",
            "  adding: training_datas/train_data14072.zip (stored 0%)\n",
            "  adding: training_datas/train_data28507.zip (stored 0%)\n",
            "  adding: training_datas/train_data28791.zip (stored 0%)\n",
            "  adding: training_datas/train_data17542.zip (stored 0%)\n",
            "  adding: training_datas/train_data30192.zip (stored 0%)\n",
            "  adding: training_datas/train_data5610.zip (stored 0%)\n",
            "  adding: training_datas/train_data11367.zip (stored 0%)\n",
            "  adding: training_datas/train_data13130.zip (stored 0%)\n",
            "  adding: training_datas/train_data26407.zip (stored 0%)\n",
            "  adding: training_datas/train_data17441.zip (stored 0%)\n",
            "  adding: training_datas/train_data25176.zip (stored 0%)\n",
            "  adding: training_datas/train_data20359.zip (stored 0%)\n",
            "  adding: training_datas/train_data13587.zip (stored 0%)\n",
            "  adding: training_datas/train_data29225.zip (stored 0%)\n",
            "  adding: training_datas/train_data965.zip (stored 0%)\n",
            "  adding: training_datas/train_data19195.zip (stored 0%)\n",
            "  adding: training_datas/train_data16680.zip (stored 0%)\n",
            "  adding: training_datas/train_data14716.zip (stored 0%)\n",
            "  adding: training_datas/train_data14500.zip (stored 0%)\n",
            "  adding: training_datas/train_data11945.zip (stored 0%)\n",
            "  adding: training_datas/train_data11185.zip (stored 0%)\n",
            "  adding: training_datas/train_data15801.zip (stored 0%)\n",
            "  adding: training_datas/train_data20106.zip (stored 0%)\n",
            "  adding: training_datas/train_data4191.zip (stored 0%)\n",
            "  adding: training_datas/train_data17190.zip (stored 0%)\n",
            "  adding: training_datas/train_data3541.zip (stored 0%)\n",
            "  adding: training_datas/train_data16096.zip (stored 0%)\n",
            "  adding: training_datas/train_data10509.zip (stored 0%)\n",
            "  adding: training_datas/train_data24881.zip (stored 0%)\n",
            "  adding: training_datas/train_data15762.zip (stored 0%)\n",
            "  adding: training_datas/train_data291.zip (stored 0%)\n",
            "  adding: training_datas/train_data24998.zip (stored 0%)\n",
            "  adding: training_datas/train_data11823.zip (stored 0%)\n",
            "  adding: training_datas/train_data8267.zip (stored 0%)\n",
            "  adding: training_datas/train_data18932.zip (stored 0%)\n",
            "  adding: training_datas/train_data18573.zip (stored 0%)\n",
            "  adding: training_datas/train_data13311.zip (stored 0%)\n",
            "  adding: training_datas/train_data19581.zip (stored 0%)\n",
            "  adding: training_datas/train_data3163.zip (stored 0%)\n",
            "  adding: training_datas/train_data7790.zip (stored 0%)\n",
            "  adding: training_datas/train_data8364.zip (stored 0%)\n",
            "  adding: training_datas/train_data27372.zip (stored 0%)\n",
            "  adding: training_datas/train_data19438.zip (stored 0%)\n",
            "  adding: training_datas/train_data11071.zip (stored 0%)\n",
            "  adding: training_datas/train_data28919.zip (stored 0%)\n",
            "  adding: training_datas/train_data19513.zip (stored 0%)\n",
            "  adding: training_datas/train_data13076.zip (stored 0%)\n",
            "  adding: training_datas/train_data22574.zip (stored 0%)\n",
            "  adding: training_datas/train_data10893.zip (stored 0%)\n",
            "  adding: training_datas/train_data1701.zip (stored 0%)\n",
            "  adding: training_datas/train_data25975.zip (stored 0%)\n",
            "  adding: training_datas/train_data1072.zip (stored 0%)\n",
            "  adding: training_datas/train_data28947.zip (stored 0%)\n",
            "  adding: training_datas/train_data22442.zip (stored 0%)\n",
            "  adding: training_datas/train_data28366.zip (stored 0%)\n",
            "  adding: training_datas/train_data10595.zip (stored 0%)\n",
            "  adding: training_datas/train_data27445.zip (stored 0%)\n",
            "  adding: training_datas/train_data12773.zip (stored 0%)\n",
            "  adding: training_datas/train_data9369.zip (stored 0%)\n",
            "  adding: training_datas/train_data11143.zip (stored 0%)\n",
            "  adding: training_datas/train_data871.zip (stored 0%)\n",
            "  adding: training_datas/train_data2164.zip (stored 0%)\n",
            "  adding: training_datas/train_data25517.zip (stored 0%)\n",
            "  adding: training_datas/train_data25034.zip (stored 0%)\n",
            "  adding: training_datas/train_data3683.zip (stored 0%)\n",
            "  adding: training_datas/train_data1211.zip (stored 0%)\n",
            "  adding: training_datas/train_data21776.zip (stored 0%)\n",
            "  adding: training_datas/train_data13473.zip (stored 0%)\n",
            "  adding: training_datas/train_data28920.zip (stored 0%)\n",
            "  adding: training_datas/train_data1111.zip (stored 0%)\n",
            "  adding: training_datas/train_data15179.zip (stored 0%)\n",
            "  adding: training_datas/train_data27505.zip (stored 0%)\n",
            "  adding: training_datas/train_data2679.zip (stored 0%)\n",
            "  adding: training_datas/train_data3325.zip (stored 0%)\n",
            "  adding: training_datas/train_data13060.zip (stored 0%)\n",
            "  adding: training_datas/train_data26905.zip (stored 0%)\n",
            "  adding: training_datas/train_data9316.zip (stored 0%)\n",
            "  adding: training_datas/train_data14350.zip (stored 0%)\n",
            "  adding: training_datas/train_data29856.zip (stored 0%)\n",
            "  adding: training_datas/train_data26916.zip (stored 0%)\n",
            "  adding: training_datas/train_data18655.zip (stored 0%)\n",
            "  adding: training_datas/train_data17322.zip (stored 0%)\n",
            "  adding: training_datas/train_data11509.zip (stored 0%)\n",
            "  adding: training_datas/train_data1540.zip (stored 0%)\n",
            "  adding: training_datas/train_data25792.zip (stored 0%)\n",
            "  adding: training_datas/train_data16755.zip (stored 0%)\n",
            "  adding: training_datas/train_data19542.zip (stored 0%)\n",
            "  adding: training_datas/train_data24156.zip (stored 0%)\n",
            "  adding: training_datas/train_data2057.zip (stored 0%)\n",
            "  adding: training_datas/train_data2774.zip (stored 0%)\n",
            "  adding: training_datas/train_data26412.zip (stored 0%)\n",
            "  adding: training_datas/train_data28368.zip (stored 0%)\n",
            "  adding: training_datas/train_data13453.zip (stored 0%)\n",
            "  adding: training_datas/train_data18714.zip (stored 0%)\n",
            "  adding: training_datas/train_data23477.zip (stored 0%)\n",
            "  adding: training_datas/train_data14489.zip (stored 0%)\n",
            "  adding: training_datas/train_data24039.zip (stored 0%)\n",
            "  adding: training_datas/train_data812.zip (stored 0%)\n",
            "  adding: training_datas/train_data18686.zip (stored 0%)\n",
            "  adding: training_datas/train_data25298.zip (stored 0%)\n",
            "  adding: training_datas/train_data29266.zip (stored 0%)\n",
            "  adding: training_datas/train_data13543.zip (stored 0%)\n",
            "  adding: training_datas/train_data20414.zip (stored 0%)\n",
            "  adding: training_datas/train_data3702.zip (stored 0%)\n",
            "  adding: training_datas/train_data4459.zip (stored 0%)\n",
            "  adding: training_datas/train_data22151.zip (stored 0%)\n",
            "  adding: training_datas/train_data14224.zip (stored 0%)\n",
            "  adding: training_datas/train_data11486.zip (stored 0%)\n",
            "  adding: training_datas/train_data1787.zip (stored 0%)\n",
            "  adding: training_datas/train_data11391.zip (stored 0%)\n",
            "  adding: training_datas/train_data23914.zip (stored 0%)\n",
            "  adding: training_datas/train_data4385.zip (stored 0%)\n",
            "  adding: training_datas/train_data10472.zip (stored 0%)\n",
            "  adding: training_datas/train_data10434.zip (stored 0%)\n",
            "  adding: training_datas/train_data10454.zip (stored 0%)\n",
            "  adding: training_datas/train_data19285.zip (stored 0%)\n",
            "  adding: training_datas/train_data26702.zip (stored 0%)\n",
            "  adding: training_datas/train_data17606.zip (stored 0%)\n",
            "  adding: training_datas/train_data27957.zip (stored 0%)\n",
            "  adding: training_datas/train_data353.zip (stored 0%)\n",
            "  adding: training_datas/train_data17302.zip (stored 0%)\n",
            "  adding: training_datas/train_data6725.zip (stored 0%)\n",
            "  adding: training_datas/train_data25499.zip (stored 0%)\n",
            "  adding: training_datas/train_data12320.zip (stored 0%)\n",
            "  adding: training_datas/train_data14727.zip (stored 0%)\n",
            "  adding: training_datas/train_data5984.zip (stored 0%)\n",
            "  adding: training_datas/train_data10901.zip (stored 0%)\n",
            "  adding: training_datas/train_data22325.zip (stored 0%)\n",
            "  adding: training_datas/train_data2000.zip (stored 0%)\n",
            "  adding: training_datas/train_data21264.zip (stored 0%)\n",
            "  adding: training_datas/train_data1830.zip (stored 0%)\n",
            "  adding: training_datas/train_data1809.zip (stored 0%)\n",
            "  adding: training_datas/train_data29135.zip (stored 0%)\n",
            "  adding: training_datas/train_data7765.zip (stored 0%)\n",
            "  adding: training_datas/train_data13032.zip (stored 0%)\n",
            "  adding: training_datas/train_data19625.zip (stored 0%)\n",
            "  adding: training_datas/train_data17627.zip (stored 0%)\n",
            "  adding: training_datas/train_data20220.zip (stored 0%)\n",
            "  adding: training_datas/train_data24661.zip (stored 0%)\n",
            "  adding: training_datas/train_data23437.zip (stored 0%)\n",
            "  adding: training_datas/train_data12102.zip (stored 0%)\n",
            "  adding: training_datas/train_data4256.zip (stored 0%)\n",
            "  adding: training_datas/train_data488.zip (stored 0%)\n",
            "  adding: training_datas/train_data12063.zip (stored 0%)\n",
            "  adding: training_datas/train_data18469.zip (stored 0%)\n",
            "  adding: training_datas/train_data26466.zip (stored 0%)\n",
            "  adding: training_datas/train_data18472.zip (stored 0%)\n",
            "  adding: training_datas/train_data10609.zip (stored 0%)\n",
            "  adding: training_datas/train_data23928.zip (stored 0%)\n",
            "  adding: training_datas/train_data28595.zip (stored 0%)\n",
            "  adding: training_datas/train_data6134.zip (stored 0%)\n",
            "  adding: training_datas/train_data29553.zip (stored 0%)\n",
            "  adding: training_datas/train_data10007.zip (stored 0%)\n",
            "  adding: training_datas/train_data24943.zip (stored 0%)\n",
            "  adding: training_datas/train_data7218.zip (stored 0%)\n",
            "  adding: training_datas/train_data4012.zip (stored 0%)\n",
            "  adding: training_datas/train_data9402.zip (stored 0%)\n",
            "  adding: training_datas/train_data21464.zip (stored 0%)\n",
            "  adding: training_datas/train_data12010.zip (stored 0%)\n",
            "  adding: training_datas/train_data14139.zip (stored 0%)\n",
            "  adding: training_datas/train_data20976.zip (stored 0%)\n",
            "  adding: training_datas/train_data5365.zip (stored 0%)\n",
            "  adding: training_datas/train_data11536.zip (stored 0%)\n",
            "  adding: training_datas/train_data7944.zip (stored 0%)\n",
            "  adding: training_datas/train_data28287.zip (stored 0%)\n",
            "  adding: training_datas/train_data9284.zip (stored 0%)\n",
            "  adding: training_datas/train_data14097.zip (stored 0%)\n",
            "  adding: training_datas/train_data13849.zip (stored 0%)\n",
            "  adding: training_datas/train_data3806.zip (stored 0%)\n",
            "  adding: training_datas/train_data18328.zip (stored 0%)\n",
            "  adding: training_datas/train_data6127.zip (stored 0%)\n",
            "  adding: training_datas/train_data12302.zip (stored 0%)\n",
            "  adding: training_datas/train_data24407.zip (stored 0%)\n",
            "  adding: training_datas/train_data29826.zip (stored 0%)\n",
            "  adding: training_datas/train_data20739.zip (stored 0%)\n",
            "  adding: training_datas/train_data9694.zip (stored 0%)\n",
            "  adding: training_datas/train_data1410.zip (stored 0%)\n",
            "  adding: training_datas/train_data16814.zip (stored 0%)\n",
            "  adding: training_datas/train_data17262.zip (stored 0%)\n",
            "  adding: training_datas/train_data28890.zip (stored 0%)\n",
            "  adding: training_datas/train_data1835.zip (stored 0%)\n",
            "  adding: training_datas/train_data20629.zip (stored 0%)\n",
            "  adding: training_datas/train_data10929.zip (stored 0%)\n",
            "  adding: training_datas/train_data7597.zip (stored 0%)\n",
            "  adding: training_datas/train_data23525.zip (stored 0%)\n",
            "  adding: training_datas/train_data24021.zip (stored 0%)\n",
            "  adding: training_datas/train_data13492.zip (stored 0%)\n",
            "  adding: training_datas/train_data2115.zip (stored 0%)\n",
            "  adding: training_datas/train_data9182.zip (stored 0%)\n",
            "  adding: training_datas/train_data24804.zip (stored 0%)\n",
            "  adding: training_datas/train_data9085.zip (stored 0%)\n",
            "  adding: training_datas/train_data22438.zip (stored 0%)\n",
            "  adding: training_datas/train_data29627.zip (stored 0%)\n",
            "  adding: training_datas/train_data2976.zip (stored 0%)\n",
            "  adding: training_datas/train_data9475.zip (stored 0%)\n",
            "  adding: training_datas/train_data7219.zip (stored 0%)\n",
            "  adding: training_datas/train_data16334.zip (stored 0%)\n",
            "  adding: training_datas/train_data13023.zip (stored 0%)\n",
            "  adding: training_datas/train_data26632.zip (stored 0%)\n",
            "  adding: training_datas/train_data28012.zip (stored 0%)\n",
            "  adding: training_datas/train_data1306.zip (stored 0%)\n",
            "  adding: training_datas/train_data28522.zip (stored 0%)\n",
            "  adding: training_datas/train_data8238.zip (stored 0%)\n",
            "  adding: training_datas/train_data16008.zip (stored 0%)\n",
            "  adding: training_datas/train_data2413.zip (stored 0%)\n",
            "  adding: training_datas/train_data16667.zip (stored 0%)\n",
            "  adding: training_datas/train_data12886.zip (stored 0%)\n",
            "  adding: training_datas/train_data13210.zip (stored 0%)\n",
            "  adding: training_datas/train_data9265.zip (stored 0%)\n",
            "  adding: training_datas/train_data8885.zip (stored 0%)\n",
            "  adding: training_datas/train_data13134.zip (stored 0%)\n",
            "  adding: training_datas/train_data8715.zip (stored 0%)\n",
            "  adding: training_datas/train_data19717.zip (stored 0%)\n",
            "  adding: training_datas/train_data28051.zip (stored 0%)\n",
            "  adding: training_datas/train_data2237.zip (stored 0%)\n",
            "  adding: training_datas/train_data21741.zip (stored 0%)\n",
            "  adding: training_datas/train_data9112.zip (stored 0%)\n",
            "  adding: training_datas/train_data9016.zip (stored 0%)\n",
            "  adding: training_datas/train_data21110.zip (stored 0%)\n",
            "  adding: training_datas/train_data28622.zip (stored 0%)\n",
            "  adding: training_datas/train_data17328.zip (stored 0%)\n",
            "  adding: training_datas/train_data5267.zip (stored 0%)\n",
            "  adding: training_datas/train_data9488.zip (stored 0%)\n",
            "  adding: training_datas/train_data8314.zip (stored 0%)\n",
            "  adding: training_datas/train_data17287.zip (stored 0%)\n",
            "  adding: training_datas/train_data23393.zip (stored 0%)\n",
            "  adding: training_datas/train_data4685.zip (stored 0%)\n",
            "  adding: training_datas/train_data16210.zip (stored 0%)\n",
            "  adding: training_datas/train_data21665.zip (stored 0%)\n",
            "  adding: training_datas/train_data6627.zip (stored 0%)\n",
            "  adding: training_datas/train_data9132.zip (stored 0%)\n",
            "  adding: training_datas/train_data8919.zip (stored 0%)\n",
            "  adding: training_datas/train_data51.zip (stored 0%)\n",
            "  adding: training_datas/train_data7353.zip (stored 0%)\n",
            "  adding: training_datas/train_data27753.zip (stored 0%)\n",
            "  adding: training_datas/train_data14255.zip (stored 0%)\n",
            "  adding: training_datas/train_data3837.zip (stored 0%)\n",
            "  adding: training_datas/train_data25302.zip (stored 0%)\n",
            "  adding: training_datas/train_data3862.zip (stored 0%)\n",
            "  adding: training_datas/train_data24570.zip (stored 0%)\n",
            "  adding: training_datas/train_data27914.zip (stored 0%)\n",
            "  adding: training_datas/train_data13895.zip (stored 0%)\n",
            "  adding: training_datas/train_data22311.zip (stored 0%)\n",
            "  adding: training_datas/train_data28321.zip (stored 0%)\n",
            "  adding: training_datas/train_data19526.zip (stored 0%)\n",
            "  adding: training_datas/train_data12266.zip (stored 0%)\n",
            "  adding: training_datas/train_data18359.zip (stored 0%)\n",
            "  adding: training_datas/train_data1495.zip (stored 0%)\n",
            "  adding: training_datas/train_data3431.zip (stored 0%)\n",
            "  adding: training_datas/train_data17737.zip (stored 0%)\n",
            "  adding: training_datas/train_data19782.zip (stored 0%)\n",
            "  adding: training_datas/train_data25742.zip (stored 0%)\n",
            "  adding: training_datas/train_data29074.zip (stored 0%)\n",
            "  adding: training_datas/train_data28136.zip (stored 0%)\n",
            "  adding: training_datas/train_data19945.zip (stored 0%)\n",
            "  adding: training_datas/train_data26060.zip (stored 0%)\n",
            "  adding: training_datas/train_data28891.zip (stored 0%)\n",
            "  adding: training_datas/train_data29802.zip (stored 0%)\n",
            "  adding: training_datas/train_data29539.zip (stored 0%)\n",
            "  adding: training_datas/train_data5665.zip (stored 0%)\n",
            "  adding: training_datas/train_data26771.zip (stored 0%)\n",
            "  adding: training_datas/train_data26614.zip (stored 0%)\n",
            "  adding: training_datas/train_data14539.zip (stored 0%)\n",
            "  adding: training_datas/train_data326.zip (stored 0%)\n",
            "  adding: training_datas/train_data1873.zip (stored 0%)\n",
            "  adding: training_datas/train_data27179.zip (stored 0%)\n",
            "  adding: training_datas/train_data25514.zip (stored 0%)\n",
            "  adding: training_datas/train_data678.zip (stored 0%)\n",
            "  adding: training_datas/train_data10760.zip (stored 0%)\n",
            "  adding: training_datas/train_data2022.zip (stored 0%)\n",
            "  adding: training_datas/train_data2616.zip (stored 0%)\n",
            "  adding: training_datas/train_data24328.zip (stored 0%)\n",
            "  adding: training_datas/train_data5920.zip (stored 0%)\n",
            "  adding: training_datas/train_data13682.zip (stored 0%)\n",
            "  adding: training_datas/train_data13490.zip (stored 0%)\n",
            "  adding: training_datas/train_data6251.zip (stored 0%)\n",
            "  adding: training_datas/train_data3342.zip (stored 0%)\n",
            "  adding: training_datas/train_data17471.zip (stored 0%)\n",
            "  adding: training_datas/train_data19228.zip (stored 0%)\n",
            "  adding: training_datas/train_data5102.zip (stored 0%)\n",
            "  adding: training_datas/train_data10541.zip (stored 0%)\n",
            "  adding: training_datas/train_data15299.zip (stored 0%)\n",
            "  adding: training_datas/train_data17643.zip (stored 0%)\n",
            "  adding: training_datas/train_data29097.zip (stored 0%)\n",
            "  adding: training_datas/train_data20036.zip (stored 0%)\n",
            "  adding: training_datas/train_data2877.zip (stored 0%)\n",
            "  adding: training_datas/train_data2312.zip (stored 0%)\n",
            "  adding: training_datas/train_data153.zip (stored 0%)\n",
            "  adding: training_datas/train_data6397.zip (stored 0%)\n",
            "  adding: training_datas/train_data19266.zip (stored 0%)\n",
            "  adding: training_datas/train_data5632.zip (stored 0%)\n",
            "  adding: training_datas/train_data21075.zip (stored 0%)\n",
            "  adding: training_datas/train_data19773.zip (stored 0%)\n",
            "  adding: training_datas/train_data26380.zip (stored 0%)\n",
            "  adding: training_datas/train_data3111.zip (stored 0%)\n",
            "  adding: training_datas/train_data30037.zip (stored 0%)\n",
            "  adding: training_datas/train_data16205.zip (stored 0%)\n",
            "  adding: training_datas/train_data13982.zip (stored 0%)\n",
            "  adding: training_datas/train_data4767.zip (stored 0%)\n",
            "  adding: training_datas/train_data27575.zip (stored 0%)\n",
            "  adding: training_datas/train_data27408.zip (stored 0%)\n",
            "  adding: training_datas/train_data23964.zip (stored 0%)\n",
            "  adding: training_datas/train_data14776.zip (stored 0%)\n",
            "  adding: training_datas/train_data14061.zip (stored 0%)\n",
            "  adding: training_datas/train_data20243.zip (stored 0%)\n",
            "  adding: training_datas/train_data15676.zip (stored 0%)\n",
            "  adding: training_datas/train_data8383.zip (stored 0%)\n",
            "  adding: training_datas/train_data20962.zip (stored 0%)\n",
            "  adding: training_datas/train_data26459.zip (stored 0%)\n",
            "  adding: training_datas/train_data17340.zip (stored 0%)\n",
            "  adding: training_datas/train_data16013.zip (stored 0%)\n",
            "  adding: training_datas/train_data1905.zip (stored 0%)\n",
            "  adding: training_datas/train_data27208.zip (stored 0%)\n",
            "  adding: training_datas/train_data15110.zip (stored 0%)\n",
            "  adding: training_datas/train_data3811.zip (stored 0%)\n",
            "  adding: training_datas/train_data12235.zip (stored 0%)\n",
            "  adding: training_datas/train_data16280.zip (stored 0%)\n",
            "  adding: training_datas/train_data23238.zip (stored 0%)\n",
            "  adding: training_datas/train_data4294.zip (stored 0%)\n",
            "  adding: training_datas/train_data28231.zip (stored 0%)\n",
            "  adding: training_datas/train_data20907.zip (stored 0%)\n",
            "  adding: training_datas/train_data14475.zip (stored 0%)\n",
            "  adding: training_datas/train_data27951.zip (stored 0%)\n",
            "  adding: training_datas/train_data3113.zip (stored 0%)\n",
            "  adding: training_datas/train_data20078.zip (stored 0%)\n",
            "  adding: training_datas/train_data24278.zip (stored 0%)\n",
            "  adding: training_datas/train_data10646.zip (stored 0%)\n",
            "  adding: training_datas/train_data10331.zip (stored 0%)\n",
            "  adding: training_datas/train_data106.zip (stored 0%)\n",
            "  adding: training_datas/train_data23694.zip (stored 0%)\n",
            "  adding: training_datas/train_data24179.zip (stored 0%)\n",
            "  adding: training_datas/train_data8505.zip (stored 0%)\n",
            "  adding: training_datas/train_data20709.zip (stored 0%)\n",
            "  adding: training_datas/train_data1060.zip (stored 0%)\n",
            "  adding: training_datas/train_data25685.zip (stored 0%)\n",
            "  adding: training_datas/train_data24613.zip (stored 0%)\n",
            "  adding: training_datas/train_data20141.zip (stored 0%)\n",
            "  adding: training_datas/train_data25130.zip (stored 0%)\n",
            "  adding: training_datas/train_data8474.zip (stored 0%)\n",
            "  adding: training_datas/train_data1357.zip (stored 0%)\n",
            "  adding: training_datas/train_data6648.zip (stored 0%)\n",
            "  adding: training_datas/train_data26274.zip (stored 0%)\n",
            "  adding: training_datas/train_data8960.zip (stored 0%)\n",
            "  adding: training_datas/train_data26688.zip (stored 0%)\n",
            "  adding: training_datas/train_data18600.zip (stored 0%)\n",
            "  adding: training_datas/train_data18670.zip (stored 0%)\n",
            "  adding: training_datas/train_data13927.zip (stored 0%)\n",
            "  adding: training_datas/train_data8835.zip (stored 0%)\n",
            "  adding: training_datas/train_data21606.zip (stored 0%)\n",
            "  adding: training_datas/train_data28631.zip (stored 0%)\n",
            "  adding: training_datas/train_data16995.zip (stored 0%)\n",
            "  adding: training_datas/train_data20638.zip (stored 0%)\n",
            "  adding: training_datas/train_data7879.zip (stored 0%)\n",
            "  adding: training_datas/train_data9485.zip (stored 0%)\n",
            "  adding: training_datas/train_data24628.zip (stored 0%)\n",
            "  adding: training_datas/train_data25541.zip (stored 0%)\n",
            "  adding: training_datas/train_data27728.zip (stored 0%)\n",
            "  adding: training_datas/train_data29469.zip (stored 0%)\n",
            "  adding: training_datas/train_data12497.zip (stored 0%)\n",
            "  adding: training_datas/train_data21509.zip (stored 0%)\n",
            "  adding: training_datas/train_data13760.zip (stored 0%)\n",
            "  adding: training_datas/train_data24411.zip (stored 0%)\n",
            "  adding: training_datas/train_data4925.zip (stored 0%)\n",
            "  adding: training_datas/train_data11023.zip (stored 0%)\n",
            "  adding: training_datas/train_data22672.zip (stored 0%)\n",
            "  adding: training_datas/train_data7465.zip (stored 0%)\n",
            "  adding: training_datas/train_data11580.zip (stored 0%)\n",
            "  adding: training_datas/train_data3897.zip (stored 0%)\n",
            "  adding: training_datas/train_data1734.zip (stored 0%)\n",
            "  adding: training_datas/train_data25344.zip (stored 0%)\n",
            "  adding: training_datas/train_data29209.zip (stored 0%)\n",
            "  adding: training_datas/train_data16648.zip (stored 0%)\n",
            "  adding: training_datas/train_data22496.zip (stored 0%)\n",
            "  adding: training_datas/train_data17198.zip (stored 0%)\n",
            "  adding: training_datas/train_data22776.zip (stored 0%)\n",
            "  adding: training_datas/train_data21291.zip (stored 0%)\n",
            "  adding: training_datas/train_data7893.zip (stored 0%)\n",
            "  adding: training_datas/train_data13043.zip (stored 0%)\n",
            "  adding: training_datas/train_data7700.zip (stored 0%)\n",
            "  adding: training_datas/train_data11858.zip (stored 0%)\n",
            "  adding: training_datas/train_data6027.zip (stored 0%)\n",
            "  adding: training_datas/train_data25429.zip (stored 0%)\n",
            "  adding: training_datas/train_data739.zip (stored 0%)\n",
            "  adding: training_datas/train_data14962.zip (stored 0%)\n",
            "  adding: training_datas/train_data24358.zip (stored 0%)\n",
            "  adding: training_datas/train_data18100.zip (stored 0%)\n",
            "  adding: training_datas/train_data16139.zip (stored 0%)\n",
            "  adding: training_datas/train_data20348.zip (stored 0%)\n",
            "  adding: training_datas/train_data6553.zip (stored 0%)\n",
            "  adding: training_datas/train_data16927.zip (stored 0%)\n",
            "  adding: training_datas/train_data30151.zip (stored 0%)\n",
            "  adding: training_datas/train_data23753.zip (stored 0%)\n",
            "  adding: training_datas/train_data16663.zip (stored 0%)\n",
            "  adding: training_datas/train_data16502.zip (stored 0%)\n",
            "  adding: training_datas/train_data22588.zip (stored 0%)\n",
            "  adding: training_datas/train_data19425.zip (stored 0%)\n",
            "  adding: training_datas/train_data6957.zip (stored 0%)\n",
            "  adding: training_datas/train_data26591.zip (stored 0%)\n",
            "  adding: training_datas/train_data13677.zip (stored 0%)\n",
            "  adding: training_datas/train_data8070.zip (stored 0%)\n",
            "  adding: training_datas/train_data552.zip (stored 0%)\n",
            "  adding: training_datas/train_data29281.zip (stored 0%)\n",
            "  adding: training_datas/train_data27197.zip (stored 0%)\n",
            "  adding: training_datas/train_data18692.zip (stored 0%)\n",
            "  adding: training_datas/train_data1375.zip (stored 0%)\n",
            "  adding: training_datas/train_data17599.zip (stored 0%)\n",
            "  adding: training_datas/train_data10808.zip (stored 0%)\n",
            "  adding: training_datas/train_data8061.zip (stored 0%)\n",
            "  adding: training_datas/train_data13001.zip (stored 0%)\n",
            "  adding: training_datas/train_data24340.zip (stored 0%)\n",
            "  adding: training_datas/train_data18759.zip (stored 0%)\n",
            "  adding: training_datas/train_data4706.zip (stored 0%)\n",
            "  adding: training_datas/train_data23486.zip (stored 0%)\n",
            "  adding: training_datas/train_data17623.zip (stored 0%)\n",
            "  adding: training_datas/train_data9347.zip (stored 0%)\n",
            "  adding: training_datas/train_data336.zip (stored 0%)\n",
            "  adding: training_datas/train_data14124.zip (stored 0%)\n",
            "  adding: training_datas/train_data18260.zip (stored 0%)\n",
            "  adding: training_datas/train_data14581.zip (stored 0%)\n",
            "  adding: training_datas/train_data16992.zip (stored 0%)\n",
            "  adding: training_datas/train_data6534.zip (stored 0%)\n",
            "  adding: training_datas/train_data24424.zip (stored 0%)\n",
            "  adding: training_datas/train_data28209.zip (stored 0%)\n",
            "  adding: training_datas/train_data15221.zip (stored 0%)\n",
            "  adding: training_datas/train_data1918.zip (stored 0%)\n",
            "  adding: training_datas/train_data16708.zip (stored 0%)\n",
            "  adding: training_datas/train_data25970.zip (stored 0%)\n",
            "  adding: training_datas/train_data22674.zip (stored 0%)\n",
            "  adding: training_datas/train_data25345.zip (stored 0%)\n",
            "  adding: training_datas/train_data880.zip (stored 0%)\n",
            "  adding: training_datas/train_data20018.zip (stored 0%)\n",
            "  adding: training_datas/train_data17610.zip (stored 0%)\n",
            "  adding: training_datas/train_data19332.zip (stored 0%)\n",
            "  adding: training_datas/train_data15030.zip (stored 0%)\n",
            "  adding: training_datas/train_data30036.zip (stored 0%)\n",
            "  adding: training_datas/train_data9072.zip (stored 0%)\n",
            "  adding: training_datas/train_data13734.zip (stored 0%)\n",
            "  adding: training_datas/train_data16906.zip (stored 0%)\n",
            "  adding: training_datas/train_data25492.zip (stored 0%)\n",
            "  adding: training_datas/train_data2318.zip (stored 0%)\n",
            "  adding: training_datas/train_data3578.zip (stored 0%)\n",
            "  adding: training_datas/train_data5936.zip (stored 0%)\n",
            "  adding: training_datas/train_data10423.zip (stored 0%)\n",
            "  adding: training_datas/train_data23685.zip (stored 0%)\n",
            "  adding: training_datas/train_data8371.zip (stored 0%)\n",
            "  adding: training_datas/train_data15989.zip (stored 0%)\n",
            "  adding: training_datas/train_data1693.zip (stored 0%)\n",
            "  adding: training_datas/train_data4129.zip (stored 0%)\n",
            "  adding: training_datas/train_data1780.zip (stored 0%)\n",
            "  adding: training_datas/train_data23506.zip (stored 0%)\n",
            "  adding: training_datas/train_data11058.zip (stored 0%)\n",
            "  adding: training_datas/train_data3309.zip (stored 0%)\n",
            "  adding: training_datas/train_data29850.zip (stored 0%)\n",
            "  adding: training_datas/train_data17274.zip (stored 0%)\n",
            "  adding: training_datas/train_data3081.zip (stored 0%)\n",
            "  adding: training_datas/train_data7545.zip (stored 0%)\n",
            "  adding: training_datas/train_data7050.zip (stored 0%)\n",
            "  adding: training_datas/train_data16586.zip (stored 0%)\n",
            "  adding: training_datas/train_data23391.zip (stored 0%)\n",
            "  adding: training_datas/train_data22526.zip (stored 0%)\n",
            "  adding: training_datas/train_data13562.zip (stored 0%)\n",
            "  adding: training_datas/train_data27454.zip (stored 0%)\n",
            "  adding: training_datas/train_data3799.zip (stored 0%)\n",
            "  adding: training_datas/train_data17603.zip (stored 0%)\n",
            "  adding: training_datas/train_data19140.zip (stored 0%)\n",
            "  adding: training_datas/train_data15389.zip (stored 0%)\n",
            "  adding: training_datas/train_data19519.zip (stored 0%)\n",
            "  adding: training_datas/train_data21934.zip (stored 0%)\n",
            "  adding: training_datas/train_data22596.zip (stored 0%)\n",
            "  adding: training_datas/train_data8801.zip (stored 0%)\n",
            "  adding: training_datas/train_data25134.zip (stored 0%)\n",
            "  adding: training_datas/train_data20154.zip (stored 0%)\n",
            "  adding: training_datas/train_data16674.zip (stored 0%)\n",
            "  adding: training_datas/train_data3217.zip (stored 0%)\n",
            "  adding: training_datas/train_data24618.zip (stored 0%)\n",
            "  adding: training_datas/train_data7783.zip (stored 0%)\n",
            "  adding: training_datas/train_data5885.zip (stored 0%)\n",
            "  adding: training_datas/train_data17647.zip (stored 0%)\n",
            "  adding: training_datas/train_data12438.zip (stored 0%)\n",
            "  adding: training_datas/train_data11034.zip (stored 0%)\n",
            "  adding: training_datas/train_data5640.zip (stored 0%)\n",
            "  adding: training_datas/train_data8692.zip (stored 0%)\n",
            "  adding: training_datas/train_data18343.zip (stored 0%)\n",
            "  adding: training_datas/train_data18942.zip (stored 0%)\n",
            "  adding: training_datas/train_data25088.zip (stored 0%)\n",
            "  adding: training_datas/train_data2485.zip (stored 0%)\n",
            "  adding: training_datas/train_data3048.zip (stored 0%)\n",
            "  adding: training_datas/train_data11399.zip (stored 0%)\n",
            "  adding: training_datas/train_data6464.zip (stored 0%)\n",
            "  adding: training_datas/train_data9258.zip (stored 0%)\n",
            "  adding: training_datas/train_data14270.zip (stored 0%)\n",
            "  adding: training_datas/train_data26485.zip (stored 0%)\n",
            "  adding: training_datas/train_data12496.zip (stored 0%)\n",
            "  adding: training_datas/train_data11570.zip (stored 0%)\n",
            "  adding: training_datas/train_data8068.zip (stored 0%)\n",
            "  adding: training_datas/train_data5057.zip (stored 0%)\n",
            "  adding: training_datas/train_data12806.zip (stored 0%)\n",
            "  adding: training_datas/train_data1839.zip (stored 0%)\n",
            "  adding: training_datas/train_data4915.zip (stored 0%)\n",
            "  adding: training_datas/train_data16671.zip (stored 0%)\n",
            "  adding: training_datas/train_data17894.zip (stored 0%)\n",
            "  adding: training_datas/train_data4168.zip (stored 0%)\n",
            "  adding: training_datas/train_data12782.zip (stored 0%)\n",
            "  adding: training_datas/train_data18333.zip (stored 0%)\n",
            "  adding: training_datas/train_data26297.zip (stored 0%)\n",
            "  adding: training_datas/train_data15190.zip (stored 0%)\n",
            "  adding: training_datas/train_data17538.zip (stored 0%)\n",
            "  adding: training_datas/train_data6857.zip (stored 0%)\n",
            "  adding: training_datas/train_data13382.zip (stored 0%)\n",
            "  adding: training_datas/train_data22431.zip (stored 0%)\n",
            "  adding: training_datas/train_data16574.zip (stored 0%)\n",
            "  adding: training_datas/train_data30070.zip (stored 0%)\n",
            "  adding: training_datas/train_data25629.zip (stored 0%)\n",
            "  adding: training_datas/train_data29930.zip (stored 0%)\n",
            "  adding: training_datas/train_data1388.zip (stored 0%)\n",
            "  adding: training_datas/train_data5840.zip (stored 0%)\n",
            "  adding: training_datas/train_data13264.zip (stored 0%)\n",
            "  adding: training_datas/train_data12556.zip (stored 0%)\n",
            "  adding: training_datas/train_data26260.zip (stored 0%)\n",
            "  adding: training_datas/train_data19985.zip (stored 0%)\n",
            "  adding: training_datas/train_data5659.zip (stored 0%)\n",
            "  adding: training_datas/train_data20295.zip (stored 0%)\n",
            "  adding: training_datas/train_data2871.zip (stored 0%)\n",
            "  adding: training_datas/train_data16560.zip (stored 0%)\n",
            "  adding: training_datas/train_data16482.zip (stored 0%)\n",
            "  adding: training_datas/train_data26596.zip (stored 0%)\n",
            "  adding: training_datas/train_data18451.zip (stored 0%)\n",
            "  adding: training_datas/train_data1002.zip (stored 0%)\n",
            "  adding: training_datas/train_data4970.zip (stored 0%)\n",
            "  adding: training_datas/train_data21126.zip (stored 0%)\n",
            "  adding: training_datas/train_data11105.zip (stored 0%)\n",
            "  adding: training_datas/train_data3371.zip (stored 0%)\n",
            "  adding: training_datas/train_data14493.zip (stored 0%)\n",
            "  adding: training_datas/train_data28239.zip (stored 0%)\n",
            "  adding: training_datas/train_data30258.zip (stored 0%)\n",
            "  adding: training_datas/train_data18433.zip (stored 0%)\n",
            "  adding: training_datas/train_data3560.zip (stored 0%)\n",
            "  adding: training_datas/train_data19718.zip (stored 0%)\n",
            "  adding: training_datas/train_data14968.zip (stored 0%)\n",
            "  adding: training_datas/train_data30065.zip (stored 0%)\n",
            "  adding: training_datas/train_data250.zip (stored 0%)\n",
            "  adding: training_datas/train_data20502.zip (stored 0%)\n",
            "  adding: training_datas/train_data1290.zip (stored 0%)\n",
            "  adding: training_datas/train_data16513.zip (stored 0%)\n",
            "  adding: training_datas/train_data3677.zip (stored 0%)\n",
            "  adding: training_datas/train_data20641.zip (stored 0%)\n",
            "  adding: training_datas/train_data14526.zip (stored 0%)\n",
            "  adding: training_datas/train_data23243.zip (stored 0%)\n",
            "  adding: training_datas/train_data5231.zip (stored 0%)\n",
            "  adding: training_datas/train_data17540.zip (stored 0%)\n",
            "  adding: training_datas/train_data14644.zip (stored 0%)\n",
            "  adding: training_datas/train_data335.zip (stored 0%)\n",
            "  adding: training_datas/train_data17988.zip (stored 0%)\n",
            "  adding: training_datas/train_data5412.zip (stored 0%)\n",
            "  adding: training_datas/train_data29372.zip (stored 0%)\n",
            "  adding: training_datas/train_data20989.zip (stored 0%)\n",
            "  adding: training_datas/train_data11600.zip (stored 0%)\n",
            "  adding: training_datas/train_data11793.zip (stored 0%)\n",
            "  adding: training_datas/train_data3260.zip (stored 0%)\n",
            "  adding: training_datas/train_data10801.zip (stored 0%)\n",
            "  adding: training_datas/train_data22889.zip (stored 0%)\n",
            "  adding: training_datas/train_data13715.zip (stored 0%)\n",
            "  adding: training_datas/train_data9521.zip (stored 0%)\n",
            "  adding: training_datas/train_data2755.zip (stored 0%)\n",
            "  adding: training_datas/train_data29790.zip (stored 0%)\n",
            "  adding: training_datas/train_data14310.zip (stored 0%)\n",
            "  adding: training_datas/train_data5507.zip (stored 0%)\n",
            "  adding: training_datas/train_data22018.zip (stored 0%)\n",
            "  adding: training_datas/train_data7343.zip (stored 0%)\n",
            "  adding: training_datas/train_data22791.zip (stored 0%)\n",
            "  adding: training_datas/train_data19484.zip (stored 0%)\n",
            "  adding: training_datas/train_data18027.zip (stored 0%)\n",
            "  adding: training_datas/train_data14556.zip (stored 0%)\n",
            "  adding: training_datas/train_data16843.zip (stored 0%)\n",
            "  adding: training_datas/train_data19170.zip (stored 0%)\n",
            "  adding: training_datas/train_data29906.zip (stored 0%)\n",
            "  adding: training_datas/train_data26554.zip (stored 0%)\n",
            "  adding: training_datas/train_data13033.zip (stored 0%)\n",
            "  adding: training_datas/train_data1395.zip (stored 0%)\n",
            "  adding: training_datas/train_data12833.zip (stored 0%)\n",
            "  adding: training_datas/train_data69.zip (stored 0%)\n",
            "  adding: training_datas/train_data13670.zip (stored 0%)\n",
            "  adding: training_datas/train_data13373.zip (stored 0%)\n",
            "  adding: training_datas/train_data9286.zip (stored 0%)\n",
            "  adding: training_datas/train_data17141.zip (stored 0%)\n",
            "  adding: training_datas/train_data20773.zip (stored 0%)\n",
            "  adding: training_datas/train_data22350.zip (stored 0%)\n",
            "  adding: training_datas/train_data27209.zip (stored 0%)\n",
            "  adding: training_datas/train_data28575.zip (stored 0%)\n",
            "  adding: training_datas/train_data30128.zip (stored 0%)\n",
            "  adding: training_datas/train_data17789.zip (stored 0%)\n",
            "  adding: training_datas/train_data6937.zip (stored 0%)\n",
            "  adding: training_datas/train_data25121.zip (stored 0%)\n",
            "  adding: training_datas/train_data939.zip (stored 0%)\n",
            "  adding: training_datas/train_data16801.zip (stored 0%)\n",
            "  adding: training_datas/train_data27231.zip (stored 0%)\n",
            "  adding: training_datas/train_data23426.zip (stored 0%)\n",
            "  adding: training_datas/train_data24553.zip (stored 0%)\n",
            "  adding: training_datas/train_data1077.zip (stored 0%)\n",
            "  adding: training_datas/train_data2715.zip (stored 0%)\n",
            "  adding: training_datas/train_data12071.zip (stored 0%)\n",
            "  adding: training_datas/train_data8138.zip (stored 0%)\n",
            "  adding: training_datas/train_data11170.zip (stored 0%)\n",
            "  adding: training_datas/train_data4834.zip (stored 0%)\n",
            "  adding: training_datas/train_data24849.zip (stored 0%)\n",
            "  adding: training_datas/train_data24182.zip (stored 0%)\n",
            "  adding: training_datas/train_data17609.zip (stored 0%)\n",
            "  adding: training_datas/train_data2296.zip (stored 0%)\n",
            "  adding: training_datas/train_data4293.zip (stored 0%)\n",
            "  adding: training_datas/train_data14937.zip (stored 0%)\n",
            "  adding: training_datas/train_data11080.zip (stored 0%)\n",
            "  adding: training_datas/train_data807.zip (stored 0%)\n",
            "  adding: training_datas/train_data2383.zip (stored 0%)\n",
            "  adding: training_datas/train_data22983.zip (stored 0%)\n",
            "  adding: training_datas/train_data19079.zip (stored 0%)\n",
            "  adding: training_datas/train_data28955.zip (stored 0%)\n",
            "  adding: training_datas/train_data16145.zip (stored 0%)\n",
            "  adding: training_datas/train_data3443.zip (stored 0%)\n",
            "  adding: training_datas/train_data14549.zip (stored 0%)\n",
            "  adding: training_datas/train_data2603.zip (stored 0%)\n",
            "  adding: training_datas/train_data15155.zip (stored 0%)\n",
            "  adding: training_datas/train_data28489.zip (stored 0%)\n",
            "  adding: training_datas/train_data4783.zip (stored 0%)\n",
            "  adding: training_datas/train_data3251.zip (stored 0%)\n",
            "  adding: training_datas/train_data27061.zip (stored 0%)\n",
            "  adding: training_datas/train_data17707.zip (stored 0%)\n",
            "  adding: training_datas/train_data2403.zip (stored 0%)\n",
            "  adding: training_datas/train_data26588.zip (stored 0%)\n",
            "  adding: training_datas/train_data13903.zip (stored 0%)\n",
            "  adding: training_datas/train_data21952.zip (stored 0%)\n",
            "  adding: training_datas/train_data8590.zip (stored 0%)\n",
            "  adding: training_datas/train_data4689.zip (stored 0%)\n",
            "  adding: training_datas/train_data5674.zip (stored 0%)\n",
            "  adding: training_datas/train_data29857.zip (stored 0%)\n",
            "  adding: training_datas/train_data8519.zip (stored 0%)\n",
            "  adding: training_datas/train_data10621.zip (stored 0%)\n",
            "  adding: training_datas/train_data10640.zip (stored 0%)\n",
            "  adding: training_datas/train_data9913.zip (stored 0%)\n",
            "  adding: training_datas/train_data691.zip (stored 0%)\n",
            "  adding: training_datas/train_data20397.zip (stored 0%)\n",
            "  adding: training_datas/train_data17435.zip (stored 0%)\n",
            "  adding: training_datas/train_data165.zip (stored 0%)\n",
            "  adding: training_datas/train_data15087.zip (stored 0%)\n",
            "  adding: training_datas/train_data20797.zip (stored 0%)\n",
            "  adding: training_datas/train_data25376.zip (stored 0%)\n",
            "  adding: training_datas/train_data15361.zip (stored 0%)\n",
            "  adding: training_datas/train_data7310.zip (stored 0%)\n",
            "  adding: training_datas/train_data6064.zip (stored 0%)\n",
            "  adding: training_datas/train_data21891.zip (stored 0%)\n",
            "  adding: training_datas/train_data20541.zip (stored 0%)\n",
            "  adding: training_datas/train_data22810.zip (stored 0%)\n",
            "  adding: training_datas/train_data16676.zip (stored 0%)\n",
            "  adding: training_datas/train_data7854.zip (stored 0%)\n",
            "  adding: training_datas/train_data4730.zip (stored 0%)\n",
            "  adding: training_datas/train_data18817.zip (stored 0%)\n",
            "  adding: training_datas/train_data16410.zip (stored 0%)\n",
            "  adding: training_datas/train_data27979.zip (stored 0%)\n",
            "  adding: training_datas/train_data15521.zip (stored 0%)\n",
            "  adding: training_datas/train_data29713.zip (stored 0%)\n",
            "  adding: training_datas/train_data15138.zip (stored 0%)\n",
            "  adding: training_datas/train_data10231.zip (stored 0%)\n",
            "  adding: training_datas/train_data21066.zip (stored 0%)\n",
            "  adding: training_datas/train_data26357.zip (stored 0%)\n",
            "  adding: training_datas/train_data28702.zip (stored 0%)\n",
            "  adding: training_datas/train_data16403.zip (stored 0%)\n",
            "  adding: training_datas/train_data20318.zip (stored 0%)\n",
            "  adding: training_datas/train_data5878.zip (stored 0%)\n",
            "  adding: training_datas/train_data14955.zip (stored 0%)\n",
            "  adding: training_datas/train_data29662.zip (stored 0%)\n",
            "  adding: training_datas/train_data26437.zip (stored 0%)\n",
            "  adding: training_datas/train_data8330.zip (stored 0%)\n",
            "  adding: training_datas/train_data7103.zip (stored 0%)\n",
            "  adding: training_datas/train_data30453.zip (stored 0%)\n",
            "  adding: training_datas/train_data10753.zip (stored 0%)\n",
            "  adding: training_datas/train_data10106.zip (stored 0%)\n",
            "  adding: training_datas/train_data20429.zip (stored 0%)\n",
            "  adding: training_datas/train_data12070.zip (stored 0%)\n",
            "  adding: training_datas/train_data23211.zip (stored 0%)\n",
            "  adding: training_datas/train_data6602.zip (stored 0%)\n",
            "  adding: training_datas/train_data28.zip (stored 0%)\n",
            "  adding: training_datas/train_data10347.zip (stored 0%)\n",
            "  adding: training_datas/train_data22351.zip (stored 0%)\n",
            "  adding: training_datas/train_data20037.zip (stored 0%)\n",
            "  adding: training_datas/train_data22070.zip (stored 0%)\n",
            "  adding: training_datas/train_data6179.zip (stored 0%)\n",
            "  adding: training_datas/train_data3134.zip (stored 0%)\n",
            "  adding: training_datas/train_data21720.zip (stored 0%)\n",
            "  adding: training_datas/train_data22196.zip (stored 0%)\n",
            "  adding: training_datas/train_data2429.zip (stored 0%)\n",
            "  adding: training_datas/train_data23553.zip (stored 0%)\n",
            "  adding: training_datas/train_data28666.zip (stored 0%)\n",
            "  adding: training_datas/train_data27867.zip (stored 0%)\n",
            "  adding: training_datas/train_data468.zip (stored 0%)\n",
            "  adding: training_datas/train_data9987.zip (stored 0%)\n",
            "  adding: training_datas/train_data6164.zip (stored 0%)\n",
            "  adding: training_datas/train_data13253.zip (stored 0%)\n",
            "  adding: training_datas/train_data25615.zip (stored 0%)\n",
            "  adding: training_datas/train_data25055.zip (stored 0%)\n",
            "  adding: training_datas/train_data14141.zip (stored 0%)\n",
            "  adding: training_datas/train_data11295.zip (stored 0%)\n",
            "  adding: training_datas/train_data2550.zip (stored 0%)\n",
            "  adding: training_datas/train_data8069.zip (stored 0%)\n",
            "  adding: training_datas/train_data25377.zip (stored 0%)\n",
            "  adding: training_datas/train_data5993.zip (stored 0%)\n",
            "  adding: training_datas/train_data8477.zip (stored 0%)\n",
            "  adding: training_datas/train_data27059.zip (stored 0%)\n",
            "  adding: training_datas/train_data3471.zip (stored 0%)\n",
            "  adding: training_datas/train_data1347.zip (stored 0%)\n",
            "  adding: training_datas/train_data4933.zip (stored 0%)\n",
            "  adding: training_datas/train_data9560.zip (stored 0%)\n",
            "  adding: training_datas/train_data5094.zip (stored 0%)\n",
            "  adding: training_datas/train_data5135.zip (stored 0%)\n",
            "  adding: training_datas/train_data30172.zip (stored 0%)\n",
            "  adding: training_datas/train_data1479.zip (stored 0%)\n",
            "  adding: training_datas/train_data13947.zip (stored 0%)\n",
            "  adding: training_datas/train_data22416.zip (stored 0%)\n",
            "  adding: training_datas/train_data28113.zip (stored 0%)\n",
            "  adding: training_datas/train_data17299.zip (stored 0%)\n",
            "  adding: training_datas/train_data243.zip (stored 0%)\n",
            "  adding: training_datas/train_data9068.zip (stored 0%)\n",
            "  adding: training_datas/train_data2228.zip (stored 0%)\n",
            "  adding: training_datas/train_data30311.zip (stored 0%)\n",
            "  adding: training_datas/train_data3787.zip (stored 0%)\n",
            "  adding: training_datas/train_data26195.zip (stored 0%)\n",
            "  adding: training_datas/train_data12361.zip (stored 0%)\n",
            "  adding: training_datas/train_data9500.zip (stored 0%)\n",
            "  adding: training_datas/train_data16639.zip (stored 0%)\n",
            "  adding: training_datas/train_data5039.zip (stored 0%)\n",
            "  adding: training_datas/train_data14813.zip (stored 0%)\n",
            "  adding: training_datas/train_data22133.zip (stored 0%)\n",
            "  adding: training_datas/train_data4709.zip (stored 0%)\n",
            "  adding: training_datas/train_data19698.zip (stored 0%)\n",
            "  adding: training_datas/train_data4137.zip (stored 0%)\n",
            "  adding: training_datas/train_data17900.zip (stored 0%)\n",
            "  adding: training_datas/train_data17681.zip (stored 0%)\n",
            "  adding: training_datas/train_data20416.zip (stored 0%)\n",
            "  adding: training_datas/train_data20291.zip (stored 0%)\n",
            "  adding: training_datas/train_data14967.zip (stored 0%)\n",
            "  adding: training_datas/train_data28680.zip (stored 0%)\n",
            "  adding: training_datas/train_data18609.zip (stored 0%)\n",
            "  adding: training_datas/train_data18291.zip (stored 0%)\n",
            "  adding: training_datas/train_data17930.zip (stored 0%)\n",
            "  adding: training_datas/train_data17386.zip (stored 0%)\n",
            "  adding: training_datas/train_data25962.zip (stored 0%)\n",
            "  adding: training_datas/train_data15420.zip (stored 0%)\n",
            "  adding: training_datas/train_data13588.zip (stored 0%)\n",
            "  adding: training_datas/train_data9761.zip (stored 0%)\n",
            "  adding: training_datas/train_data19024.zip (stored 0%)\n",
            "  adding: training_datas/train_data21514.zip (stored 0%)\n",
            "  adding: training_datas/train_data4634.zip (stored 0%)\n",
            "  adding: training_datas/train_data20761.zip (stored 0%)\n",
            "  adding: training_datas/train_data2849.zip (stored 0%)\n",
            "  adding: training_datas/train_data9049.zip (stored 0%)\n",
            "  adding: training_datas/train_data13422.zip (stored 0%)\n",
            "  adding: training_datas/train_data26976.zip (stored 0%)\n",
            "  adding: training_datas/train_data30217.zip (stored 0%)\n",
            "  adding: training_datas/train_data18829.zip (stored 0%)\n",
            "  adding: training_datas/train_data1194.zip (stored 0%)\n",
            "  adding: training_datas/train_data22253.zip (stored 0%)\n",
            "  adding: training_datas/train_data2462.zip (stored 0%)\n",
            "  adding: training_datas/train_data6344.zip (stored 0%)\n",
            "  adding: training_datas/train_data759.zip (stored 0%)\n",
            "  adding: training_datas/train_data23377.zip (stored 0%)\n",
            "  adding: training_datas/train_data16016.zip (stored 0%)\n",
            "  adding: training_datas/train_data20000.zip (stored 0%)\n",
            "  adding: training_datas/train_data14017.zip (stored 0%)\n",
            "  adding: training_datas/train_data18145.zip (stored 0%)\n",
            "  adding: training_datas/train_data27018.zip (stored 0%)\n",
            "  adding: training_datas/train_data111.zip (stored 0%)\n",
            "  adding: training_datas/train_data5772.zip (stored 0%)\n",
            "  adding: training_datas/train_data1475.zip (stored 0%)\n",
            "  adding: training_datas/train_data953.zip (stored 0%)\n",
            "  adding: training_datas/train_data21892.zip (stored 0%)\n",
            "  adding: training_datas/train_data6774.zip (stored 0%)\n",
            "  adding: training_datas/train_data4790.zip (stored 0%)\n",
            "  adding: training_datas/train_data24646.zip (stored 0%)\n",
            "  adding: training_datas/train_data16626.zip (stored 0%)\n",
            "  adding: training_datas/train_data4475.zip (stored 0%)\n",
            "  adding: training_datas/train_data24525.zip (stored 0%)\n",
            "  adding: training_datas/train_data28803.zip (stored 0%)\n",
            "  adding: training_datas/train_data14171.zip (stored 0%)\n",
            "  adding: training_datas/train_data15883.zip (stored 0%)\n",
            "  adding: training_datas/train_data22181.zip (stored 0%)\n",
            "  adding: training_datas/train_data28020.zip (stored 0%)\n",
            "  adding: training_datas/train_data12995.zip (stored 0%)\n",
            "  adding: training_datas/train_data4628.zip (stored 0%)\n",
            "  adding: training_datas/train_data28387.zip (stored 0%)\n",
            "  adding: training_datas/train_data310.zip (stored 0%)\n",
            "  adding: training_datas/train_data30004.zip (stored 0%)\n",
            "  adding: training_datas/train_data1238.zip (stored 0%)\n",
            "  adding: training_datas/train_data8811.zip (stored 0%)\n",
            "  adding: training_datas/train_data15975.zip (stored 0%)\n",
            "  adding: training_datas/train_data370.zip (stored 0%)\n",
            "  adding: training_datas/train_data12325.zip (stored 0%)\n",
            "  adding: training_datas/train_data5305.zip (stored 0%)\n",
            "  adding: training_datas/train_data13796.zip (stored 0%)\n",
            "  adding: training_datas/train_data14938.zip (stored 0%)\n",
            "  adding: training_datas/train_data18256.zip (stored 0%)\n",
            "  adding: training_datas/train_data29239.zip (stored 0%)\n",
            "  adding: training_datas/train_data30480.zip (stored 0%)\n",
            "  adding: training_datas/train_data13213.zip (stored 0%)\n",
            "  adding: training_datas/train_data7114.zip (stored 0%)\n",
            "  adding: training_datas/train_data20663.zip (stored 0%)\n",
            "  adding: training_datas/train_data4751.zip (stored 0%)\n",
            "  adding: training_datas/train_data26781.zip (stored 0%)\n",
            "  adding: training_datas/train_data25620.zip (stored 0%)\n",
            "  adding: training_datas/train_data20677.zip (stored 0%)\n",
            "  adding: training_datas/train_data25170.zip (stored 0%)\n",
            "  adding: training_datas/train_data2765.zip (stored 0%)\n",
            "  adding: training_datas/train_data17451.zip (stored 0%)\n",
            "  adding: training_datas/train_data23764.zip (stored 0%)\n",
            "  adding: training_datas/train_data29269.zip (stored 0%)\n",
            "  adding: training_datas/train_data25043.zip (stored 0%)\n",
            "  adding: training_datas/train_data18230.zip (stored 0%)\n",
            "  adding: training_datas/train_data16041.zip (stored 0%)\n",
            "  adding: training_datas/train_data8358.zip (stored 0%)\n",
            "  adding: training_datas/train_data4565.zip (stored 0%)\n",
            "  adding: training_datas/train_data4230.zip (stored 0%)\n",
            "  adding: training_datas/train_data28751.zip (stored 0%)\n",
            "  adding: training_datas/train_data13990.zip (stored 0%)\n",
            "  adding: training_datas/train_data20783.zip (stored 0%)\n",
            "  adding: training_datas/train_data24388.zip (stored 0%)\n",
            "  adding: training_datas/train_data27190.zip (stored 0%)\n",
            "  adding: training_datas/train_data30179.zip (stored 0%)\n",
            "  adding: training_datas/train_data10255.zip (stored 0%)\n",
            "  adding: training_datas/train_data2637.zip (stored 0%)\n",
            "  adding: training_datas/train_data5070.zip (stored 0%)\n",
            "  adding: training_datas/train_data30182.zip (stored 0%)\n",
            "  adding: training_datas/train_data11239.zip (stored 0%)\n",
            "  adding: training_datas/train_data22046.zip (stored 0%)\n",
            "  adding: training_datas/train_data8621.zip (stored 0%)\n",
            "  adding: training_datas/train_data28578.zip (stored 0%)\n",
            "  adding: training_datas/train_data16191.zip (stored 0%)\n",
            "  adding: training_datas/train_data29639.zip (stored 0%)\n",
            "  adding: training_datas/train_data26908.zip (stored 0%)\n",
            "  adding: training_datas/train_data8541.zip (stored 0%)\n",
            "  adding: training_datas/train_data11463.zip (stored 0%)\n",
            "  adding: training_datas/train_data196.zip (stored 0%)\n",
            "  adding: training_datas/train_data17652.zip (stored 0%)\n",
            "  adding: training_datas/train_data8496.zip (stored 0%)\n",
            "  adding: training_datas/train_data9856.zip (stored 0%)\n",
            "  adding: training_datas/train_data26444.zip (stored 0%)\n",
            "  adding: training_datas/train_data8917.zip (stored 0%)\n",
            "  adding: training_datas/train_data11350.zip (stored 0%)\n",
            "  adding: training_datas/train_data8119.zip (stored 0%)\n",
            "  adding: training_datas/train_data27577.zip (stored 0%)\n",
            "  adding: training_datas/train_data28280.zip (stored 0%)\n",
            "  adding: training_datas/train_data24956.zip (stored 0%)\n",
            "  adding: training_datas/train_data1419.zip (stored 0%)\n",
            "  adding: training_datas/train_data22559.zip (stored 0%)\n",
            "  adding: training_datas/train_data28206.zip (stored 0%)\n",
            "  adding: training_datas/train_data14502.zip (stored 0%)\n",
            "  adding: training_datas/train_data12638.zip (stored 0%)\n",
            "  adding: training_datas/train_data6656.zip (stored 0%)\n",
            "  adding: training_datas/train_data7542.zip (stored 0%)\n",
            "  adding: training_datas/train_data9829.zip (stored 0%)\n",
            "  adding: training_datas/train_data11511.zip (stored 0%)\n",
            "  adding: training_datas/train_data23292.zip (stored 0%)\n",
            "  adding: training_datas/train_data18691.zip (stored 0%)\n",
            "  adding: training_datas/train_data28389.zip (stored 0%)\n",
            "  adding: training_datas/train_data3933.zip (stored 0%)\n",
            "  adding: training_datas/train_data8482.zip (stored 0%)\n",
            "  adding: training_datas/train_data22248.zip (stored 0%)\n",
            "  adding: training_datas/train_data17162.zip (stored 0%)\n",
            "  adding: training_datas/train_data10453.zip (stored 0%)\n",
            "  adding: training_datas/train_data28518.zip (stored 0%)\n",
            "  adding: training_datas/train_data24848.zip (stored 0%)\n",
            "  adding: training_datas/train_data2875.zip (stored 0%)\n",
            "  adding: training_datas/train_data21084.zip (stored 0%)\n",
            "  adding: training_datas/train_data8031.zip (stored 0%)\n",
            "  adding: training_datas/train_data28177.zip (stored 0%)\n",
            "  adding: training_datas/train_data10592.zip (stored 0%)\n",
            "  adding: training_datas/train_data20021.zip (stored 0%)\n",
            "  adding: training_datas/train_data16617.zip (stored 0%)\n",
            "  adding: training_datas/train_data18154.zip (stored 0%)\n",
            "  adding: training_datas/train_data1550.zip (stored 0%)\n",
            "  adding: training_datas/train_data900.zip (stored 0%)\n",
            "  adding: training_datas/train_data8074.zip (stored 0%)\n",
            "  adding: training_datas/train_data20706.zip (stored 0%)\n",
            "  adding: training_datas/train_data6203.zip (stored 0%)\n",
            "  adding: training_datas/train_data17898.zip (stored 0%)\n",
            "  adding: training_datas/train_data28775.zip (stored 0%)\n",
            "  adding: training_datas/train_data17099.zip (stored 0%)\n",
            "  adding: training_datas/train_data28084.zip (stored 0%)\n",
            "  adding: training_datas/train_data7749.zip (stored 0%)\n",
            "  adding: training_datas/train_data3690.zip (stored 0%)\n",
            "  adding: training_datas/train_data11634.zip (stored 0%)\n",
            "  adding: training_datas/train_data17572.zip (stored 0%)\n",
            "  adding: training_datas/train_data27767.zip (stored 0%)\n",
            "  adding: training_datas/train_data22671.zip (stored 0%)\n",
            "  adding: training_datas/train_data18162.zip (stored 0%)\n",
            "  adding: training_datas/train_data29654.zip (stored 0%)\n",
            "  adding: training_datas/train_data11886.zip (stored 0%)\n",
            "  adding: training_datas/train_data1084.zip (stored 0%)\n",
            "  adding: training_datas/train_data8587.zip (stored 0%)\n",
            "  adding: training_datas/train_data3286.zip (stored 0%)\n",
            "  adding: training_datas/train_data23736.zip (stored 0%)\n",
            "  adding: training_datas/train_data12194.zip (stored 0%)\n",
            "  adding: training_datas/train_data9817.zip (stored 0%)\n",
            "  adding: training_datas/train_data3766.zip (stored 0%)\n",
            "  adding: training_datas/train_data1953.zip (stored 0%)\n",
            "  adding: training_datas/train_data27563.zip (stored 0%)\n",
            "  adding: training_datas/train_data12198.zip (stored 0%)\n",
            "  adding: training_datas/train_data26362.zip (stored 0%)\n",
            "  adding: training_datas/train_data29982.zip (stored 0%)\n",
            "  adding: training_datas/train_data29643.zip (stored 0%)\n",
            "  adding: training_datas/train_data21135.zip (stored 0%)\n",
            "  adding: training_datas/train_data15214.zip (stored 0%)\n",
            "  adding: training_datas/train_data11100.zip (stored 0%)\n",
            "  adding: training_datas/train_data16387.zip (stored 0%)\n",
            "  adding: training_datas/train_data14334.zip (stored 0%)\n",
            "  adding: training_datas/train_data23662.zip (stored 0%)\n",
            "  adding: training_datas/train_data30387.zip (stored 0%)\n",
            "  adding: training_datas/train_data7511.zip (stored 0%)\n",
            "  adding: training_datas/train_data19023.zip (stored 0%)\n",
            "  adding: training_datas/train_data12617.zip (stored 0%)\n",
            "  adding: training_datas/train_data4617.zip (stored 0%)\n",
            "  adding: training_datas/train_data5714.zip (stored 0%)\n",
            "  adding: training_datas/train_data16152.zip (stored 0%)\n",
            "  adding: training_datas/train_data796.zip (stored 0%)\n",
            "  adding: training_datas/train_data25764.zip (stored 0%)\n",
            "  adding: training_datas/train_data12164.zip (stored 0%)\n",
            "  adding: training_datas/train_data28225.zip (stored 0%)\n",
            "  adding: training_datas/train_data12482.zip (stored 0%)\n",
            "  adding: training_datas/train_data20248.zip (stored 0%)\n",
            "  adding: training_datas/train_data12268.zip (stored 0%)\n",
            "  adding: training_datas/train_data22703.zip (stored 0%)\n",
            "  adding: training_datas/train_data16223.zip (stored 0%)\n",
            "  adding: training_datas/train_data27139.zip (stored 0%)\n",
            "  adding: training_datas/train_data6746.zip (stored 0%)\n",
            "  adding: training_datas/train_data22642.zip (stored 0%)\n",
            "  adding: training_datas/train_data14387.zip (stored 0%)\n",
            "  adding: training_datas/train_data13726.zip (stored 0%)\n",
            "  adding: training_datas/train_data24048.zip (stored 0%)\n",
            "  adding: training_datas/train_data16052.zip (stored 0%)\n",
            "  adding: training_datas/train_data14733.zip (stored 0%)\n",
            "  adding: training_datas/train_data27319.zip (stored 0%)\n",
            "  adding: training_datas/train_data770.zip (stored 0%)\n",
            "  adding: training_datas/train_data30329.zip (stored 0%)\n",
            "  adding: training_datas/train_data22960.zip (stored 0%)\n",
            "  adding: training_datas/train_data13803.zip (stored 0%)\n",
            "  adding: training_datas/train_data13882.zip (stored 0%)\n",
            "  adding: training_datas/train_data18046.zip (stored 0%)\n",
            "  adding: training_datas/train_data7077.zip (stored 0%)\n",
            "  adding: training_datas/train_data21648.zip (stored 0%)\n",
            "  adding: training_datas/train_data27035.zip (stored 0%)\n",
            "  adding: training_datas/train_data29255.zip (stored 0%)\n",
            "  adding: training_datas/train_data30424.zip (stored 0%)\n",
            "  adding: training_datas/train_data5860.zip (stored 0%)\n",
            "  adding: training_datas/train_data13197.zip (stored 0%)\n",
            "  adding: training_datas/train_data6958.zip (stored 0%)\n",
            "  adding: training_datas/train_data11867.zip (stored 0%)\n",
            "  adding: training_datas/train_data1331.zip (stored 0%)\n",
            "  adding: training_datas/train_data12126.zip (stored 0%)\n",
            "  adding: training_datas/train_data7198.zip (stored 0%)\n",
            "  adding: training_datas/train_data11723.zip (stored 0%)\n",
            "  adding: training_datas/train_data24140.zip (stored 0%)\n",
            "  adding: training_datas/train_data20285.zip (stored 0%)\n",
            "  adding: training_datas/train_data13051.zip (stored 0%)\n",
            "  adding: training_datas/train_data26972.zip (stored 0%)\n",
            "  adding: training_datas/train_data9924.zip (stored 0%)\n",
            "  adding: training_datas/train_data12684.zip (stored 0%)\n",
            "  adding: training_datas/train_data1294.zip (stored 0%)\n",
            "  adding: training_datas/train_data27303.zip (stored 0%)\n",
            "  adding: training_datas/train_data9480.zip (stored 0%)\n",
            "  adding: training_datas/train_data24359.zip (stored 0%)\n",
            "  adding: training_datas/train_data24577.zip (stored 0%)\n",
            "  adding: training_datas/train_data18279.zip (stored 0%)\n",
            "  adding: training_datas/train_data10172.zip (stored 0%)\n",
            "  adding: training_datas/train_data11220.zip (stored 0%)\n",
            "  adding: training_datas/train_data6200.zip (stored 0%)\n",
            "  adding: training_datas/train_data20288.zip (stored 0%)\n",
            "  adding: training_datas/train_data17616.zip (stored 0%)\n",
            "  adding: training_datas/train_data9670.zip (stored 0%)\n",
            "  adding: training_datas/train_data9750.zip (stored 0%)\n",
            "  adding: training_datas/train_data9803.zip (stored 0%)\n",
            "  adding: training_datas/train_data6543.zip (stored 0%)\n",
            "  adding: training_datas/train_data12342.zip (stored 0%)\n",
            "  adding: training_datas/train_data22635.zip (stored 0%)\n",
            "  adding: training_datas/train_data29349.zip (stored 0%)\n",
            "  adding: training_datas/train_data14565.zip (stored 0%)\n",
            "  adding: training_datas/train_data67.zip (stored 0%)\n",
            "  adding: training_datas/train_data26006.zip (stored 0%)\n",
            "  adding: training_datas/train_data3907.zip (stored 0%)\n",
            "  adding: training_datas/train_data25024.zip (stored 0%)\n",
            "  adding: training_datas/train_data2038.zip (stored 0%)\n",
            "  adding: training_datas/train_data23487.zip (stored 0%)\n",
            "  adding: training_datas/train_data22096.zip (stored 0%)\n",
            "  adding: training_datas/train_data20323.zip (stored 0%)\n",
            "  adding: training_datas/train_data1094.zip (stored 0%)\n",
            "  adding: training_datas/train_data14997.zip (stored 0%)\n",
            "  adding: training_datas/train_data9722.zip (stored 0%)\n",
            "  adding: training_datas/train_data28079.zip (stored 0%)\n",
            "  adding: training_datas/train_data1777.zip (stored 0%)\n",
            "  adding: training_datas/train_data653.zip (stored 0%)\n",
            "  adding: training_datas/train_data14434.zip (stored 0%)\n",
            "  adding: training_datas/train_data13683.zip (stored 0%)\n",
            "  adding: training_datas/train_data12272.zip (stored 0%)\n",
            "  adding: training_datas/train_data12603.zip (stored 0%)\n",
            "  adding: training_datas/train_data18504.zip (stored 0%)\n",
            "  adding: training_datas/train_data29214.zip (stored 0%)\n",
            "  adding: training_datas/train_data5211.zip (stored 0%)\n",
            "  adding: training_datas/train_data14321.zip (stored 0%)\n",
            "  adding: training_datas/train_data789.zip (stored 0%)\n",
            "  adding: training_datas/train_data25743.zip (stored 0%)\n",
            "  adding: training_datas/train_data6873.zip (stored 0%)\n",
            "  adding: training_datas/train_data27341.zip (stored 0%)\n",
            "  adding: training_datas/train_data10554.zip (stored 0%)\n",
            "  adding: training_datas/train_data30054.zip (stored 0%)\n",
            "  adding: training_datas/train_data12955.zip (stored 0%)\n",
            "  adding: training_datas/train_data15884.zip (stored 0%)\n",
            "  adding: training_datas/train_data14095.zip (stored 0%)\n",
            "  adding: training_datas/train_data17067.zip (stored 0%)\n",
            "  adding: training_datas/train_data1504.zip (stored 0%)\n",
            "  adding: training_datas/train_data8357.zip (stored 0%)\n",
            "  adding: training_datas/train_data28530.zip (stored 0%)\n",
            "  adding: training_datas/train_data29367.zip (stored 0%)\n",
            "  adding: training_datas/train_data6418.zip (stored 0%)\n",
            "  adding: training_datas/train_data24161.zip (stored 0%)\n",
            "  adding: training_datas/train_data3301.zip (stored 0%)\n",
            "  adding: training_datas/train_data27873.zip (stored 0%)\n",
            "  adding: training_datas/train_data29744.zip (stored 0%)\n",
            "  adding: training_datas/train_data13088.zip (stored 0%)\n",
            "  adding: training_datas/train_data27947.zip (stored 0%)\n",
            "  adding: training_datas/train_data21595.zip (stored 0%)\n",
            "  adding: training_datas/train_data19222.zip (stored 0%)\n",
            "  adding: training_datas/train_data2988.zip (stored 0%)\n",
            "  adding: training_datas/train_data4108.zip (stored 0%)\n",
            "  adding: training_datas/train_data23993.zip (stored 0%)\n",
            "  adding: training_datas/train_data19845.zip (stored 0%)\n",
            "  adding: training_datas/train_data2283.zip (stored 0%)\n",
            "  adding: training_datas/train_data10558.zip (stored 0%)\n",
            "  adding: training_datas/train_data9795.zip (stored 0%)\n",
            "  adding: training_datas/train_data25818.zip (stored 0%)\n",
            "  adding: training_datas/train_data26811.zip (stored 0%)\n",
            "  adding: training_datas/train_data8352.zip (stored 0%)\n",
            "  adding: training_datas/train_data4952.zip (stored 0%)\n",
            "  adding: training_datas/train_data22873.zip (stored 0%)\n",
            "  adding: training_datas/train_data12605.zip (stored 0%)\n",
            "  adding: training_datas/train_data21876.zip (stored 0%)\n",
            "  adding: training_datas/train_data19036.zip (stored 0%)\n",
            "  adding: training_datas/train_data26586.zip (stored 0%)\n",
            "  adding: training_datas/train_data28123.zip (stored 0%)\n",
            "  adding: training_datas/train_data14609.zip (stored 0%)\n",
            "  adding: training_datas/train_data11408.zip (stored 0%)\n",
            "  adding: training_datas/train_data30251.zip (stored 0%)\n",
            "  adding: training_datas/train_data25611.zip (stored 0%)\n",
            "  adding: training_datas/train_data24227.zip (stored 0%)\n",
            "  adding: training_datas/train_data10393.zip (stored 0%)\n",
            "  adding: training_datas/train_data2654.zip (stored 0%)\n",
            "  adding: training_datas/train_data22199.zip (stored 0%)\n",
            "  adding: training_datas/train_data26681.zip (stored 0%)\n",
            "  adding: training_datas/train_data26974.zip (stored 0%)\n",
            "  adding: training_datas/train_data20586.zip (stored 0%)\n",
            "  adding: training_datas/train_data11623.zip (stored 0%)\n",
            "  adding: training_datas/train_data16127.zip (stored 0%)\n",
            "  adding: training_datas/train_data23378.zip (stored 0%)\n",
            "  adding: training_datas/train_data29291.zip (stored 0%)\n",
            "  adding: training_datas/train_data16966.zip (stored 0%)\n",
            "  adding: training_datas/train_data27304.zip (stored 0%)\n",
            "  adding: training_datas/train_data9228.zip (stored 0%)\n",
            "  adding: training_datas/train_data16382.zip (stored 0%)\n",
            "  adding: training_datas/train_data21197.zip (stored 0%)\n",
            "  adding: training_datas/train_data2234.zip (stored 0%)\n",
            "  adding: training_datas/train_data16172.zip (stored 0%)\n",
            "  adding: training_datas/train_data4222.zip (stored 0%)\n",
            "  adding: training_datas/train_data21786.zip (stored 0%)\n",
            "  adding: training_datas/train_data7526.zip (stored 0%)\n",
            "  adding: training_datas/train_data12957.zip (stored 0%)\n",
            "  adding: training_datas/train_data10422.zip (stored 0%)\n",
            "  adding: training_datas/train_data14312.zip (stored 0%)\n",
            "  adding: training_datas/train_data15618.zip (stored 0%)\n",
            "  adding: training_datas/train_data9723.zip (stored 0%)\n",
            "  adding: training_datas/train_data1655.zip (stored 0%)\n",
            "  adding: training_datas/train_data6485.zip (stored 0%)\n",
            "  adding: training_datas/train_data2394.zip (stored 0%)\n",
            "  adding: training_datas/train_data2572.zip (stored 0%)\n",
            "  adding: training_datas/train_data21250.zip (stored 0%)\n",
            "  adding: training_datas/train_data16882.zip (stored 0%)\n",
            "  adding: training_datas/train_data23609.zip (stored 0%)\n",
            "  adding: training_datas/train_data10546.zip (stored 0%)\n",
            "  adding: training_datas/train_data16539.zip (stored 0%)\n",
            "  adding: training_datas/train_data2133.zip (stored 0%)\n",
            "  adding: training_datas/train_data24152.zip (stored 0%)\n",
            "  adding: training_datas/train_data3713.zip (stored 0%)\n",
            "  adding: training_datas/train_data1712.zip (stored 0%)\n",
            "  adding: training_datas/train_data30322.zip (stored 0%)\n",
            "  adding: training_datas/train_data19530.zip (stored 0%)\n",
            "  adding: training_datas/train_data9484.zip (stored 0%)\n",
            "  adding: training_datas/train_data4097.zip (stored 0%)\n",
            "  adding: training_datas/train_data4744.zip (stored 0%)\n",
            "  adding: training_datas/train_data9599.zip (stored 0%)\n",
            "  adding: training_datas/train_data16222.zip (stored 0%)\n",
            "  adding: training_datas/train_data21292.zip (stored 0%)\n",
            "  adding: training_datas/train_data22187.zip (stored 0%)\n",
            "  adding: training_datas/train_data16218.zip (stored 0%)\n",
            "  adding: training_datas/train_data28254.zip (stored 0%)\n",
            "  adding: training_datas/train_data14107.zip (stored 0%)\n",
            "  adding: training_datas/train_data28393.zip (stored 0%)\n",
            "  adding: training_datas/train_data13412.zip (stored 0%)\n",
            "  adding: training_datas/train_data26121.zip (stored 0%)\n",
            "  adding: training_datas/train_data18756.zip (stored 0%)\n",
            "  adding: training_datas/train_data26330.zip (stored 0%)\n",
            "  adding: training_datas/train_data13103.zip (stored 0%)\n",
            "  adding: training_datas/train_data14343.zip (stored 0%)\n",
            "  adding: training_datas/train_data24081.zip (stored 0%)\n",
            "  adding: training_datas/train_data28599.zip (stored 0%)\n",
            "  adding: training_datas/train_data11362.zip (stored 0%)\n",
            "  adding: training_datas/train_data15859.zip (stored 0%)\n",
            "  adding: training_datas/train_data6032.zip (stored 0%)\n",
            "  adding: training_datas/train_data27919.zip (stored 0%)\n",
            "  adding: training_datas/train_data26877.zip (stored 0%)\n",
            "  adding: training_datas/train_data7742.zip (stored 0%)\n",
            "  adding: training_datas/train_data18909.zip (stored 0%)\n",
            "  adding: training_datas/train_data29224.zip (stored 0%)\n",
            "  adding: training_datas/train_data9149.zip (stored 0%)\n",
            "  adding: training_datas/train_data14620.zip (stored 0%)\n",
            "  adding: training_datas/train_data20023.zip (stored 0%)\n",
            "  adding: training_datas/train_data3472.zip (stored 0%)\n",
            "  adding: training_datas/train_data3932.zip (stored 0%)\n",
            "  adding: training_datas/train_data18082.zip (stored 0%)\n",
            "  adding: training_datas/train_data20375.zip (stored 0%)\n",
            "  adding: training_datas/train_data30045.zip (stored 0%)\n",
            "  adding: training_datas/train_data6145.zip (stored 0%)\n",
            "  adding: training_datas/train_data15128.zip (stored 0%)\n",
            "  adding: training_datas/train_data10427.zip (stored 0%)\n",
            "  adding: training_datas/train_data19889.zip (stored 0%)\n",
            "  adding: training_datas/train_data22290.zip (stored 0%)\n",
            "  adding: training_datas/train_data1703.zip (stored 0%)\n",
            "  adding: training_datas/train_data23018.zip (stored 0%)\n",
            "  adding: training_datas/train_data2763.zip (stored 0%)\n",
            "  adding: training_datas/train_data20102.zip (stored 0%)\n",
            "  adding: training_datas/train_data956.zip (stored 0%)\n",
            "  adding: training_datas/train_data19580.zip (stored 0%)\n",
            "  adding: training_datas/train_data5177.zip (stored 0%)\n",
            "  adding: training_datas/train_data20153.zip (stored 0%)\n",
            "  adding: training_datas/train_data13825.zip (stored 0%)\n",
            "  adding: training_datas/train_data21222.zip (stored 0%)\n",
            "  adding: training_datas/train_data15538.zip (stored 0%)\n",
            "  adding: training_datas/train_data4909.zip (stored 0%)\n",
            "  adding: training_datas/train_data13907.zip (stored 0%)\n",
            "  adding: training_datas/train_data27862.zip (stored 0%)\n",
            "  adding: training_datas/train_data21675.zip (stored 0%)\n",
            "  adding: training_datas/train_data1732.zip (stored 0%)\n",
            "  adding: training_datas/train_data23539.zip (stored 0%)\n",
            "  adding: training_datas/train_data18497.zip (stored 0%)\n",
            "  adding: training_datas/train_data16209.zip (stored 0%)\n",
            "  adding: training_datas/train_data15527.zip (stored 0%)\n",
            "  adding: training_datas/train_data18431.zip (stored 0%)\n",
            "  adding: training_datas/train_data14471.zip (stored 0%)\n",
            "  adding: training_datas/train_data7640.zip (stored 0%)\n",
            "  adding: training_datas/train_data1365.zip (stored 0%)\n",
            "  adding: training_datas/train_data23122.zip (stored 0%)\n",
            "  adding: training_datas/train_data13784.zip (stored 0%)\n",
            "  adding: training_datas/train_data20801.zip (stored 0%)\n",
            "  adding: training_datas/train_data14985.zip (stored 0%)\n",
            "  adding: training_datas/train_data10323.zip (stored 0%)\n",
            "  adding: training_datas/train_data20355.zip (stored 0%)\n",
            "  adding: training_datas/train_data2663.zip (stored 0%)\n",
            "  adding: training_datas/train_data6492.zip (stored 0%)\n",
            "  adding: training_datas/train_data15444.zip (stored 0%)\n",
            "  adding: training_datas/train_data11376.zip (stored 0%)\n",
            "  adding: training_datas/train_data14708.zip (stored 0%)\n",
            "  adding: training_datas/train_data12885.zip (stored 0%)\n",
            "  adding: training_datas/train_data8793.zip (stored 0%)\n",
            "  adding: training_datas/train_data18987.zip (stored 0%)\n",
            "  adding: training_datas/train_data18870.zip (stored 0%)\n",
            "  adding: training_datas/train_data13385.zip (stored 0%)\n",
            "  adding: training_datas/train_data24629.zip (stored 0%)\n",
            "  adding: training_datas/train_data1120.zip (stored 0%)\n",
            "  adding: training_datas/train_data3979.zip (stored 0%)\n",
            "  adding: training_datas/train_data21847.zip (stored 0%)\n",
            "  adding: training_datas/train_data24051.zip (stored 0%)\n",
            "  adding: training_datas/train_data4039.zip (stored 0%)\n",
            "  adding: training_datas/train_data27006.zip (stored 0%)\n",
            "  adding: training_datas/train_data18610.zip (stored 0%)\n",
            "  adding: training_datas/train_data10584.zip (stored 0%)\n",
            "  adding: training_datas/train_data21737.zip (stored 0%)\n",
            "  adding: training_datas/train_data20610.zip (stored 0%)\n",
            "  adding: training_datas/train_data3870.zip (stored 0%)\n",
            "  adding: training_datas/train_data8098.zip (stored 0%)\n",
            "  adding: training_datas/train_data18720.zip (stored 0%)\n",
            "  adding: training_datas/train_data16497.zip (stored 0%)\n",
            "  adding: training_datas/train_data21412.zip (stored 0%)\n",
            "  adding: training_datas/train_data3296.zip (stored 0%)\n",
            "  adding: training_datas/train_data1957.zip (stored 0%)\n",
            "  adding: training_datas/train_data3101.zip (stored 0%)\n",
            "  adding: training_datas/train_data6310.zip (stored 0%)\n",
            "  adding: training_datas/train_data24109.zip (stored 0%)\n",
            "  adding: training_datas/train_data537.zip (stored 0%)\n",
            "  adding: training_datas/train_data3105.zip (stored 0%)\n",
            "  adding: training_datas/train_data8678.zip (stored 0%)\n",
            "  adding: training_datas/train_data1362.zip (stored 0%)\n",
            "  adding: training_datas/train_data24589.zip (stored 0%)\n",
            "  adding: training_datas/train_data6868.zip (stored 0%)\n",
            "  adding: training_datas/train_data25877.zip (stored 0%)\n",
            "  adding: training_datas/train_data10271.zip (stored 0%)\n",
            "  adding: training_datas/train_data9013.zip (stored 0%)\n",
            "  adding: training_datas/train_data30328.zip (stored 0%)\n",
            "  adding: training_datas/train_data18666.zip (stored 0%)\n",
            "  adding: training_datas/train_data7935.zip (stored 0%)\n",
            "  adding: training_datas/train_data11555.zip (stored 0%)\n",
            "  adding: training_datas/train_data2065.zip (stored 0%)\n",
            "  adding: training_datas/train_data16647.zip (stored 0%)\n",
            "  adding: training_datas/train_data15949.zip (stored 0%)\n",
            "  adding: training_datas/train_data27691.zip (stored 0%)\n",
            "  adding: training_datas/train_data23927.zip (stored 0%)\n",
            "  adding: training_datas/train_data28756.zip (stored 0%)\n",
            "  adding: training_datas/train_data29102.zip (stored 0%)\n",
            "  adding: training_datas/train_data24248.zip (stored 0%)\n",
            "  adding: training_datas/train_data25899.zip (stored 0%)\n",
            "  adding: training_datas/train_data20658.zip (stored 0%)\n",
            "  adding: training_datas/train_data9682.zip (stored 0%)\n",
            "  adding: training_datas/train_data23541.zip (stored 0%)\n",
            "  adding: training_datas/train_data17110.zip (stored 0%)\n",
            "  adding: training_datas/train_data218.zip (stored 0%)\n",
            "  adding: training_datas/train_data17595.zip (stored 0%)\n",
            "  adding: training_datas/train_data18510.zip (stored 0%)\n",
            "  adding: training_datas/train_data1417.zip (stored 0%)\n",
            "  adding: training_datas/train_data714.zip (stored 0%)\n",
            "  adding: training_datas/train_data18185.zip (stored 0%)\n",
            "  adding: training_datas/train_data27536.zip (stored 0%)\n",
            "  adding: training_datas/train_data12459.zip (stored 0%)\n",
            "  adding: training_datas/train_data14617.zip (stored 0%)\n",
            "  adding: training_datas/train_data15654.zip (stored 0%)\n",
            "  adding: training_datas/train_data1997.zip (stored 0%)\n",
            "  adding: training_datas/train_data19240.zip (stored 0%)\n",
            "  adding: training_datas/train_data23628.zip (stored 0%)\n",
            "  adding: training_datas/train_data16987.zip (stored 0%)\n",
            "  adding: training_datas/train_data8898.zip (stored 0%)\n",
            "  adding: training_datas/train_data5650.zip (stored 0%)\n",
            "  adding: training_datas/train_data12584.zip (stored 0%)\n",
            "  adding: training_datas/train_data10070.zip (stored 0%)\n",
            "  adding: training_datas/train_data8516.zip (stored 0%)\n",
            "  adding: training_datas/train_data24026.zip (stored 0%)\n",
            "  adding: training_datas/train_data26662.zip (stored 0%)\n",
            "  adding: training_datas/train_data16131.zip (stored 0%)\n",
            "  adding: training_datas/train_data7388.zip (stored 0%)\n",
            "  adding: training_datas/train_data21516.zip (stored 0%)\n",
            "  adding: training_datas/train_data17477.zip (stored 0%)\n",
            "  adding: training_datas/train_data30131.zip (stored 0%)\n",
            "  adding: training_datas/train_data3306.zip (stored 0%)\n",
            "  adding: training_datas/train_data24399.zip (stored 0%)\n",
            "  adding: training_datas/train_data18981.zip (stored 0%)\n",
            "  adding: training_datas/train_data11346.zip (stored 0%)\n",
            "  adding: training_datas/train_data5293.zip (stored 0%)\n",
            "  adding: training_datas/train_data22803.zip (stored 0%)\n",
            "  adding: training_datas/train_data7369.zip (stored 0%)\n",
            "  adding: training_datas/train_data17325.zip (stored 0%)\n",
            "  adding: training_datas/train_data25810.zip (stored 0%)\n",
            "  adding: training_datas/train_data10043.zip (stored 0%)\n",
            "  adding: training_datas/train_data2883.zip (stored 0%)\n",
            "  adding: training_datas/train_data28326.zip (stored 0%)\n",
            "  adding: training_datas/train_data8577.zip (stored 0%)\n",
            "  adding: training_datas/train_data30064.zip (stored 0%)\n",
            "  adding: training_datas/train_data9830.zip (stored 0%)\n",
            "  adding: training_datas/train_data21688.zip (stored 0%)\n",
            "  adding: training_datas/train_data22057.zip (stored 0%)\n",
            "  adding: training_datas/train_data8072.zip (stored 0%)\n",
            "  adding: training_datas/train_data27396.zip (stored 0%)\n",
            "  adding: training_datas/train_data8701.zip (stored 0%)\n",
            "  adding: training_datas/train_data3232.zip (stored 0%)\n",
            "  adding: training_datas/train_data28932.zip (stored 0%)\n",
            "  adding: training_datas/train_data3633.zip (stored 0%)\n",
            "  adding: training_datas/train_data15440.zip (stored 0%)\n",
            "  adding: training_datas/train_data637.zip (stored 0%)\n",
            "  adding: training_datas/train_data2775.zip (stored 0%)\n",
            "  adding: training_datas/train_data11012.zip (stored 0%)\n",
            "  adding: training_datas/train_data21766.zip (stored 0%)\n",
            "  adding: training_datas/train_data5690.zip (stored 0%)\n",
            "  adding: training_datas/train_data96.zip (stored 0%)\n",
            "  adding: training_datas/train_data4290.zip (stored 0%)\n",
            "  adding: training_datas/train_data392.zip (stored 0%)\n",
            "  adding: training_datas/train_data12134.zip (stored 0%)\n",
            "  adding: training_datas/train_data6477.zip (stored 0%)\n",
            "  adding: training_datas/train_data3295.zip (stored 0%)\n",
            "  adding: training_datas/train_data6717.zip (stored 0%)\n",
            "  adding: training_datas/train_data28457.zip (stored 0%)\n",
            "  adding: training_datas/train_data25108.zip (stored 0%)\n",
            "  adding: training_datas/train_data29668.zip (stored 0%)\n",
            "  adding: training_datas/train_data26095.zip (stored 0%)\n",
            "  adding: training_datas/train_data19687.zip (stored 0%)\n",
            "  adding: training_datas/train_data22566.zip (stored 0%)\n",
            "  adding: training_datas/train_data19113.zip (stored 0%)\n",
            "  adding: training_datas/train_data5826.zip (stored 0%)\n",
            "  adding: training_datas/train_data5409.zip (stored 0%)\n",
            "  adding: training_datas/train_data9396.zip (stored 0%)\n",
            "  adding: training_datas/train_data15900.zip (stored 0%)\n",
            "  adding: training_datas/train_data7621.zip (stored 0%)\n",
            "  adding: training_datas/train_data16374.zip (stored 0%)\n",
            "  adding: training_datas/train_data21715.zip (stored 0%)\n",
            "  adding: training_datas/train_data17918.zip (stored 0%)\n",
            "  adding: training_datas/train_data1421.zip (stored 0%)\n",
            "  adding: training_datas/train_data22930.zip (stored 0%)\n",
            "  adding: training_datas/train_data6142.zip (stored 0%)\n",
            "  adding: training_datas/train_data22153.zip (stored 0%)\n",
            "  adding: training_datas/train_data10750.zip (stored 0%)\n",
            "  adding: training_datas/train_data7550.zip (stored 0%)\n",
            "  adding: training_datas/train_data15866.zip (stored 0%)\n",
            "  adding: training_datas/train_data3950.zip (stored 0%)\n",
            "  adding: training_datas/train_data22941.zip (stored 0%)\n",
            "  adding: training_datas/train_data13434.zip (stored 0%)\n",
            "  adding: training_datas/train_data15581.zip (stored 0%)\n",
            "  adding: training_datas/train_data23726.zip (stored 0%)\n",
            "  adding: training_datas/train_data7728.zip (stored 0%)\n",
            "  adding: training_datas/train_data5736.zip (stored 0%)\n",
            "  adding: training_datas/train_data10562.zip (stored 0%)\n",
            "  adding: training_datas/train_data19122.zip (stored 0%)\n",
            "  adding: training_datas/train_data19811.zip (stored 0%)\n",
            "  adding: training_datas/train_data19243.zip (stored 0%)\n",
            "  adding: training_datas/train_data6126.zip (stored 0%)\n",
            "  adding: training_datas/train_data23840.zip (stored 0%)\n",
            "  adding: training_datas/train_data29852.zip (stored 0%)\n",
            "  adding: training_datas/train_data21159.zip (stored 0%)\n",
            "  adding: training_datas/train_data4605.zip (stored 0%)\n",
            "  adding: training_datas/train_data26979.zip (stored 0%)\n",
            "  adding: training_datas/train_data9499.zip (stored 0%)\n",
            "  adding: training_datas/train_data2303.zip (stored 0%)\n",
            "  adding: training_datas/train_data20585.zip (stored 0%)\n",
            "  adding: training_datas/train_data23875.zip (stored 0%)\n",
            "  adding: training_datas/train_data29786.zip (stored 0%)\n",
            "  adding: training_datas/train_data992.zip (stored 0%)\n",
            "  adding: training_datas/train_data24274.zip (stored 0%)\n",
            "  adding: training_datas/train_data21177.zip (stored 0%)\n",
            "  adding: training_datas/train_data1104.zip (stored 0%)\n",
            "  adding: training_datas/train_data8927.zip (stored 0%)\n",
            "  adding: training_datas/train_data27516.zip (stored 0%)\n",
            "  adding: training_datas/train_data18958.zip (stored 0%)\n",
            "  adding: training_datas/train_data17612.zip (stored 0%)\n",
            "  adding: training_datas/train_data5706.zip (stored 0%)\n",
            "  adding: training_datas/train_data30256.zip (stored 0%)\n",
            "  adding: training_datas/train_data4920.zip (stored 0%)\n",
            "  adding: training_datas/train_data26902.zip (stored 0%)\n",
            "  adding: training_datas/train_data8176.zip (stored 0%)\n",
            "  adding: training_datas/train_data11107.zip (stored 0%)\n",
            "  adding: training_datas/train_data27830.zip (stored 0%)\n",
            "  adding: training_datas/train_data11583.zip (stored 0%)\n",
            "  adding: training_datas/train_data2067.zip (stored 0%)\n",
            "  adding: training_datas/train_data142.zip (stored 0%)\n",
            "  adding: training_datas/train_data20635.zip (stored 0%)\n",
            "  adding: training_datas/train_data19198.zip (stored 0%)\n",
            "  adding: training_datas/train_data1615.zip (stored 0%)\n",
            "  adding: training_datas/train_data5266.zip (stored 0%)\n",
            "  adding: training_datas/train_data3665.zip (stored 0%)\n",
            "  adding: training_datas/train_data8807.zip (stored 0%)\n",
            "  adding: training_datas/train_data5020.zip (stored 0%)\n",
            "  adding: training_datas/train_data3559.zip (stored 0%)\n",
            "  adding: training_datas/train_data4152.zip (stored 0%)\n",
            "  adding: training_datas/train_data24332.zip (stored 0%)\n",
            "  adding: training_datas/train_data29527.zip (stored 0%)\n",
            "  adding: training_datas/train_data10326.zip (stored 0%)\n",
            "  adding: training_datas/train_data3981.zip (stored 0%)\n",
            "  adding: training_datas/train_data24334.zip (stored 0%)\n",
            "  adding: training_datas/train_data22692.zip (stored 0%)\n",
            "  adding: training_datas/train_data26709.zip (stored 0%)\n",
            "  adding: training_datas/train_data24996.zip (stored 0%)\n",
            "  adding: training_datas/train_data9083.zip (stored 0%)\n",
            "  adding: training_datas/train_data20128.zip (stored 0%)\n",
            "  adding: training_datas/train_data14494.zip (stored 0%)\n",
            "  adding: training_datas/train_data19022.zip (stored 0%)\n",
            "  adding: training_datas/train_data1538.zip (stored 0%)\n",
            "  adding: training_datas/train_data19912.zip (stored 0%)\n",
            "  adding: training_datas/train_data23920.zip (stored 0%)\n",
            "  adding: training_datas/train_data13986.zip (stored 0%)\n",
            "  adding: training_datas/train_data26452.zip (stored 0%)\n",
            "  adding: training_datas/train_data26927.zip (stored 0%)\n",
            "  adding: training_datas/train_data16654.zip (stored 0%)\n",
            "  adding: training_datas/train_data24276.zip (stored 0%)\n",
            "  adding: training_datas/train_data4587.zip (stored 0%)\n",
            "  adding: training_datas/train_data10246.zip (stored 0%)\n",
            "  adding: training_datas/train_data8549.zip (stored 0%)\n",
            "  adding: training_datas/train_data26763.zip (stored 0%)\n",
            "  adding: training_datas/train_data3808.zip (stored 0%)\n",
            "  adding: training_datas/train_data3018.zip (stored 0%)\n",
            "  adding: training_datas/train_data30079.zip (stored 0%)\n",
            "  adding: training_datas/train_data24056.zip (stored 0%)\n",
            "  adding: training_datas/train_data11567.zip (stored 0%)\n",
            "  adding: training_datas/train_data3968.zip (stored 0%)\n",
            "  adding: training_datas/train_data16830.zip (stored 0%)\n",
            "  adding: training_datas/train_data15267.zip (stored 0%)\n",
            "  adding: training_datas/train_data18732.zip (stored 0%)\n",
            "  adding: training_datas/train_data26096.zip (stored 0%)\n",
            "  adding: training_datas/train_data29054.zip (stored 0%)\n",
            "  adding: training_datas/train_data9689.zip (stored 0%)\n",
            "  adding: training_datas/train_data23939.zip (stored 0%)\n",
            "  adding: training_datas/train_data10622.zip (stored 0%)\n",
            "  adding: training_datas/train_data6007.zip (stored 0%)\n",
            "  adding: training_datas/train_data27350.zip (stored 0%)\n",
            "  adding: training_datas/train_data3951.zip (stored 0%)\n",
            "  adding: training_datas/train_data1442.zip (stored 0%)\n",
            "  adding: training_datas/train_data15348.zip (stored 0%)\n",
            "  adding: training_datas/train_data12675.zip (stored 0%)\n",
            "  adding: training_datas/train_data23259.zip (stored 0%)\n",
            "  adding: training_datas/train_data850.zip (stored 0%)\n",
            "  adding: training_datas/train_data20129.zip (stored 0%)\n",
            "  adding: training_datas/train_data20120.zip (stored 0%)\n",
            "  adding: training_datas/train_data7532.zip (stored 0%)\n",
            "  adding: training_datas/train_data3242.zip (stored 0%)\n",
            "  adding: training_datas/train_data28320.zip (stored 0%)\n",
            "  adding: training_datas/train_data17556.zip (stored 0%)\n",
            "  adding: training_datas/train_data2432.zip (stored 0%)\n",
            "  adding: training_datas/train_data26708.zip (stored 0%)\n",
            "  adding: training_datas/train_data4043.zip (stored 0%)\n",
            "  adding: training_datas/train_data20728.zip (stored 0%)\n",
            "  adding: training_datas/train_data17147.zip (stored 0%)\n",
            "  adding: training_datas/train_data17237.zip (stored 0%)\n",
            "  adding: training_datas/train_data2983.zip (stored 0%)\n",
            "  adding: training_datas/train_data2162.zip (stored 0%)\n",
            "  adding: training_datas/train_data1503.zip (stored 0%)\n",
            "  adding: training_datas/train_data14649.zip (stored 0%)\n",
            "  adding: training_datas/train_data11188.zip (stored 0%)\n",
            "  adding: training_datas/train_data24083.zip (stored 0%)\n",
            "  adding: training_datas/train_data18827.zip (stored 0%)\n",
            "  adding: training_datas/train_data8010.zip (stored 0%)\n",
            "  adding: training_datas/train_data26001.zip (stored 0%)\n",
            "  adding: training_datas/train_data2194.zip (stored 0%)\n",
            "  adding: training_datas/train_data10025.zip (stored 0%)\n",
            "  adding: training_datas/train_data9119.zip (stored 0%)\n",
            "  adding: training_datas/train_data14695.zip (stored 0%)\n",
            "  adding: training_datas/train_data4945.zip (stored 0%)\n",
            "  adding: training_datas/train_data29138.zip (stored 0%)\n",
            "  adding: training_datas/train_data25888.zip (stored 0%)\n",
            "  adding: training_datas/train_data17668.zip (stored 0%)\n",
            "  adding: training_datas/train_data28910.zip (stored 0%)\n",
            "  adding: training_datas/train_data11011.zip (stored 0%)\n",
            "  adding: training_datas/train_data18098.zip (stored 0%)\n",
            "  adding: training_datas/train_data14804.zip (stored 0%)\n",
            "  adding: training_datas/train_data29624.zip (stored 0%)\n",
            "  adding: training_datas/train_data27966.zip (stored 0%)\n",
            "  adding: training_datas/train_data7451.zip (stored 0%)\n",
            "  adding: training_datas/train_data7864.zip (stored 0%)\n",
            "  adding: training_datas/train_data3384.zip (stored 0%)\n",
            "  adding: training_datas/train_data23102.zip (stored 0%)\n",
            "  adding: training_datas/train_data16153.zip (stored 0%)\n",
            "  adding: training_datas/train_data6787.zip (stored 0%)\n",
            "  adding: training_datas/train_data17721.zip (stored 0%)\n",
            "  adding: training_datas/train_data21025.zip (stored 0%)\n",
            "  adding: training_datas/train_data26202.zip (stored 0%)\n",
            "  adding: training_datas/train_data10927.zip (stored 0%)\n",
            "  adding: training_datas/train_data613.zip (stored 0%)\n",
            "  adding: training_datas/train_data29528.zip (stored 0%)\n",
            "  adding: training_datas/train_data3899.zip (stored 0%)\n",
            "  adding: training_datas/train_data190.zip (stored 0%)\n",
            "  adding: training_datas/train_data20189.zip (stored 0%)\n",
            "  adding: training_datas/train_data23630.zip (stored 0%)\n",
            "  adding: training_datas/train_data15984.zip (stored 0%)\n",
            "  adding: training_datas/train_data22397.zip (stored 0%)\n",
            "  adding: training_datas/train_data14754.zip (stored 0%)\n",
            "  adding: training_datas/train_data17573.zip (stored 0%)\n",
            "  adding: training_datas/train_data4856.zip (stored 0%)\n",
            "  adding: training_datas/train_data18241.zip (stored 0%)\n",
            "  adding: training_datas/train_data14405.zip (stored 0%)\n",
            "  adding: training_datas/train_data15240.zip (stored 0%)\n",
            "  adding: training_datas/train_data29729.zip (stored 0%)\n",
            "  adding: training_datas/train_data13591.zip (stored 0%)\n",
            "  adding: training_datas/train_data2493.zip (stored 0%)\n",
            "  adding: training_datas/train_data1112.zip (stored 0%)\n",
            "  adding: training_datas/train_data9771.zip (stored 0%)\n",
            "  adding: training_datas/train_data11617.zip (stored 0%)\n",
            "  adding: training_datas/train_data25941.zip (stored 0%)\n",
            "  adding: training_datas/train_data18197.zip (stored 0%)\n",
            "  adding: training_datas/train_data11225.zip (stored 0%)\n",
            "  adding: training_datas/train_data28151.zip (stored 0%)\n",
            "  adding: training_datas/train_data14331.zip (stored 0%)\n",
            "  adding: training_datas/train_data3237.zip (stored 0%)\n",
            "  adding: training_datas/train_data2095.zip (stored 0%)\n",
            "  adding: training_datas/train_data18311.zip (stored 0%)\n",
            "  adding: training_datas/train_data22953.zip (stored 0%)\n",
            "  adding: training_datas/train_data14974.zip (stored 0%)\n",
            "  adding: training_datas/train_data29640.zip (stored 0%)\n",
            "  adding: training_datas/train_data12948.zip (stored 0%)\n",
            "  adding: training_datas/train_data26556.zip (stored 0%)\n",
            "  adding: training_datas/train_data18151.zip (stored 0%)\n",
            "  adding: training_datas/train_data26161.zip (stored 0%)\n",
            "  adding: training_datas/train_data359.zip (stored 0%)\n",
            "  adding: training_datas/train_data27834.zip (stored 0%)\n",
            "  adding: training_datas/train_data4608.zip (stored 0%)\n",
            "  adding: training_datas/train_data14388.zip (stored 0%)\n",
            "  adding: training_datas/train_data20417.zip (stored 0%)\n",
            "  adding: training_datas/train_data9963.zip (stored 0%)\n",
            "  adding: training_datas/train_data3524.zip (stored 0%)\n",
            "  adding: training_datas/train_data9988.zip (stored 0%)\n",
            "  adding: training_datas/train_data29931.zip (stored 0%)\n",
            "  adding: training_datas/train_data17617.zip (stored 0%)\n",
            "  adding: training_datas/train_data5418.zip (stored 0%)\n",
            "  adding: training_datas/train_data30100.zip (stored 0%)\n",
            "  adding: training_datas/train_data1095.zip (stored 0%)\n",
            "  adding: training_datas/train_data26532.zip (stored 0%)\n",
            "  adding: training_datas/train_data14602.zip (stored 0%)\n",
            "  adding: training_datas/train_data26501.zip (stored 0%)\n",
            "  adding: training_datas/train_data6618.zip (stored 0%)\n",
            "  adding: training_datas/train_data2511.zip (stored 0%)\n",
            "  adding: training_datas/train_data8184.zip (stored 0%)\n",
            "  adding: training_datas/train_data18273.zip (stored 0%)\n",
            "  adding: training_datas/train_data9935.zip (stored 0%)\n",
            "  adding: training_datas/train_data21435.zip (stored 0%)\n",
            "  adding: training_datas/train_data10169.zip (stored 0%)\n",
            "  adding: training_datas/train_data29289.zip (stored 0%)\n",
            "  adding: training_datas/train_data12149.zip (stored 0%)\n",
            "  adding: training_datas/train_data23449.zip (stored 0%)\n",
            "  adding: training_datas/train_data10936.zip (stored 0%)\n",
            "  adding: training_datas/train_data23502.zip (stored 0%)\n",
            "  adding: training_datas/train_data3961.zip (stored 0%)\n",
            "  adding: training_datas/train_data12824.zip (stored 0%)\n",
            "  adding: training_datas/train_data14156.zip (stored 0%)\n",
            "  adding: training_datas/train_data29208.zip (stored 0%)\n",
            "  adding: training_datas/train_data26228.zip (stored 0%)\n",
            "  adding: training_datas/train_data17910.zip (stored 0%)\n",
            "  adding: training_datas/train_data4032.zip (stored 0%)\n",
            "  adding: training_datas/train_data21484.zip (stored 0%)\n",
            "  adding: training_datas/train_data19524.zip (stored 0%)\n",
            "  adding: training_datas/train_data24186.zip (stored 0%)\n",
            "  adding: training_datas/train_data19553.zip (stored 0%)\n",
            "  adding: training_datas/train_data17187.zip (stored 0%)\n",
            "  adding: training_datas/train_data547.zip (stored 0%)\n",
            "  adding: training_datas/train_data27961.zip (stored 0%)\n",
            "  adding: training_datas/train_data8756.zip (stored 0%)\n",
            "  adding: training_datas/train_data5928.zip (stored 0%)\n",
            "  adding: training_datas/train_data17473.zip (stored 0%)\n",
            "  adding: training_datas/train_data12858.zip (stored 0%)\n",
            "  adding: training_datas/train_data5607.zip (stored 0%)\n",
            "  adding: training_datas/train_data16563.zip (stored 0%)\n",
            "  adding: training_datas/train_data4003.zip (stored 0%)\n",
            "  adding: training_datas/train_data885.zip (stored 0%)\n",
            "  adding: training_datas/train_data21546.zip (stored 0%)\n",
            "  adding: training_datas/train_data454.zip (stored 0%)\n",
            "  adding: training_datas/train_data11826.zip (stored 0%)\n",
            "  adding: training_datas/train_data7555.zip (stored 0%)\n",
            "  adding: training_datas/train_data17596.zip (stored 0%)\n",
            "  adding: training_datas/train_data29547.zip (stored 0%)\n",
            "  adding: training_datas/train_data2732.zip (stored 0%)\n",
            "  adding: training_datas/train_data13609.zip (stored 0%)\n",
            "  adding: training_datas/train_data7493.zip (stored 0%)\n",
            "  adding: training_datas/train_data3122.zip (stored 0%)\n",
            "  adding: training_datas/train_data20670.zip (stored 0%)\n",
            "  adding: training_datas/train_data26075.zip (stored 0%)\n",
            "  adding: training_datas/train_data8353.zip (stored 0%)\n",
            "  adding: training_datas/train_data10586.zip (stored 0%)\n",
            "  adding: training_datas/train_data15359.zip (stored 0%)\n",
            "  adding: training_datas/train_data17410.zip (stored 0%)\n",
            "  adding: training_datas/train_data3497.zip (stored 0%)\n",
            "  adding: training_datas/train_data1270.zip (stored 0%)\n",
            "  adding: training_datas/train_data29331.zip (stored 0%)\n",
            "  adding: training_datas/train_data7122.zip (stored 0%)\n",
            "  adding: training_datas/train_data25900.zip (stored 0%)\n",
            "  adding: training_datas/train_data3380.zip (stored 0%)\n",
            "  adding: training_datas/train_data2873.zip (stored 0%)\n",
            "  adding: training_datas/train_data24231.zip (stored 0%)\n",
            "  adding: training_datas/train_data25320.zip (stored 0%)\n",
            "  adding: training_datas/train_data18755.zip (stored 0%)\n",
            "  adding: training_datas/train_data22289.zip (stored 0%)\n",
            "  adding: training_datas/train_data5891.zip (stored 0%)\n",
            "  adding: training_datas/train_data7082.zip (stored 0%)\n",
            "  adding: training_datas/train_data2546.zip (stored 0%)\n",
            "  adding: training_datas/train_data22242.zip (stored 0%)\n",
            "  adding: training_datas/train_data16600.zip (stored 0%)\n",
            "  adding: training_datas/train_data4831.zip (stored 0%)\n",
            "  adding: training_datas/train_data1400.zip (stored 0%)\n",
            "  adding: training_datas/train_data6082.zip (stored 0%)\n",
            "  adding: training_datas/train_data24262.zip (stored 0%)\n",
            "  adding: training_datas/train_data16282.zip (stored 0%)\n",
            "  adding: training_datas/train_data29923.zip (stored 0%)\n",
            "  adding: training_datas/train_data4452.zip (stored 0%)\n",
            "  adding: training_datas/train_data6806.zip (stored 0%)\n",
            "  adding: training_datas/train_data24702.zip (stored 0%)\n",
            "  adding: training_datas/train_data16251.zip (stored 0%)\n",
            "  adding: training_datas/train_data28963.zip (stored 0%)\n",
            "  adding: training_datas/train_data25431.zip (stored 0%)\n",
            "  adding: training_datas/train_data20597.zip (stored 0%)\n",
            "  adding: training_datas/train_data7869.zip (stored 0%)\n",
            "  adding: training_datas/train_data25682.zip (stored 0%)\n",
            "  adding: training_datas/train_data19701.zip (stored 0%)\n",
            "  adding: training_datas/train_data7736.zip (stored 0%)\n",
            "  adding: training_datas/train_data14143.zip (stored 0%)\n",
            "  adding: training_datas/train_data28645.zip (stored 0%)\n",
            "  adding: training_datas/train_data16335.zip (stored 0%)\n",
            "  adding: training_datas/train_data6555.zip (stored 0%)\n",
            "  adding: training_datas/train_data740.zip (stored 0%)\n",
            "  adding: training_datas/train_data20335.zip (stored 0%)\n",
            "  adding: training_datas/train_data21986.zip (stored 0%)\n",
            "  adding: training_datas/train_data29711.zip (stored 0%)\n",
            "  adding: training_datas/train_data4533.zip (stored 0%)\n",
            "  adding: training_datas/train_data24247.zip (stored 0%)\n",
            "  adding: training_datas/train_data8891.zip (stored 0%)\n",
            "  adding: training_datas/train_data3844.zip (stored 0%)\n",
            "  adding: training_datas/train_data27584.zip (stored 0%)\n",
            "  adding: training_datas/train_data25187.zip (stored 0%)\n",
            "  adding: training_datas/train_data2632.zip (stored 0%)\n",
            "  adding: training_datas/train_data15875.zip (stored 0%)\n",
            "  adding: training_datas/train_data15357.zip (stored 0%)\n",
            "  adding: training_datas/train_data19497.zip (stored 0%)\n",
            "  adding: training_datas/train_data28807.zip (stored 0%)\n",
            "  adding: training_datas/train_data9758.zip (stored 0%)\n",
            "  adding: training_datas/train_data10829.zip (stored 0%)\n",
            "  adding: training_datas/train_data16193.zip (stored 0%)\n",
            "  adding: training_datas/train_data28965.zip (stored 0%)\n",
            "  adding: training_datas/train_data11794.zip (stored 0%)\n",
            "  adding: training_datas/train_data27560.zip (stored 0%)\n",
            "  adding: training_datas/train_data23399.zip (stored 0%)\n",
            "  adding: training_datas/train_data22180.zip (stored 0%)\n",
            "  adding: training_datas/train_data11082.zip (stored 0%)\n",
            "  adding: training_datas/train_data26052.zip (stored 0%)\n",
            "  adding: training_datas/train_data2398.zip (stored 0%)\n",
            "  adding: training_datas/train_data28700.zip (stored 0%)\n",
            "  adding: training_datas/train_data3970.zip (stored 0%)\n",
            "  adding: training_datas/train_data4713.zip (stored 0%)\n",
            "  adding: training_datas/train_data25924.zip (stored 0%)\n",
            "  adding: training_datas/train_data19233.zip (stored 0%)\n",
            "  adding: training_datas/train_data9591.zip (stored 0%)\n",
            "  adding: training_datas/train_data14451.zip (stored 0%)\n",
            "  adding: training_datas/train_data9890.zip (stored 0%)\n",
            "  adding: training_datas/train_data18804.zip (stored 0%)\n",
            "  adding: training_datas/train_data27620.zip (stored 0%)\n",
            "  adding: training_datas/train_data19413.zip (stored 0%)\n",
            "  adding: training_datas/train_data2966.zip (stored 0%)\n",
            "  adding: training_datas/train_data3362.zip (stored 0%)\n",
            "  adding: training_datas/train_data23140.zip (stored 0%)\n",
            "  adding: training_datas/train_data7414.zip (stored 0%)\n",
            "  adding: training_datas/train_data18741.zip (stored 0%)\n",
            "  adding: training_datas/train_data15339.zip (stored 0%)\n",
            "  adding: training_datas/train_data9974.zip (stored 0%)\n",
            "  adding: training_datas/train_data15956.zip (stored 0%)\n",
            "  adding: training_datas/train_data12318.zip (stored 0%)\n",
            "  adding: training_datas/train_data4316.zip (stored 0%)\n",
            "  adding: training_datas/train_data15224.zip (stored 0%)\n",
            "  adding: training_datas/train_data17044.zip (stored 0%)\n",
            "  adding: training_datas/train_data10102.zip (stored 0%)\n",
            "  adding: training_datas/train_data28191.zip (stored 0%)\n",
            "  adding: training_datas/train_data10912.zip (stored 0%)\n",
            "  adding: training_datas/train_data3347.zip (stored 0%)\n",
            "  adding: training_datas/train_data6757.zip (stored 0%)\n",
            "  adding: training_datas/train_data20434.zip (stored 0%)\n",
            "  adding: training_datas/train_data23087.zip (stored 0%)\n",
            "  adding: training_datas/train_data18386.zip (stored 0%)\n",
            "  adding: training_datas/train_data13894.zip (stored 0%)\n",
            "  adding: training_datas/train_data16473.zip (stored 0%)\n",
            "  adding: training_datas/train_data27598.zip (stored 0%)\n",
            "  adding: training_datas/train_data6592.zip (stored 0%)\n",
            "  adding: training_datas/train_data20745.zip (stored 0%)\n",
            "  adding: training_datas/train_data14702.zip (stored 0%)\n",
            "  adding: training_datas/train_data9009.zip (stored 0%)\n",
            "  adding: training_datas/train_data28439.zip (stored 0%)\n",
            "  adding: training_datas/train_data28446.zip (stored 0%)\n",
            "  adding: training_datas/train_data6682.zip (stored 0%)\n",
            "  adding: training_datas/train_data22298.zip (stored 0%)\n",
            "  adding: training_datas/train_data8191.zip (stored 0%)\n",
            "  adding: training_datas/train_data14031.zip (stored 0%)\n",
            "  adding: training_datas/train_data10098.zip (stored 0%)\n",
            "  adding: training_datas/train_data16110.zip (stored 0%)\n",
            "  adding: training_datas/train_data5698.zip (stored 0%)\n",
            "  adding: training_datas/train_data14007.zip (stored 0%)\n",
            "  adding: training_datas/train_data25359.zip (stored 0%)\n",
            "  adding: training_datas/train_data13777.zip (stored 0%)\n",
            "  adding: training_datas/train_data24279.zip (stored 0%)\n",
            "  adding: training_datas/train_data3572.zip (stored 0%)\n",
            "  adding: training_datas/train_data2993.zip (stored 0%)\n",
            "  adding: training_datas/train_data13304.zip (stored 0%)\n",
            "  adding: training_datas/train_data16201.zip (stored 0%)\n",
            "  adding: training_datas/train_data14258.zip (stored 0%)\n",
            "  adding: training_datas/train_data14501.zip (stored 0%)\n",
            "  adding: training_datas/train_data12876.zip (stored 0%)\n",
            "  adding: training_datas/train_data27748.zip (stored 0%)\n",
            "  adding: training_datas/train_data2737.zip (stored 0%)\n",
            "  adding: training_datas/train_data6674.zip (stored 0%)\n",
            "  adding: training_datas/train_data18789.zip (stored 0%)\n",
            "  adding: training_datas/train_data14829.zip (stored 0%)\n",
            "  adding: training_datas/train_data9379.zip (stored 0%)\n",
            "  adding: training_datas/train_data27787.zip (stored 0%)\n",
            "  adding: training_datas/train_data10163.zip (stored 0%)\n",
            "  adding: training_datas/train_data2345.zip (stored 0%)\n",
            "  adding: training_datas/train_data21957.zip (stored 0%)\n",
            "  adding: training_datas/train_data23874.zip (stored 0%)\n",
            "  adding: training_datas/train_data1711.zip (stored 0%)\n",
            "  adding: training_datas/train_data23187.zip (stored 0%)\n",
            "  adding: training_datas/train_data13764.zip (stored 0%)\n",
            "  adding: training_datas/train_data24061.zip (stored 0%)\n",
            "  adding: training_datas/train_data9655.zip (stored 0%)\n",
            "  adding: training_datas/train_data10718.zip (stored 0%)\n",
            "  adding: training_datas/train_data21900.zip (stored 0%)\n",
            "  adding: training_datas/train_data20182.zip (stored 0%)\n",
            "  adding: training_datas/train_data7273.zip (stored 0%)\n",
            "  adding: training_datas/train_data8457.zip (stored 0%)\n",
            "  adding: training_datas/train_data25403.zip (stored 0%)\n",
            "  adding: training_datas/train_data7048.zip (stored 0%)\n",
            "  adding: training_datas/train_data14185.zip (stored 0%)\n",
            "  adding: training_datas/train_data25142.zip (stored 0%)\n",
            "  adding: training_datas/train_data27587.zip (stored 0%)\n",
            "  adding: training_datas/train_data5939.zip (stored 0%)\n",
            "  adding: training_datas/train_data25113.zip (stored 0%)\n",
            "  adding: training_datas/train_data26721.zip (stored 0%)\n",
            "  adding: training_datas/train_data13739.zip (stored 0%)\n",
            "  adding: training_datas/train_data22280.zip (stored 0%)\n",
            "  adding: training_datas/train_data27643.zip (stored 0%)\n",
            "  adding: training_datas/train_data29747.zip (stored 0%)\n",
            "  adding: training_datas/train_data16185.zip (stored 0%)\n",
            "  adding: training_datas/train_data19799.zip (stored 0%)\n",
            "  adding: training_datas/train_data24498.zip (stored 0%)\n",
            "  adding: training_datas/train_data8910.zip (stored 0%)\n",
            "  adding: training_datas/train_data15824.zip (stored 0%)\n",
            "  adding: training_datas/train_data23226.zip (stored 0%)\n",
            "  adding: training_datas/train_data9788.zip (stored 0%)\n",
            "  adding: training_datas/train_data25227.zip (stored 0%)\n",
            "  adding: training_datas/train_data14148.zip (stored 0%)\n",
            "  adding: training_datas/train_data27143.zip (stored 0%)\n",
            "  adding: training_datas/train_data1561.zip (stored 0%)\n",
            "  adding: training_datas/train_data15994.zip (stored 0%)\n",
            "  adding: training_datas/train_data19414.zip (stored 0%)\n",
            "  adding: training_datas/train_data25060.zip (stored 0%)\n",
            "  adding: training_datas/train_data12729.zip (stored 0%)\n",
            "  adding: training_datas/train_data5827.zip (stored 0%)\n",
            "  adding: training_datas/train_data4224.zip (stored 0%)\n",
            "  adding: training_datas/train_data19780.zip (stored 0%)\n",
            "  adding: training_datas/train_data12112.zip (stored 0%)\n",
            "  adding: training_datas/train_data6306.zip (stored 0%)\n",
            "  adding: training_datas/train_data29733.zip (stored 0%)\n",
            "  adding: training_datas/train_data29240.zip (stored 0%)\n",
            "  adding: training_datas/train_data28991.zip (stored 0%)\n",
            "  adding: training_datas/train_data24245.zip (stored 0%)\n",
            "  adding: training_datas/train_data10100.zip (stored 0%)\n",
            "  adding: training_datas/train_data16059.zip (stored 0%)\n",
            "  adding: training_datas/train_data12060.zip (stored 0%)\n",
            "  adding: training_datas/train_data2442.zip (stored 0%)\n",
            "  adding: training_datas/train_data17251.zip (stored 0%)\n",
            "  adding: training_datas/train_data29454.zip (stored 0%)\n",
            "  adding: training_datas/train_data4609.zip (stored 0%)\n",
            "  adding: training_datas/train_data25869.zip (stored 0%)\n",
            "  adding: training_datas/train_data19937.zip (stored 0%)\n",
            "  adding: training_datas/train_data27971.zip (stored 0%)\n",
            "  adding: training_datas/train_data10116.zip (stored 0%)\n",
            "  adding: training_datas/train_data12374.zip (stored 0%)\n",
            "  adding: training_datas/train_data3809.zip (stored 0%)\n",
            "  adding: training_datas/train_data15281.zip (stored 0%)\n",
            "  adding: training_datas/train_data18323.zip (stored 0%)\n",
            "  adding: training_datas/train_data16661.zip (stored 0%)\n",
            "  adding: training_datas/train_data1725.zip (stored 0%)\n",
            "  adding: training_datas/train_data25048.zip (stored 0%)\n",
            "  adding: training_datas/train_data622.zip (stored 0%)\n",
            "  adding: training_datas/train_data14606.zip (stored 0%)\n",
            "  adding: training_datas/train_data19641.zip (stored 0%)\n",
            "  adding: training_datas/train_data10511.zip (stored 0%)\n",
            "  adding: training_datas/train_data12422.zip (stored 0%)\n",
            "  adding: training_datas/train_data9381.zip (stored 0%)\n",
            "  adding: training_datas/train_data18168.zip (stored 0%)\n",
            "  adding: training_datas/train_data17874.zip (stored 0%)\n",
            "  adding: training_datas/train_data19364.zip (stored 0%)\n",
            "  adding: training_datas/train_data12750.zip (stored 0%)\n",
            "  adding: training_datas/train_data20307.zip (stored 0%)\n",
            "  adding: training_datas/train_data6561.zip (stored 0%)\n",
            "  adding: training_datas/train_data20364.zip (stored 0%)\n",
            "  adding: training_datas/train_data20887.zip (stored 0%)\n",
            "  adding: training_datas/train_data30356.zip (stored 0%)\n",
            "  adding: training_datas/train_data26502.zip (stored 0%)\n",
            "  adding: training_datas/train_data27804.zip (stored 0%)\n",
            "  adding: training_datas/train_data17980.zip (stored 0%)\n",
            "  adding: training_datas/train_data1653.zip (stored 0%)\n",
            "  adding: training_datas/train_data8903.zip (stored 0%)\n",
            "  adding: training_datas/train_data20271.zip (stored 0%)\n",
            "  adding: training_datas/train_data21725.zip (stored 0%)\n",
            "  adding: training_datas/train_data6233.zip (stored 0%)\n",
            "  adding: training_datas/train_data28277.zip (stored 0%)\n",
            "  adding: training_datas/train_data12930.zip (stored 0%)\n",
            "  adding: training_datas/train_data17341.zip (stored 0%)\n",
            "  adding: training_datas/train_data10359.zip (stored 0%)\n",
            "  adding: training_datas/train_data1629.zip (stored 0%)\n",
            "  adding: training_datas/train_data21667.zip (stored 0%)\n",
            "  adding: training_datas/train_data29739.zip (stored 0%)\n",
            "  adding: training_datas/train_data1636.zip (stored 0%)\n",
            "  adding: training_datas/train_data15962.zip (stored 0%)\n",
            "  adding: training_datas/train_data2087.zip (stored 0%)\n",
            "  adding: training_datas/train_data28033.zip (stored 0%)\n",
            "  adding: training_datas/train_data9061.zip (stored 0%)\n",
            "  adding: training_datas/train_data9593.zip (stored 0%)\n",
            "  adding: training_datas/train_data8550.zip (stored 0%)\n",
            "  adding: training_datas/train_data24584.zip (stored 0%)\n",
            "  adding: training_datas/train_data11966.zip (stored 0%)\n",
            "  adding: training_datas/train_data6735.zip (stored 0%)\n",
            "  adding: training_datas/train_data3225.zip (stored 0%)\n",
            "  adding: training_datas/train_data7943.zip (stored 0%)\n",
            "  adding: training_datas/train_data25349.zip (stored 0%)\n",
            "  adding: training_datas/train_data4363.zip (stored 0%)\n",
            "  adding: training_datas/train_data22876.zip (stored 0%)\n",
            "  adding: training_datas/train_data26654.zip (stored 0%)\n",
            "  adding: training_datas/train_data363.zip (stored 0%)\n",
            "  adding: training_datas/train_data13219.zip (stored 0%)\n",
            "  adding: training_datas/train_data26543.zip (stored 0%)\n",
            "  adding: training_datas/train_data1195.zip (stored 0%)\n",
            "  adding: training_datas/train_data13892.zip (stored 0%)\n",
            "  adding: training_datas/train_data13162.zip (stored 0%)\n",
            "  adding: training_datas/train_data12875.zip (stored 0%)\n",
            "  adding: training_datas/train_data12404.zip (stored 0%)\n",
            "  adding: training_datas/train_data12213.zip (stored 0%)\n",
            "  adding: training_datas/train_data2882.zip (stored 0%)\n",
            "  adding: training_datas/train_data29434.zip (stored 0%)\n",
            "  adding: training_datas/train_data19098.zip (stored 0%)\n",
            "  adding: training_datas/train_data22087.zip (stored 0%)\n",
            "  adding: training_datas/train_data2132.zip (stored 0%)\n",
            "  adding: training_datas/train_data20560.zip (stored 0%)\n",
            "  adding: training_datas/train_data3454.zip (stored 0%)\n",
            "  adding: training_datas/train_data11183.zip (stored 0%)\n",
            "  adding: training_datas/train_data10091.zip (stored 0%)\n",
            "  adding: training_datas/train_data21062.zip (stored 0%)\n",
            "  adding: training_datas/train_data17718.zip (stored 0%)\n",
            "  adding: training_datas/train_data27411.zip (stored 0%)\n",
            "  adding: training_datas/train_data22880.zip (stored 0%)\n",
            "  adding: training_datas/train_data5875.zip (stored 0%)\n",
            "  adding: training_datas/train_data9144.zip (stored 0%)\n",
            "  adding: training_datas/train_data3858.zip (stored 0%)\n",
            "  adding: training_datas/train_data18810.zip (stored 0%)\n",
            "  adding: training_datas/train_data12322.zip (stored 0%)\n",
            "  adding: training_datas/train_data13345.zip (stored 0%)\n",
            "  adding: training_datas/train_data25623.zip (stored 0%)\n",
            "  adding: training_datas/train_data14890.zip (stored 0%)\n",
            "  adding: training_datas/train_data24958.zip (stored 0%)\n",
            "  adding: training_datas/train_data12419.zip (stored 0%)\n",
            "  adding: training_datas/train_data11423.zip (stored 0%)\n",
            "  adding: training_datas/train_data15292.zip (stored 0%)\n",
            "  adding: training_datas/train_data24576.zip (stored 0%)\n",
            "  adding: training_datas/train_data8755.zip (stored 0%)\n",
            "  adding: training_datas/train_data5158.zip (stored 0%)\n",
            "  adding: training_datas/train_data18455.zip (stored 0%)\n",
            "  adding: training_datas/train_data5534.zip (stored 0%)\n",
            "  adding: training_datas/train_data4762.zip (stored 0%)\n",
            "  adding: training_datas/train_data28341.zip (stored 0%)\n",
            "  adding: training_datas/train_data8223.zip (stored 0%)\n",
            "  adding: training_datas/train_data11092.zip (stored 0%)\n",
            "  adding: training_datas/train_data20093.zip (stored 0%)\n",
            "  adding: training_datas/train_data23823.zip (stored 0%)\n",
            "  adding: training_datas/train_data17458.zip (stored 0%)\n",
            "  adding: training_datas/train_data12809.zip (stored 0%)\n",
            "  adding: training_datas/train_data4620.zip (stored 0%)\n",
            "  adding: training_datas/train_data22146.zip (stored 0%)\n",
            "  adding: training_datas/train_data18563.zip (stored 0%)\n",
            "  adding: training_datas/train_data3840.zip (stored 0%)\n",
            "  adding: training_datas/train_data26732.zip (stored 0%)\n",
            "  adding: training_datas/train_data21800.zip (stored 0%)\n",
            "  adding: training_datas/train_data16468.zip (stored 0%)\n",
            "  adding: training_datas/train_data18352.zip (stored 0%)\n",
            "  adding: training_datas/train_data328.zip (stored 0%)\n",
            "  adding: training_datas/train_data24442.zip (stored 0%)\n",
            "  adding: training_datas/train_data24224.zip (stored 0%)\n",
            "  adding: training_datas/train_data17452.zip (stored 0%)\n",
            "  adding: training_datas/train_data7628.zip (stored 0%)\n",
            "  adding: training_datas/train_data2141.zip (stored 0%)\n",
            "  adding: training_datas/train_data10254.zip (stored 0%)\n",
            "  adding: training_datas/train_data11157.zip (stored 0%)\n",
            "  adding: training_datas/train_data18066.zip (stored 0%)\n",
            "  adding: training_datas/train_data20707.zip (stored 0%)\n",
            "  adding: training_datas/train_data9191.zip (stored 0%)\n",
            "  adding: training_datas/train_data6124.zip (stored 0%)\n",
            "  adding: training_datas/train_data11586.zip (stored 0%)\n",
            "  adding: training_datas/train_data18289.zip (stored 0%)\n",
            "  adding: training_datas/train_data22293.zip (stored 0%)\n",
            "  adding: training_datas/train_data19045.zip (stored 0%)\n",
            "  adding: training_datas/train_data11205.zip (stored 0%)\n",
            "  adding: training_datas/train_data22000.zip (stored 0%)\n",
            "  adding: training_datas/train_data18404.zip (stored 0%)\n",
            "  adding: training_datas/train_data23961.zip (stored 0%)\n",
            "  adding: training_datas/train_data9278.zip (stored 0%)\n",
            "  adding: training_datas/train_data23352.zip (stored 0%)\n",
            "  adding: training_datas/train_data24049.zip (stored 0%)\n",
            "  adding: training_datas/train_data13747.zip (stored 0%)\n",
            "  adding: training_datas/train_data23015.zip (stored 0%)\n",
            "  adding: training_datas/train_data14993.zip (stored 0%)\n",
            "  adding: training_datas/train_data15845.zip (stored 0%)\n",
            "  adding: training_datas/train_data518.zip (stored 0%)\n",
            "  adding: training_datas/train_data315.zip (stored 0%)\n",
            "  adding: training_datas/train_data11814.zip (stored 0%)\n",
            "  adding: training_datas/train_data877.zip (stored 0%)\n",
            "  adding: training_datas/train_data5897.zip (stored 0%)\n",
            "  adding: training_datas/train_data27722.zip (stored 0%)\n",
            "  adding: training_datas/train_data25171.zip (stored 0%)\n",
            "  adding: training_datas/train_data8905.zip (stored 0%)\n",
            "  adding: training_datas/train_data30385.zip (stored 0%)\n",
            "  adding: training_datas/train_data9155.zip (stored 0%)\n",
            "  adding: training_datas/train_data8969.zip (stored 0%)\n",
            "  adding: training_datas/train_data6695.zip (stored 0%)\n",
            "  adding: training_datas/train_data25281.zip (stored 0%)\n",
            "  adding: training_datas/train_data25584.zip (stored 0%)\n",
            "  adding: training_datas/train_data29905.zip (stored 0%)\n",
            "  adding: training_datas/train_data19409.zip (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCarWPWpS30T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c768d2a6-46d4-46cb-c3a7-70ad1e2a1e0b"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3z1Z5VNTRbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7955fc0-ce83-4394-f779-987352463ced"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data  training_datas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "225AxoYKTYNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r training_datas/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWlkTACev0zH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "26a925cd-059f-43de-d2f9-77fbc67c2e8d"
      },
      "source": [
        "with zipfile.ZipFile(\"./training_datas.zip\") as myzip:\n",
        "    filelist = myzip.namelist()\n",
        "    df = pd.read_csv(myzip.extract(filelist[10]))\n",
        "\n",
        "print(df.shape)\n",
        "print(len(filelist))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-711233816816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./training_datas.zip\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfilelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xbb in position 0: invalid start byte"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi-eyaAHrj5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79d3c7db-1899-4b60-9686-63c2dad6dabd"
      },
      "source": [
        "for i in range(len(listdir[10])):\n",
        "    with zipfile.ZipFile(\"./training_datas/\" + listdir[i]) as zip:\n",
        "        filelist = zip.namelist()\n",
        "        print(filelist)\n",
        "        data = pickle.loads(zip.read(filelist[0]))\n",
        "        print(data.shape)\n",
        "        print(data)\n",
        "        # for info in zip.infolist():\n",
        "        #     if info.is_dir():\n",
        "        #         continue\n",
        "        #     data = pickle.loads(zip.read(info.filename))\n",
        "        #     print(\"\\n\", data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['./training_datas/train_data0.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  8.382812   0.0\n",
            "1965        0        0        0  ...   0  8.382812   0.0\n",
            "1966        0        0        0  ...   0  8.382812   0.0\n",
            "1967        0        0        0  ...   0  8.382812   0.0\n",
            "1968        0        0        0  ...   0  8.382812   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data1.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  3.970703   0.0\n",
            "1965        0        0        0  ...   0  3.970703   0.0\n",
            "1966        0        0        0  ...   0  3.970703   0.0\n",
            "1967        0        0        0  ...   0  3.970703   0.0\n",
            "1968        0        0        0  ...   0  3.970703   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  4.878906   0.0\n",
            "1965        0        0        0  ...   0  4.878906   0.0\n",
            "1966        0        0        0  ...   0  4.878906   0.0\n",
            "1967        0        0        0  ...   0  4.878906   0.0\n",
            "1968        0        0        0  ...   0  4.878906   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data100.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  3.480469   0.0\n",
            "1965        0        0        0  ...   0  3.480469   0.0\n",
            "1966        0        0        0  ...   0  3.480469   0.0\n",
            "1967        0        0        0  ...   0  3.480469   0.0\n",
            "1968        0        0        0  ...   0  3.480469   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data1000.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  event_name_1_Chanukah End  ...  21  22  price  sale\n",
            "0           0        0        0                          0  ...   0   0    0.0   0.0\n",
            "1           0        0        0                          0  ...   0   0    0.0   0.0\n",
            "2           0        0        0                          0  ...   0   0    0.0   0.0\n",
            "3           1        1        0                          0  ...   0   0    0.0   0.0\n",
            "4           1        0        1                          0  ...   0   0    0.0   0.0\n",
            "...       ...      ...      ...                        ...  ...  ..  ..    ...   ...\n",
            "1964        0        1        1                          0  ...   0   0    1.5   0.0\n",
            "1965        0        0        0                          0  ...   0   0    1.5   0.0\n",
            "1966        0        0        0                          0  ...   0   0    1.5   0.0\n",
            "1967        0        0        0                          0  ...   0   0    1.5   0.0\n",
            "1968        0        0        0                          0  ...   0   0    1.5   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10000.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  1.980469   1.0\n",
            "1           0        0        0  ...   0  1.980469   5.0\n",
            "2           0        0        0  ...   0  1.980469   0.0\n",
            "3           1        1        0  ...   0  1.980469   5.0\n",
            "4           1        0        1  ...   0  1.980469   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  2.240234   0.0\n",
            "1965        0        0        0  ...   0  2.240234   0.0\n",
            "1966        0        0        0  ...   0  2.240234   0.0\n",
            "1967        0        0        0  ...   0  2.240234   0.0\n",
            "1968        0        0        0  ...   0  2.240234   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10001.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22      price  sale\n",
            "0           0        0        0  ...   0   0.000000   0.0\n",
            "1           0        0        0  ...   0   0.000000   0.0\n",
            "2           0        0        0  ...   0   0.000000   0.0\n",
            "3           1        1        0  ...   0   0.000000   0.0\n",
            "4           1        0        1  ...   0   0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..        ...   ...\n",
            "1964        0        1        1  ...   0  12.679688   0.0\n",
            "1965        0        0        0  ...   0  12.679688   0.0\n",
            "1966        0        0        0  ...   0  12.679688   0.0\n",
            "1967        0        0        0  ...   0  12.679688   0.0\n",
            "1968        0        0        0  ...   0  12.679688   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10002.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0   0.00000   0.0\n",
            "1           0        0        0  ...   0   0.00000   0.0\n",
            "2           0        0        0  ...   0   0.00000   0.0\n",
            "3           1        1        0  ...   0   0.00000   0.0\n",
            "4           1        0        1  ...   0   0.00000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  12.84375   0.0\n",
            "1965        0        0        0  ...   0  12.84375   0.0\n",
            "1966        0        0        0  ...   0  12.84375   0.0\n",
            "1967        0        0        0  ...   0  12.84375   0.0\n",
            "1968        0        0        0  ...   0  12.84375   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10003.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  5.980469   0.0\n",
            "1965        0        0        0  ...   0  5.980469   0.0\n",
            "1966        0        0        0  ...   0  5.980469   0.0\n",
            "1967        0        0        0  ...   0  5.980469   0.0\n",
            "1968        0        0        0  ...   0  5.980469   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10004.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  5.890625   1.0\n",
            "1           0        0        0  ...   0  5.890625   3.0\n",
            "2           0        0        0  ...   0  5.890625   1.0\n",
            "3           1        1        0  ...   0  5.890625   3.0\n",
            "4           1        0        1  ...   0  5.890625   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  5.980469   0.0\n",
            "1965        0        0        0  ...   0  5.980469   0.0\n",
            "1966        0        0        0  ...   0  5.980469   0.0\n",
            "1967        0        0        0  ...   0  5.980469   0.0\n",
            "1968        0        0        0  ...   0  5.980469   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10005.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  1.570312   1.0\n",
            "1           0        0        0  ...   0  1.570312   3.0\n",
            "2           0        0        0  ...   0  1.570312   1.0\n",
            "3           1        1        0  ...   0  1.570312   1.0\n",
            "4           1        0        1  ...   0  1.570312   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  0.959961   0.0\n",
            "1965        0        0        0  ...   0  0.959961   0.0\n",
            "1966        0        0        0  ...   0  0.959961   0.0\n",
            "1967        0        0        0  ...   0  0.959961   0.0\n",
            "1968        0        0        0  ...   0  0.959961   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10006.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  5.921875   0.0\n",
            "1965        0        0        0  ...   0  5.921875   0.0\n",
            "1966        0        0        0  ...   0  5.921875   0.0\n",
            "1967        0        0        0  ...   0  5.921875   0.0\n",
            "1968        0        0        0  ...   0  5.921875   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10007.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.979980   4.0\n",
            "1           0        0        0  ...   0  0.979980   6.0\n",
            "2           0        0        0  ...   0  0.979980   5.0\n",
            "3           1        1        0  ...   0  0.979980   1.0\n",
            "4           1        0        1  ...   0  0.979980   3.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  0.970215   0.0\n",
            "1965        0        0        0  ...   0  0.970215   0.0\n",
            "1966        0        0        0  ...   0  0.970215   0.0\n",
            "1967        0        0        0  ...   0  0.970215   0.0\n",
            "1968        0        0        0  ...   0  0.970215   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10008.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22      price  sale\n",
            "0           0        0        0  ...   0   0.000000   0.0\n",
            "1           0        0        0  ...   0   0.000000   0.0\n",
            "2           0        0        0  ...   0   0.000000   0.0\n",
            "3           1        1        0  ...   0   0.000000   0.0\n",
            "4           1        0        1  ...   0   0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..        ...   ...\n",
            "1964        0        1        1  ...   0  12.476562   0.0\n",
            "1965        0        0        0  ...   0  12.476562   0.0\n",
            "1966        0        0        0  ...   0  12.476562   0.0\n",
            "1967        0        0        0  ...   0  12.476562   0.0\n",
            "1968        0        0        0  ...   0  12.476562   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10009.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  0.879883   0.0\n",
            "1965        0        0        0  ...   0  0.879883   0.0\n",
            "1966        0        0        0  ...   0  0.879883   0.0\n",
            "1967        0        0        0  ...   0  0.879883   0.0\n",
            "1968        0        0        0  ...   0  0.879883   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data1001.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  1.969727   4.0\n",
            "1           0        0        0  ...   0  1.969727   3.0\n",
            "2           0        0        0  ...   0  1.969727   1.0\n",
            "3           1        1        0  ...   0  1.969727   0.0\n",
            "4           1        0        1  ...   0  1.969727   1.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  2.000000   0.0\n",
            "1965        0        0        0  ...   0  2.000000   0.0\n",
            "1966        0        0        0  ...   0  2.000000   0.0\n",
            "1967        0        0        0  ...   0  2.000000   0.0\n",
            "1968        0        0        0  ...   0  2.000000   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10010.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  9.976562   0.0\n",
            "1965        0        0        0  ...   0  9.976562   0.0\n",
            "1966        0        0        0  ...   0  9.976562   0.0\n",
            "1967        0        0        0  ...   0  9.976562   0.0\n",
            "1968        0        0        0  ...   0  9.976562   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10011.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  1.969727   0.0\n",
            "1965        0        0        0  ...   0  1.969727   0.0\n",
            "1966        0        0        0  ...   0  1.969727   0.0\n",
            "1967        0        0        0  ...   0  1.969727   0.0\n",
            "1968        0        0        0  ...   0  1.969727   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10012.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  3.279297   2.0\n",
            "1           0        0        0  ...   0  3.279297   1.0\n",
            "2           0        0        0  ...   0  3.279297   2.0\n",
            "3           1        1        0  ...   0  3.279297   1.0\n",
            "4           1        0        1  ...   0  3.279297   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  2.960938   0.0\n",
            "1965        0        0        0  ...   0  2.960938   0.0\n",
            "1966        0        0        0  ...   0  2.960938   0.0\n",
            "1967        0        0        0  ...   0  2.960938   0.0\n",
            "1968        0        0        0  ...   0  2.960938   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tdNWWq9C_2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "715a4694-2117-4219-8701-00b150a56ebb"
      },
      "source": [
        "    listdir = os.listdir(\"./training_datas\")\n",
        "    listdir.sort()\n",
        "    listdir[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_data0.zip',\n",
              " 'train_data1.zip',\n",
              " 'train_data10.zip',\n",
              " 'train_data100.zip',\n",
              " 'train_data1000.zip',\n",
              " 'train_data10000.zip',\n",
              " 'train_data10001.zip',\n",
              " 'train_data10002.zip',\n",
              " 'train_data10003.zip',\n",
              " 'train_data10004.zip']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RexdF3drcA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "listdir = os.listdir(DATA_PATH)\n",
        "listdir[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWffdQ5pKmOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd70e1b8-56ef-4e63-de85-b294e9300b20"
      },
      "source": [
        "os.path.isdir(\"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas_onehot/training_datas\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfC-F4l3LQVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cb82e65-843d-4dda-d63a-14f6196ad643"
      },
      "source": [
        "os.path.isdir(DATA_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNtlklycOPUw",
        "colab_type": "text"
      },
      "source": [
        "# データ生成後は以下を実行するだけでOK\n",
        "→ .py にして一部はライブラリ化する？\n",
        "<br />\n",
        "<br />\n",
        "6/19: 追記<br />\n",
        "google driveから読みだすのではなく、colab側にファイルを移動してから学習した方が良い(通信コストを下げることができるので、高速化につながる。)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEntpHnXq0LX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas_moving_average.zip\" \"./\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZtSuvJIrMFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c510403-8057-49e5-f893-2776016939d5"
      },
      "source": [
        "!unzip \"training_datas_moving_average.zip\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            " extracting: training_datas/train_data22586.zip  \n",
            " extracting: training_datas/train_data4114.zip  \n",
            " extracting: training_datas/train_data28298.zip  \n",
            " extracting: training_datas/train_data21834.zip  \n",
            " extracting: training_datas/train_data30159.zip  \n",
            " extracting: training_datas/train_data27591.zip  \n",
            " extracting: training_datas/train_data19314.zip  \n",
            " extracting: training_datas/train_data24863.zip  \n",
            " extracting: training_datas/train_data20693.zip  \n",
            " extracting: training_datas/train_data16423.zip  \n",
            " extracting: training_datas/train_data2086.zip  \n",
            " extracting: training_datas/train_data14186.zip  \n",
            " extracting: training_datas/train_data5602.zip  \n",
            " extracting: training_datas/train_data9052.zip  \n",
            " extracting: training_datas/train_data15380.zip  \n",
            " extracting: training_datas/train_data10922.zip  \n",
            " extracting: training_datas/train_data7026.zip  \n",
            " extracting: training_datas/train_data8418.zip  \n",
            " extracting: training_datas/train_data16488.zip  \n",
            " extracting: training_datas/train_data1763.zip  \n",
            " extracting: training_datas/train_data27281.zip  \n",
            " extracting: training_datas/train_data252.zip  \n",
            " extracting: training_datas/train_data6375.zip  \n",
            " extracting: training_datas/train_data26715.zip  \n",
            " extracting: training_datas/train_data2131.zip  \n",
            " extracting: training_datas/train_data1374.zip  \n",
            " extracting: training_datas/train_data2741.zip  \n",
            " extracting: training_datas/train_data5359.zip  \n",
            " extracting: training_datas/train_data3816.zip  \n",
            " extracting: training_datas/train_data821.zip  \n",
            " extracting: training_datas/train_data19134.zip  \n",
            " extracting: training_datas/train_data23632.zip  \n",
            " extracting: training_datas/train_data435.zip  \n",
            " extracting: training_datas/train_data15519.zip  \n",
            " extracting: training_datas/train_data23645.zip  \n",
            " extracting: training_datas/train_data22981.zip  \n",
            " extracting: training_datas/train_data15199.zip  \n",
            " extracting: training_datas/train_data25939.zip  \n",
            " extracting: training_datas/train_data5234.zip  \n",
            " extracting: training_datas/train_data28420.zip  \n",
            " extracting: training_datas/train_data4113.zip  \n",
            " extracting: training_datas/train_data24443.zip  \n",
            " extracting: training_datas/train_data30467.zip  \n",
            " extracting: training_datas/train_data18116.zip  \n",
            " extracting: training_datas/train_data20478.zip  \n",
            " extracting: training_datas/train_data25491.zip  \n",
            " extracting: training_datas/train_data13406.zip  \n",
            " extracting: training_datas/train_data24513.zip  \n",
            " extracting: training_datas/train_data1999.zip  \n",
            " extracting: training_datas/train_data23669.zip  \n",
            " extracting: training_datas/train_data10201.zip  \n",
            " extracting: training_datas/train_data28786.zip  \n",
            " extracting: training_datas/train_data5837.zip  \n",
            " extracting: training_datas/train_data14992.zip  \n",
            " extracting: training_datas/train_data22506.zip  \n",
            " extracting: training_datas/train_data15974.zip  \n",
            " extracting: training_datas/train_data28741.zip  \n",
            " extracting: training_datas/train_data25498.zip  \n",
            " extracting: training_datas/train_data22509.zip  \n",
            " extracting: training_datas/train_data15640.zip  \n",
            " extracting: training_datas/train_data13594.zip  \n",
            " extracting: training_datas/train_data4074.zip  \n",
            " extracting: training_datas/train_data24277.zip  \n",
            " extracting: training_datas/train_data304.zip  \n",
            " extracting: training_datas/train_data8514.zip  \n",
            " extracting: training_datas/train_data19999.zip  \n",
            " extracting: training_datas/train_data13254.zip  \n",
            " extracting: training_datas/train_data25154.zip  \n",
            " extracting: training_datas/train_data18783.zip  \n",
            " extracting: training_datas/train_data13290.zip  \n",
            " extracting: training_datas/train_data24569.zip  \n",
            " extracting: training_datas/train_data5435.zip  \n",
            " extracting: training_datas/train_data19872.zip  \n",
            " extracting: training_datas/train_data11349.zip  \n",
            " extracting: training_datas/train_data9169.zip  \n",
            " extracting: training_datas/train_data19200.zip  \n",
            " extracting: training_datas/train_data11995.zip  \n",
            " extracting: training_datas/train_data14449.zip  \n",
            " extracting: training_datas/train_data3375.zip  \n",
            " extracting: training_datas/train_data12001.zip  \n",
            " extracting: training_datas/train_data14741.zip  \n",
            " extracting: training_datas/train_data14099.zip  \n",
            " extracting: training_datas/train_data16977.zip  \n",
            " extracting: training_datas/train_data1679.zip  \n",
            " extracting: training_datas/train_data17311.zip  \n",
            " extracting: training_datas/train_data18591.zip  \n",
            " extracting: training_datas/train_data11743.zip  \n",
            " extracting: training_datas/train_data7454.zip  \n",
            " extracting: training_datas/train_data18996.zip  \n",
            " extracting: training_datas/train_data10795.zip  \n",
            " extracting: training_datas/train_data23049.zip  \n",
            " extracting: training_datas/train_data11167.zip  \n",
            " extracting: training_datas/train_data2942.zip  \n",
            " extracting: training_datas/train_data881.zip  \n",
            " extracting: training_datas/train_data4190.zip  \n",
            " extracting: training_datas/train_data28832.zip  \n",
            " extracting: training_datas/train_data17125.zip  \n",
            " extracting: training_datas/train_data22763.zip  \n",
            " extracting: training_datas/train_data25336.zip  \n",
            " extracting: training_datas/train_data8087.zip  \n",
            " extracting: training_datas/train_data7669.zip  \n",
            " extracting: training_datas/train_data10084.zip  \n",
            " extracting: training_datas/train_data1798.zip  \n",
            " extracting: training_datas/train_data7096.zip  \n",
            " extracting: training_datas/train_data20311.zip  \n",
            " extracting: training_datas/train_data15744.zip  \n",
            " extracting: training_datas/train_data14400.zip  \n",
            " extracting: training_datas/train_data9405.zip  \n",
            " extracting: training_datas/train_data7009.zip  \n",
            " extracting: training_datas/train_data9818.zip  \n",
            " extracting: training_datas/train_data1904.zip  \n",
            " extracting: training_datas/train_data22548.zip  \n",
            " extracting: training_datas/train_data6536.zip  \n",
            " extracting: training_datas/train_data15782.zip  \n",
            " extracting: training_datas/train_data3605.zip  \n",
            " extracting: training_datas/train_data5122.zip  \n",
            " extracting: training_datas/train_data7522.zip  \n",
            " extracting: training_datas/train_data3183.zip  \n",
            " extracting: training_datas/train_data3795.zip  \n",
            " extracting: training_datas/train_data8580.zip  \n",
            " extracting: training_datas/train_data28216.zip  \n",
            " extracting: training_datas/train_data15262.zip  \n",
            " extracting: training_datas/train_data9958.zip  \n",
            " extracting: training_datas/train_data17442.zip  \n",
            " extracting: training_datas/train_data15675.zip  \n",
            " extracting: training_datas/train_data7402.zip  \n",
            " extracting: training_datas/train_data14900.zip  \n",
            " extracting: training_datas/train_data17399.zip  \n",
            " extracting: training_datas/train_data20862.zip  \n",
            " extracting: training_datas/train_data21078.zip  \n",
            " extracting: training_datas/train_data14999.zip  \n",
            " extracting: training_datas/train_data20109.zip  \n",
            " extracting: training_datas/train_data7450.zip  \n",
            " extracting: training_datas/train_data30129.zip  \n",
            " extracting: training_datas/train_data6161.zip  \n",
            " extracting: training_datas/train_data9573.zip  \n",
            " extracting: training_datas/train_data20733.zip  \n",
            " extracting: training_datas/train_data12147.zip  \n",
            " extracting: training_datas/train_data5622.zip  \n",
            " extracting: training_datas/train_data26338.zip  \n",
            " extracting: training_datas/train_data13642.zip  \n",
            " extracting: training_datas/train_data1183.zip  \n",
            " extracting: training_datas/train_data28082.zip  \n",
            " extracting: training_datas/train_data21312.zip  \n",
            " extracting: training_datas/train_data24042.zip  \n",
            " extracting: training_datas/train_data7726.zip  \n",
            " extracting: training_datas/train_data24485.zip  \n",
            " extracting: training_datas/train_data20207.zip  \n",
            " extracting: training_datas/train_data19957.zip  \n",
            " extracting: training_datas/train_data15494.zip  \n",
            " extracting: training_datas/train_data24920.zip  \n",
            " extracting: training_datas/train_data1341.zip  \n",
            " extracting: training_datas/train_data5109.zip  \n",
            " extracting: training_datas/train_data25963.zip  \n",
            " extracting: training_datas/train_data8880.zip  \n",
            " extracting: training_datas/train_data22186.zip  \n",
            " extracting: training_datas/train_data38.zip  \n",
            " extracting: training_datas/train_data8887.zip  \n",
            " extracting: training_datas/train_data18700.zip  \n",
            " extracting: training_datas/train_data3140.zip  \n",
            " extracting: training_datas/train_data25365.zip  \n",
            " extracting: training_datas/train_data2478.zip  \n",
            " extracting: training_datas/train_data3849.zip  \n",
            " extracting: training_datas/train_data19026.zip  \n",
            " extracting: training_datas/train_data19565.zip  \n",
            " extracting: training_datas/train_data22089.zip  \n",
            " extracting: training_datas/train_data94.zip  \n",
            " extracting: training_datas/train_data823.zip  \n",
            " extracting: training_datas/train_data27065.zip  \n",
            " extracting: training_datas/train_data23637.zip  \n",
            " extracting: training_datas/train_data1326.zip  \n",
            " extracting: training_datas/train_data322.zip  \n",
            " extracting: training_datas/train_data25404.zip  \n",
            " extracting: training_datas/train_data12204.zip  \n",
            " extracting: training_datas/train_data13144.zip  \n",
            " extracting: training_datas/train_data13020.zip  \n",
            " extracting: training_datas/train_data1995.zip  \n",
            " extracting: training_datas/train_data15305.zip  \n",
            " extracting: training_datas/train_data29019.zip  \n",
            " extracting: training_datas/train_data22769.zip  \n",
            " extracting: training_datas/train_data11313.zip  \n",
            " extracting: training_datas/train_data21405.zip  \n",
            " extracting: training_datas/train_data7517.zip  \n",
            " extracting: training_datas/train_data1791.zip  \n",
            " extracting: training_datas/train_data18908.zip  \n",
            " extracting: training_datas/train_data21199.zip  \n",
            " extracting: training_datas/train_data14487.zip  \n",
            " extracting: training_datas/train_data16769.zip  \n",
            " extracting: training_datas/train_data601.zip  \n",
            " extracting: training_datas/train_data6776.zip  \n",
            " extracting: training_datas/train_data25094.zip  \n",
            " extracting: training_datas/train_data18906.zip  \n",
            " extracting: training_datas/train_data5858.zip  \n",
            " extracting: training_datas/train_data6340.zip  \n",
            " extracting: training_datas/train_data21285.zip  \n",
            " extracting: training_datas/train_data27252.zip  \n",
            " extracting: training_datas/train_data11117.zip  \n",
            " extracting: training_datas/train_data22656.zip  \n",
            " extracting: training_datas/train_data12673.zip  \n",
            " extracting: training_datas/train_data26986.zip  \n",
            " extracting: training_datas/train_data3937.zip  \n",
            " extracting: training_datas/train_data9923.zip  \n",
            " extracting: training_datas/train_data28848.zip  \n",
            " extracting: training_datas/train_data29324.zip  \n",
            " extracting: training_datas/train_data6688.zip  \n",
            " extracting: training_datas/train_data11716.zip  \n",
            " extracting: training_datas/train_data6182.zip  \n",
            " extracting: training_datas/train_data16964.zip  \n",
            " extracting: training_datas/train_data23231.zip  \n",
            " extracting: training_datas/train_data13731.zip  \n",
            " extracting: training_datas/train_data3908.zip  \n",
            " extracting: training_datas/train_data21473.zip  \n",
            " extracting: training_datas/train_data1880.zip  \n",
            " extracting: training_datas/train_data22756.zip  \n",
            " extracting: training_datas/train_data30021.zip  \n",
            " extracting: training_datas/train_data13794.zip  \n",
            " extracting: training_datas/train_data23440.zip  \n",
            " extracting: training_datas/train_data3236.zip  \n",
            " extracting: training_datas/train_data26233.zip  \n",
            " extracting: training_datas/train_data7024.zip  \n",
            " extracting: training_datas/train_data10348.zip  \n",
            " extracting: training_datas/train_data2806.zip  \n",
            " extracting: training_datas/train_data24088.zip  \n",
            " extracting: training_datas/train_data27509.zip  \n",
            " extracting: training_datas/train_data17747.zip  \n",
            " extracting: training_datas/train_data24098.zip  \n",
            " extracting: training_datas/train_data29330.zip  \n",
            " extracting: training_datas/train_data1529.zip  \n",
            " extracting: training_datas/train_data24007.zip  \n",
            " extracting: training_datas/train_data16503.zip  \n",
            " extracting: training_datas/train_data16551.zip  \n",
            " extracting: training_datas/train_data16035.zip  \n",
            " extracting: training_datas/train_data11518.zip  \n",
            " extracting: training_datas/train_data29651.zip  \n",
            " extracting: training_datas/train_data18407.zip  \n",
            " extracting: training_datas/train_data27365.zip  \n",
            " extracting: training_datas/train_data11508.zip  \n",
            " extracting: training_datas/train_data3655.zip  \n",
            " extracting: training_datas/train_data19527.zip  \n",
            " extracting: training_datas/train_data9555.zip  \n",
            " extracting: training_datas/train_data23644.zip  \n",
            " extracting: training_datas/train_data24464.zip  \n",
            " extracting: training_datas/train_data12125.zip  \n",
            " extracting: training_datas/train_data14136.zip  \n",
            " extracting: training_datas/train_data23918.zip  \n",
            " extracting: training_datas/train_data6187.zip  \n",
            " extracting: training_datas/train_data21659.zip  \n",
            " extracting: training_datas/train_data13644.zip  \n",
            " extracting: training_datas/train_data5395.zip  \n",
            " extracting: training_datas/train_data7393.zip  \n",
            " extracting: training_datas/train_data2230.zip  \n",
            " extracting: training_datas/train_data15132.zip  \n",
            " extracting: training_datas/train_data4084.zip  \n",
            " extracting: training_datas/train_data26821.zip  \n",
            " extracting: training_datas/train_data14758.zip  \n",
            " extracting: training_datas/train_data3029.zip  \n",
            " extracting: training_datas/train_data16738.zip  \n",
            " extracting: training_datas/train_data1524.zip  \n",
            " extracting: training_datas/train_data1035.zip  \n",
            " extracting: training_datas/train_data14067.zip  \n",
            " extracting: training_datas/train_data1737.zip  \n",
            " extracting: training_datas/train_data27248.zip  \n",
            " extracting: training_datas/train_data15755.zip  \n",
            " extracting: training_datas/train_data7381.zip  \n",
            " extracting: training_datas/train_data13362.zip  \n",
            " extracting: training_datas/train_data18916.zip  \n",
            " extracting: training_datas/train_data21390.zip  \n",
            " extracting: training_datas/train_data13160.zip  \n",
            " extracting: training_datas/train_data25831.zip  \n",
            " extracting: training_datas/train_data15855.zip  \n",
            " extracting: training_datas/train_data16395.zip  \n",
            " extracting: training_datas/train_data20015.zip  \n",
            " extracting: training_datas/train_data22392.zip  \n",
            " extracting: training_datas/train_data28952.zip  \n",
            " extracting: training_datas/train_data542.zip  \n",
            " extracting: training_datas/train_data29681.zip  \n",
            " extracting: training_datas/train_data12313.zip  \n",
            " extracting: training_datas/train_data15241.zip  \n",
            " extracting: training_datas/train_data27060.zip  \n",
            " extracting: training_datas/train_data28477.zip  \n",
            " extracting: training_datas/train_data8599.zip  \n",
            " extracting: training_datas/train_data19350.zip  \n",
            " extracting: training_datas/train_data14492.zip  \n",
            " extracting: training_datas/train_data15954.zip  \n",
            " extracting: training_datas/train_data22885.zip  \n",
            " extracting: training_datas/train_data16484.zip  \n",
            " extracting: training_datas/train_data5741.zip  \n",
            " extracting: training_datas/train_data12944.zip  \n",
            " extracting: training_datas/train_data23054.zip  \n",
            " extracting: training_datas/train_data18001.zip  \n",
            " extracting: training_datas/train_data20626.zip  \n",
            " extracting: training_datas/train_data25636.zip  \n",
            " extracting: training_datas/train_data24739.zip  \n",
            " extracting: training_datas/train_data10572.zip  \n",
            " extracting: training_datas/train_data15699.zip  \n",
            " extracting: training_datas/train_data16358.zip  \n",
            " extracting: training_datas/train_data4667.zip  \n",
            " extracting: training_datas/train_data25069.zip  \n",
            " extracting: training_datas/train_data3123.zip  \n",
            " extracting: training_datas/train_data3985.zip  \n",
            " extracting: training_datas/train_data3869.zip  \n",
            " extracting: training_datas/train_data5428.zip  \n",
            " extracting: training_datas/train_data16575.zip  \n",
            " extracting: training_datas/train_data20644.zip  \n",
            " extracting: training_datas/train_data25160.zip  \n",
            " extracting: training_datas/train_data3789.zip  \n",
            " extracting: training_datas/train_data23842.zip  \n",
            " extracting: training_datas/train_data1273.zip  \n",
            " extracting: training_datas/train_data12370.zip  \n",
            " extracting: training_datas/train_data9920.zip  \n",
            " extracting: training_datas/train_data13323.zip  \n",
            " extracting: training_datas/train_data13669.zip  \n",
            " extracting: training_datas/train_data17225.zip  \n",
            " extracting: training_datas/train_data26583.zip  \n",
            " extracting: training_datas/train_data6849.zip  \n",
            " extracting: training_datas/train_data12385.zip  \n",
            " extracting: training_datas/train_data19612.zip  \n",
            " extracting: training_datas/train_data11047.zip  \n",
            " extracting: training_datas/train_data24428.zip  \n",
            " extracting: training_datas/train_data10203.zip  \n",
            " extracting: training_datas/train_data59.zip  \n",
            " extracting: training_datas/train_data14069.zip  \n",
            " extracting: training_datas/train_data9800.zip  \n",
            " extracting: training_datas/train_data11554.zip  \n",
            " extracting: training_datas/train_data24683.zip  \n",
            " extracting: training_datas/train_data21083.zip  \n",
            " extracting: training_datas/train_data29959.zip  \n",
            " extracting: training_datas/train_data29468.zip  \n",
            " extracting: training_datas/train_data28990.zip  \n",
            " extracting: training_datas/train_data15225.zip  \n",
            " extracting: training_datas/train_data11381.zip  \n",
            " extracting: training_datas/train_data25539.zip  \n",
            " extracting: training_datas/train_data4766.zip  \n",
            " extracting: training_datas/train_data7653.zip  \n",
            " extracting: training_datas/train_data5664.zip  \n",
            " extracting: training_datas/train_data28047.zip  \n",
            " extracting: training_datas/train_data7292.zip  \n",
            " extracting: training_datas/train_data28146.zip  \n",
            " extracting: training_datas/train_data19929.zip  \n",
            " extracting: training_datas/train_data27153.zip  \n",
            " extracting: training_datas/train_data11533.zip  \n",
            " extracting: training_datas/train_data27224.zip  \n",
            " extracting: training_datas/train_data21263.zip  \n",
            " extracting: training_datas/train_data3958.zip  \n",
            " extracting: training_datas/train_data20897.zip  \n",
            " extracting: training_datas/train_data2104.zip  \n",
            " extracting: training_datas/train_data29458.zip  \n",
            " extracting: training_datas/train_data16885.zip  \n",
            " extracting: training_datas/train_data26875.zip  \n",
            " extracting: training_datas/train_data8924.zip  \n",
            " extracting: training_datas/train_data18960.zip  \n",
            " extracting: training_datas/train_data13950.zip  \n",
            " extracting: training_datas/train_data15861.zip  \n",
            " extracting: training_datas/train_data22901.zip  \n",
            " extracting: training_datas/train_data5113.zip  \n",
            " extracting: training_datas/train_data3964.zip  \n",
            " extracting: training_datas/train_data29880.zip  \n",
            " extracting: training_datas/train_data706.zip  \n",
            " extracting: training_datas/train_data16524.zip  \n",
            " extracting: training_datas/train_data17193.zip  \n",
            " extracting: training_datas/train_data7286.zip  \n",
            " extracting: training_datas/train_data9021.zip  \n",
            " extracting: training_datas/train_data14803.zip  \n",
            " extracting: training_datas/train_data18766.zip  \n",
            " extracting: training_datas/train_data2609.zip  \n",
            " extracting: training_datas/train_data28654.zip  \n",
            " extracting: training_datas/train_data2692.zip  \n",
            " extracting: training_datas/train_data28325.zip  \n",
            " extracting: training_datas/train_data22227.zip  \n",
            " extracting: training_datas/train_data18929.zip  \n",
            " extracting: training_datas/train_data28327.zip  \n",
            " extracting: training_datas/train_data27466.zip  \n",
            " extracting: training_datas/train_data4656.zip  \n",
            " extracting: training_datas/train_data23545.zip  \n",
            " extracting: training_datas/train_data17431.zip  \n",
            " extracting: training_datas/train_data1191.zip  \n",
            " extracting: training_datas/train_data9663.zip  \n",
            " extracting: training_datas/train_data29861.zip  \n",
            " extracting: training_datas/train_data2295.zip  \n",
            " extracting: training_datas/train_data30242.zip  \n",
            " extracting: training_datas/train_data21112.zip  \n",
            " extracting: training_datas/train_data18925.zip  \n",
            " extracting: training_datas/train_data4343.zip  \n",
            " extracting: training_datas/train_data378.zip  \n",
            " extracting: training_datas/train_data26665.zip  \n",
            " extracting: training_datas/train_data15577.zip  \n",
            " extracting: training_datas/train_data22043.zip  \n",
            " extracting: training_datas/train_data15583.zip  \n",
            " extracting: training_datas/train_data6672.zip  \n",
            " extracting: training_datas/train_data2424.zip  \n",
            " extracting: training_datas/train_data24401.zip  \n",
            " extracting: training_datas/train_data14394.zip  \n",
            " extracting: training_datas/train_data29702.zip  \n",
            " extracting: training_datas/train_data4593.zip  \n",
            " extracting: training_datas/train_data24289.zip  \n",
            " extracting: training_datas/train_data20833.zip  \n",
            " extracting: training_datas/train_data3352.zip  \n",
            " extracting: training_datas/train_data21201.zip  \n",
            " extracting: training_datas/train_data5540.zip  \n",
            " extracting: training_datas/train_data13597.zip  \n",
            " extracting: training_datas/train_data20661.zip  \n",
            " extracting: training_datas/train_data19671.zip  \n",
            " extracting: training_datas/train_data22150.zip  \n",
            " extracting: training_datas/train_data16904.zip  \n",
            " extracting: training_datas/train_data7116.zip  \n",
            " extracting: training_datas/train_data28397.zip  \n",
            " extracting: training_datas/train_data3445.zip  \n",
            " extracting: training_datas/train_data2626.zip  \n",
            " extracting: training_datas/train_data20936.zip  \n",
            " extracting: training_datas/train_data15772.zip  \n",
            " extracting: training_datas/train_data27832.zip  \n",
            " extracting: training_datas/train_data20503.zip  \n",
            " extracting: training_datas/train_data14205.zip  \n",
            " extracting: training_datas/train_data17633.zip  \n",
            " extracting: training_datas/train_data5835.zip  \n",
            " extracting: training_datas/train_data26308.zip  \n",
            " extracting: training_datas/train_data5104.zip  \n",
            " extracting: training_datas/train_data5628.zip  \n",
            " extracting: training_datas/train_data5364.zip  \n",
            " extracting: training_datas/train_data1145.zip  \n",
            " extracting: training_datas/train_data9248.zip  \n",
            " extracting: training_datas/train_data5832.zip  \n",
            " extracting: training_datas/train_data1530.zip  \n",
            " extracting: training_datas/train_data10408.zip  \n",
            " extracting: training_datas/train_data17561.zip  \n",
            " extracting: training_datas/train_data23785.zip  \n",
            " extracting: training_datas/train_data15695.zip  \n",
            " extracting: training_datas/train_data477.zip  \n",
            " extracting: training_datas/train_data26431.zip  \n",
            " extracting: training_datas/train_data8107.zip  \n",
            " extracting: training_datas/train_data25561.zip  \n",
            " extracting: training_datas/train_data3159.zip  \n",
            " extracting: training_datas/train_data7288.zip  \n",
            " extracting: training_datas/train_data13685.zip  \n",
            " extracting: training_datas/train_data2270.zip  \n",
            " extracting: training_datas/train_data17002.zip  \n",
            " extracting: training_datas/train_data17437.zip  \n",
            " extracting: training_datas/train_data6719.zip  \n",
            " extracting: training_datas/train_data15918.zip  \n",
            " extracting: training_datas/train_data14886.zip  \n",
            " extracting: training_datas/train_data5975.zip  \n",
            " extracting: training_datas/train_data8393.zip  \n",
            " extracting: training_datas/train_data9725.zip  \n",
            " extracting: training_datas/train_data20930.zip  \n",
            " extracting: training_datas/train_data1988.zip  \n",
            " extracting: training_datas/train_data3693.zip  \n",
            " extracting: training_datas/train_data22074.zip  \n",
            " extracting: training_datas/train_data28458.zip  \n",
            " extracting: training_datas/train_data26957.zip  \n",
            " extracting: training_datas/train_data14525.zip  \n",
            " extracting: training_datas/train_data1869.zip  \n",
            " extracting: training_datas/train_data5371.zip  \n",
            " extracting: training_datas/train_data499.zip  \n",
            " extracting: training_datas/train_data9632.zip  \n",
            " extracting: training_datas/train_data2622.zip  \n",
            " extracting: training_datas/train_data7418.zip  \n",
            " extracting: training_datas/train_data3116.zip  \n",
            " extracting: training_datas/train_data17326.zip  \n",
            " extracting: training_datas/train_data8250.zip  \n",
            " extracting: training_datas/train_data16133.zip  \n",
            " extracting: training_datas/train_data8928.zip  \n",
            " extracting: training_datas/train_data11768.zip  \n",
            " extracting: training_datas/train_data12646.zip  \n",
            " extracting: training_datas/train_data15779.zip  \n",
            " extracting: training_datas/train_data25230.zip  \n",
            " extracting: training_datas/train_data5086.zip  \n",
            " extracting: training_datas/train_data25733.zip  \n",
            " extracting: training_datas/train_data28314.zip  \n",
            " extracting: training_datas/train_data4753.zip  \n",
            " extracting: training_datas/train_data13891.zip  \n",
            " extracting: training_datas/train_data1943.zip  \n",
            " extracting: training_datas/train_data26764.zip  \n",
            " extracting: training_datas/train_data15716.zip  \n",
            " extracting: training_datas/train_data29444.zip  \n",
            " extracting: training_datas/train_data23019.zip  \n",
            " extracting: training_datas/train_data23931.zip  \n",
            " extracting: training_datas/train_data20353.zip  \n",
            " extracting: training_datas/train_data5175.zip  \n",
            " extracting: training_datas/train_data6328.zip  \n",
            " extracting: training_datas/train_data5126.zip  \n",
            " extracting: training_datas/train_data28444.zip  \n",
            " extracting: training_datas/train_data11783.zip  \n",
            " extracting: training_datas/train_data24868.zip  \n",
            " extracting: training_datas/train_data4586.zip  \n",
            " extracting: training_datas/train_data22157.zip  \n",
            " extracting: training_datas/train_data23070.zip  \n",
            " extracting: training_datas/train_data13972.zip  \n",
            " extracting: training_datas/train_data15035.zip  \n",
            " extracting: training_datas/train_data13869.zip  \n",
            " extracting: training_datas/train_data29109.zip  \n",
            " extracting: training_datas/train_data23392.zip  \n",
            " extracting: training_datas/train_data30201.zip  \n",
            " extracting: training_datas/train_data26461.zip  \n",
            " extracting: training_datas/train_data10168.zip  \n",
            " extracting: training_datas/train_data26322.zip  \n",
            " extracting: training_datas/train_data28443.zip  \n",
            " extracting: training_datas/train_data29842.zip  \n",
            " extracting: training_datas/train_data27110.zip  \n",
            " extracting: training_datas/train_data5385.zip  \n",
            " extracting: training_datas/train_data6347.zip  \n",
            " extracting: training_datas/train_data17091.zip  \n",
            " extracting: training_datas/train_data28517.zip  \n",
            " extracting: training_datas/train_data13329.zip  \n",
            " extracting: training_datas/train_data14458.zip  \n",
            " extracting: training_datas/train_data10179.zip  \n",
            " extracting: training_datas/train_data16072.zip  \n",
            " extracting: training_datas/train_data4728.zip  \n",
            " extracting: training_datas/train_data2157.zip  \n",
            " extracting: training_datas/train_data10632.zip  \n",
            " extracting: training_datas/train_data17818.zip  \n",
            " extracting: training_datas/train_data10516.zip  \n",
            " extracting: training_datas/train_data28384.zip  \n",
            " extracting: training_datas/train_data11288.zip  \n",
            " extracting: training_datas/train_data822.zip  \n",
            " extracting: training_datas/train_data19186.zip  \n",
            " extracting: training_datas/train_data5292.zip  \n",
            " extracting: training_datas/train_data11532.zip  \n",
            " extracting: training_datas/train_data22834.zip  \n",
            " extracting: training_datas/train_data16750.zip  \n",
            " extracting: training_datas/train_data5143.zip  \n",
            " extracting: training_datas/train_data11462.zip  \n",
            " extracting: training_datas/train_data803.zip  \n",
            " extracting: training_datas/train_data10042.zip  \n",
            " extracting: training_datas/train_data210.zip  \n",
            " extracting: training_datas/train_data22414.zip  \n",
            " extracting: training_datas/train_data3647.zip  \n",
            " extracting: training_datas/train_data21620.zip  \n",
            " extracting: training_datas/train_data22269.zip  \n",
            " extracting: training_datas/train_data22011.zip  \n",
            " extracting: training_datas/train_data7867.zip  \n",
            " extracting: training_datas/train_data4163.zip  \n",
            " extracting: training_datas/train_data6131.zip  \n",
            " extracting: training_datas/train_data5580.zip  \n",
            " extracting: training_datas/train_data24823.zip  \n",
            " extracting: training_datas/train_data6943.zip  \n",
            " extracting: training_datas/train_data12118.zip  \n",
            " extracting: training_datas/train_data29196.zip  \n",
            " extracting: training_datas/train_data13142.zip  \n",
            " extracting: training_datas/train_data8866.zip  \n",
            " extracting: training_datas/train_data10736.zip  \n",
            " extracting: training_datas/train_data25592.zip  \n",
            " extracting: training_datas/train_data13322.zip  \n",
            " extracting: training_datas/train_data9989.zip  \n",
            " extracting: training_datas/train_data27431.zip  \n",
            " extracting: training_datas/train_data18178.zip  \n",
            " extracting: training_datas/train_data13676.zip  \n",
            " extracting: training_datas/train_data25554.zip  \n",
            " extracting: training_datas/train_data23973.zip  \n",
            " extracting: training_datas/train_data21489.zip  \n",
            " extracting: training_datas/train_data30332.zip  \n",
            " extracting: training_datas/train_data4352.zip  \n",
            " extracting: training_datas/train_data116.zip  \n",
            " extracting: training_datas/train_data6804.zip  \n",
            " extracting: training_datas/train_data13463.zip  \n",
            " extracting: training_datas/train_data27253.zip  \n",
            " extracting: training_datas/train_data19921.zip  \n",
            " extracting: training_datas/train_data14821.zip  \n",
            " extracting: training_datas/train_data8280.zip  \n",
            " extracting: training_datas/train_data8957.zip  \n",
            " extracting: training_datas/train_data21071.zip  \n",
            " extracting: training_datas/train_data26724.zip  \n",
            " extracting: training_datas/train_data27087.zip  \n",
            " extracting: training_datas/train_data2348.zip  \n",
            " extracting: training_datas/train_data19171.zip  \n",
            " extracting: training_datas/train_data20230.zip  \n",
            " extracting: training_datas/train_data20408.zip  \n",
            " extracting: training_datas/train_data22106.zip  \n",
            " extracting: training_datas/train_data9823.zip  \n",
            " extracting: training_datas/train_data22054.zip  \n",
            " extracting: training_datas/train_data6283.zip  \n",
            " extracting: training_datas/train_data5606.zip  \n",
            " extracting: training_datas/train_data8721.zip  \n",
            " extracting: training_datas/train_data26432.zip  \n",
            " extracting: training_datas/train_data20524.zip  \n",
            " extracting: training_datas/train_data3980.zip  \n",
            " extracting: training_datas/train_data11383.zip  \n",
            " extracting: training_datas/train_data8469.zip  \n",
            " extracting: training_datas/train_data16851.zip  \n",
            " extracting: training_datas/train_data21899.zip  \n",
            " extracting: training_datas/train_data12295.zip  \n",
            " extracting: training_datas/train_data9188.zip  \n",
            " extracting: training_datas/train_data11150.zip  \n",
            " extracting: training_datas/train_data21421.zip  \n",
            " extracting: training_datas/train_data12294.zip  \n",
            " extracting: training_datas/train_data17426.zip  \n",
            " extracting: training_datas/train_data3603.zip  \n",
            " extracting: training_datas/train_data1857.zip  \n",
            " extracting: training_datas/train_data11236.zip  \n",
            " extracting: training_datas/train_data5079.zip  \n",
            " extracting: training_datas/train_data446.zip  \n",
            " extracting: training_datas/train_data19935.zip  \n",
            " extracting: training_datas/train_data4928.zip  \n",
            " extracting: training_datas/train_data22940.zip  \n",
            " extracting: training_datas/train_data9343.zip  \n",
            " extracting: training_datas/train_data18406.zip  \n",
            " extracting: training_datas/train_data2300.zip  \n",
            " extracting: training_datas/train_data29933.zip  \n",
            " extracting: training_datas/train_data13461.zip  \n",
            " extracting: training_datas/train_data2284.zip  \n",
            " extracting: training_datas/train_data4893.zip  \n",
            " extracting: training_datas/train_data16405.zip  \n",
            " extracting: training_datas/train_data13250.zip  \n",
            " extracting: training_datas/train_data14423.zip  \n",
            " extracting: training_datas/train_data10820.zip  \n",
            " extracting: training_datas/train_data10383.zip  \n",
            " extracting: training_datas/train_data3073.zip  \n",
            " extracting: training_datas/train_data27785.zip  \n",
            " extracting: training_datas/train_data674.zip  \n",
            " extracting: training_datas/train_data15836.zip  \n",
            " extracting: training_datas/train_data21302.zip  \n",
            " extracting: training_datas/train_data4889.zip  \n",
            " extracting: training_datas/train_data12255.zip  \n",
            " extracting: training_datas/train_data8339.zip  \n",
            " extracting: training_datas/train_data11897.zip  \n",
            " extracting: training_datas/train_data7405.zip  \n",
            " extracting: training_datas/train_data23948.zip  \n",
            " extracting: training_datas/train_data25406.zip  \n",
            " extracting: training_datas/train_data22580.zip  \n",
            " extracting: training_datas/train_data25165.zip  \n",
            " extracting: training_datas/train_data13619.zip  \n",
            " extracting: training_datas/train_data27063.zip  \n",
            " extracting: training_datas/train_data24175.zip  \n",
            " extracting: training_datas/train_data19152.zip  \n",
            " extracting: training_datas/train_data24789.zip  \n",
            " extracting: training_datas/train_data27132.zip  \n",
            " extracting: training_datas/train_data23758.zip  \n",
            " extracting: training_datas/train_data23346.zip  \n",
            " extracting: training_datas/train_data27229.zip  \n",
            " extracting: training_datas/train_data27653.zip  \n",
            " extracting: training_datas/train_data10892.zip  \n",
            " extracting: training_datas/train_data4300.zip  \n",
            " extracting: training_datas/train_data4980.zip  \n",
            " extracting: training_datas/train_data839.zip  \n",
            " extracting: training_datas/train_data29212.zip  \n",
            " extracting: training_datas/train_data21407.zip  \n",
            " extracting: training_datas/train_data3017.zip  \n",
            " extracting: training_datas/train_data27949.zip  \n",
            " extracting: training_datas/train_data12554.zip  \n",
            " extracting: training_datas/train_data27761.zip  \n",
            " extracting: training_datas/train_data5324.zip  \n",
            " extracting: training_datas/train_data20158.zip  \n",
            " extracting: training_datas/train_data13055.zip  \n",
            " extracting: training_datas/train_data25632.zip  \n",
            " extracting: training_datas/train_data14229.zip  \n",
            " extracting: training_datas/train_data27773.zip  \n",
            " extracting: training_datas/train_data21289.zip  \n",
            " extracting: training_datas/train_data20442.zip  \n",
            " extracting: training_datas/train_data12982.zip  \n",
            " extracting: training_datas/train_data1150.zip  \n",
            " extracting: training_datas/train_data14355.zip  \n",
            " extracting: training_datas/train_data27055.zip  \n",
            " extracting: training_datas/train_data19993.zip  \n",
            " extracting: training_datas/train_data28405.zip  \n",
            " extracting: training_datas/train_data21248.zip  \n",
            " extracting: training_datas/train_data10904.zip  \n",
            " extracting: training_datas/train_data25393.zip  \n",
            " extracting: training_datas/train_data760.zip  \n",
            " extracting: training_datas/train_data11189.zip  \n",
            " extracting: training_datas/train_data18982.zip  \n",
            " extracting: training_datas/train_data1650.zip  \n",
            " extracting: training_datas/train_data8667.zip  \n",
            " extracting: training_datas/train_data2757.zip  \n",
            " extracting: training_datas/train_data30433.zip  \n",
            " extracting: training_datas/train_data3224.zip  \n",
            " extracting: training_datas/train_data607.zip  \n",
            " extracting: training_datas/train_data621.zip  \n",
            " extracting: training_datas/train_data13656.zip  \n",
            " extracting: training_datas/train_data9350.zip  \n",
            " extracting: training_datas/train_data27415.zip  \n",
            " extracting: training_datas/train_data8775.zip  \n",
            " extracting: training_datas/train_data8710.zip  \n",
            " extracting: training_datas/train_data108.zip  \n",
            " extracting: training_datas/train_data6964.zip  \n",
            " extracting: training_datas/train_data5974.zip  \n",
            " extracting: training_datas/train_data14765.zip  \n",
            " extracting: training_datas/train_data14690.zip  \n",
            " extracting: training_datas/train_data12267.zip  \n",
            " extracting: training_datas/train_data24242.zip  \n",
            " extracting: training_datas/train_data28703.zip  \n",
            " extracting: training_datas/train_data2078.zip  \n",
            " extracting: training_datas/train_data19181.zip  \n",
            " extracting: training_datas/train_data28034.zip  \n",
            " extracting: training_datas/train_data1162.zip  \n",
            " extracting: training_datas/train_data18300.zip  \n",
            " extracting: training_datas/train_data19619.zip  \n",
            " extracting: training_datas/train_data27934.zip  \n",
            " extracting: training_datas/train_data24899.zip  \n",
            " extracting: training_datas/train_data11771.zip  \n",
            " extracting: training_datas/train_data24856.zip  \n",
            " extracting: training_datas/train_data7756.zip  \n",
            " extracting: training_datas/train_data17216.zip  \n",
            " extracting: training_datas/train_data15879.zip  \n",
            " extracting: training_datas/train_data21575.zip  \n",
            " extracting: training_datas/train_data7294.zip  \n",
            " extracting: training_datas/train_data27725.zip  \n",
            " extracting: training_datas/train_data23310.zip  \n",
            " extracting: training_datas/train_data16357.zip  \n",
            " extracting: training_datas/train_data5473.zip  \n",
            " extracting: training_datas/train_data8942.zip  \n",
            " extracting: training_datas/train_data27439.zip  \n",
            " extracting: training_datas/train_data5463.zip  \n",
            " extracting: training_datas/train_data26243.zip  \n",
            " extracting: training_datas/train_data20457.zip  \n",
            " extracting: training_datas/train_data11084.zip  \n",
            " extracting: training_datas/train_data13932.zip  \n",
            " extracting: training_datas/train_data2418.zip  \n",
            " extracting: training_datas/train_data27249.zip  \n",
            " extracting: training_datas/train_data4225.zip  \n",
            " extracting: training_datas/train_data15020.zip  \n",
            " extracting: training_datas/train_data10486.zip  \n",
            " extracting: training_datas/train_data20758.zip  \n",
            " extracting: training_datas/train_data27033.zip  \n",
            " extracting: training_datas/train_data20205.zip  \n",
            " extracting: training_datas/train_data22386.zip  \n",
            " extracting: training_datas/train_data6842.zip  \n",
            " extracting: training_datas/train_data21734.zip  \n",
            " extracting: training_datas/train_data30143.zip  \n",
            " extracting: training_datas/train_data9264.zip  \n",
            " extracting: training_datas/train_data19575.zip  \n",
            " extracting: training_datas/train_data27959.zip  \n",
            " extracting: training_datas/train_data29465.zip  \n",
            " extracting: training_datas/train_data21547.zip  \n",
            " extracting: training_datas/train_data28028.zip  \n",
            " extracting: training_datas/train_data1247.zip  \n",
            " extracting: training_datas/train_data5014.zip  \n",
            " extracting: training_datas/train_data20237.zip  \n",
            " extracting: training_datas/train_data26126.zip  \n",
            " extracting: training_datas/train_data4117.zip  \n",
            " extracting: training_datas/train_data7485.zip  \n",
            " extracting: training_datas/train_data15661.zip  \n",
            " extracting: training_datas/train_data12828.zip  \n",
            " extracting: training_datas/train_data7264.zip  \n",
            " extracting: training_datas/train_data21486.zip  \n",
            " extracting: training_datas/train_data5226.zip  \n",
            " extracting: training_datas/train_data10491.zip  \n",
            " extracting: training_datas/train_data4969.zip  \n",
            " extracting: training_datas/train_data20896.zip  \n",
            " extracting: training_datas/train_data9727.zip  \n",
            " extracting: training_datas/train_data23201.zip  \n",
            " extracting: training_datas/train_data11816.zip  \n",
            " extracting: training_datas/train_data28995.zip  \n",
            " extracting: training_datas/train_data14661.zip  \n",
            " extracting: training_datas/train_data6038.zip  \n",
            " extracting: training_datas/train_data9266.zip  \n",
            " extracting: training_datas/train_data24728.zip  \n",
            " extracting: training_datas/train_data1836.zip  \n",
            " extracting: training_datas/train_data24765.zip  \n",
            " extracting: training_datas/train_data4020.zip  \n",
            " extracting: training_datas/train_data11642.zip  \n",
            " extracting: training_datas/train_data8954.zip  \n",
            " extracting: training_datas/train_data10307.zip  \n",
            " extracting: training_datas/train_data29841.zip  \n",
            " extracting: training_datas/train_data25974.zip  \n",
            " extracting: training_datas/train_data18258.zip  \n",
            " extracting: training_datas/train_data17087.zip  \n",
            " extracting: training_datas/train_data7656.zip  \n",
            " extracting: training_datas/train_data17562.zip  \n",
            " extracting: training_datas/train_data27797.zip  \n",
            " extracting: training_datas/train_data9197.zip  \n",
            " extracting: training_datas/train_data11303.zip  \n",
            " extracting: training_datas/train_data20500.zip  \n",
            " extracting: training_datas/train_data30475.zip  \n",
            " extracting: training_datas/train_data13465.zip  \n",
            " extracting: training_datas/train_data21690.zip  \n",
            " extracting: training_datas/train_data21467.zip  \n",
            " extracting: training_datas/train_data10885.zip  \n",
            " extracting: training_datas/train_data30464.zip  \n",
            " extracting: training_datas/train_data6889.zip  \n",
            " extracting: training_datas/train_data14383.zip  \n",
            " extracting: training_datas/train_data10217.zip  \n",
            " extracting: training_datas/train_data5719.zip  \n",
            " extracting: training_datas/train_data7786.zip  \n",
            " extracting: training_datas/train_data22369.zip  \n",
            " extracting: training_datas/train_data10097.zip  \n",
            " extracting: training_datas/train_data14516.zip  \n",
            " extracting: training_datas/train_data20013.zip  \n",
            " extracting: training_datas/train_data19135.zip  \n",
            " extracting: training_datas/train_data2857.zip  \n",
            " extracting: training_datas/train_data17725.zip  \n",
            " extracting: training_datas/train_data10038.zip  \n",
            " extracting: training_datas/train_data24543.zip  \n",
            " extracting: training_datas/train_data28245.zip  \n",
            " extracting: training_datas/train_data21561.zip  \n",
            " extracting: training_datas/train_data13372.zip  \n",
            " extracting: training_datas/train_data30089.zip  \n",
            " extracting: training_datas/train_data14403.zip  \n",
            " extracting: training_datas/train_data20456.zip  \n",
            " extracting: training_datas/train_data26858.zip  \n",
            " extracting: training_datas/train_data28180.zip  \n",
            " extracting: training_datas/train_data23100.zip  \n",
            " extracting: training_datas/train_data20619.zip  \n",
            " extracting: training_datas/train_data29989.zip  \n",
            " extracting: training_datas/train_data20050.zip  \n",
            " extracting: training_datas/train_data5657.zip  \n",
            " extracting: training_datas/train_data11030.zip  \n",
            " extracting: training_datas/train_data6918.zip  \n",
            " extracting: training_datas/train_data10055.zip  \n",
            " extracting: training_datas/train_data7837.zip  \n",
            " extracting: training_datas/train_data22639.zip  \n",
            " extracting: training_datas/train_data14648.zip  \n",
            " extracting: training_datas/train_data4645.zip  \n",
            " extracting: training_datas/train_data21018.zip  \n",
            " extracting: training_datas/train_data27817.zip  \n",
            " extracting: training_datas/train_data4233.zip  \n",
            " extracting: training_datas/train_data5367.zip  \n",
            " extracting: training_datas/train_data18351.zip  \n",
            " extracting: training_datas/train_data13523.zip  \n",
            " extracting: training_datas/train_data4485.zip  \n",
            " extracting: training_datas/train_data19086.zip  \n",
            " extracting: training_datas/train_data22974.zip  \n",
            " extracting: training_datas/train_data8625.zip  \n",
            " extracting: training_datas/train_data10126.zip  \n",
            " extracting: training_datas/train_data9698.zip  \n",
            " extracting: training_datas/train_data11557.zip  \n",
            " extracting: training_datas/train_data29479.zip  \n",
            " extracting: training_datas/train_data7155.zip  \n",
            " extracting: training_datas/train_data7320.zip  \n",
            " extracting: training_datas/train_data21430.zip  \n",
            " extracting: training_datas/train_data7613.zip  \n",
            " extracting: training_datas/train_data2279.zip  \n",
            " extracting: training_datas/train_data1109.zip  \n",
            " extracting: training_datas/train_data18038.zip  \n",
            " extracting: training_datas/train_data8015.zip  \n",
            " extracting: training_datas/train_data16030.zip  \n",
            " extracting: training_datas/train_data4274.zip  \n",
            " extracting: training_datas/train_data12034.zip  \n",
            " extracting: training_datas/train_data7449.zip  \n",
            " extracting: training_datas/train_data28588.zip  \n",
            " extracting: training_datas/train_data8909.zip  \n",
            " extracting: training_datas/train_data11627.zip  \n",
            " extracting: training_datas/train_data4026.zip  \n",
            " extracting: training_datas/train_data23681.zip  \n",
            " extracting: training_datas/train_data20025.zip  \n",
            " extracting: training_datas/train_data4504.zip  \n",
            " extracting: training_datas/train_data21740.zip  \n",
            " extracting: training_datas/train_data26576.zip  \n",
            " extracting: training_datas/train_data2210.zip  \n",
            " extracting: training_datas/train_data7693.zip  \n",
            " extracting: training_datas/train_data2248.zip  \n",
            " extracting: training_datas/train_data4535.zip  \n",
            " extracting: training_datas/train_data25772.zip  \n",
            " extracting: training_datas/train_data18220.zip  \n",
            " extracting: training_datas/train_data2287.zip  \n",
            " extracting: training_datas/train_data13911.zip  \n",
            " extracting: training_datas/train_data6077.zip  \n",
            " extracting: training_datas/train_data25701.zip  \n",
            " extracting: training_datas/train_data16918.zip  \n",
            " extracting: training_datas/train_data19587.zip  \n",
            " extracting: training_datas/train_data2107.zip  \n",
            " extracting: training_datas/train_data12178.zip  \n",
            " extracting: training_datas/train_data21602.zip  \n",
            " extracting: training_datas/train_data14276.zip  \n",
            " extracting: training_datas/train_data10568.zip  \n",
            " extracting: training_datas/train_data20517.zip  \n",
            " extracting: training_datas/train_data2453.zip  \n",
            " extracting: training_datas/train_data10733.zip  \n",
            " extracting: training_datas/train_data13929.zip  \n",
            " extracting: training_datas/train_data11326.zip  \n",
            " extracting: training_datas/train_data20643.zip  \n",
            " extracting: training_datas/train_data9874.zip  \n",
            " extracting: training_datas/train_data17567.zip  \n",
            " extracting: training_datas/train_data1669.zip  \n",
            " extracting: training_datas/train_data22372.zip  \n",
            " extracting: training_datas/train_data19835.zip  \n",
            " extracting: training_datas/train_data6823.zip  \n",
            " extracting: training_datas/train_data29538.zip  \n",
            " extracting: training_datas/train_data18318.zip  \n",
            " extracting: training_datas/train_data14921.zip  \n",
            " extracting: training_datas/train_data13421.zip  \n",
            " extracting: training_datas/train_data20531.zip  \n",
            " extracting: training_datas/train_data5116.zip  \n",
            " extracting: training_datas/train_data17771.zip  \n",
            " extracting: training_datas/train_data12222.zip  \n",
            " extracting: training_datas/train_data14507.zip  \n",
            " extracting: training_datas/train_data5255.zip  \n",
            " extracting: training_datas/train_data5675.zip  \n",
            " extracting: training_datas/train_data564.zip  \n",
            " extracting: training_datas/train_data12356.zip  \n",
            " extracting: training_datas/train_data9386.zip  \n",
            " extracting: training_datas/train_data8325.zip  \n",
            " extracting: training_datas/train_data14356.zip  \n",
            " extracting: training_datas/train_data13788.zip  \n",
            " extracting: training_datas/train_data17934.zip  \n",
            " extracting: training_datas/train_data19289.zip  \n",
            " extracting: training_datas/train_data9422.zip  \n",
            " extracting: training_datas/train_data1623.zip  \n",
            " extracting: training_datas/train_data14093.zip  \n",
            " extracting: training_datas/train_data12234.zip  \n",
            " extracting: training_datas/train_data9050.zip  \n",
            " extracting: training_datas/train_data2422.zip  \n",
            " extracting: training_datas/train_data22739.zip  \n",
            " extracting: training_datas/train_data6307.zip  \n",
            " extracting: training_datas/train_data29268.zip  \n",
            " extracting: training_datas/train_data501.zip  \n",
            " extracting: training_datas/train_data21085.zip  \n",
            " extracting: training_datas/train_data26828.zip  \n",
            " extracting: training_datas/train_data30161.zip  \n",
            " extracting: training_datas/train_data29623.zip  \n",
            " extracting: training_datas/train_data14629.zip  \n",
            " extracting: training_datas/train_data11787.zip  \n",
            " extracting: training_datas/train_data19910.zip  \n",
            " extracting: training_datas/train_data21233.zip  \n",
            " extracting: training_datas/train_data17824.zip  \n",
            " extracting: training_datas/train_data12651.zip  \n",
            " extracting: training_datas/train_data8733.zip  \n",
            " extracting: training_datas/train_data15693.zip  \n",
            " extracting: training_datas/train_data29611.zip  \n",
            " extracting: training_datas/train_data4033.zip  \n",
            " extracting: training_datas/train_data27222.zip  \n",
            " extracting: training_datas/train_data7638.zip  \n",
            " extracting: training_datas/train_data8189.zip  \n",
            " extracting: training_datas/train_data13632.zip  \n",
            " extracting: training_datas/train_data1834.zip  \n",
            " extracting: training_datas/train_data27273.zip  \n",
            " extracting: training_datas/train_data4902.zip  \n",
            " extracting: training_datas/train_data2689.zip  \n",
            " extracting: training_datas/train_data24496.zip  \n",
            " extracting: training_datas/train_data5167.zip  \n",
            " extracting: training_datas/train_data19199.zip  \n",
            " extracting: training_datas/train_data7847.zip  \n",
            " extracting: training_datas/train_data12045.zip  \n",
            " extracting: training_datas/train_data178.zip  \n",
            " extracting: training_datas/train_data3624.zip  \n",
            " extracting: training_datas/train_data4390.zip  \n",
            " extracting: training_datas/train_data7215.zip  \n",
            " extracting: training_datas/train_data25932.zip  \n",
            " extracting: training_datas/train_data10759.zip  \n",
            " extracting: training_datas/train_data28258.zip  \n",
            " extracting: training_datas/train_data4511.zip  \n",
            " extracting: training_datas/train_data17017.zip  \n",
            " extracting: training_datas/train_data13529.zip  \n",
            " extracting: training_datas/train_data24723.zip  \n",
            " extracting: training_datas/train_data1429.zip  \n",
            " extracting: training_datas/train_data29817.zip  \n",
            " extracting: training_datas/train_data13890.zip  \n",
            " extracting: training_datas/train_data10489.zip  \n",
            " extracting: training_datas/train_data6280.zip  \n",
            " extracting: training_datas/train_data9413.zip  \n",
            " extracting: training_datas/train_data28847.zip  \n",
            " extracting: training_datas/train_data13493.zip  \n",
            " extracting: training_datas/train_data17040.zip  \n",
            " extracting: training_datas/train_data3841.zip  \n",
            " extracting: training_datas/train_data16428.zip  \n",
            " extracting: training_datas/train_data27335.zip  \n",
            " extracting: training_datas/train_data18213.zip  \n",
            " extracting: training_datas/train_data27552.zip  \n",
            " extracting: training_datas/train_data17085.zip  \n",
            " extracting: training_datas/train_data27708.zip  \n",
            " extracting: training_datas/train_data4729.zip  \n",
            " extracting: training_datas/train_data1324.zip  \n",
            " extracting: training_datas/train_data16640.zip  \n",
            " extracting: training_datas/train_data20611.zip  \n",
            " extracting: training_datas/train_data5570.zip  \n",
            " extracting: training_datas/train_data7052.zip  \n",
            " extracting: training_datas/train_data30033.zip  \n",
            " extracting: training_datas/train_data3822.zip  \n",
            " extracting: training_datas/train_data26064.zip  \n",
            " extracting: training_datas/train_data8630.zip  \n",
            " extracting: training_datas/train_data24453.zip  \n",
            " extracting: training_datas/train_data22794.zip  \n",
            " extracting: training_datas/train_data16169.zip  \n",
            " extracting: training_datas/train_data28304.zip  \n",
            " extracting: training_datas/train_data11067.zip  \n",
            " extracting: training_datas/train_data26657.zip  \n",
            " extracting: training_datas/train_data27779.zip  \n",
            " extracting: training_datas/train_data26956.zip  \n",
            " extracting: training_datas/train_data18127.zip  \n",
            " extracting: training_datas/train_data16509.zip  \n",
            " extracting: training_datas/train_data9868.zip  \n",
            " extracting: training_datas/train_data23208.zip  \n",
            " extracting: training_datas/train_data2129.zip  \n",
            " extracting: training_datas/train_data18037.zip  \n",
            " extracting: training_datas/train_data10205.zip  \n",
            " extracting: training_datas/train_data6078.zip  \n",
            " extracting: training_datas/train_data28661.zip  \n",
            " extracting: training_datas/train_data29661.zip  \n",
            " extracting: training_datas/train_data3121.zip  \n",
            " extracting: training_datas/train_data18699.zip  \n",
            " extracting: training_datas/train_data1043.zip  \n",
            " extracting: training_datas/train_data12929.zip  \n",
            " extracting: training_datas/train_data27814.zip  \n",
            " extracting: training_datas/train_data7255.zip  \n",
            " extracting: training_datas/train_data5046.zip  \n",
            " extracting: training_datas/train_data6061.zip  \n",
            " extracting: training_datas/train_data7919.zip  \n",
            " extracting: training_datas/train_data11672.zip  \n",
            " extracting: training_datas/train_data10369.zip  \n",
            " extracting: training_datas/train_data25787.zip  \n",
            " extracting: training_datas/train_data11276.zip  \n",
            " extracting: training_datas/train_data17001.zip  \n",
            " extracting: training_datas/train_data4502.zip  \n",
            " extracting: training_datas/train_data12343.zip  \n",
            " extracting: training_datas/train_data1861.zip  \n",
            " extracting: training_datas/train_data661.zip  \n",
            " extracting: training_datas/train_data25068.zip  \n",
            " extracting: training_datas/train_data22992.zip  \n",
            " extracting: training_datas/train_data1681.zip  \n",
            " extracting: training_datas/train_data8913.zip  \n",
            " extracting: training_datas/train_data19616.zip  \n",
            " extracting: training_datas/train_data13265.zip  \n",
            " extracting: training_datas/train_data15172.zip  \n",
            " extracting: training_datas/train_data3776.zip  \n",
            " extracting: training_datas/train_data14697.zip  \n",
            " extracting: training_datas/train_data1236.zip  \n",
            " extracting: training_datas/train_data15463.zip  \n",
            " extracting: training_datas/train_data2378.zip  \n",
            " extracting: training_datas/train_data5058.zip  \n",
            " extracting: training_datas/train_data4397.zip  \n",
            " extracting: training_datas/train_data3373.zip  \n",
            " extracting: training_datas/train_data26836.zip  \n",
            " extracting: training_datas/train_data28793.zip  \n",
            " extracting: training_datas/train_data4999.zip  \n",
            " extracting: training_datas/train_data6692.zip  \n",
            " extracting: training_datas/train_data8376.zip  \n",
            " extracting: training_datas/train_data4335.zip  \n",
            " extracting: training_datas/train_data3846.zip  \n",
            " extracting: training_datas/train_data11949.zip  \n",
            " extracting: training_datas/train_data22852.zip  \n",
            " extracting: training_datas/train_data9414.zip  \n",
            " extracting: training_datas/train_data7017.zip  \n",
            " extracting: training_datas/train_data23591.zip  \n",
            " extracting: training_datas/train_data4109.zip  \n",
            " extracting: training_datas/train_data15050.zip  \n",
            " extracting: training_datas/train_data28712.zip  \n",
            " extracting: training_datas/train_data19995.zip  \n",
            " extracting: training_datas/train_data7617.zip  \n",
            " extracting: training_datas/train_data9302.zip  \n",
            " extracting: training_datas/train_data11621.zip  \n",
            " extracting: training_datas/train_data22704.zip  \n",
            " extracting: training_datas/train_data5381.zip  \n",
            " extracting: training_datas/train_data25114.zip  \n",
            " extracting: training_datas/train_data25290.zip  \n",
            " extracting: training_datas/train_data24196.zip  \n",
            " extracting: training_datas/train_data16873.zip  \n",
            " extracting: training_datas/train_data4699.zip  \n",
            " extracting: training_datas/train_data3582.zip  \n",
            " extracting: training_datas/train_data22313.zip  \n",
            " extracting: training_datas/train_data3302.zip  \n",
            " extracting: training_datas/train_data18430.zip  \n",
            " extracting: training_datas/train_data26792.zip  \n",
            " extracting: training_datas/train_data21565.zip  \n",
            " extracting: training_datas/train_data12541.zip  \n",
            " extracting: training_datas/train_data30094.zip  \n",
            " extracting: training_datas/train_data20329.zip  \n",
            " extracting: training_datas/train_data9820.zip  \n",
            " extracting: training_datas/train_data20599.zip  \n",
            " extracting: training_datas/train_data19608.zip  \n",
            " extracting: training_datas/train_data26365.zip  \n",
            " extracting: training_datas/train_data24867.zip  \n",
            " extracting: training_datas/train_data5295.zip  \n",
            " extracting: training_datas/train_data10741.zip  \n",
            " extracting: training_datas/train_data23347.zip  \n",
            " extracting: training_datas/train_data3366.zip  \n",
            " extracting: training_datas/train_data11653.zip  \n",
            " extracting: training_datas/train_data8863.zip  \n",
            " extracting: training_datas/train_data8159.zip  \n",
            " extracting: training_datas/train_data3852.zip  \n",
            " extracting: training_datas/train_data19130.zip  \n",
            " extracting: training_datas/train_data28559.zip  \n",
            " extracting: training_datas/train_data9985.zip  \n",
            " extracting: training_datas/train_data8.zip  \n",
            " extracting: training_datas/train_data11965.zip  \n",
            " extracting: training_datas/train_data7694.zip  \n",
            " extracting: training_datas/train_data28909.zip  \n",
            " extracting: training_datas/train_data22458.zip  \n",
            " extracting: training_datas/train_data12297.zip  \n",
            " extracting: training_datas/train_data4447.zip  \n",
            " extracting: training_datas/train_data29550.zip  \n",
            " extracting: training_datas/train_data8445.zip  \n",
            " extracting: training_datas/train_data21542.zip  \n",
            " extracting: training_datas/train_data586.zip  \n",
            " extracting: training_datas/train_data2879.zip  \n",
            " extracting: training_datas/train_data17815.zip  \n",
            " extracting: training_datas/train_data17064.zip  \n",
            " extracting: training_datas/train_data14058.zip  \n",
            " extracting: training_datas/train_data16424.zip  \n",
            " extracting: training_datas/train_data28452.zip  \n",
            " extracting: training_datas/train_data8436.zip  \n",
            " extracting: training_datas/train_data19311.zip  \n",
            " extracting: training_datas/train_data2639.zip  \n",
            " extracting: training_datas/train_data5148.zip  \n",
            " extracting: training_datas/train_data4660.zip  \n",
            " extracting: training_datas/train_data16888.zip  \n",
            " extracting: training_datas/train_data4800.zip  \n",
            " extracting: training_datas/train_data15823.zip  \n",
            " extracting: training_datas/train_data29253.zip  \n",
            " extracting: training_datas/train_data29419.zip  \n",
            " extracting: training_datas/train_data24544.zip  \n",
            " extracting: training_datas/train_data11997.zip  \n",
            " extracting: training_datas/train_data16979.zip  \n",
            " extracting: training_datas/train_data25790.zip  \n",
            " extracting: training_datas/train_data1082.zip  \n",
            " extracting: training_datas/train_data12844.zip  \n",
            " extracting: training_datas/train_data20045.zip  \n",
            " extracting: training_datas/train_data25389.zip  \n",
            " extracting: training_datas/train_data11334.zip  \n",
            " extracting: training_datas/train_data9572.zip  \n",
            " extracting: training_datas/train_data24094.zip  \n",
            " extracting: training_datas/train_data28391.zip  \n",
            " extracting: training_datas/train_data6694.zip  \n",
            " extracting: training_datas/train_data22274.zip  \n",
            " extracting: training_datas/train_data13967.zip  \n",
            " extracting: training_datas/train_data1380.zip  \n",
            " extracting: training_datas/train_data10225.zip  \n",
            " extracting: training_datas/train_data23808.zip  \n",
            " extracting: training_datas/train_data16517.zip  \n",
            " extracting: training_datas/train_data9794.zip  \n",
            " extracting: training_datas/train_data6617.zip  \n",
            " extracting: training_datas/train_data5686.zip  \n",
            " extracting: training_datas/train_data9921.zip  \n",
            " extracting: training_datas/train_data1718.zip  \n",
            " extracting: training_datas/train_data7789.zip  \n",
            " extracting: training_datas/train_data18632.zip  \n",
            " extracting: training_datas/train_data11094.zip  \n",
            " extracting: training_datas/train_data26630.zip  \n",
            " extracting: training_datas/train_data18724.zip  \n",
            " extracting: training_datas/train_data28080.zip  \n",
            " extracting: training_datas/train_data23504.zip  \n",
            " extracting: training_datas/train_data15462.zip  \n",
            " extracting: training_datas/train_data27741.zip  \n",
            " extracting: training_datas/train_data29825.zip  \n",
            " extracting: training_datas/train_data7423.zip  \n",
            " extracting: training_datas/train_data17624.zip  \n",
            " extracting: training_datas/train_data26804.zip  \n",
            " extracting: training_datas/train_data11273.zip  \n",
            " extracting: training_datas/train_data904.zip  \n",
            " extracting: training_datas/train_data9971.zip  \n",
            " extracting: training_datas/train_data26962.zip  \n",
            " extracting: training_datas/train_data7242.zip  \n",
            " extracting: training_datas/train_data4445.zip  \n",
            " extracting: training_datas/train_data15569.zip  \n",
            " extracting: training_datas/train_data21896.zip  \n",
            " extracting: training_datas/train_data16478.zip  \n",
            " extracting: training_datas/train_data11286.zip  \n",
            " extracting: training_datas/train_data14949.zip  \n",
            " extracting: training_datas/train_data30035.zip  \n",
            " extracting: training_datas/train_data1354.zip  \n",
            " extracting: training_datas/train_data1164.zip  \n",
            " extracting: training_datas/train_data8806.zip  \n",
            " extracting: training_datas/train_data25558.zip  \n",
            " extracting: training_datas/train_data17392.zip  \n",
            " extracting: training_datas/train_data15715.zip  \n",
            " extracting: training_datas/train_data21901.zip  \n",
            " extracting: training_datas/train_data25504.zip  \n",
            " extracting: training_datas/train_data1022.zip  \n",
            " extracting: training_datas/train_data3372.zip  \n",
            " extracting: training_datas/train_data24685.zip  \n",
            " extracting: training_datas/train_data17398.zip  \n",
            " extracting: training_datas/train_data11985.zip  \n",
            " extracting: training_datas/train_data17947.zip  \n",
            " extracting: training_datas/train_data29162.zip  \n",
            " extracting: training_datas/train_data13330.zip  \n",
            " extracting: training_datas/train_data21632.zip  \n",
            " extracting: training_datas/train_data15476.zip  \n",
            " extracting: training_datas/train_data14870.zip  \n",
            " extracting: training_datas/train_data4885.zip  \n",
            " extracting: training_datas/train_data17621.zip  \n",
            " extracting: training_datas/train_data14120.zip  \n",
            " extracting: training_datas/train_data7923.zip  \n",
            " extracting: training_datas/train_data17498.zip  \n",
            " extracting: training_datas/train_data21000.zip  \n",
            " extracting: training_datas/train_data1786.zip  \n",
            " extracting: training_datas/train_data7090.zip  \n",
            " extracting: training_datas/train_data905.zip  \n",
            " extracting: training_datas/train_data13743.zip  \n",
            " extracting: training_datas/train_data12640.zip  \n",
            " extracting: training_datas/train_data295.zip  \n",
            " extracting: training_datas/train_data18788.zip  \n",
            " extracting: training_datas/train_data22159.zip  \n",
            " extracting: training_datas/train_data21594.zip  \n",
            " extracting: training_datas/train_data26359.zip  \n",
            " extracting: training_datas/train_data27735.zip  \n",
            " extracting: training_datas/train_data8612.zip  \n",
            " extracting: training_datas/train_data23978.zip  \n",
            " extracting: training_datas/train_data8487.zip  \n",
            " extracting: training_datas/train_data23829.zip  \n",
            " extracting: training_datas/train_data27513.zip  \n",
            " extracting: training_datas/train_data16950.zip  \n",
            " extracting: training_datas/train_data13180.zip  \n",
            " extracting: training_datas/train_data15995.zip  \n",
            " extracting: training_datas/train_data11153.zip  \n",
            " extracting: training_datas/train_data9539.zip  \n",
            " extracting: training_datas/train_data21118.zip  \n",
            " extracting: training_datas/train_data27679.zip  \n",
            " extracting: training_datas/train_data18986.zip  \n",
            " extracting: training_datas/train_data8113.zip  \n",
            " extracting: training_datas/train_data11923.zip  \n",
            " extracting: training_datas/train_data2420.zip  \n",
            " extracting: training_datas/train_data25335.zip  \n",
            " extracting: training_datas/train_data7413.zip  \n",
            " extracting: training_datas/train_data29972.zip  \n",
            " extracting: training_datas/train_data26619.zip  \n",
            " extracting: training_datas/train_data10337.zip  \n",
            " extracting: training_datas/train_data13426.zip  \n",
            " extracting: training_datas/train_data27532.zip  \n",
            " extracting: training_datas/train_data23422.zip  \n",
            " extracting: training_datas/train_data5662.zip  \n",
            " extracting: training_datas/train_data1403.zip  \n",
            " extracting: training_datas/train_data27094.zip  \n",
            " extracting: training_datas/train_data7284.zip  \n",
            " extracting: training_datas/train_data11847.zip  \n",
            " extracting: training_datas/train_data17942.zip  \n",
            " extracting: training_datas/train_data19813.zip  \n",
            " extracting: training_datas/train_data6730.zip  \n",
            " extracting: training_datas/train_data8204.zip  \n",
            " extracting: training_datas/train_data2507.zip  \n",
            " extracting: training_datas/train_data15601.zip  \n",
            " extracting: training_datas/train_data25136.zip  \n",
            " extracting: training_datas/train_data7792.zip  \n",
            " extracting: training_datas/train_data18358.zip  \n",
            " extracting: training_datas/train_data23381.zip  \n",
            " extracting: training_datas/train_data12008.zip  \n",
            " extracting: training_datas/train_data1783.zip  \n",
            " extracting: training_datas/train_data15455.zip  \n",
            " extracting: training_datas/train_data6317.zip  \n",
            " extracting: training_datas/train_data10934.zip  \n",
            " extracting: training_datas/train_data24970.zip  \n",
            " extracting: training_datas/train_data20603.zip  \n",
            " extracting: training_datas/train_data14018.zip  \n",
            " extracting: training_datas/train_data4780.zip  \n",
            " extracting: training_datas/train_data25035.zip  \n",
            " extracting: training_datas/train_data8718.zip  \n",
            " extracting: training_datas/train_data11352.zip  \n",
            " extracting: training_datas/train_data11434.zip  \n",
            " extracting: training_datas/train_data15047.zip  \n",
            " extracting: training_datas/train_data1225.zip  \n",
            " extracting: training_datas/train_data3643.zip  \n",
            " extracting: training_datas/train_data7173.zip  \n",
            " extracting: training_datas/train_data28073.zip  \n",
            " extracting: training_datas/train_data13280.zip  \n",
            " extracting: training_datas/train_data28980.zip  \n",
            " extracting: training_datas/train_data16625.zip  \n",
            " extracting: training_datas/train_data12761.zip  \n",
            " extracting: training_datas/train_data14441.zip  \n",
            " extracting: training_datas/train_data14195.zip  \n",
            " extracting: training_datas/train_data15594.zip  \n",
            " extracting: training_datas/train_data28417.zip  \n",
            " extracting: training_datas/train_data24053.zip  \n",
            " extracting: training_datas/train_data5538.zip  \n",
            " extracting: training_datas/train_data11069.zip  \n",
            " extracting: training_datas/train_data9855.zip  \n",
            " extracting: training_datas/train_data5401.zip  \n",
            " extracting: training_datas/train_data1212.zip  \n",
            " extracting: training_datas/train_data8802.zip  \n",
            " extracting: training_datas/train_data14681.zip  \n",
            " extracting: training_datas/train_data5252.zip  \n",
            " extracting: training_datas/train_data23059.zip  \n",
            " extracting: training_datas/train_data25150.zip  \n",
            " extracting: training_datas/train_data17290.zip  \n",
            " extracting: training_datas/train_data22065.zip  \n",
            " extracting: training_datas/train_data24066.zip  \n",
            " extracting: training_datas/train_data355.zip  \n",
            " extracting: training_datas/train_data24955.zip  \n",
            " extracting: training_datas/train_data23010.zip  \n",
            " extracting: training_datas/train_data5270.zip  \n",
            " extracting: training_datas/train_data26725.zip  \n",
            " extracting: training_datas/train_data20774.zip  \n",
            " extracting: training_datas/train_data2170.zip  \n",
            " extracting: training_datas/train_data28560.zip  \n",
            " extracting: training_datas/train_data9118.zip  \n",
            " extracting: training_datas/train_data16142.zip  \n",
            " extracting: training_datas/train_data29579.zip  \n",
            " extracting: training_datas/train_data9055.zip  \n",
            " extracting: training_datas/train_data21502.zip  \n",
            " extracting: training_datas/train_data26463.zip  \n",
            " extracting: training_datas/train_data23787.zip  \n",
            " extracting: training_datas/train_data7941.zip  \n",
            " extracting: training_datas/train_data6759.zip  \n",
            " extracting: training_datas/train_data4841.zip  \n",
            " extracting: training_datas/train_data20398.zip  \n",
            " extracting: training_datas/train_data556.zip  \n",
            " extracting: training_datas/train_data6472.zip  \n",
            " extracting: training_datas/train_data17170.zip  \n",
            " extracting: training_datas/train_data29969.zip  \n",
            " extracting: training_datas/train_data21256.zip  \n",
            " extracting: training_datas/train_data16694.zip  \n",
            " extracting: training_datas/train_data16628.zip  \n",
            " extracting: training_datas/train_data13183.zip  \n",
            " extracting: training_datas/train_data6308.zip  \n",
            " extracting: training_datas/train_data20798.zip  \n",
            " extracting: training_datas/train_data15360.zip  \n",
            " extracting: training_datas/train_data16994.zip  \n",
            " extracting: training_datas/train_data29673.zip  \n",
            " extracting: training_datas/train_data171.zip  \n",
            " extracting: training_datas/train_data26435.zip  \n",
            " extracting: training_datas/train_data25647.zip  \n",
            " extracting: training_datas/train_data25537.zip  \n",
            " extracting: training_datas/train_data23509.zip  \n",
            " extracting: training_datas/train_data7862.zip  \n",
            " extracting: training_datas/train_data22331.zip  \n",
            " extracting: training_datas/train_data28929.zip  \n",
            " extracting: training_datas/train_data13392.zip  \n",
            " extracting: training_datas/train_data9793.zip  \n",
            " extracting: training_datas/train_data28727.zip  \n",
            " extracting: training_datas/train_data6904.zip  \n",
            " extracting: training_datas/train_data1268.zip  \n",
            " extracting: training_datas/train_data5247.zip  \n",
            " extracting: training_datas/train_data9129.zip  \n",
            " extracting: training_datas/train_data21898.zip  \n",
            " extracting: training_datas/train_data25982.zip  \n",
            " extracting: training_datas/train_data13603.zip  \n",
            " extracting: training_datas/train_data13244.zip  \n",
            " extracting: training_datas/train_data20261.zip  \n",
            " extracting: training_datas/train_data24256.zip  \n",
            " extracting: training_datas/train_data6828.zip  \n",
            " extracting: training_datas/train_data18826.zip  \n",
            " extracting: training_datas/train_data18928.zip  \n",
            " extracting: training_datas/train_data12768.zip  \n",
            " extracting: training_datas/train_data9685.zip  \n",
            " extracting: training_datas/train_data13520.zip  \n",
            " extracting: training_datas/train_data8791.zip  \n",
            " extracting: training_datas/train_data11491.zip  \n",
            " extracting: training_datas/train_data8220.zip  \n",
            " extracting: training_datas/train_data27592.zip  \n",
            " extracting: training_datas/train_data23568.zip  \n",
            " extracting: training_datas/train_data28766.zip  \n",
            " extracting: training_datas/train_data13556.zip  \n",
            " extracting: training_datas/train_data5635.zip  \n",
            " extracting: training_datas/train_data18581.zip  \n",
            " extracting: training_datas/train_data10628.zip  \n",
            " extracting: training_datas/train_data5089.zip  \n",
            " extracting: training_datas/train_data3514.zip  \n",
            " extracting: training_datas/train_data15447.zip  \n",
            " extracting: training_datas/train_data15024.zip  \n",
            " extracting: training_datas/train_data10316.zip  \n",
            " extracting: training_datas/train_data20212.zip  \n",
            " extracting: training_datas/train_data21262.zip  \n",
            " extracting: training_datas/train_data28413.zip  \n",
            " extracting: training_datas/train_data1455.zip  \n",
            " extracting: training_datas/train_data17211.zip  \n",
            " extracting: training_datas/train_data25462.zip  \n",
            " extracting: training_datas/train_data7047.zip  \n",
            " extracting: training_datas/train_data10532.zip  \n",
            " extracting: training_datas/train_data23124.zip  \n",
            " extracting: training_datas/train_data12049.zip  \n",
            " extracting: training_datas/train_data9968.zip  \n",
            " extracting: training_datas/train_data22395.zip  \n",
            " extracting: training_datas/train_data7972.zip  \n",
            " extracting: training_datas/train_data16264.zip  \n",
            " extracting: training_datas/train_data1643.zip  \n",
            " extracting: training_datas/train_data6364.zip  \n",
            " extracting: training_datas/train_data15136.zip  \n",
            " extracting: training_datas/train_data16370.zip  \n",
            " extracting: training_datas/train_data12598.zip  \n",
            " extracting: training_datas/train_data852.zip  \n",
            " extracting: training_datas/train_data2677.zip  \n",
            " extracting: training_datas/train_data3399.zip  \n",
            " extracting: training_datas/train_data1355.zip  \n",
            " extracting: training_datas/train_data21506.zip  \n",
            " extracting: training_datas/train_data29301.zip  \n",
            " extracting: training_datas/train_data20719.zip  \n",
            " extracting: training_datas/train_data21880.zip  \n",
            " extracting: training_datas/train_data9959.zip  \n",
            " extracting: training_datas/train_data15309.zip  \n",
            " extracting: training_datas/train_data6066.zip  \n",
            " extracting: training_datas/train_data7167.zip  \n",
            " extracting: training_datas/train_data27362.zip  \n",
            " extracting: training_datas/train_data18068.zip  \n",
            " extracting: training_datas/train_data20234.zip  \n",
            " extracting: training_datas/train_data1985.zip  \n",
            " extracting: training_datas/train_data5839.zip  \n",
            " extracting: training_datas/train_data19547.zip  \n",
            " extracting: training_datas/train_data7905.zip  \n",
            " extracting: training_datas/train_data22955.zip  \n",
            " extracting: training_datas/train_data17285.zip  \n",
            " extracting: training_datas/train_data14382.zip  \n",
            " extracting: training_datas/train_data12394.zip  \n",
            " extracting: training_datas/train_data26089.zip  \n",
            " extracting: training_datas/train_data21946.zip  \n",
            " extracting: training_datas/train_data6253.zip  \n",
            " extracting: training_datas/train_data9932.zip  \n",
            " extracting: training_datas/train_data15108.zip  \n",
            " extracting: training_datas/train_data9624.zip  \n",
            " extracting: training_datas/train_data25586.zip  \n",
            " extracting: training_datas/train_data21607.zip  \n",
            " extracting: training_datas/train_data23789.zip  \n",
            " extracting: training_datas/train_data2049.zip  \n",
            " extracting: training_datas/train_data27082.zip  \n",
            " extracting: training_datas/train_data21960.zip  \n",
            " extracting: training_datas/train_data27041.zip  \n",
            " extracting: training_datas/train_data14625.zip  \n",
            " extracting: training_datas/train_data24203.zip  \n",
            " extracting: training_datas/train_data13061.zip  \n",
            " extracting: training_datas/train_data7920.zip  \n",
            " extracting: training_datas/train_data26931.zip  \n",
            " extracting: training_datas/train_data22796.zip  \n",
            " extracting: training_datas/train_data22050.zip  \n",
            " extracting: training_datas/train_data13599.zip  \n",
            " extracting: training_datas/train_data15765.zip  \n",
            " extracting: training_datas/train_data7201.zip  \n",
            " extracting: training_datas/train_data21588.zip  \n",
            " extracting: training_datas/train_data12030.zip  \n",
            " extracting: training_datas/train_data9211.zip  \n",
            " extracting: training_datas/train_data5332.zip  \n",
            " extracting: training_datas/train_data17271.zip  \n",
            " extracting: training_datas/train_data12938.zip  \n",
            " extracting: training_datas/train_data8111.zip  \n",
            " extracting: training_datas/train_data2251.zip  \n",
            " extracting: training_datas/train_data9711.zip  \n",
            " extracting: training_datas/train_data8375.zip  \n",
            " extracting: training_datas/train_data24987.zip  \n",
            " extracting: training_datas/train_data24211.zip  \n",
            " extracting: training_datas/train_data17768.zip  \n",
            " extracting: training_datas/train_data10570.zip  \n",
            " extracting: training_datas/train_data13293.zip  \n",
            " extracting: training_datas/train_data13159.zip  \n",
            " extracting: training_datas/train_data6354.zip  \n",
            " extracting: training_datas/train_data4083.zip  \n",
            " extracting: training_datas/train_data14411.zip  \n",
            " extracting: training_datas/train_data530.zip  \n",
            " extracting: training_datas/train_data26046.zip  \n",
            " extracting: training_datas/train_data13919.zip  \n",
            " extracting: training_datas/train_data29219.zip  \n",
            " extracting: training_datas/train_data23473.zip  \n",
            " extracting: training_datas/train_data25188.zip  \n",
            " extracting: training_datas/train_data27795.zip  \n",
            " extracting: training_datas/train_data28430.zip  \n",
            " extracting: training_datas/train_data8601.zip  \n",
            " extracting: training_datas/train_data27958.zip  \n",
            " extracting: training_datas/train_data23519.zip  \n",
            " extracting: training_datas/train_data6862.zip  \n",
            " extracting: training_datas/train_data21807.zip  \n",
            " extracting: training_datas/train_data26381.zip  \n",
            " extracting: training_datas/train_data18485.zip  \n",
            " extracting: training_datas/train_data18040.zip  \n",
            " extracting: training_datas/train_data21398.zip  \n",
            " extracting: training_datas/train_data14288.zip  \n",
            " extracting: training_datas/train_data7793.zip  \n",
            " extracting: training_datas/train_data5448.zip  \n",
            " extracting: training_datas/train_data16241.zip  \n",
            " extracting: training_datas/train_data29810.zip  \n",
            " extracting: training_datas/train_data25466.zip  \n",
            " extracting: training_datas/train_data21945.zip  \n",
            " extracting: training_datas/train_data30136.zip  \n",
            " extracting: training_datas/train_data9583.zip  \n",
            " extracting: training_datas/train_data13772.zip  \n",
            " extracting: training_datas/train_data5572.zip  \n",
            " extracting: training_datas/train_data20536.zip  \n",
            " extracting: training_datas/train_data5745.zip  \n",
            " extracting: training_datas/train_data11044.zip  \n",
            " extracting: training_datas/train_data25194.zip  \n",
            " extracting: training_datas/train_data28843.zip  \n",
            " extracting: training_datas/train_data9383.zip  \n",
            " extracting: training_datas/train_data14244.zip  \n",
            " extracting: training_datas/train_data1662.zip  \n",
            " extracting: training_datas/train_data25952.zip  \n",
            " extracting: training_datas/train_data25732.zip  \n",
            " extracting: training_datas/train_data12471.zip  \n",
            " extracting: training_datas/train_data23394.zip  \n",
            " extracting: training_datas/train_data6967.zip  \n",
            " extracting: training_datas/train_data23132.zip  \n",
            " extracting: training_datas/train_data17433.zip  \n",
            " extracting: training_datas/train_data8063.zip  \n",
            " extracting: training_datas/train_data24102.zip  \n",
            " extracting: training_datas/train_data23474.zip  \n",
            " extracting: training_datas/train_data11104.zip  \n",
            " extracting: training_datas/train_data4857.zip  \n",
            " extracting: training_datas/train_data29800.zip  \n",
            " extracting: training_datas/train_data12183.zip  \n",
            " extracting: training_datas/train_data22437.zip  \n",
            " extracting: training_datas/train_data24633.zip  \n",
            " extracting: training_datas/train_data26833.zip  \n",
            " extracting: training_datas/train_data10987.zip  \n",
            " extracting: training_datas/train_data8400.zip  \n",
            " extracting: training_datas/train_data2143.zip  \n",
            " extracting: training_datas/train_data2932.zip  \n",
            " extracting: training_datas/train_data24347.zip  \n",
            " extracting: training_datas/train_data1770.zip  \n",
            " extracting: training_datas/train_data23066.zip  \n",
            " extracting: training_datas/train_data14839.zip  \n",
            " extracting: training_datas/train_data15724.zip  \n",
            " extracting: training_datas/train_data18796.zip  \n",
            " extracting: training_datas/train_data18078.zip  \n",
            " extracting: training_datas/train_data7535.zip  \n",
            " extracting: training_datas/train_data2979.zip  \n",
            " extracting: training_datas/train_data22335.zip  \n",
            " extracting: training_datas/train_data24473.zip  \n",
            " extracting: training_datas/train_data16086.zip  \n",
            " extracting: training_datas/train_data6689.zip  \n",
            " extracting: training_datas/train_data5174.zip  \n",
            " extracting: training_datas/train_data30173.zip  \n",
            " extracting: training_datas/train_data4718.zip  \n",
            " extracting: training_datas/train_data9282.zip  \n",
            " extracting: training_datas/train_data492.zip  \n",
            " extracting: training_datas/train_data7655.zip  \n",
            " extracting: training_datas/train_data5624.zip  \n",
            " extracting: training_datas/train_data16946.zip  \n",
            " extracting: training_datas/train_data26951.zip  \n",
            " extracting: training_datas/train_data8053.zip  \n",
            " extracting: training_datas/train_data4989.zip  \n",
            " extracting: training_datas/train_data20513.zip  \n",
            " extracting: training_datas/train_data24150.zip  \n",
            " extracting: training_datas/train_data531.zip  \n",
            " extracting: training_datas/train_data11222.zip  \n",
            " extracting: training_datas/train_data29213.zip  \n",
            " extracting: training_datas/train_data17739.zip  \n",
            " extracting: training_datas/train_data11200.zip  \n",
            " extracting: training_datas/train_data23953.zip  \n",
            " extracting: training_datas/train_data23258.zip  \n",
            " extracting: training_datas/train_data18871.zip  \n",
            " extracting: training_datas/train_data16528.zip  \n",
            " extracting: training_datas/train_data15442.zip  \n",
            " extracting: training_datas/train_data22626.zip  \n",
            " extracting: training_datas/train_data16098.zip  \n",
            " extracting: training_datas/train_data19605.zip  \n",
            " extracting: training_datas/train_data20533.zip  \n",
            " extracting: training_datas/train_data1203.zip  \n",
            " extracting: training_datas/train_data25334.zip  \n",
            " extracting: training_datas/train_data23533.zip  \n",
            " extracting: training_datas/train_data2846.zip  \n",
            " extracting: training_datas/train_data9824.zip  \n",
            " extracting: training_datas/train_data2829.zip  \n",
            " extracting: training_datas/train_data9979.zip  \n",
            " extracting: training_datas/train_data3575.zip  \n",
            " extracting: training_datas/train_data4120.zip  \n",
            " extracting: training_datas/train_data16095.zip  \n",
            " extracting: training_datas/train_data1676.zip  \n",
            " extracting: training_datas/train_data20071.zip  \n",
            " extracting: training_datas/train_data1964.zip  \n",
            " extracting: training_datas/train_data2537.zip  \n",
            " extracting: training_datas/train_data16090.zip  \n",
            " extracting: training_datas/train_data72.zip  \n",
            " extracting: training_datas/train_data17872.zip  \n",
            " extracting: training_datas/train_data13125.zip  \n",
            " extracting: training_datas/train_data14444.zip  \n",
            " extracting: training_datas/train_data1221.zip  \n",
            " extracting: training_datas/train_data25236.zip  \n",
            " extracting: training_datas/train_data5900.zip  \n",
            " extracting: training_datas/train_data12280.zip  \n",
            " extracting: training_datas/train_data26372.zip  \n",
            " extracting: training_datas/train_data29942.zip  \n",
            " extracting: training_datas/train_data10813.zip  \n",
            " extracting: training_datas/train_data23955.zip  \n",
            " extracting: training_datas/train_data19356.zip  \n",
            " extracting: training_datas/train_data19482.zip  \n",
            " extracting: training_datas/train_data20444.zip  \n",
            " extracting: training_datas/train_data8423.zip  \n",
            " extracting: training_datas/train_data22655.zip  \n",
            " extracting: training_datas/train_data5592.zip  \n",
            " extracting: training_datas/train_data8240.zip  \n",
            " extracting: training_datas/train_data25943.zip  \n",
            " extracting: training_datas/train_data12139.zip  \n",
            " extracting: training_datas/train_data28819.zip  \n",
            " extracting: training_datas/train_data28001.zip  \n",
            " extracting: training_datas/train_data15493.zip  \n",
            " extracting: training_datas/train_data25223.zip  \n",
            " extracting: training_datas/train_data9277.zip  \n",
            " extracting: training_datas/train_data27588.zip  \n",
            " extracting: training_datas/train_data14180.zip  \n",
            " extracting: training_datas/train_data8097.zip  \n",
            " extracting: training_datas/train_data16879.zip  \n",
            " extracting: training_datas/train_data4910.zip  \n",
            " extracting: training_datas/train_data2536.zip  \n",
            " extracting: training_datas/train_data3684.zip  \n",
            " extracting: training_datas/train_data7435.zip  \n",
            " extracting: training_datas/train_data14770.zip  \n",
            " extracting: training_datas/train_data21646.zip  \n",
            " extracting: training_datas/train_data16229.zip  \n",
            " extracting: training_datas/train_data27545.zip  \n",
            " extracting: training_datas/train_data13168.zip  \n",
            " extracting: training_datas/train_data5614.zip  \n",
            " extracting: training_datas/train_data20031.zip  \n",
            " extracting: training_datas/train_data4079.zip  \n",
            " extracting: training_datas/train_data11644.zip  \n",
            " extracting: training_datas/train_data5406.zip  \n",
            " extracting: training_datas/train_data6949.zip  \n",
            " extracting: training_datas/train_data23801.zip  \n",
            " extracting: training_datas/train_data11232.zip  \n",
            " extracting: training_datas/train_data3076.zip  \n",
            " extracting: training_datas/train_data9403.zip  \n",
            " extracting: training_datas/train_data24913.zip  \n",
            " extracting: training_datas/train_data21103.zip  \n",
            " extracting: training_datas/train_data12470.zip  \n",
            " extracting: training_datas/train_data9900.zip  \n",
            " extracting: training_datas/train_data17220.zip  \n",
            " extracting: training_datas/train_data21611.zip  \n",
            " extracting: training_datas/train_data24261.zip  \n",
            " extracting: training_datas/train_data25016.zip  \n",
            " extracting: training_datas/train_data16699.zip  \n",
            " extracting: training_datas/train_data26044.zip  \n",
            " extracting: training_datas/train_data29223.zip  \n",
            " extracting: training_datas/train_data26379.zip  \n",
            " extracting: training_datas/train_data30186.zip  \n",
            " extracting: training_datas/train_data28850.zip  \n",
            " extracting: training_datas/train_data17767.zip  \n",
            " extracting: training_datas/train_data16985.zip  \n",
            " extracting: training_datas/train_data19247.zip  \n",
            " extracting: training_datas/train_data10986.zip  \n",
            " extracting: training_datas/train_data30092.zip  \n",
            " extracting: training_datas/train_data5505.zip  \n",
            " extracting: training_datas/train_data6998.zip  \n",
            " extracting: training_datas/train_data7074.zip  \n",
            " extracting: training_datas/train_data14576.zip  \n",
            " extracting: training_datas/train_data8743.zip  \n",
            " extracting: training_datas/train_data19385.zip  \n",
            " extracting: training_datas/train_data5688.zip  \n",
            " extracting: training_datas/train_data683.zip  \n",
            " extracting: training_datas/train_data6463.zip  \n",
            " extracting: training_datas/train_data1038.zip  \n",
            " extracting: training_datas/train_data7272.zip  \n",
            " extracting: training_datas/train_data5796.zip  \n",
            " extracting: training_datas/train_data10514.zip  \n",
            " extracting: training_datas/train_data7516.zip  \n",
            " extracting: training_datas/train_data5379.zip  \n",
            " extracting: training_datas/train_data22840.zip  \n",
            " extracting: training_datas/train_data4781.zip  \n",
            " extracting: training_datas/train_data30175.zip  \n",
            " extracting: training_datas/train_data19567.zip  \n",
            " extracting: training_datas/train_data27978.zip  \n",
            " extracting: training_datas/train_data27446.zip  \n",
            " extracting: training_datas/train_data14002.zip  \n",
            " extracting: training_datas/train_data5353.zip  \n",
            " extracting: training_datas/train_data6367.zip  \n",
            " extracting: training_datas/train_data4128.zip  \n",
            " extracting: training_datas/train_data17406.zip  \n",
            " extracting: training_datas/train_data24693.zip  \n",
            " extracting: training_datas/train_data29898.zip  \n",
            " extracting: training_datas/train_data11397.zip  \n",
            " extracting: training_datas/train_data23534.zip  \n",
            " extracting: training_datas/train_data10544.zip  \n",
            " extracting: training_datas/train_data4510.zip  \n",
            " extracting: training_datas/train_data1351.zip  \n",
            " extracting: training_datas/train_data21744.zip  \n",
            " extracting: training_datas/train_data17958.zip  \n",
            " extracting: training_datas/train_data8605.zip  \n",
            " extracting: training_datas/train_data8466.zip  \n",
            " extracting: training_datas/train_data12913.zip  \n",
            " extracting: training_datas/train_data15430.zip  \n",
            " extracting: training_datas/train_data26130.zip  \n",
            " extracting: training_datas/train_data17649.zip  \n",
            " extracting: training_datas/train_data15017.zip  \n",
            " extracting: training_datas/train_data11413.zip  \n",
            " extracting: training_datas/train_data17358.zip  \n",
            " extracting: training_datas/train_data11605.zip  \n",
            " extracting: training_datas/train_data5639.zip  \n",
            " extracting: training_datas/train_data1445.zip  \n",
            " extracting: training_datas/train_data5948.zip  \n",
            " extracting: training_datas/train_data1209.zip  \n",
            " extracting: training_datas/train_data27301.zip  \n",
            " extracting: training_datas/train_data16631.zip  \n",
            " extracting: training_datas/train_data23242.zip  \n",
            " extracting: training_datas/train_data11173.zip  \n",
            " extracting: training_datas/train_data12587.zip  \n",
            " extracting: training_datas/train_data8570.zip  \n",
            " extracting: training_datas/train_data10394.zip  \n",
            " extracting: training_datas/train_data17455.zip  \n",
            " extracting: training_datas/train_data766.zip  \n",
            " extracting: training_datas/train_data13309.zip  \n",
            " extracting: training_datas/train_data25797.zip  \n",
            " extracting: training_datas/train_data28144.zip  \n",
            " extracting: training_datas/train_data7379.zip  \n",
            " extracting: training_datas/train_data15656.zip  \n",
            " extracting: training_datas/train_data14070.zip  \n",
            " extracting: training_datas/train_data2222.zip  \n",
            " extracting: training_datas/train_data20118.zip  \n",
            " extracting: training_datas/train_data19716.zip  \n",
            " extracting: training_datas/train_data23359.zip  \n",
            " extracting: training_datas/train_data9398.zip  \n",
            " extracting: training_datas/train_data27931.zip  \n",
            " extracting: training_datas/train_data10333.zip  \n",
            " extracting: training_datas/train_data7426.zip  \n",
            " extracting: training_datas/train_data3966.zip  \n",
            " extracting: training_datas/train_data8995.zip  \n",
            " extracting: training_datas/train_data9977.zip  \n",
            " extracting: training_datas/train_data29064.zip  \n",
            " extracting: training_datas/train_data28111.zip  \n",
            " extracting: training_datas/train_data20273.zip  \n",
            " extracting: training_datas/train_data29472.zip  \n",
            " extracting: training_datas/train_data24417.zip  \n",
            " extracting: training_datas/train_data22306.zip  \n",
            " extracting: training_datas/train_data10200.zip  \n",
            " extracting: training_datas/train_data1348.zip  \n",
            " extracting: training_datas/train_data28039.zip  \n",
            " extracting: training_datas/train_data24658.zip  \n",
            " extracting: training_datas/train_data12275.zip  \n",
            " extracting: training_datas/train_data11799.zip  \n",
            " extracting: training_datas/train_data1789.zip  \n",
            " extracting: training_datas/train_data17534.zip  \n",
            " extracting: training_datas/train_data15347.zip  \n",
            " extracting: training_datas/train_data19449.zip  \n",
            " extracting: training_datas/train_data12718.zip  \n",
            " extracting: training_datas/train_data4092.zip  \n",
            " extracting: training_datas/train_data14277.zip  \n",
            " extracting: training_datas/train_data27447.zip  \n",
            " extracting: training_datas/train_data27576.zip  \n",
            " extracting: training_datas/train_data8922.zip  \n",
            " extracting: training_datas/train_data17716.zip  \n",
            " extracting: training_datas/train_data19692.zip  \n",
            " extracting: training_datas/train_data1210.zip  \n",
            " extracting: training_datas/train_data29712.zip  \n",
            " extracting: training_datas/train_data28586.zip  \n",
            " extracting: training_datas/train_data26192.zip  \n",
            " extracting: training_datas/train_data30421.zip  \n",
            " extracting: training_datas/train_data14521.zip  \n",
            " extracting: training_datas/train_data11126.zip  \n",
            " extracting: training_datas/train_data21802.zip  \n",
            " extracting: training_datas/train_data12715.zip  \n",
            " extracting: training_datas/train_data21183.zip  \n",
            " extracting: training_datas/train_data24704.zip  \n",
            " extracting: training_datas/train_data9692.zip  \n",
            " extracting: training_datas/train_data11612.zip  \n",
            " extracting: training_datas/train_data3710.zip  \n",
            " extracting: training_datas/train_data27308.zip  \n",
            " extracting: training_datas/train_data27848.zip  \n",
            " extracting: training_datas/train_data26690.zip  \n",
            " extracting: training_datas/train_data7232.zip  \n",
            " extracting: training_datas/train_data5384.zip  \n",
            " extracting: training_datas/train_data29622.zip  \n",
            " extracting: training_datas/train_data30040.zip  \n",
            " extracting: training_datas/train_data28360.zip  \n",
            " extracting: training_datas/train_data11043.zip  \n",
            " extracting: training_datas/train_data19218.zip  \n",
            " extracting: training_datas/train_data20738.zip  \n",
            " extracting: training_datas/train_data14412.zip  \n",
            " extracting: training_datas/train_data17843.zip  \n",
            " extracting: training_datas/train_data5138.zip  \n",
            " extracting: training_datas/train_data17547.zip  \n",
            " extracting: training_datas/train_data23158.zip  \n",
            " extracting: training_datas/train_data6574.zip  \n",
            " extracting: training_datas/train_data19939.zip  \n",
            " extracting: training_datas/train_data2680.zip  \n",
            " extracting: training_datas/train_data1745.zip  \n",
            " extracting: training_datas/train_data28635.zip  \n",
            " extracting: training_datas/train_data29146.zip  \n",
            " extracting: training_datas/train_data17488.zip  \n",
            " extracting: training_datas/train_data24535.zip  \n",
            " extracting: training_datas/train_data29077.zip  \n",
            " extracting: training_datas/train_data26817.zip  \n",
            " extracting: training_datas/train_data22931.zip  \n",
            " extracting: training_datas/train_data2972.zip  \n",
            " extracting: training_datas/train_data543.zip  \n",
            " extracting: training_datas/train_data29483.zip  \n",
            " extracting: training_datas/train_data17071.zip  \n",
            " extracting: training_datas/train_data7674.zip  \n",
            " extracting: training_datas/train_data14892.zip  \n",
            " extracting: training_datas/train_data18879.zip  \n",
            " extracting: training_datas/train_data4394.zip  \n",
            " extracting: training_datas/train_data16687.zip  \n",
            " extracting: training_datas/train_data4199.zip  \n",
            " extracting: training_datas/train_data2199.zip  \n",
            " extracting: training_datas/train_data24031.zip  \n",
            " extracting: training_datas/train_data11162.zip  \n",
            " extracting: training_datas/train_data9618.zip  \n",
            " extracting: training_datas/train_data24288.zip  \n",
            " extracting: training_datas/train_data12274.zip  \n",
            " extracting: training_datas/train_data14630.zip  \n",
            " extracting: training_datas/train_data5260.zip  \n",
            " extracting: training_datas/train_data19287.zip  \n",
            " extracting: training_datas/train_data11435.zip  \n",
            " extracting: training_datas/train_data4760.zip  \n",
            " extracting: training_datas/train_data16390.zip  \n",
            " extracting: training_datas/train_data14473.zip  \n",
            " extracting: training_datas/train_data3694.zip  \n",
            " extracting: training_datas/train_data11214.zip  \n",
            " extracting: training_datas/train_data23949.zip  \n",
            " extracting: training_datas/train_data13170.zip  \n",
            " extracting: training_datas/train_data12144.zip  \n",
            " extracting: training_datas/train_data8818.zip  \n",
            " extracting: training_datas/train_data26273.zip  \n",
            " extracting: training_datas/train_data22154.zip  \n",
            " extracting: training_datas/train_data4170.zip  \n",
            " extracting: training_datas/train_data29805.zip  \n",
            " extracting: training_datas/train_data2071.zip  \n",
            " extracting: training_datas/train_data14787.zip  \n",
            " extracting: training_datas/train_data9251.zip  \n",
            " extracting: training_datas/train_data8915.zip  \n",
            " extracting: training_datas/train_data22321.zip  \n",
            " extracting: training_datas/train_data18805.zip  \n",
            " extracting: training_datas/train_data3891.zip  \n",
            " extracting: training_datas/train_data19070.zip  \n",
            " extracting: training_datas/train_data7446.zip  \n",
            " extracting: training_datas/train_data14855.zip  \n",
            " extracting: training_datas/train_data198.zip  \n",
            " extracting: training_datas/train_data7120.zip  \n",
            " extracting: training_datas/train_data14698.zip  \n",
            " extracting: training_datas/train_data13939.zip  \n",
            " extracting: training_datas/train_data25282.zip  \n",
            " extracting: training_datas/train_data6125.zip  \n",
            " extracting: training_datas/train_data20843.zip  \n",
            " extracting: training_datas/train_data1794.zip  \n",
            " extracting: training_datas/train_data6590.zip  \n",
            " extracting: training_datas/train_data2203.zip  \n",
            " extracting: training_datas/train_data6417.zip  \n",
            " extracting: training_datas/train_data21603.zip  \n",
            " extracting: training_datas/train_data14230.zip  \n",
            " extracting: training_datas/train_data24533.zip  \n",
            " extracting: training_datas/train_data25649.zip  \n",
            " extracting: training_datas/train_data6994.zip  \n",
            " extracting: training_datas/train_data10031.zip  \n",
            " extracting: training_datas/train_data11828.zip  \n",
            " extracting: training_datas/train_data9789.zip  \n",
            " extracting: training_datas/train_data2488.zip  \n",
            " extracting: training_datas/train_data20694.zip  \n",
            " extracting: training_datas/train_data5611.zip  \n",
            " extracting: training_datas/train_data26302.zip  \n",
            " extracting: training_datas/train_data17370.zip  \n",
            " extracting: training_datas/train_data28924.zip  \n",
            " extracting: training_datas/train_data21324.zip  \n",
            " extracting: training_datas/train_data8967.zip  \n",
            " extracting: training_datas/train_data29398.zip  \n",
            " extracting: training_datas/train_data13185.zip  \n",
            " extracting: training_datas/train_data15520.zip  \n",
            " extracting: training_datas/train_data21051.zip  \n",
            " extracting: training_datas/train_data19442.zip  \n",
            " extracting: training_datas/train_data29762.zip  \n",
            " extracting: training_datas/train_data26047.zip  \n",
            " extracting: training_datas/train_data24398.zip  \n",
            " extracting: training_datas/train_data23191.zip  \n",
            " extracting: training_datas/train_data17519.zip  \n",
            " extracting: training_datas/train_data30337.zip  \n",
            " extracting: training_datas/train_data3257.zip  \n",
            " extracting: training_datas/train_data3052.zip  \n",
            " extracting: training_datas/train_data5999.zip  \n",
            " extracting: training_datas/train_data6326.zip  \n",
            " extracting: training_datas/train_data12925.zip  \n",
            " extracting: training_datas/train_data18540.zip  \n",
            " extracting: training_datas/train_data5845.zip  \n",
            " extracting: training_datas/train_data8677.zip  \n",
            " extracting: training_datas/train_data19439.zip  \n",
            " extracting: training_datas/train_data28557.zip  \n",
            " extracting: training_datas/train_data727.zip  \n",
            " extracting: training_datas/train_data23493.zip  \n",
            " extracting: training_datas/train_data26883.zip  \n",
            " extracting: training_datas/train_data8950.zip  \n",
            " extracting: training_datas/train_data6065.zip  \n",
            " extracting: training_datas/train_data15514.zip  \n",
            " extracting: training_datas/train_data18184.zip  \n",
            " extracting: training_datas/train_data18658.zip  \n",
            " extracting: training_datas/train_data16141.zip  \n",
            " extracting: training_datas/train_data28308.zip  \n",
            " extracting: training_datas/train_data21757.zip  \n",
            " extracting: training_datas/train_data29701.zip  \n",
            " extracting: training_datas/train_data5943.zip  \n",
            " extracting: training_datas/train_data23806.zip  \n",
            " extracting: training_datas/train_data98.zip  \n",
            " extracting: training_datas/train_data20108.zip  \n",
            " extracting: training_datas/train_data23696.zip  \n",
            " extracting: training_datas/train_data3254.zip  \n",
            " extracting: training_datas/train_data15771.zip  \n",
            " extracting: training_datas/train_data6309.zip  \n",
            " extracting: training_datas/train_data4600.zip  \n",
            " extracting: training_datas/train_data22793.zip  \n",
            " extracting: training_datas/train_data7234.zip  \n",
            " extracting: training_datas/train_data2452.zip  \n",
            " extracting: training_datas/train_data19182.zip  \n",
            " extracting: training_datas/train_data22396.zip  \n",
            " extracting: training_datas/train_data9116.zip  \n",
            " extracting: training_datas/train_data18336.zip  \n",
            " extracting: training_datas/train_data21566.zip  \n",
            " extracting: training_datas/train_data16469.zip  \n",
            " extracting: training_datas/train_data2029.zip  \n",
            " extracting: training_datas/train_data12386.zip  \n",
            " extracting: training_datas/train_data20468.zip  \n",
            " extracting: training_datas/train_data21627.zip  \n",
            " extracting: training_datas/train_data843.zip  \n",
            " extracting: training_datas/train_data30232.zip  \n",
            " extracting: training_datas/train_data22475.zip  \n",
            " extracting: training_datas/train_data22015.zip  \n",
            " extracting: training_datas/train_data23500.zip  \n",
            " extracting: training_datas/train_data11051.zip  \n",
            " extracting: training_datas/train_data14954.zip  \n",
            " extracting: training_datas/train_data17993.zip  \n",
            " extracting: training_datas/train_data2147.zip  \n",
            " extracting: training_datas/train_data2562.zip  \n",
            " extracting: training_datas/train_data20779.zip  \n",
            " extracting: training_datas/train_data204.zip  \n",
            " extracting: training_datas/train_data28866.zip  \n",
            " extracting: training_datas/train_data8026.zip  \n",
            " extracting: training_datas/train_data19346.zip  \n",
            " extracting: training_datas/train_data21014.zip  \n",
            " extracting: training_datas/train_data26814.zip  \n",
            " extracting: training_datas/train_data1132.zip  \n",
            " extracting: training_datas/train_data6501.zip  \n",
            " extracting: training_datas/train_data10015.zip  \n",
            " extracting: training_datas/train_data23959.zip  \n",
            " extracting: training_datas/train_data27965.zip  \n",
            " extracting: training_datas/train_data20084.zip  \n",
            " extracting: training_datas/train_data11704.zip  \n",
            " extracting: training_datas/train_data13700.zip  \n",
            " extracting: training_datas/train_data1631.zip  \n",
            " extracting: training_datas/train_data25844.zip  \n",
            " extracting: training_datas/train_data28495.zip  \n",
            " extracting: training_datas/train_data11055.zip  \n",
            " extracting: training_datas/train_data27985.zip  \n",
            " extracting: training_datas/train_data17730.zip  \n",
            " extracting: training_datas/train_data28679.zip  \n",
            " extracting: training_datas/train_data16559.zip  \n",
            " extracting: training_datas/train_data6183.zip  \n",
            " extracting: training_datas/train_data12931.zip  \n",
            " extracting: training_datas/train_data6336.zip  \n",
            " extracting: training_datas/train_data21140.zip  \n",
            " extracting: training_datas/train_data26034.zip  \n",
            " extracting: training_datas/train_data10575.zip  \n",
            " extracting: training_datas/train_data10530.zip  \n",
            " extracting: training_datas/train_data4451.zip  \n",
            " extracting: training_datas/train_data29957.zip  \n",
            " extracting: training_datas/train_data11025.zip  \n",
            " extracting: training_datas/train_data16936.zip  \n",
            " extracting: training_datas/train_data27633.zip  \n",
            " extracting: training_datas/train_data21260.zip  \n",
            " extracting: training_datas/train_data954.zip  \n",
            " extracting: training_datas/train_data12260.zip  \n",
            " extracting: training_datas/train_data8529.zip  \n",
            " extracting: training_datas/train_data28055.zip  \n",
            " extracting: training_datas/train_data9234.zip  \n",
            " extracting: training_datas/train_data1373.zip  \n",
            " extracting: training_datas/train_data23316.zip  \n",
            " extracting: training_datas/train_data2443.zip  \n",
            " extracting: training_datas/train_data24298.zip  \n",
            " extracting: training_datas/train_data18099.zip  \n",
            " extracting: training_datas/train_data7886.zip  \n",
            " extracting: training_datas/train_data19203.zip  \n",
            " extracting: training_datas/train_data28667.zip  \n",
            " extracting: training_datas/train_data6502.zip  \n",
            " extracting: training_datas/train_data8656.zip  \n",
            " extracting: training_datas/train_data9724.zip  \n",
            " extracting: training_datas/train_data23496.zip  \n",
            " extracting: training_datas/train_data15837.zip  \n",
            " extracting: training_datas/train_data20006.zip  \n",
            " extracting: training_datas/train_data20526.zip  \n",
            " extracting: training_datas/train_data4659.zip  \n",
            " extracting: training_datas/train_data16768.zip  \n",
            " extracting: training_datas/train_data30331.zip  \n",
            " extracting: training_datas/train_data22356.zip  \n",
            " extracting: training_datas/train_data20846.zip  \n",
            " extracting: training_datas/train_data20752.zip  \n",
            " extracting: training_datas/train_data15369.zip  \n",
            " extracting: training_datas/train_data27327.zip  \n",
            " extracting: training_datas/train_data11002.zip  \n",
            " extracting: training_datas/train_data4401.zip  \n",
            " extracting: training_datas/train_data17230.zip  \n",
            " extracting: training_datas/train_data6915.zip  \n",
            " extracting: training_datas/train_data27556.zip  \n",
            " extracting: training_datas/train_data1633.zip  \n",
            " extracting: training_datas/train_data19982.zip  \n",
            " extracting: training_datas/train_data12009.zip  \n",
            " extracting: training_datas/train_data27799.zip  \n",
            " extracting: training_datas/train_data17948.zip  \n",
            " extracting: training_datas/train_data9030.zip  \n",
            " extracting: training_datas/train_data6987.zip  \n",
            " extracting: training_datas/train_data3026.zip  \n",
            " extracting: training_datas/train_data13703.zip  \n",
            " extracting: training_datas/train_data936.zip  \n",
            " extracting: training_datas/train_data24700.zip  \n",
            " extracting: training_datas/train_data25811.zip  \n",
            " extracting: training_datas/train_data8407.zip  \n",
            " extracting: training_datas/train_data29986.zip  \n",
            " extracting: training_datas/train_data22972.zip  \n",
            " extracting: training_datas/train_data6049.zip  \n",
            " extracting: training_datas/train_data21674.zip  \n",
            " extracting: training_datas/train_data5695.zip  \n",
            " extracting: training_datas/train_data21994.zip  \n",
            " extracting: training_datas/train_data3745.zip  \n",
            " extracting: training_datas/train_data10151.zip  \n",
            " extracting: training_datas/train_data3398.zip  \n",
            " extracting: training_datas/train_data15044.zip  \n",
            " extracting: training_datas/train_data12869.zip  \n",
            " extracting: training_datas/train_data3775.zip  \n",
            " extracting: training_datas/train_data27597.zip  \n",
            " extracting: training_datas/train_data28307.zip  \n",
            " extracting: training_datas/train_data12513.zip  \n",
            " extracting: training_datas/train_data7703.zip  \n",
            " extracting: training_datas/train_data3946.zip  \n",
            " extracting: training_datas/train_data28004.zip  \n",
            " extracting: training_datas/train_data18313.zip  \n",
            " extracting: training_datas/train_data15586.zip  \n",
            " extracting: training_datas/train_data1545.zip  \n",
            " extracting: training_datas/train_data2100.zip  \n",
            " extracting: training_datas/train_data6264.zip  \n",
            " extracting: training_datas/train_data26204.zip  \n",
            " extracting: training_datas/train_data7070.zip  \n",
            " extracting: training_datas/train_data28235.zip  \n",
            " extracting: training_datas/train_data174.zip  \n",
            " extracting: training_datas/train_data495.zip  \n",
            " extracting: training_datas/train_data23142.zip  \n",
            " extracting: training_datas/train_data17655.zip  \n",
            " extracting: training_datas/train_data1731.zip  \n",
            " extracting: training_datas/train_data11548.zip  \n",
            " extracting: training_datas/train_data5810.zip  \n",
            " extracting: training_datas/train_data20002.zip  \n",
            " extracting: training_datas/train_data6311.zip  \n",
            " extracting: training_datas/train_data26818.zip  \n",
            " extracting: training_datas/train_data23554.zip  \n",
            " extracting: training_datas/train_data24352.zip  \n",
            " extracting: training_datas/train_data23832.zip  \n",
            " extracting: training_datas/train_data30056.zip  \n",
            " extracting: training_datas/train_data3577.zip  \n",
            " extracting: training_datas/train_data2904.zip  \n",
            " extracting: training_datas/train_data8017.zip  \n",
            " extracting: training_datas/train_data2325.zip  \n",
            " extracting: training_datas/train_data7127.zip  \n",
            " extracting: training_datas/train_data26112.zip  \n",
            " extracting: training_datas/train_data8234.zip  \n",
            " extracting: training_datas/train_data8892.zip  \n",
            " extracting: training_datas/train_data26173.zip  \n",
            " extracting: training_datas/train_data7192.zip  \n",
            " extracting: training_datas/train_data19801.zip  \n",
            " extracting: training_datas/train_data18434.zip  \n",
            " extracting: training_datas/train_data6951.zip  \n",
            " extracting: training_datas/train_data4255.zip  \n",
            " extracting: training_datas/train_data9567.zip  \n",
            " extracting: training_datas/train_data13145.zip  \n",
            " extracting: training_datas/train_data4080.zip  \n",
            " extracting: training_datas/train_data12916.zip  \n",
            " extracting: training_datas/train_data8195.zip  \n",
            " extracting: training_datas/train_data8160.zip  \n",
            " extracting: training_datas/train_data4432.zip  \n",
            " extracting: training_datas/train_data4423.zip  \n",
            " extracting: training_datas/train_data27108.zip  \n",
            " extracting: training_datas/train_data28331.zip  \n",
            " extracting: training_datas/train_data13521.zip  \n",
            " extracting: training_datas/train_data20900.zip  \n",
            " extracting: training_datas/train_data5791.zip  \n",
            " extracting: training_datas/train_data6993.zip  \n",
            " extracting: training_datas/train_data5413.zip  \n",
            " extracting: training_datas/train_data6825.zip  \n",
            " extracting: training_datas/train_data23452.zip  \n",
            " extracting: training_datas/train_data10186.zip  \n",
            " extracting: training_datas/train_data15707.zip  \n",
            " extracting: training_datas/train_data27397.zip  \n",
            " extracting: training_datas/train_data21124.zip  \n",
            " extracting: training_datas/train_data24745.zip  \n",
            " extracting: training_datas/train_data7445.zip  \n",
            " extracting: training_datas/train_data14289.zip  \n",
            " extracting: training_datas/train_data11460.zip  \n",
            " extracting: training_datas/train_data19535.zip  \n",
            " extracting: training_datas/train_data5806.zip  \n",
            " extracting: training_datas/train_data5001.zip  \n",
            " extracting: training_datas/train_data16533.zip  \n",
            " extracting: training_datas/train_data5800.zip  \n",
            " extracting: training_datas/train_data26826.zip  \n",
            " extracting: training_datas/train_data20149.zip  \n",
            " extracting: training_datas/train_data10625.zip  \n",
            " extracting: training_datas/train_data13666.zip  \n",
            " extracting: training_datas/train_data27344.zip  \n",
            " extracting: training_datas/train_data13252.zip  \n",
            " extracting: training_datas/train_data484.zip  \n",
            " extracting: training_datas/train_data27925.zip  \n",
            " extracting: training_datas/train_data8686.zip  \n",
            " extracting: training_datas/train_data23362.zip  \n",
            " extracting: training_datas/train_data5673.zip  \n",
            " extracting: training_datas/train_data3144.zip  \n",
            " extracting: training_datas/train_data26577.zip  \n",
            " extracting: training_datas/train_data8291.zip  \n",
            " extracting: training_datas/train_data5171.zip  \n",
            " extracting: training_datas/train_data5637.zip  \n",
            " extracting: training_datas/train_data23678.zip  \n",
            " extracting: training_datas/train_data28658.zip  \n",
            " extracting: training_datas/train_data10767.zip  \n",
            " extracting: training_datas/train_data28656.zip  \n",
            " extracting: training_datas/train_data9098.zip  \n",
            " extracting: training_datas/train_data29934.zip  \n",
            " extracting: training_datas/train_data14717.zip  \n",
            " extracting: training_datas/train_data17569.zip  \n",
            " extracting: training_datas/train_data6031.zip  \n",
            " extracting: training_datas/train_data29296.zip  \n",
            " extracting: training_datas/train_data4585.zip  \n",
            " extracting: training_datas/train_data17136.zip  \n",
            " extracting: training_datas/train_data2768.zip  \n",
            " extracting: training_datas/train_data25152.zip  \n",
            " extracting: training_datas/train_data3860.zip  \n",
            " extracting: training_datas/train_data5314.zip  \n",
            " extracting: training_datas/train_data14000.zip  \n",
            " extracting: training_datas/train_data24687.zip  \n",
            " extracting: training_datas/train_data28801.zip  \n",
            " extracting: training_datas/train_data3455.zip  \n",
            " extracting: training_datas/train_data12029.zip  \n",
            " extracting: training_datas/train_data26190.zip  \n",
            " extracting: training_datas/train_data5717.zip  \n",
            " extracting: training_datas/train_data19920.zip  \n",
            " extracting: training_datas/train_data259.zip  \n",
            " extracting: training_datas/train_data7969.zip  \n",
            " extracting: training_datas/train_data19106.zip  \n",
            " extracting: training_datas/train_data17883.zip  \n",
            " extracting: training_datas/train_data568.zip  \n",
            " extracting: training_datas/train_data8178.zip  \n",
            " extracting: training_datas/train_data3041.zip  \n",
            " extracting: training_datas/train_data19051.zip  \n",
            " extracting: training_datas/train_data23350.zip  \n",
            " extracting: training_datas/train_data2856.zip  \n",
            " extracting: training_datas/train_data22268.zip  \n",
            " extracting: training_datas/train_data25680.zip  \n",
            " extracting: training_datas/train_data23521.zip  \n",
            " extracting: training_datas/train_data29314.zip  \n",
            " extracting: training_datas/train_data26144.zip  \n",
            " extracting: training_datas/train_data6710.zip  \n",
            " extracting: training_datas/train_data1562.zip  \n",
            " extracting: training_datas/train_data5091.zip  \n",
            " extracting: training_datas/train_data25973.zip  \n",
            " extracting: training_datas/train_data20097.zip  \n",
            " extracting: training_datas/train_data11622.zip  \n",
            " extracting: training_datas/train_data2938.zip  \n",
            " extracting: training_datas/train_data28469.zip  \n",
            " extracting: training_datas/train_data29361.zip  \n",
            " extracting: training_datas/train_data6830.zip  \n",
            " extracting: training_datas/train_data18704.zip  \n",
            " extracting: training_datas/train_data29532.zip  \n",
            " extracting: training_datas/train_data8076.zip  \n",
            " extracting: training_datas/train_data2601.zip  \n",
            " extracting: training_datas/train_data17189.zip  \n",
            " extracting: training_datas/train_data18731.zip  \n",
            " extracting: training_datas/train_data2656.zip  \n",
            " extracting: training_datas/train_data23686.zip  \n",
            " extracting: training_datas/train_data25606.zip  \n",
            " extracting: training_datas/train_data12474.zip  \n",
            " extracting: training_datas/train_data22139.zip  \n",
            " extracting: training_datas/train_data15933.zip  \n",
            " extracting: training_datas/train_data21254.zip  \n",
            " extracting: training_datas/train_data5479.zip  \n",
            " extracting: training_datas/train_data14100.zip  \n",
            " extracting: training_datas/train_data23881.zip  \n",
            " extracting: training_datas/train_data2523.zip  \n",
            " extracting: training_datas/train_data4673.zip  \n",
            " extracting: training_datas/train_data1413.zip  \n",
            " extracting: training_datas/train_data7058.zip  \n",
            " extracting: training_datas/train_data12251.zip  \n",
            " extracting: training_datas/train_data5550.zip  \n",
            " extracting: training_datas/train_data10165.zip  \n",
            " extracting: training_datas/train_data22009.zip  \n",
            " extracting: training_datas/train_data15184.zip  \n",
            " extracting: training_datas/train_data185.zip  \n",
            " extracting: training_datas/train_data25284.zip  \n",
            " extracting: training_datas/train_data4306.zip  \n",
            " extracting: training_datas/train_data19552.zip  \n",
            " extracting: training_datas/train_data14357.zip  \n",
            " extracting: training_datas/train_data20821.zip  \n",
            " extracting: training_datas/train_data3074.zip  \n",
            " extracting: training_datas/train_data25163.zip  \n",
            " extracting: training_datas/train_data6316.zip  \n",
            " extracting: training_datas/train_data18158.zip  \n",
            " extracting: training_datas/train_data27389.zip  \n",
            " extracting: training_datas/train_data29741.zip  \n",
            " extracting: training_datas/train_data20782.zip  \n",
            " extracting: training_datas/train_data16377.zip  \n",
            " extracting: training_datas/train_data1295.zip  \n",
            " extracting: training_datas/train_data29809.zip  \n",
            " extracting: training_datas/train_data1761.zip  \n",
            " extracting: training_datas/train_data27254.zip  \n",
            " extracting: training_datas/train_data6213.zip  \n",
            " extracting: training_datas/train_data25330.zip  \n",
            " extracting: training_datas/train_data13823.zip  \n",
            " extracting: training_datas/train_data17330.zip  \n",
            " extracting: training_datas/train_data28354.zip  \n",
            " extracting: training_datas/train_data28373.zip  \n",
            " extracting: training_datas/train_data16644.zip  \n",
            " extracting: training_datas/train_data27150.zip  \n",
            " extracting: training_datas/train_data21917.zip  \n",
            " extracting: training_datas/train_data3189.zip  \n",
            " extracting: training_datas/train_data30124.zip  \n",
            " extracting: training_datas/train_data17491.zip  \n",
            " extracting: training_datas/train_data2495.zip  \n",
            " extracting: training_datas/train_data9362.zip  \n",
            " extracting: training_datas/train_data27214.zip  \n",
            " extracting: training_datas/train_data810.zip  \n",
            " extracting: training_datas/train_data7029.zip  \n",
            " extracting: training_datas/train_data5003.zip  \n",
            " extracting: training_datas/train_data16703.zip  \n",
            " extracting: training_datas/train_data4513.zip  \n",
            " extracting: training_datas/train_data14290.zip  \n",
            " extracting: training_datas/train_data28742.zip  \n",
            " extracting: training_datas/train_data20803.zip  \n",
            " extracting: training_datas/train_data19386.zip  \n",
            " extracting: training_datas/train_data22597.zip  \n",
            " extracting: training_datas/train_data6302.zip  \n",
            " extracting: training_datas/train_data942.zip  \n",
            " extracting: training_datas/train_data21593.zip  \n",
            " extracting: training_datas/train_data14730.zip  \n",
            " extracting: training_datas/train_data26890.zip  \n",
            " extracting: training_datas/train_data13365.zip  \n",
            " extracting: training_datas/train_data11161.zip  \n",
            " extracting: training_datas/train_data25563.zip  \n",
            " extracting: training_datas/train_data8705.zip  \n",
            " extracting: training_datas/train_data22415.zip  \n",
            " extracting: training_datas/train_data27131.zip  \n",
            " extracting: training_datas/train_data348.zip  \n",
            " extracting: training_datas/train_data29979.zip  \n",
            " extracting: training_datas/train_data25579.zip  \n",
            " extracting: training_datas/train_data17159.zip  \n",
            " extracting: training_datas/train_data23172.zip  \n",
            " extracting: training_datas/train_data549.zip  \n",
            " extracting: training_datas/train_data14816.zip  \n",
            " extracting: training_datas/train_data22539.zip  \n",
            " extracting: training_datas/train_data12811.zip  \n",
            " extracting: training_datas/train_data5567.zip  \n",
            " extracting: training_datas/train_data30299.zip  \n",
            " extracting: training_datas/train_data967.zip  \n",
            " extracting: training_datas/train_data29326.zip  \n",
            " extracting: training_datas/train_data25341.zip  \n",
            " extracting: training_datas/train_data30289.zip  \n",
            " extracting: training_datas/train_data21505.zip  \n",
            " extracting: training_datas/train_data24696.zip  \n",
            " extracting: training_datas/train_data29474.zip  \n",
            " extracting: training_datas/train_data27514.zip  \n",
            " extracting: training_datas/train_data17975.zip  \n",
            " extracting: training_datas/train_data23994.zip  \n",
            " extracting: training_datas/train_data30459.zip  \n",
            " extracting: training_datas/train_data24510.zip  \n",
            " extracting: training_datas/train_data26660.zip  \n",
            " extracting: training_datas/train_data16204.zip  \n",
            " extracting: training_datas/train_data5025.zip  \n",
            " extracting: training_datas/train_data258.zip  \n",
            " extracting: training_datas/train_data21828.zip  \n",
            " extracting: training_datas/train_data7719.zip  \n",
            " extracting: training_datas/train_data25716.zip  \n",
            " extracting: training_datas/train_data2558.zip  \n",
            " extracting: training_datas/train_data11614.zip  \n",
            " extracting: training_datas/train_data12641.zip  \n",
            " extracting: training_datas/train_data20558.zip  \n",
            " extracting: training_datas/train_data17373.zip  \n",
            " extracting: training_datas/train_data16829.zip  \n",
            " extracting: training_datas/train_data17857.zip  \n",
            " extracting: training_datas/train_data28569.zip  \n",
            " extracting: training_datas/train_data25286.zip  \n",
            " extracting: training_datas/train_data4206.zip  \n",
            " extracting: training_datas/train_data8035.zip  \n",
            " extracting: training_datas/train_data25168.zip  \n",
            " extracting: training_datas/train_data23451.zip  \n",
            " extracting: training_datas/train_data21016.zip  \n",
            " extracting: training_datas/train_data11473.zip  \n",
            " extracting: training_datas/train_data10747.zip  \n",
            " extracting: training_datas/train_data6657.zip  \n",
            " extracting: training_datas/train_data24664.zip  \n",
            " extracting: training_datas/train_data20662.zip  \n",
            " extracting: training_datas/train_data22565.zip  \n",
            " extracting: training_datas/train_data11278.zip  \n",
            " extracting: training_datas/train_data4259.zip  \n",
            " extracting: training_datas/train_data2623.zip  \n",
            " extracting: training_datas/train_data8916.zip  \n",
            " extracting: training_datas/train_data20210.zip  \n",
            " extracting: training_datas/train_data22727.zip  \n",
            " extracting: training_datas/train_data29667.zip  \n",
            " extracting: training_datas/train_data22999.zip  \n",
            " extracting: training_datas/train_data22760.zip  \n",
            " extracting: training_datas/train_data20963.zip  \n",
            " extracting: training_datas/train_data6241.zip  \n",
            " extracting: training_datas/train_data14973.zip  \n",
            " extracting: training_datas/train_data23713.zip  \n",
            " extracting: training_datas/train_data13274.zip  \n",
            " extracting: training_datas/train_data30395.zip  \n",
            " extracting: training_datas/train_data16338.zip  \n",
            " extracting: training_datas/train_data14190.zip  \n",
            " extracting: training_datas/train_data19885.zip  \n",
            " extracting: training_datas/train_data8312.zip  \n",
            " extracting: training_datas/train_data736.zip  \n",
            " extracting: training_datas/train_data28633.zip  \n",
            " extracting: training_datas/train_data11639.zip  \n",
            " extracting: training_datas/train_data963.zip  \n",
            " extracting: training_datas/train_data9879.zip  \n",
            " extracting: training_datas/train_data30487.zip  \n",
            " extracting: training_datas/train_data10178.zip  \n",
            " extracting: training_datas/train_data14875.zip  \n",
            " extracting: training_datas/train_data27913.zip  \n",
            " extracting: training_datas/train_data2020.zip  \n",
            " extracting: training_datas/train_data3734.zip  \n",
            " extracting: training_datas/train_data15714.zip  \n",
            " extracting: training_datas/train_data13887.zip  \n",
            " extracting: training_datas/train_data4280.zip  \n",
            " extracting: training_datas/train_data18310.zip  \n",
            " extracting: training_datas/train_data17777.zip  \n",
            " extracting: training_datas/train_data29983.zip  \n",
            " extracting: training_datas/train_data4248.zip  \n",
            " extracting: training_datas/train_data19004.zip  \n",
            " extracting: training_datas/train_data9726.zip  \n",
            " extracting: training_datas/train_data7745.zip  \n",
            " extracting: training_datas/train_data8907.zip  \n",
            " extracting: training_datas/train_data782.zip  \n",
            " extracting: training_datas/train_data3642.zip  \n",
            " extracting: training_datas/train_data22384.zip  \n",
            " extracting: training_datas/train_data7494.zip  \n",
            " extracting: training_datas/train_data7093.zip  \n",
            " extracting: training_datas/train_data23867.zip  \n",
            " extracting: training_datas/train_data11289.zip  \n",
            " extracting: training_datas/train_data14928.zip  \n",
            " extracting: training_datas/train_data18502.zip  \n",
            " extracting: training_datas/train_data19002.zip  \n",
            " extracting: training_datas/train_data18716.zip  \n",
            " extracting: training_datas/train_data18678.zip  \n",
            " extracting: training_datas/train_data26756.zip  \n",
            " extracting: training_datas/train_data17008.zip  \n",
            " extracting: training_datas/train_data22008.zip  \n",
            " extracting: training_datas/train_data11597.zip  \n",
            " extracting: training_datas/train_data7295.zip  \n",
            " extracting: training_datas/train_data28493.zip  \n",
            " extracting: training_datas/train_data17867.zip  \n",
            " extracting: training_datas/train_data15876.zip  \n",
            " extracting: training_datas/train_data15498.zip  \n",
            " extracting: training_datas/train_data3682.zip  \n",
            " extracting: training_datas/train_data9951.zip  \n",
            " extracting: training_datas/train_data26070.zip  \n",
            " extracting: training_datas/train_data21924.zip  \n",
            " extracting: training_datas/train_data19141.zip  \n",
            " extracting: training_datas/train_data13533.zip  \n",
            " extracting: training_datas/train_data16863.zip  \n",
            " extracting: training_datas/train_data15996.zip  \n",
            " extracting: training_datas/train_data24938.zip  \n",
            " extracting: training_datas/train_data6416.zip  \n",
            " extracting: training_datas/train_data11432.zip  \n",
            " extracting: training_datas/train_data5533.zip  \n",
            " extracting: training_datas/train_data9696.zip  \n",
            " extracting: training_datas/train_data12418.zip  \n",
            " extracting: training_datas/train_data26879.zip  \n",
            " extracting: training_datas/train_data6454.zip  \n",
            " extracting: training_datas/train_data19626.zip  \n",
            " extracting: training_datas/train_data7761.zip  \n",
            " extracting: training_datas/train_data8422.zip  \n",
            " extracting: training_datas/train_data16017.zip  \n",
            " extracting: training_datas/train_data10715.zip  \n",
            " extracting: training_datas/train_data2447.zip  \n",
            " extracting: training_datas/train_data13494.zip  \n",
            " extracting: training_datas/train_data4623.zip  \n",
            " extracting: training_datas/train_data24481.zip  \n",
            " extracting: training_datas/train_data3446.zip  \n",
            " extracting: training_datas/train_data20138.zip  \n",
            " extracting: training_datas/train_data25816.zip  \n",
            " extracting: training_datas/train_data4715.zip  \n",
            " extracting: training_datas/train_data28385.zip  \n",
            " extracting: training_datas/train_data12428.zip  \n",
            " extracting: training_datas/train_data18734.zip  \n",
            " extracting: training_datas/train_data13688.zip  \n",
            " extracting: training_datas/train_data16216.zip  \n",
            " extracting: training_datas/train_data26520.zip  \n",
            " extracting: training_datas/train_data12993.zip  \n",
            " extracting: training_datas/train_data25714.zip  \n",
            " extracting: training_datas/train_data13643.zip  \n",
            " extracting: training_datas/train_data1726.zip  \n",
            " extracting: training_datas/train_data12676.zip  \n",
            " extracting: training_datas/train_data18102.zip  \n",
            " extracting: training_datas/train_data5242.zip  \n",
            " extracting: training_datas/train_data30282.zip  \n",
            " extracting: training_datas/train_data18169.zip  \n",
            " extracting: training_datas/train_data22568.zip  \n",
            " extracting: training_datas/train_data22630.zip  \n",
            " extracting: training_datas/train_data9193.zip  \n",
            " extracting: training_datas/train_data4918.zip  \n",
            " extracting: training_datas/train_data24100.zip  \n",
            " extracting: training_datas/train_data11615.zip  \n",
            " extracting: training_datas/train_data28671.zip  \n",
            " extracting: training_datas/train_data22382.zip  \n",
            " extracting: training_datas/train_data7658.zip  \n",
            " extracting: training_datas/train_data29581.zip  \n",
            " extracting: training_datas/train_data15061.zip  \n",
            " extracting: training_datas/train_data1614.zip  \n",
            " extracting: training_datas/train_data5221.zip  \n",
            " extracting: training_datas/train_data16793.zip  \n",
            " extracting: training_datas/train_data15098.zip  \n",
            " extracting: training_datas/train_data12575.zip  \n",
            " extracting: training_datas/train_data2385.zip  \n",
            " extracting: training_datas/train_data13933.zip  \n",
            " extracting: training_datas/train_data8606.zip  \n",
            " extracting: training_datas/train_data12465.zip  \n",
            " extracting: training_datas/train_data11191.zip  \n",
            " extracting: training_datas/train_data5638.zip  \n",
            " extracting: training_datas/train_data27497.zip  \n",
            " extracting: training_datas/train_data12692.zip  \n",
            " extracting: training_datas/train_data5761.zip  \n",
            " extracting: training_datas/train_data12011.zip  \n",
            " extracting: training_datas/train_data23972.zip  \n",
            " extracting: training_datas/train_data26590.zip  \n",
            " extracting: training_datas/train_data23851.zip  \n",
            " extracting: training_datas/train_data25800.zip  \n",
            " extracting: training_datas/train_data5150.zip  \n",
            " extracting: training_datas/train_data6079.zip  \n",
            " extracting: training_datas/train_data8934.zip  \n",
            " extracting: training_datas/train_data27478.zip  \n",
            " extracting: training_datas/train_data16162.zip  \n",
            " extracting: training_datas/train_data1765.zip  \n",
            " extracting: training_datas/train_data9832.zip  \n",
            " extracting: training_datas/train_data27941.zip  \n",
            " extracting: training_datas/train_data23704.zip  \n",
            " extracting: training_datas/train_data9496.zip  \n",
            " extracting: training_datas/train_data27448.zip  \n",
            " extracting: training_datas/train_data9842.zip  \n",
            " extracting: training_datas/train_data8142.zip  \n",
            " extracting: training_datas/train_data27201.zip  \n",
            " extracting: training_datas/train_data17607.zip  \n",
            " extracting: training_datas/train_data16609.zip  \n",
            " extracting: training_datas/train_data3355.zip  \n",
            " extracting: training_datas/train_data24876.zip  \n",
            " extracting: training_datas/train_data29096.zip  \n",
            " extracting: training_datas/train_data19853.zip  \n",
            " extracting: training_datas/train_data8657.zip  \n",
            " extracting: training_datas/train_data9389.zip  \n",
            " extracting: training_datas/train_data463.zip  \n",
            " extracting: training_datas/train_data16000.zip  \n",
            " extracting: training_datas/train_data28606.zip  \n",
            " extracting: training_datas/train_data17344.zip  \n",
            " extracting: training_datas/train_data21678.zip  \n",
            " extracting: training_datas/train_data20583.zip  \n",
            " extracting: training_datas/train_data2541.zip  \n",
            " extracting: training_datas/train_data5386.zip  \n",
            " extracting: training_datas/train_data4399.zip  \n",
            " extracting: training_datas/train_data24077.zip  \n",
            " extracting: training_datas/train_data16865.zip  \n",
            " extracting: training_datas/train_data22137.zip  \n",
            " extracting: training_datas/train_data24627.zip  \n",
            " extracting: training_datas/train_data9975.zip  \n",
            " extracting: training_datas/train_data23454.zip  \n",
            " extracting: training_datas/train_data5076.zip  \n",
            " extracting: training_datas/train_data9821.zip  \n",
            " extracting: training_datas/train_data18350.zip  \n",
            " extracting: training_datas/train_data24436.zip  \n",
            " extracting: training_datas/train_data9365.zip  \n",
            " extracting: training_datas/train_data21947.zip  \n",
            " extracting: training_datas/train_data12622.zip  \n",
            " extracting: training_datas/train_data18206.zip  \n",
            " extracting: training_datas/train_data18556.zip  \n",
            " extracting: training_datas/train_data20304.zip  \n",
            " extracting: training_datas/train_data22557.zip  \n",
            " extracting: training_datas/train_data247.zip  \n",
            " extracting: training_datas/train_data14268.zip  \n",
            " extracting: training_datas/train_data12366.zip  \n",
            " extracting: training_datas/train_data20820.zip  \n",
            " extracting: training_datas/train_data24280.zip  \n",
            " extracting: training_datas/train_data21625.zip  \n",
            " extracting: training_datas/train_data245.zip  \n",
            " extracting: training_datas/train_data11906.zip  \n",
            " extracting: training_datas/train_data15560.zip  \n",
            " extracting: training_datas/train_data21117.zip  \n",
            " extracting: training_datas/train_data20559.zip  \n",
            " extracting: training_datas/train_data17115.zip  \n",
            " extracting: training_datas/train_data4310.zip  \n",
            " extracting: training_datas/train_data4022.zip  \n",
            " extracting: training_datas/train_data3909.zip  \n",
            " extracting: training_datas/train_data20866.zip  \n",
            " extracting: training_datas/train_data29963.zip  \n",
            " extracting: training_datas/train_data16068.zip  \n",
            " extracting: training_datas/train_data12974.zip  \n",
            " extracting: training_datas/train_data4126.zip  \n",
            " extracting: training_datas/train_data553.zip  \n",
            " extracting: training_datas/train_data9319.zip  \n",
            " extracting: training_datas/train_data17456.zip  \n",
            " extracting: training_datas/train_data6060.zip  \n",
            " extracting: training_datas/train_data21288.zip  \n",
            " extracting: training_datas/train_data1584.zip  \n",
            " extracting: training_datas/train_data24919.zip  \n",
            " extracting: training_datas/train_data12551.zip  \n",
            " extracting: training_datas/train_data5069.zip  \n",
            " extracting: training_datas/train_data28576.zip  \n",
            " extracting: training_datas/train_data10712.zip  \n",
            " extracting: training_datas/train_data434.zip  \n",
            " extracting: training_datas/train_data30479.zip  \n",
            " extracting: training_datas/train_data1148.zip  \n",
            " extracting: training_datas/train_data12924.zip  \n",
            " extracting: training_datas/train_data17881.zip  \n",
            " extracting: training_datas/train_data7112.zip  \n",
            " extracting: training_datas/train_data5362.zip  \n",
            " extracting: training_datas/train_data19704.zip  \n",
            " extracting: training_datas/train_data9881.zip  \n",
            " extracting: training_datas/train_data3617.zip  \n",
            " extracting: training_datas/train_data23911.zip  \n",
            " extracting: training_datas/train_data5751.zip  \n",
            " extracting: training_datas/train_data9608.zip  \n",
            " extracting: training_datas/train_data9703.zip  \n",
            " extracting: training_datas/train_data21969.zip  \n",
            " extracting: training_datas/train_data8511.zip  \n",
            " extracting: training_datas/train_data3876.zip  \n",
            " extracting: training_datas/train_data27987.zip  \n",
            " extracting: training_datas/train_data15041.zip  \n",
            " extracting: training_datas/train_data7600.zip  \n",
            " extracting: training_datas/train_data1126.zip  \n",
            " extracting: training_datas/train_data20048.zip  \n",
            " extracting: training_datas/train_data5147.zip  \n",
            " extracting: training_datas/train_data28248.zip  \n",
            " extracting: training_datas/train_data22051.zip  \n",
            " extracting: training_datas/train_data28087.zip  \n",
            " extracting: training_datas/train_data28531.zip  \n",
            " extracting: training_datas/train_data814.zip  \n",
            " extracting: training_datas/train_data19201.zip  \n",
            " extracting: training_datas/train_data8906.zip  \n",
            " extracting: training_datas/train_data15621.zip  \n",
            " extracting: training_datas/train_data3201.zip  \n",
            " extracting: training_datas/train_data16884.zip  \n",
            " extracting: training_datas/train_data25425.zip  \n",
            " extracting: training_datas/train_data24145.zip  \n",
            " extracting: training_datas/train_data2773.zip  \n",
            " extracting: training_datas/train_data26244.zip  \n",
            " extracting: training_datas/train_data24785.zip  \n",
            " extracting: training_datas/train_data23235.zip  \n",
            " extracting: training_datas/train_data10908.zip  \n",
            " extracting: training_datas/train_data9869.zip  \n",
            " extracting: training_datas/train_data14212.zip  \n",
            " extracting: training_datas/train_data12025.zip  \n",
            " extracting: training_datas/train_data1728.zip  \n",
            " extracting: training_datas/train_data25589.zip  \n",
            " extracting: training_datas/train_data19260.zip  \n",
            " extracting: training_datas/train_data8361.zip  \n",
            " extracting: training_datas/train_data26824.zip  \n",
            " extracting: training_datas/train_data4913.zip  \n",
            " extracting: training_datas/train_data4725.zip  \n",
            " extracting: training_datas/train_data28737.zip  \n",
            " extracting: training_datas/train_data16189.zip  \n",
            " extracting: training_datas/train_data11027.zip  \n",
            " extracting: training_datas/train_data3313.zip  \n",
            " extracting: training_datas/train_data28264.zip  \n",
            " extracting: training_datas/train_data13720.zip  \n",
            " extracting: training_datas/train_data24676.zip  \n",
            " extracting: training_datas/train_data29382.zip  \n",
            " extracting: training_datas/train_data12271.zip  \n",
            " extracting: training_datas/train_data24091.zip  \n",
            " extracting: training_datas/train_data20813.zip  \n",
            " extracting: training_datas/train_data12421.zip  \n",
            " extracting: training_datas/train_data14830.zip  \n",
            " extracting: training_datas/train_data20063.zip  \n",
            " extracting: training_datas/train_data8302.zip  \n",
            " extracting: training_datas/train_data3818.zip  \n",
            " extracting: training_datas/train_data6072.zip  \n",
            " extracting: training_datas/train_data3583.zip  \n",
            " extracting: training_datas/train_data29642.zip  \n",
            " extracting: training_datas/train_data27895.zip  \n",
            " extracting: training_datas/train_data10851.zip  \n",
            " extracting: training_datas/train_data2658.zip  \n",
            " extracting: training_datas/train_data7565.zip  \n",
            " extracting: training_datas/train_data1299.zip  \n",
            " extracting: training_datas/train_data1258.zip  \n",
            " extracting: training_datas/train_data23518.zip  \n",
            " extracting: training_datas/train_data14085.zip  \n",
            " extracting: training_datas/train_data24871.zip  \n",
            " extracting: training_datas/train_data22062.zip  \n",
            " extracting: training_datas/train_data14987.zip  \n",
            " extracting: training_datas/train_data17070.zip  \n",
            " extracting: training_datas/train_data23324.zip  \n",
            " extracting: training_datas/train_data5774.zip  \n",
            " extracting: training_datas/train_data20973.zip  \n",
            " extracting: training_datas/train_data840.zip  \n",
            " extracting: training_datas/train_data21091.zip  \n",
            " extracting: training_datas/train_data23935.zip  \n",
            " extracting: training_datas/train_data17949.zip  \n",
            " extracting: training_datas/train_data26703.zip  \n",
            " extracting: training_datas/train_data19637.zip  \n",
            " extracting: training_datas/train_data469.zip  \n",
            " extracting: training_datas/train_data22862.zip  \n",
            " extracting: training_datas/train_data5219.zip  \n",
            " extracting: training_datas/train_data1041.zip  \n",
            " extracting: training_datas/train_data30178.zip  \n",
            " extracting: training_datas/train_data4758.zip  \n",
            " extracting: training_datas/train_data16164.zip  \n",
            " extracting: training_datas/train_data14488.zip  \n",
            " extracting: training_datas/train_data28543.zip  \n",
            " extracting: training_datas/train_data5404.zip  \n",
            " extracting: training_datas/train_data13992.zip  \n",
            " extracting: training_datas/train_data15086.zip  \n",
            " extracting: training_datas/train_data15358.zip  \n",
            " extracting: training_datas/train_data15209.zip  \n",
            " extracting: training_datas/train_data10761.zip  \n",
            " extracting: training_datas/train_data28603.zip  \n",
            " extracting: training_datas/train_data20909.zip  \n",
            " extracting: training_datas/train_data19958.zip  \n",
            " extracting: training_datas/train_data9330.zip  \n",
            " extracting: training_datas/train_data16445.zip  \n",
            " extracting: training_datas/train_data17348.zip  \n",
            " extracting: training_datas/train_data4506.zip  \n",
            " extracting: training_datas/train_data17719.zip  \n",
            " extracting: training_datas/train_data25328.zip  \n",
            " extracting: training_datas/train_data25782.zip  \n",
            " extracting: training_datas/train_data17512.zip  \n",
            " extracting: training_datas/train_data602.zip  \n",
            " extracting: training_datas/train_data9854.zip  \n",
            " extracting: training_datas/train_data2740.zip  \n",
            " extracting: training_datas/train_data15680.zip  \n",
            " extracting: training_datas/train_data14443.zip  \n",
            " extracting: training_datas/train_data20167.zip  \n",
            " extracting: training_datas/train_data16682.zip  \n",
            " extracting: training_datas/train_data16760.zip  \n",
            " extracting: training_datas/train_data15412.zip  \n",
            " extracting: training_datas/train_data18576.zip  \n",
            " extracting: training_datas/train_data5044.zip  \n",
            " extracting: training_datas/train_data16779.zip  \n",
            " extracting: training_datas/train_data15068.zip  \n",
            " extracting: training_datas/train_data13850.zip  \n",
            " extracting: training_datas/train_data4396.zip  \n",
            " extracting: training_datas/train_data23468.zip  \n",
            " extracting: training_datas/train_data13797.zip  \n",
            " extracting: training_datas/train_data6199.zip  \n",
            " extracting: training_datas/train_data5469.zip  \n",
            " extracting: training_datas/train_data18623.zip  \n",
            " extracting: training_datas/train_data8615.zip  \n",
            " extracting: training_datas/train_data23624.zip  \n",
            " extracting: training_datas/train_data22037.zip  \n",
            " extracting: training_datas/train_data23546.zip  \n",
            " extracting: training_datas/train_data18671.zip  \n",
            " extracting: training_datas/train_data27546.zip  \n",
            " extracting: training_datas/train_data25945.zip  \n",
            " extracting: training_datas/train_data26300.zip  \n",
            " extracting: training_datas/train_data8264.zip  \n",
            " extracting: training_datas/train_data10719.zip  \n",
            " extracting: training_datas/train_data13941.zip  \n",
            " extracting: training_datas/train_data28644.zip  \n",
            " extracting: training_datas/train_data3602.zip  \n",
            " extracting: training_datas/train_data11078.zip  \n",
            " extracting: training_datas/train_data23849.zip  \n",
            " extracting: training_datas/train_data23348.zip  \n",
            " extracting: training_datas/train_data15598.zip  \n",
            " extracting: training_datas/train_data9999.zip  \n",
            " extracting: training_datas/train_data26798.zip  \n",
            " extracting: training_datas/train_data14873.zip  \n",
            " extracting: training_datas/train_data28252.zip  \n",
            " extracting: training_datas/train_data9517.zip  \n",
            " extracting: training_datas/train_data18250.zip  \n",
            " extracting: training_datas/train_data14527.zip  \n",
            " extracting: training_datas/train_data28227.zip  \n",
            " extracting: training_datas/train_data2913.zip  \n",
            " extracting: training_datas/train_data20484.zip  \n",
            " extracting: training_datas/train_data27660.zip  \n",
            " extracting: training_datas/train_data11155.zip  \n",
            " extracting: training_datas/train_data1261.zip  \n",
            " extracting: training_datas/train_data22279.zip  \n",
            " extracting: training_datas/train_data29820.zip  \n",
            " extracting: training_datas/train_data3100.zip  \n",
            " extracting: training_datas/train_data11781.zip  \n",
            " extracting: training_datas/train_data2786.zip  \n",
            " extracting: training_datas/train_data4710.zip  \n",
            " extracting: training_datas/train_data19075.zip  \n",
            " extracting: training_datas/train_data19745.zip  \n",
            " extracting: training_datas/train_data15312.zip  \n",
            " extracting: training_datas/train_data24721.zip  \n",
            " extracting: training_datas/train_data14192.zip  \n",
            " extracting: training_datas/train_data27977.zip  \n",
            " extracting: training_datas/train_data27889.zip  \n",
            " extracting: training_datas/train_data13117.zip  \n",
            " extracting: training_datas/train_data12668.zip  \n",
            " extracting: training_datas/train_data7848.zip  \n",
            " extracting: training_datas/train_data14144.zip  \n",
            " extracting: training_datas/train_data13595.zip  \n",
            " extracting: training_datas/train_data21195.zip  \n",
            " extracting: training_datas/train_data10957.zip  \n",
            " extracting: training_datas/train_data21869.zip  \n",
            " extracting: training_datas/train_data20098.zip  \n",
            " extracting: training_datas/train_data16940.zip  \n",
            " extracting: training_datas/train_data16875.zip  \n",
            " extracting: training_datas/train_data29966.zip  \n",
            " extracting: training_datas/train_data10313.zip  \n",
            " extracting: training_datas/train_data27438.zip  \n",
            " extracting: training_datas/train_data27561.zip  \n",
            " extracting: training_datas/train_data11134.zip  \n",
            " extracting: training_datas/train_data26324.zip  \n",
            " extracting: training_datas/train_data10312.zip  \n",
            " extracting: training_datas/train_data3186.zip  \n",
            " extracting: training_datas/train_data29684.zip  \n",
            " extracting: training_datas/train_data14108.zip  \n",
            " extracting: training_datas/train_data9090.zip  \n",
            " extracting: training_datas/train_data1670.zip  \n",
            " extracting: training_datas/train_data17080.zip  \n",
            " extracting: training_datas/train_data6159.zip  \n",
            " extracting: training_datas/train_data27062.zip  \n",
            " extracting: training_datas/train_data28545.zip  \n",
            " extracting: training_datas/train_data627.zip  \n",
            " extracting: training_datas/train_data27102.zip  \n",
            " extracting: training_datas/train_data25023.zip  \n",
            " extracting: training_datas/train_data24928.zip  \n",
            " extracting: training_datas/train_data7687.zip  \n",
            " extracting: training_datas/train_data4905.zip  \n",
            " extracting: training_datas/train_data8206.zip  \n",
            " extracting: training_datas/train_data11862.zip  \n",
            " extracting: training_datas/train_data737.zip  \n",
            " extracting: training_datas/train_data29700.zip  \n",
            " extracting: training_datas/train_data10020.zip  \n",
            " extracting: training_datas/train_data24342.zip  \n",
            " extracting: training_datas/train_data5100.zip  \n",
            " extracting: training_datas/train_data21883.zip  \n",
            " extracting: training_datas/train_data24005.zip  \n",
            " extracting: training_datas/train_data22782.zip  \n",
            " extracting: training_datas/train_data20415.zip  \n",
            " extracting: training_datas/train_data593.zip  \n",
            " extracting: training_datas/train_data22554.zip  \n",
            " extracting: training_datas/train_data11888.zip  \n",
            " extracting: training_datas/train_data16610.zip  \n",
            " extracting: training_datas/train_data7398.zip  \n",
            " extracting: training_datas/train_data28297.zip  \n",
            " extracting: training_datas/train_data23575.zip  \n",
            " extracting: training_datas/train_data22368.zip  \n",
            " extracting: training_datas/train_data13725.zip  \n",
            " extracting: training_datas/train_data7588.zip  \n",
            " extracting: training_datas/train_data16920.zip  \n",
            " extracting: training_datas/train_data20975.zip  \n",
            " extracting: training_datas/train_data25894.zip  \n",
            " extracting: training_datas/train_data28928.zip  \n",
            " extracting: training_datas/train_data12220.zip  \n",
            " extracting: training_datas/train_data24733.zip  \n",
            " extracting: training_datas/train_data26341.zip  \n",
            " extracting: training_datas/train_data9076.zip  \n",
            " extracting: training_datas/train_data10076.zip  \n",
            " extracting: training_datas/train_data25423.zip  \n",
            " extracting: training_datas/train_data29394.zip  \n",
            " extracting: training_datas/train_data22239.zip  \n",
            " extracting: training_datas/train_data15852.zip  \n",
            " extracting: training_datas/train_data24255.zip  \n",
            " extracting: training_datas/train_data300.zip  \n",
            " extracting: training_datas/train_data14399.zip  \n",
            " extracting: training_datas/train_data13358.zip  \n",
            " extracting: training_datas/train_data18117.zip  \n",
            " extracting: training_datas/train_data23412.zip  \n",
            " extracting: training_datas/train_data22659.zip  \n",
            " extracting: training_datas/train_data18877.zip  \n",
            " extracting: training_datas/train_data11837.zip  \n",
            " extracting: training_datas/train_data19406.zip  \n",
            " extracting: training_datas/train_data17195.zip  \n",
            " extracting: training_datas/train_data1310.zip  \n",
            " extracting: training_datas/train_data29646.zip  \n",
            " extracting: training_datas/train_data22822.zip  \n",
            " extracting: training_datas/train_data8860.zip  \n",
            " extracting: training_datas/train_data21404.zip  \n",
            " extracting: training_datas/train_data11635.zip  \n",
            " extracting: training_datas/train_data5202.zip  \n",
            " extracting: training_datas/train_data27020.zip  \n",
            " extracting: training_datas/train_data3708.zip  \n",
            " extracting: training_datas/train_data15282.zip  \n",
            " extracting: training_datas/train_data22587.zip  \n",
            " extracting: training_datas/train_data29903.zip  \n",
            " extracting: training_datas/train_data16274.zip  \n",
            " extracting: training_datas/train_data20088.zip  \n",
            " extracting: training_datas/train_data11964.zip  \n",
            " extracting: training_datas/train_data21703.zip  \n",
            " extracting: training_datas/train_data28243.zip  \n",
            " extracting: training_datas/train_data29243.zip  \n",
            " extracting: training_datas/train_data1471.zip  \n",
            " extracting: training_datas/train_data4069.zip  \n",
            " extracting: training_datas/train_data14645.zip  \n",
            " extracting: training_datas/train_data19401.zip  \n",
            " extracting: training_datas/train_data1412.zip  \n",
            " extracting: training_datas/train_data733.zip  \n",
            " extracting: training_datas/train_data8216.zip  \n",
            " extracting: training_datas/train_data9441.zip  \n",
            " extracting: training_datas/train_data24112.zip  \n",
            " extracting: training_datas/train_data9243.zip  \n",
            " extracting: training_datas/train_data23679.zip  \n",
            " extracting: training_datas/train_data6886.zip  \n",
            " extracting: training_datas/train_data1736.zip  \n",
            " extracting: training_datas/train_data23512.zip  \n",
            " extracting: training_datas/train_data28681.zip  \n",
            " extracting: training_datas/train_data9153.zip  \n",
            " extracting: training_datas/train_data19318.zip  \n",
            " extracting: training_datas/train_data10398.zip  \n",
            " extracting: training_datas/train_data4236.zip  \n",
            " extracting: training_datas/train_data17155.zip  \n",
            " extracting: training_datas/train_data12872.zip  \n",
            " extracting: training_datas/train_data20628.zip  \n",
            " extracting: training_datas/train_data2880.zip  \n",
            " extracting: training_datas/train_data26625.zip  \n",
            " extracting: training_datas/train_data17163.zip  \n",
            " extracting: training_datas/train_data18586.zip  \n",
            " extracting: training_datas/train_data24060.zip  \n",
            " extracting: training_datas/train_data24420.zip  \n",
            " extracting: training_datas/train_data795.zip  \n",
            " extracting: training_datas/train_data20608.zip  \n",
            " extracting: training_datas/train_data20112.zip  \n",
            " extracting: training_datas/train_data13856.zip  \n",
            " extracting: training_datas/train_data10662.zip  \n",
            " extracting: training_datas/train_data19737.zip  \n",
            " extracting: training_datas/train_data28400.zip  \n",
            " extracting: training_datas/train_data3539.zip  \n",
            " extracting: training_datas/train_data10680.zip  \n",
            " extracting: training_datas/train_data24519.zip  \n",
            " extracting: training_datas/train_data18424.zip  \n",
            " extracting: training_datas/train_data457.zip  \n",
            " extracting: training_datas/train_data5959.zip  \n",
            " extracting: training_datas/train_data3024.zip  \n",
            " extracting: training_datas/train_data10364.zip  \n",
            " extracting: training_datas/train_data20491.zip  \n",
            " extracting: training_datas/train_data18545.zip  \n",
            " extracting: training_datas/train_data5511.zip  \n",
            " extracting: training_datas/train_data26514.zip  \n",
            " extracting: training_datas/train_data19534.zip  \n",
            " extracting: training_datas/train_data27184.zip  \n",
            " extracting: training_datas/train_data29318.zip  \n",
            " extracting: training_datas/train_data28506.zip  \n",
            " extracting: training_datas/train_data14553.zip  \n",
            " extracting: training_datas/train_data13580.zip  \n",
            " extracting: training_datas/train_data2009.zip  \n",
            " extracting: training_datas/train_data27602.zip  \n",
            " extracting: training_datas/train_data9701.zip  \n",
            " extracting: training_datas/train_data23697.zip  \n",
            " extracting: training_datas/train_data20878.zip  \n",
            " extracting: training_datas/train_data25464.zip  \n",
            " extracting: training_datas/train_data8566.zip  \n",
            " extracting: training_datas/train_data24754.zip  \n",
            " extracting: training_datas/train_data13211.zip  \n",
            " extracting: training_datas/train_data17605.zip  \n",
            " extracting: training_datas/train_data3920.zip  \n",
            " extracting: training_datas/train_data1883.zip  \n",
            " extracting: training_datas/train_data28833.zip  \n",
            " extracting: training_datas/train_data20421.zip  \n",
            " extracting: training_datas/train_data490.zip  \n",
            " extracting: training_datas/train_data9494.zip  \n",
            " extracting: training_datas/train_data3947.zip  \n",
            " extracting: training_datas/train_data8759.zip  \n",
            " extracting: training_datas/train_data10917.zip  \n",
            " extracting: training_datas/train_data11712.zip  \n",
            " extracting: training_datas/train_data22600.zip  \n",
            " extracting: training_datas/train_data11691.zip  \n",
            " extracting: training_datas/train_data20606.zip  \n",
            " extracting: training_datas/train_data28066.zip  \n",
            " extracting: training_datas/train_data30169.zip  \n",
            " extracting: training_datas/train_data14262.zip  \n",
            " extracting: training_datas/train_data4347.zip  \n",
            " extracting: training_datas/train_data6285.zip  \n",
            " extracting: training_datas/train_data15350.zip  \n",
            " extracting: training_datas/train_data25528.zip  \n",
            " extracting: training_datas/train_data17000.zip  \n",
            " extracting: training_datas/train_data22219.zip  \n",
            " extracting: training_datas/train_data2596.zip  \n",
            " extracting: training_datas/train_data29170.zip  \n",
            " extracting: training_datas/train_data26069.zip  \n",
            " extracting: training_datas/train_data1625.zip  \n",
            " extracting: training_datas/train_data1078.zip  \n",
            " extracting: training_datas/train_data15985.zip  \n",
            " extracting: training_datas/train_data24960.zip  \n",
            " extracting: training_datas/train_data20014.zip  \n",
            " extracting: training_datas/train_data20861.zip  \n",
            " extracting: training_datas/train_data3904.zip  \n",
            " extracting: training_datas/train_data17546.zip  \n",
            " extracting: training_datas/train_data2780.zip  \n",
            " extracting: training_datas/train_data6157.zip  \n",
            " extracting: training_datas/train_data2197.zip  \n",
            " extracting: training_datas/train_data2465.zip  \n",
            " extracting: training_datas/train_data28698.zip  \n",
            " extracting: training_datas/train_data18268.zip  \n",
            " extracting: training_datas/train_data25497.zip  \n",
            " extracting: training_datas/train_data17995.zip  \n",
            " extracting: training_datas/train_data17489.zip  \n",
            " extracting: training_datas/train_data3630.zip  \n",
            " extracting: training_datas/train_data28353.zip  \n",
            " extracting: training_datas/train_data2908.zip  \n",
            " extracting: training_datas/train_data5981.zip  \n",
            " extracting: training_datas/train_data5370.zip  \n",
            " extracting: training_datas/train_data13092.zip  \n",
            " extracting: training_datas/train_data28732.zip  \n",
            " extracting: training_datas/train_data3715.zip  \n",
            " extracting: training_datas/train_data3462.zip  \n",
            " extracting: training_datas/train_data20232.zip  \n",
            " extracting: training_datas/train_data17825.zip  \n",
            " extracting: training_datas/train_data21370.zip  \n",
            " extracting: training_datas/train_data19984.zip  \n",
            " extracting: training_datas/train_data11994.zip  \n",
            " extracting: training_datas/train_data11546.zip  \n",
            " extracting: training_datas/train_data22516.zip  \n",
            " extracting: training_datas/train_data24293.zip  \n",
            " extracting: training_datas/train_data1143.zip  \n",
            " extracting: training_datas/train_data20069.zip  \n",
            " extracting: training_datas/train_data6598.zip  \n",
            " extracting: training_datas/train_data17811.zip  \n",
            " extracting: training_datas/train_data12690.zip  \n",
            " extracting: training_datas/train_data6489.zip  \n",
            " extracting: training_datas/train_data6272.zip  \n",
            " extracting: training_datas/train_data19031.zip  \n",
            " extracting: training_datas/train_data18872.zip  \n",
            " extracting: training_datas/train_data27657.zip  \n",
            " extracting: training_datas/train_data6513.zip  \n",
            " extracting: training_datas/train_data28617.zip  \n",
            " extracting: training_datas/train_data20344.zip  \n",
            " extracting: training_datas/train_data23057.zip  \n",
            " extracting: training_datas/train_data24912.zip  \n",
            " extracting: training_datas/train_data28233.zip  \n",
            " extracting: training_datas/train_data5880.zip  \n",
            " extracting: training_datas/train_data1243.zip  \n",
            " extracting: training_datas/train_data9190.zip  \n",
            " extracting: training_datas/train_data9966.zip  \n",
            " extracting: training_datas/train_data18075.zip  \n",
            " extracting: training_datas/train_data15702.zip  \n",
            " extracting: training_datas/train_data23730.zip  \n",
            " extracting: training_datas/train_data25859.zip  \n",
            " extracting: training_datas/train_data13946.zip  \n",
            " extracting: training_datas/train_data21679.zip  \n",
            " extracting: training_datas/train_data25656.zip  \n",
            " extracting: training_datas/train_data21180.zip  \n",
            " extracting: training_datas/train_data30176.zip  \n",
            " extracting: training_datas/train_data3202.zip  \n",
            " extracting: training_datas/train_data4414.zip  \n",
            " extracting: training_datas/train_data11031.zip  \n",
            " extracting: training_datas/train_data30389.zip  \n",
            " extracting: training_datas/train_data4104.zip  \n",
            " extracting: training_datas/train_data24521.zip  \n",
            " extracting: training_datas/train_data24045.zip  \n",
            " extracting: training_datas/train_data6366.zip  \n",
            " extracting: training_datas/train_data16972.zip  \n",
            " extracting: training_datas/train_data8071.zip  \n",
            " extracting: training_datas/train_data10370.zip  \n",
            " extracting: training_datas/train_data25552.zip  \n",
            " extracting: training_datas/train_data16762.zip  \n",
            " extracting: training_datas/train_data16899.zip  \n",
            " extracting: training_datas/train_data1502.zip  \n",
            " extracting: training_datas/train_data22330.zip  \n",
            " extracting: training_datas/train_data17873.zip  \n",
            " extracting: training_datas/train_data4739.zip  \n",
            " extracting: training_datas/train_data18463.zip  \n",
            " extracting: training_datas/train_data6946.zip  \n",
            " extracting: training_datas/train_data8614.zip  \n",
            " extracting: training_datas/train_data1682.zip  \n",
            " extracting: training_datas/train_data16244.zip  \n",
            " extracting: training_datas/train_data19381.zip  \n",
            " extracting: training_datas/train_data964.zip  \n",
            " extracting: training_datas/train_data23112.zip  \n",
            " extracting: training_datas/train_data8879.zip  \n",
            " extracting: training_datas/train_data12879.zip  \n",
            " extracting: training_datas/train_data12591.zip  \n",
            " extracting: training_datas/train_data15990.zip  \n",
            " extracting: training_datas/train_data7002.zip  \n",
            " extracting: training_datas/train_data10552.zip  \n",
            " extracting: training_datas/train_data27496.zip  \n",
            " extracting: training_datas/train_data1784.zip  \n",
            " extracting: training_datas/train_data7385.zip  \n",
            " extracting: training_datas/train_data27322.zip  \n",
            " extracting: training_datas/train_data4368.zip  \n",
            " extracting: training_datas/train_data2309.zip  \n",
            " extracting: training_datas/train_data28303.zip  \n",
            " extracting: training_datas/train_data28957.zip  \n",
            " extracting: training_datas/train_data19681.zip  \n",
            " extracting: training_datas/train_data13156.zip  \n",
            " extracting: training_datas/train_data18709.zip  \n",
            " extracting: training_datas/train_data11835.zip  \n",
            " extracting: training_datas/train_data14941.zip  \n",
            " extracting: training_datas/train_data11241.zip  \n",
            " extracting: training_datas/train_data23076.zip  \n",
            " extracting: training_datas/train_data14164.zip  \n",
            " extracting: training_datas/train_data15140.zip  \n",
            " extracting: training_datas/train_data11970.zip  \n",
            " extracting: training_datas/train_data21416.zip  \n",
            " extracting: training_datas/train_data747.zip  \n",
            " extracting: training_datas/train_data27157.zip  \n",
            " extracting: training_datas/train_data25640.zip  \n",
            " extracting: training_datas/train_data29813.zip  \n",
            " extracting: training_datas/train_data18592.zip  \n",
            " extracting: training_datas/train_data3777.zip  \n",
            " extracting: training_datas/train_data21175.zip  \n",
            " extracting: training_datas/train_data5521.zip  \n",
            " extracting: training_datas/train_data15441.zip  \n",
            " extracting: training_datas/train_data6295.zip  \n",
            " extracting: training_datas/train_data30434.zip  \n",
            " extracting: training_datas/train_data4323.zip  \n",
            " extracting: training_datas/train_data15589.zip  \n",
            " extracting: training_datas/train_data8742.zip  \n",
            " extracting: training_datas/train_data6476.zip  \n",
            " extracting: training_datas/train_data816.zip  \n",
            " extracting: training_datas/train_data29176.zip  \n",
            " extracting: training_datas/train_data21971.zip  \n",
            " extracting: training_datas/train_data6919.zip  \n",
            " extracting: training_datas/train_data13844.zip  \n",
            " extracting: training_datas/train_data10642.zip  \n",
            " extracting: training_datas/train_data17585.zip  \n",
            " extracting: training_datas/train_data4544.zip  \n",
            " extracting: training_datas/train_data6517.zip  \n",
            " extracting: training_datas/train_data19272.zip  \n",
            " extracting: training_datas/train_data14978.zip  \n",
            " extracting: training_datas/train_data6663.zip  \n",
            " extracting: training_datas/train_data1882.zip  \n",
            " extracting: training_datas/train_data23778.zip  \n",
            " extracting: training_datas/train_data18242.zip  \n",
            " extracting: training_datas/train_data17856.zip  \n",
            " extracting: training_datas/train_data19249.zip  \n",
            " extracting: training_datas/train_data22629.zip  \n",
            " extracting: training_datas/train_data29037.zip  \n",
            " extracting: training_datas/train_data13485.zip  \n",
            " extracting: training_datas/train_data22874.zip  \n",
            " extracting: training_datas/train_data10386.zip  \n",
            " extracting: training_datas/train_data22887.zip  \n",
            " extracting: training_datas/train_data21348.zip  \n",
            " extracting: training_datas/train_data226.zip  \n",
            " extracting: training_datas/train_data22477.zip  \n",
            " extracting: training_datas/train_data16996.zip  \n",
            " extracting: training_datas/train_data1970.zip  \n",
            " extracting: training_datas/train_data16655.zip  \n",
            " extracting: training_datas/train_data6667.zip  \n",
            " extracting: training_datas/train_data26306.zip  \n",
            " extracting: training_datas/train_data20759.zip  \n",
            " extracting: training_datas/train_data9208.zip  \n",
            " extracting: training_datas/train_data29373.zip  \n",
            " extracting: training_datas/train_data6711.zip  \n",
            " extracting: training_datas/train_data21518.zip  \n",
            " extracting: training_datas/train_data18792.zip  \n",
            " extracting: training_datas/train_data18938.zip  \n",
            " extracting: training_datas/train_data1206.zip  \n",
            " extracting: training_datas/train_data10012.zip  \n",
            " extracting: training_datas/train_data22085.zip  \n",
            " extracting: training_datas/train_data9762.zip  \n",
            " extracting: training_datas/train_data18837.zip  \n",
            " extracting: training_datas/train_data3746.zip  \n",
            " extracting: training_datas/train_data27051.zip  \n",
            " extracting: training_datas/train_data7196.zip  \n",
            " extracting: training_datas/train_data8984.zip  \n",
            " extracting: training_datas/train_data23498.zip  \n",
            " extracting: training_datas/train_data380.zip  \n",
            " extracting: training_datas/train_data23041.zip  \n",
            " extracting: training_datas/train_data28978.zip  \n",
            " extracting: training_datas/train_data22333.zip  \n",
            " extracting: training_datas/train_data1163.zip  \n",
            " extracting: training_datas/train_data8702.zip  \n",
            " extracting: training_datas/train_data11151.zip  \n",
            " extracting: training_datas/train_data11792.zip  \n",
            " extracting: training_datas/train_data28760.zip  \n",
            " extracting: training_datas/train_data21617.zip  \n",
            " extracting: training_datas/train_data22029.zip  \n",
            " extracting: training_datas/train_data27839.zip  \n",
            " extracting: training_datas/train_data9549.zip  \n",
            " extracting: training_datas/train_data19846.zip  \n",
            " extracting: training_datas/train_data20814.zip  \n",
            " extracting: training_datas/train_data21600.zip  \n",
            " extracting: training_datas/train_data7668.zip  \n",
            " extracting: training_datas/train_data19812.zip  \n",
            " extracting: training_datas/train_data14278.zip  \n",
            " extracting: training_datas/train_data1841.zip  \n",
            " extracting: training_datas/train_data3307.zip  \n",
            " extracting: training_datas/train_data21024.zip  \n",
            " extracting: training_datas/train_data26468.zip  \n",
            " extracting: training_datas/train_data19862.zip  \n",
            " extracting: training_datas/train_data10783.zip  \n",
            " extracting: training_datas/train_data13271.zip  \n",
            " extracting: training_datas/train_data20481.zip  \n",
            " extracting: training_datas/train_data22469.zip  \n",
            " extracting: training_datas/train_data12174.zip  \n",
            " extracting: training_datas/train_data14956.zip  \n",
            " extracting: training_datas/train_data2556.zip  \n",
            " extracting: training_datas/train_data18668.zip  \n",
            " extracting: training_datas/train_data14800.zip  \n",
            " extracting: training_datas/train_data15742.zip  \n",
            " extracting: training_datas/train_data9806.zip  \n",
            " extracting: training_datas/train_data12975.zip  \n",
            " extracting: training_datas/train_data21612.zip  \n",
            " extracting: training_datas/train_data11910.zip  \n",
            " extracting: training_datas/train_data24454.zip  \n",
            " extracting: training_datas/train_data6997.zip  \n",
            " extracting: training_datas/train_data19595.zip  \n",
            " extracting: training_datas/train_data6925.zip  \n",
            " extracting: training_datas/train_data10452.zip  \n",
            " extracting: training_datas/train_data15787.zip  \n",
            " extracting: training_datas/train_data23588.zip  \n",
            " extracting: training_datas/train_data16384.zip  \n",
            " extracting: training_datas/train_data6660.zip  \n",
            " extracting: training_datas/train_data24806.zip  \n",
            " extracting: training_datas/train_data18904.zip  \n",
            " extracting: training_datas/train_data3912.zip  \n",
            " extracting: training_datas/train_data14385.zip  \n",
            " extracting: training_datas/train_data21466.zip  \n",
            " extracting: training_datas/train_data13883.zip  \n",
            " extracting: training_datas/train_data20775.zip  \n",
            " extracting: training_datas/train_data20582.zip  \n",
            " extracting: training_datas/train_data27125.zip  \n",
            " extracting: training_datas/train_data10118.zip  \n",
            " extracting: training_datas/train_data4207.zip  \n",
            " extracting: training_datas/train_data24434.zip  \n",
            " extracting: training_datas/train_data7938.zip  \n",
            " extracting: training_datas/train_data11492.zip  \n",
            " extracting: training_datas/train_data28721.zip  \n",
            " extracting: training_datas/train_data24006.zip  \n",
            " extracting: training_datas/train_data12447.zip  \n",
            " extracting: training_datas/train_data29653.zip  \n",
            " extracting: training_datas/train_data27854.zip  \n",
            " extracting: training_datas/train_data6242.zip  \n",
            " extracting: training_datas/train_data15825.zip  \n",
            " extracting: training_datas/train_data18500.zip  \n",
            " extracting: training_datas/train_data3774.zip  \n",
            " extracting: training_datas/train_data14742.zip  \n",
            " extracting: training_datas/train_data10598.zip  \n",
            " extracting: training_datas/train_data25910.zip  \n",
            " extracting: training_datas/train_data27508.zip  \n",
            " extracting: training_datas/train_data28083.zip  \n",
            " extracting: training_datas/train_data27241.zip  \n",
            " extracting: training_datas/train_data9241.zip  \n",
            " extracting: training_datas/train_data22902.zip  \n",
            " extracting: training_datas/train_data433.zip  \n",
            " extracting: training_datas/train_data4071.zip  \n",
            " extracting: training_datas/train_data23538.zip  \n",
            " extracting: training_datas/train_data10766.zip  \n",
            " extracting: training_datas/train_data8041.zip  \n",
            " extracting: training_datas/train_data20294.zip  \n",
            " extracting: training_datas/train_data20734.zip  \n",
            " extracting: training_datas/train_data21133.zip  \n",
            " extracting: training_datas/train_data25766.zip  \n",
            " extracting: training_datas/train_data1735.zip  \n",
            " extracting: training_datas/train_data1339.zip  \n",
            " extracting: training_datas/train_data20841.zip  \n",
            " extracting: training_datas/train_data9380.zip  \n",
            " extracting: training_datas/train_data14860.zip  \n",
            " extracting: training_datas/train_data12390.zip  \n",
            " extracting: training_datas/train_data28584.zip  \n",
            " extracting: training_datas/train_data13671.zip  \n",
            " extracting: training_datas/train_data22354.zip  \n",
            " extracting: training_datas/train_data26580.zip  \n",
            " extracting: training_datas/train_data5994.zip  \n",
            " extracting: training_datas/train_data5763.zip  \n",
            " extracting: training_datas/train_data15488.zip  \n",
            " extracting: training_datas/train_data2522.zip  \n",
            " extracting: training_datas/train_data11038.zip  \n",
            " extracting: training_datas/train_data29770.zip  \n",
            " extracting: training_datas/train_data2299.zip  \n",
            " extracting: training_datas/train_data24304.zip  \n",
            " extracting: training_datas/train_data17152.zip  \n",
            " extracting: training_datas/train_data16376.zip  \n",
            " extracting: training_datas/train_data6385.zip  \n",
            " extracting: training_datas/train_data20347.zip  \n",
            " extracting: training_datas/train_data25333.zip  \n",
            " extracting: training_datas/train_data16808.zip  \n",
            " extracting: training_datas/train_data28497.zip  \n",
            " extracting: training_datas/train_data17154.zip  \n",
            " extracting: training_datas/train_data12396.zip  \n",
            " extracting: training_datas/train_data28214.zip  \n",
            " extracting: training_datas/train_data9656.zip  \n",
            " extracting: training_datas/train_data3481.zip  \n",
            " extracting: training_datas/train_data4868.zip  \n",
            " extracting: training_datas/train_data16121.zip  \n",
            " extracting: training_datas/train_data10615.zip  \n",
            " extracting: training_datas/train_data10053.zip  \n",
            " extracting: training_datas/train_data30303.zip  \n",
            " extracting: training_datas/train_data9798.zip  \n",
            " extracting: training_datas/train_data5935.zip  \n",
            " extracting: training_datas/train_data14996.zip  \n",
            " extracting: training_datas/train_data26800.zip  \n",
            " extracting: training_datas/train_data10036.zip  \n",
            " extracting: training_datas/train_data10969.zip  \n",
            " extracting: training_datas/train_data30432.zip  \n",
            " extracting: training_datas/train_data11119.zip  \n",
            " extracting: training_datas/train_data27477.zip  \n",
            " extracting: training_datas/train_data1961.zip  \n",
            " extracting: training_datas/train_data15121.zip  \n",
            " extracting: training_datas/train_data5578.zip  \n",
            " extracting: training_datas/train_data27791.zip  \n",
            " extracting: training_datas/train_data20795.zip  \n",
            " extracting: training_datas/train_data22895.zip  \n",
            " extracting: training_datas/train_data22729.zip  \n",
            " extracting: training_datas/train_data8091.zip  \n",
            " extracting: training_datas/train_data8303.zip  \n",
            " extracting: training_datas/train_data14072.zip  \n",
            " extracting: training_datas/train_data28507.zip  \n",
            " extracting: training_datas/train_data28791.zip  \n",
            " extracting: training_datas/train_data17542.zip  \n",
            " extracting: training_datas/train_data30192.zip  \n",
            " extracting: training_datas/train_data5610.zip  \n",
            " extracting: training_datas/train_data11367.zip  \n",
            " extracting: training_datas/train_data13130.zip  \n",
            " extracting: training_datas/train_data26407.zip  \n",
            " extracting: training_datas/train_data17441.zip  \n",
            " extracting: training_datas/train_data25176.zip  \n",
            " extracting: training_datas/train_data20359.zip  \n",
            " extracting: training_datas/train_data13587.zip  \n",
            " extracting: training_datas/train_data29225.zip  \n",
            " extracting: training_datas/train_data965.zip  \n",
            " extracting: training_datas/train_data19195.zip  \n",
            " extracting: training_datas/train_data16680.zip  \n",
            " extracting: training_datas/train_data14716.zip  \n",
            " extracting: training_datas/train_data14500.zip  \n",
            " extracting: training_datas/train_data11945.zip  \n",
            " extracting: training_datas/train_data11185.zip  \n",
            " extracting: training_datas/train_data15801.zip  \n",
            " extracting: training_datas/train_data20106.zip  \n",
            " extracting: training_datas/train_data4191.zip  \n",
            " extracting: training_datas/train_data17190.zip  \n",
            " extracting: training_datas/train_data3541.zip  \n",
            " extracting: training_datas/train_data16096.zip  \n",
            " extracting: training_datas/train_data10509.zip  \n",
            " extracting: training_datas/train_data24881.zip  \n",
            " extracting: training_datas/train_data15762.zip  \n",
            " extracting: training_datas/train_data291.zip  \n",
            " extracting: training_datas/train_data24998.zip  \n",
            " extracting: training_datas/train_data11823.zip  \n",
            " extracting: training_datas/train_data8267.zip  \n",
            " extracting: training_datas/train_data18932.zip  \n",
            " extracting: training_datas/train_data18573.zip  \n",
            " extracting: training_datas/train_data13311.zip  \n",
            " extracting: training_datas/train_data19581.zip  \n",
            " extracting: training_datas/train_data3163.zip  \n",
            " extracting: training_datas/train_data7790.zip  \n",
            " extracting: training_datas/train_data8364.zip  \n",
            " extracting: training_datas/train_data27372.zip  \n",
            " extracting: training_datas/train_data19438.zip  \n",
            " extracting: training_datas/train_data11071.zip  \n",
            " extracting: training_datas/train_data28919.zip  \n",
            " extracting: training_datas/train_data19513.zip  \n",
            " extracting: training_datas/train_data13076.zip  \n",
            " extracting: training_datas/train_data22574.zip  \n",
            " extracting: training_datas/train_data10893.zip  \n",
            " extracting: training_datas/train_data1701.zip  \n",
            " extracting: training_datas/train_data25975.zip  \n",
            " extracting: training_datas/train_data1072.zip  \n",
            " extracting: training_datas/train_data28947.zip  \n",
            " extracting: training_datas/train_data22442.zip  \n",
            " extracting: training_datas/train_data28366.zip  \n",
            " extracting: training_datas/train_data10595.zip  \n",
            " extracting: training_datas/train_data27445.zip  \n",
            " extracting: training_datas/train_data12773.zip  \n",
            " extracting: training_datas/train_data9369.zip  \n",
            " extracting: training_datas/train_data11143.zip  \n",
            " extracting: training_datas/train_data871.zip  \n",
            " extracting: training_datas/train_data2164.zip  \n",
            " extracting: training_datas/train_data25517.zip  \n",
            " extracting: training_datas/train_data25034.zip  \n",
            " extracting: training_datas/train_data3683.zip  \n",
            " extracting: training_datas/train_data1211.zip  \n",
            " extracting: training_datas/train_data21776.zip  \n",
            " extracting: training_datas/train_data13473.zip  \n",
            " extracting: training_datas/train_data28920.zip  \n",
            " extracting: training_datas/train_data1111.zip  \n",
            " extracting: training_datas/train_data15179.zip  \n",
            " extracting: training_datas/train_data27505.zip  \n",
            " extracting: training_datas/train_data2679.zip  \n",
            " extracting: training_datas/train_data3325.zip  \n",
            " extracting: training_datas/train_data13060.zip  \n",
            " extracting: training_datas/train_data26905.zip  \n",
            " extracting: training_datas/train_data9316.zip  \n",
            " extracting: training_datas/train_data14350.zip  \n",
            " extracting: training_datas/train_data29856.zip  \n",
            " extracting: training_datas/train_data26916.zip  \n",
            " extracting: training_datas/train_data18655.zip  \n",
            " extracting: training_datas/train_data17322.zip  \n",
            " extracting: training_datas/train_data11509.zip  \n",
            " extracting: training_datas/train_data1540.zip  \n",
            " extracting: training_datas/train_data25792.zip  \n",
            " extracting: training_datas/train_data16755.zip  \n",
            " extracting: training_datas/train_data19542.zip  \n",
            " extracting: training_datas/train_data24156.zip  \n",
            " extracting: training_datas/train_data2057.zip  \n",
            " extracting: training_datas/train_data2774.zip  \n",
            " extracting: training_datas/train_data26412.zip  \n",
            " extracting: training_datas/train_data28368.zip  \n",
            " extracting: training_datas/train_data13453.zip  \n",
            " extracting: training_datas/train_data18714.zip  \n",
            " extracting: training_datas/train_data23477.zip  \n",
            " extracting: training_datas/train_data14489.zip  \n",
            " extracting: training_datas/train_data24039.zip  \n",
            " extracting: training_datas/train_data812.zip  \n",
            " extracting: training_datas/train_data18686.zip  \n",
            " extracting: training_datas/train_data25298.zip  \n",
            " extracting: training_datas/train_data29266.zip  \n",
            " extracting: training_datas/train_data13543.zip  \n",
            " extracting: training_datas/train_data20414.zip  \n",
            " extracting: training_datas/train_data3702.zip  \n",
            " extracting: training_datas/train_data4459.zip  \n",
            " extracting: training_datas/train_data22151.zip  \n",
            " extracting: training_datas/train_data14224.zip  \n",
            " extracting: training_datas/train_data11486.zip  \n",
            " extracting: training_datas/train_data1787.zip  \n",
            " extracting: training_datas/train_data11391.zip  \n",
            " extracting: training_datas/train_data23914.zip  \n",
            " extracting: training_datas/train_data4385.zip  \n",
            " extracting: training_datas/train_data10472.zip  \n",
            " extracting: training_datas/train_data10434.zip  \n",
            " extracting: training_datas/train_data10454.zip  \n",
            " extracting: training_datas/train_data19285.zip  \n",
            " extracting: training_datas/train_data26702.zip  \n",
            " extracting: training_datas/train_data17606.zip  \n",
            " extracting: training_datas/train_data27957.zip  \n",
            " extracting: training_datas/train_data353.zip  \n",
            " extracting: training_datas/train_data17302.zip  \n",
            " extracting: training_datas/train_data6725.zip  \n",
            " extracting: training_datas/train_data25499.zip  \n",
            " extracting: training_datas/train_data12320.zip  \n",
            " extracting: training_datas/train_data14727.zip  \n",
            " extracting: training_datas/train_data5984.zip  \n",
            " extracting: training_datas/train_data10901.zip  \n",
            " extracting: training_datas/train_data22325.zip  \n",
            " extracting: training_datas/train_data2000.zip  \n",
            " extracting: training_datas/train_data21264.zip  \n",
            " extracting: training_datas/train_data1830.zip  \n",
            " extracting: training_datas/train_data1809.zip  \n",
            " extracting: training_datas/train_data29135.zip  \n",
            " extracting: training_datas/train_data7765.zip  \n",
            " extracting: training_datas/train_data13032.zip  \n",
            " extracting: training_datas/train_data19625.zip  \n",
            " extracting: training_datas/train_data17627.zip  \n",
            " extracting: training_datas/train_data20220.zip  \n",
            " extracting: training_datas/train_data24661.zip  \n",
            " extracting: training_datas/train_data23437.zip  \n",
            " extracting: training_datas/train_data12102.zip  \n",
            " extracting: training_datas/train_data4256.zip  \n",
            " extracting: training_datas/train_data488.zip  \n",
            " extracting: training_datas/train_data12063.zip  \n",
            " extracting: training_datas/train_data18469.zip  \n",
            " extracting: training_datas/train_data26466.zip  \n",
            " extracting: training_datas/train_data18472.zip  \n",
            " extracting: training_datas/train_data10609.zip  \n",
            " extracting: training_datas/train_data23928.zip  \n",
            " extracting: training_datas/train_data28595.zip  \n",
            " extracting: training_datas/train_data6134.zip  \n",
            " extracting: training_datas/train_data29553.zip  \n",
            " extracting: training_datas/train_data10007.zip  \n",
            " extracting: training_datas/train_data24943.zip  \n",
            " extracting: training_datas/train_data7218.zip  \n",
            " extracting: training_datas/train_data4012.zip  \n",
            " extracting: training_datas/train_data9402.zip  \n",
            " extracting: training_datas/train_data21464.zip  \n",
            " extracting: training_datas/train_data12010.zip  \n",
            " extracting: training_datas/train_data14139.zip  \n",
            " extracting: training_datas/train_data20976.zip  \n",
            " extracting: training_datas/train_data5365.zip  \n",
            " extracting: training_datas/train_data11536.zip  \n",
            " extracting: training_datas/train_data7944.zip  \n",
            " extracting: training_datas/train_data28287.zip  \n",
            " extracting: training_datas/train_data9284.zip  \n",
            " extracting: training_datas/train_data14097.zip  \n",
            " extracting: training_datas/train_data13849.zip  \n",
            " extracting: training_datas/train_data3806.zip  \n",
            " extracting: training_datas/train_data18328.zip  \n",
            " extracting: training_datas/train_data6127.zip  \n",
            " extracting: training_datas/train_data12302.zip  \n",
            " extracting: training_datas/train_data24407.zip  \n",
            " extracting: training_datas/train_data29826.zip  \n",
            " extracting: training_datas/train_data20739.zip  \n",
            " extracting: training_datas/train_data9694.zip  \n",
            " extracting: training_datas/train_data1410.zip  \n",
            " extracting: training_datas/train_data16814.zip  \n",
            " extracting: training_datas/train_data17262.zip  \n",
            " extracting: training_datas/train_data28890.zip  \n",
            " extracting: training_datas/train_data1835.zip  \n",
            " extracting: training_datas/train_data20629.zip  \n",
            " extracting: training_datas/train_data10929.zip  \n",
            " extracting: training_datas/train_data7597.zip  \n",
            " extracting: training_datas/train_data23525.zip  \n",
            " extracting: training_datas/train_data24021.zip  \n",
            " extracting: training_datas/train_data13492.zip  \n",
            " extracting: training_datas/train_data2115.zip  \n",
            " extracting: training_datas/train_data9182.zip  \n",
            " extracting: training_datas/train_data24804.zip  \n",
            " extracting: training_datas/train_data9085.zip  \n",
            " extracting: training_datas/train_data22438.zip  \n",
            " extracting: training_datas/train_data29627.zip  \n",
            " extracting: training_datas/train_data2976.zip  \n",
            " extracting: training_datas/train_data9475.zip  \n",
            " extracting: training_datas/train_data7219.zip  \n",
            " extracting: training_datas/train_data16334.zip  \n",
            " extracting: training_datas/train_data13023.zip  \n",
            " extracting: training_datas/train_data26632.zip  \n",
            " extracting: training_datas/train_data28012.zip  \n",
            " extracting: training_datas/train_data1306.zip  \n",
            " extracting: training_datas/train_data28522.zip  \n",
            " extracting: training_datas/train_data8238.zip  \n",
            " extracting: training_datas/train_data16008.zip  \n",
            " extracting: training_datas/train_data2413.zip  \n",
            " extracting: training_datas/train_data16667.zip  \n",
            " extracting: training_datas/train_data12886.zip  \n",
            " extracting: training_datas/train_data13210.zip  \n",
            " extracting: training_datas/train_data9265.zip  \n",
            " extracting: training_datas/train_data8885.zip  \n",
            " extracting: training_datas/train_data13134.zip  \n",
            " extracting: training_datas/train_data8715.zip  \n",
            " extracting: training_datas/train_data19717.zip  \n",
            " extracting: training_datas/train_data28051.zip  \n",
            " extracting: training_datas/train_data2237.zip  \n",
            " extracting: training_datas/train_data21741.zip  \n",
            " extracting: training_datas/train_data9112.zip  \n",
            " extracting: training_datas/train_data9016.zip  \n",
            " extracting: training_datas/train_data21110.zip  \n",
            " extracting: training_datas/train_data28622.zip  \n",
            " extracting: training_datas/train_data17328.zip  \n",
            " extracting: training_datas/train_data5267.zip  \n",
            " extracting: training_datas/train_data9488.zip  \n",
            " extracting: training_datas/train_data8314.zip  \n",
            " extracting: training_datas/train_data17287.zip  \n",
            " extracting: training_datas/train_data23393.zip  \n",
            " extracting: training_datas/train_data4685.zip  \n",
            " extracting: training_datas/train_data16210.zip  \n",
            " extracting: training_datas/train_data21665.zip  \n",
            " extracting: training_datas/train_data6627.zip  \n",
            " extracting: training_datas/train_data9132.zip  \n",
            " extracting: training_datas/train_data8919.zip  \n",
            " extracting: training_datas/train_data51.zip  \n",
            " extracting: training_datas/train_data7353.zip  \n",
            " extracting: training_datas/train_data27753.zip  \n",
            " extracting: training_datas/train_data14255.zip  \n",
            " extracting: training_datas/train_data3837.zip  \n",
            " extracting: training_datas/train_data25302.zip  \n",
            " extracting: training_datas/train_data3862.zip  \n",
            " extracting: training_datas/train_data24570.zip  \n",
            " extracting: training_datas/train_data27914.zip  \n",
            " extracting: training_datas/train_data13895.zip  \n",
            " extracting: training_datas/train_data22311.zip  \n",
            " extracting: training_datas/train_data28321.zip  \n",
            " extracting: training_datas/train_data19526.zip  \n",
            " extracting: training_datas/train_data12266.zip  \n",
            " extracting: training_datas/train_data18359.zip  \n",
            " extracting: training_datas/train_data1495.zip  \n",
            " extracting: training_datas/train_data3431.zip  \n",
            " extracting: training_datas/train_data17737.zip  \n",
            " extracting: training_datas/train_data19782.zip  \n",
            " extracting: training_datas/train_data25742.zip  \n",
            " extracting: training_datas/train_data29074.zip  \n",
            " extracting: training_datas/train_data28136.zip  \n",
            " extracting: training_datas/train_data19945.zip  \n",
            " extracting: training_datas/train_data26060.zip  \n",
            " extracting: training_datas/train_data28891.zip  \n",
            " extracting: training_datas/train_data29802.zip  \n",
            " extracting: training_datas/train_data29539.zip  \n",
            " extracting: training_datas/train_data5665.zip  \n",
            " extracting: training_datas/train_data26771.zip  \n",
            " extracting: training_datas/train_data26614.zip  \n",
            " extracting: training_datas/train_data14539.zip  \n",
            " extracting: training_datas/train_data326.zip  \n",
            " extracting: training_datas/train_data1873.zip  \n",
            " extracting: training_datas/train_data27179.zip  \n",
            " extracting: training_datas/train_data25514.zip  \n",
            " extracting: training_datas/train_data678.zip  \n",
            " extracting: training_datas/train_data10760.zip  \n",
            " extracting: training_datas/train_data2022.zip  \n",
            " extracting: training_datas/train_data2616.zip  \n",
            " extracting: training_datas/train_data24328.zip  \n",
            " extracting: training_datas/train_data5920.zip  \n",
            " extracting: training_datas/train_data13682.zip  \n",
            " extracting: training_datas/train_data13490.zip  \n",
            " extracting: training_datas/train_data6251.zip  \n",
            " extracting: training_datas/train_data3342.zip  \n",
            " extracting: training_datas/train_data17471.zip  \n",
            " extracting: training_datas/train_data19228.zip  \n",
            " extracting: training_datas/train_data5102.zip  \n",
            " extracting: training_datas/train_data10541.zip  \n",
            " extracting: training_datas/train_data15299.zip  \n",
            " extracting: training_datas/train_data17643.zip  \n",
            " extracting: training_datas/train_data29097.zip  \n",
            " extracting: training_datas/train_data20036.zip  \n",
            " extracting: training_datas/train_data2877.zip  \n",
            " extracting: training_datas/train_data2312.zip  \n",
            " extracting: training_datas/train_data153.zip  \n",
            " extracting: training_datas/train_data6397.zip  \n",
            " extracting: training_datas/train_data19266.zip  \n",
            " extracting: training_datas/train_data5632.zip  \n",
            " extracting: training_datas/train_data21075.zip  \n",
            " extracting: training_datas/train_data19773.zip  \n",
            " extracting: training_datas/train_data26380.zip  \n",
            " extracting: training_datas/train_data3111.zip  \n",
            " extracting: training_datas/train_data30037.zip  \n",
            " extracting: training_datas/train_data16205.zip  \n",
            " extracting: training_datas/train_data13982.zip  \n",
            " extracting: training_datas/train_data4767.zip  \n",
            " extracting: training_datas/train_data27575.zip  \n",
            " extracting: training_datas/train_data27408.zip  \n",
            " extracting: training_datas/train_data23964.zip  \n",
            " extracting: training_datas/train_data14776.zip  \n",
            " extracting: training_datas/train_data14061.zip  \n",
            " extracting: training_datas/train_data20243.zip  \n",
            " extracting: training_datas/train_data15676.zip  \n",
            " extracting: training_datas/train_data8383.zip  \n",
            " extracting: training_datas/train_data20962.zip  \n",
            " extracting: training_datas/train_data26459.zip  \n",
            " extracting: training_datas/train_data17340.zip  \n",
            " extracting: training_datas/train_data16013.zip  \n",
            " extracting: training_datas/train_data1905.zip  \n",
            " extracting: training_datas/train_data27208.zip  \n",
            " extracting: training_datas/train_data15110.zip  \n",
            " extracting: training_datas/train_data3811.zip  \n",
            " extracting: training_datas/train_data12235.zip  \n",
            " extracting: training_datas/train_data16280.zip  \n",
            " extracting: training_datas/train_data23238.zip  \n",
            " extracting: training_datas/train_data4294.zip  \n",
            " extracting: training_datas/train_data28231.zip  \n",
            " extracting: training_datas/train_data20907.zip  \n",
            " extracting: training_datas/train_data14475.zip  \n",
            " extracting: training_datas/train_data27951.zip  \n",
            " extracting: training_datas/train_data3113.zip  \n",
            " extracting: training_datas/train_data20078.zip  \n",
            " extracting: training_datas/train_data24278.zip  \n",
            " extracting: training_datas/train_data10646.zip  \n",
            " extracting: training_datas/train_data10331.zip  \n",
            " extracting: training_datas/train_data106.zip  \n",
            " extracting: training_datas/train_data23694.zip  \n",
            " extracting: training_datas/train_data24179.zip  \n",
            " extracting: training_datas/train_data8505.zip  \n",
            " extracting: training_datas/train_data20709.zip  \n",
            " extracting: training_datas/train_data1060.zip  \n",
            " extracting: training_datas/train_data25685.zip  \n",
            " extracting: training_datas/train_data24613.zip  \n",
            " extracting: training_datas/train_data20141.zip  \n",
            " extracting: training_datas/train_data25130.zip  \n",
            " extracting: training_datas/train_data8474.zip  \n",
            " extracting: training_datas/train_data1357.zip  \n",
            " extracting: training_datas/train_data6648.zip  \n",
            " extracting: training_datas/train_data26274.zip  \n",
            " extracting: training_datas/train_data8960.zip  \n",
            " extracting: training_datas/train_data26688.zip  \n",
            " extracting: training_datas/train_data18600.zip  \n",
            " extracting: training_datas/train_data18670.zip  \n",
            " extracting: training_datas/train_data13927.zip  \n",
            " extracting: training_datas/train_data8835.zip  \n",
            " extracting: training_datas/train_data21606.zip  \n",
            " extracting: training_datas/train_data28631.zip  \n",
            " extracting: training_datas/train_data16995.zip  \n",
            " extracting: training_datas/train_data20638.zip  \n",
            " extracting: training_datas/train_data7879.zip  \n",
            " extracting: training_datas/train_data9485.zip  \n",
            " extracting: training_datas/train_data24628.zip  \n",
            " extracting: training_datas/train_data25541.zip  \n",
            " extracting: training_datas/train_data27728.zip  \n",
            " extracting: training_datas/train_data29469.zip  \n",
            " extracting: training_datas/train_data12497.zip  \n",
            " extracting: training_datas/train_data21509.zip  \n",
            " extracting: training_datas/train_data13760.zip  \n",
            " extracting: training_datas/train_data24411.zip  \n",
            " extracting: training_datas/train_data4925.zip  \n",
            " extracting: training_datas/train_data11023.zip  \n",
            " extracting: training_datas/train_data22672.zip  \n",
            " extracting: training_datas/train_data7465.zip  \n",
            " extracting: training_datas/train_data11580.zip  \n",
            " extracting: training_datas/train_data3897.zip  \n",
            " extracting: training_datas/train_data1734.zip  \n",
            " extracting: training_datas/train_data25344.zip  \n",
            " extracting: training_datas/train_data29209.zip  \n",
            " extracting: training_datas/train_data16648.zip  \n",
            " extracting: training_datas/train_data22496.zip  \n",
            " extracting: training_datas/train_data17198.zip  \n",
            " extracting: training_datas/train_data22776.zip  \n",
            " extracting: training_datas/train_data21291.zip  \n",
            " extracting: training_datas/train_data7893.zip  \n",
            " extracting: training_datas/train_data13043.zip  \n",
            " extracting: training_datas/train_data7700.zip  \n",
            " extracting: training_datas/train_data11858.zip  \n",
            " extracting: training_datas/train_data6027.zip  \n",
            " extracting: training_datas/train_data25429.zip  \n",
            " extracting: training_datas/train_data739.zip  \n",
            " extracting: training_datas/train_data14962.zip  \n",
            " extracting: training_datas/train_data24358.zip  \n",
            " extracting: training_datas/train_data18100.zip  \n",
            " extracting: training_datas/train_data16139.zip  \n",
            " extracting: training_datas/train_data20348.zip  \n",
            " extracting: training_datas/train_data6553.zip  \n",
            " extracting: training_datas/train_data16927.zip  \n",
            " extracting: training_datas/train_data30151.zip  \n",
            " extracting: training_datas/train_data23753.zip  \n",
            " extracting: training_datas/train_data16663.zip  \n",
            " extracting: training_datas/train_data16502.zip  \n",
            " extracting: training_datas/train_data22588.zip  \n",
            " extracting: training_datas/train_data19425.zip  \n",
            " extracting: training_datas/train_data6957.zip  \n",
            " extracting: training_datas/train_data26591.zip  \n",
            " extracting: training_datas/train_data13677.zip  \n",
            " extracting: training_datas/train_data8070.zip  \n",
            " extracting: training_datas/train_data552.zip  \n",
            " extracting: training_datas/train_data29281.zip  \n",
            " extracting: training_datas/train_data27197.zip  \n",
            " extracting: training_datas/train_data18692.zip  \n",
            " extracting: training_datas/train_data1375.zip  \n",
            " extracting: training_datas/train_data17599.zip  \n",
            " extracting: training_datas/train_data10808.zip  \n",
            " extracting: training_datas/train_data8061.zip  \n",
            " extracting: training_datas/train_data13001.zip  \n",
            " extracting: training_datas/train_data24340.zip  \n",
            " extracting: training_datas/train_data18759.zip  \n",
            " extracting: training_datas/train_data4706.zip  \n",
            " extracting: training_datas/train_data23486.zip  \n",
            " extracting: training_datas/train_data17623.zip  \n",
            " extracting: training_datas/train_data9347.zip  \n",
            " extracting: training_datas/train_data336.zip  \n",
            " extracting: training_datas/train_data14124.zip  \n",
            " extracting: training_datas/train_data18260.zip  \n",
            " extracting: training_datas/train_data14581.zip  \n",
            " extracting: training_datas/train_data16992.zip  \n",
            " extracting: training_datas/train_data6534.zip  \n",
            " extracting: training_datas/train_data24424.zip  \n",
            " extracting: training_datas/train_data28209.zip  \n",
            " extracting: training_datas/train_data15221.zip  \n",
            " extracting: training_datas/train_data1918.zip  \n",
            " extracting: training_datas/train_data16708.zip  \n",
            " extracting: training_datas/train_data25970.zip  \n",
            " extracting: training_datas/train_data22674.zip  \n",
            " extracting: training_datas/train_data25345.zip  \n",
            " extracting: training_datas/train_data880.zip  \n",
            " extracting: training_datas/train_data20018.zip  \n",
            " extracting: training_datas/train_data17610.zip  \n",
            " extracting: training_datas/train_data19332.zip  \n",
            " extracting: training_datas/train_data15030.zip  \n",
            " extracting: training_datas/train_data30036.zip  \n",
            " extracting: training_datas/train_data9072.zip  \n",
            " extracting: training_datas/train_data13734.zip  \n",
            " extracting: training_datas/train_data16906.zip  \n",
            " extracting: training_datas/train_data25492.zip  \n",
            " extracting: training_datas/train_data2318.zip  \n",
            " extracting: training_datas/train_data3578.zip  \n",
            " extracting: training_datas/train_data5936.zip  \n",
            " extracting: training_datas/train_data10423.zip  \n",
            " extracting: training_datas/train_data23685.zip  \n",
            " extracting: training_datas/train_data8371.zip  \n",
            " extracting: training_datas/train_data15989.zip  \n",
            " extracting: training_datas/train_data1693.zip  \n",
            " extracting: training_datas/train_data4129.zip  \n",
            " extracting: training_datas/train_data1780.zip  \n",
            " extracting: training_datas/train_data23506.zip  \n",
            " extracting: training_datas/train_data11058.zip  \n",
            " extracting: training_datas/train_data3309.zip  \n",
            " extracting: training_datas/train_data29850.zip  \n",
            " extracting: training_datas/train_data17274.zip  \n",
            " extracting: training_datas/train_data3081.zip  \n",
            " extracting: training_datas/train_data7545.zip  \n",
            " extracting: training_datas/train_data7050.zip  \n",
            " extracting: training_datas/train_data16586.zip  \n",
            " extracting: training_datas/train_data23391.zip  \n",
            " extracting: training_datas/train_data22526.zip  \n",
            " extracting: training_datas/train_data13562.zip  \n",
            " extracting: training_datas/train_data27454.zip  \n",
            " extracting: training_datas/train_data3799.zip  \n",
            " extracting: training_datas/train_data17603.zip  \n",
            " extracting: training_datas/train_data19140.zip  \n",
            " extracting: training_datas/train_data15389.zip  \n",
            " extracting: training_datas/train_data19519.zip  \n",
            " extracting: training_datas/train_data21934.zip  \n",
            " extracting: training_datas/train_data22596.zip  \n",
            " extracting: training_datas/train_data8801.zip  \n",
            " extracting: training_datas/train_data25134.zip  \n",
            " extracting: training_datas/train_data20154.zip  \n",
            " extracting: training_datas/train_data16674.zip  \n",
            " extracting: training_datas/train_data3217.zip  \n",
            " extracting: training_datas/train_data24618.zip  \n",
            " extracting: training_datas/train_data7783.zip  \n",
            " extracting: training_datas/train_data5885.zip  \n",
            " extracting: training_datas/train_data17647.zip  \n",
            " extracting: training_datas/train_data12438.zip  \n",
            " extracting: training_datas/train_data11034.zip  \n",
            " extracting: training_datas/train_data5640.zip  \n",
            " extracting: training_datas/train_data8692.zip  \n",
            " extracting: training_datas/train_data18343.zip  \n",
            " extracting: training_datas/train_data18942.zip  \n",
            " extracting: training_datas/train_data25088.zip  \n",
            " extracting: training_datas/train_data2485.zip  \n",
            " extracting: training_datas/train_data3048.zip  \n",
            " extracting: training_datas/train_data11399.zip  \n",
            " extracting: training_datas/train_data6464.zip  \n",
            " extracting: training_datas/train_data9258.zip  \n",
            " extracting: training_datas/train_data14270.zip  \n",
            " extracting: training_datas/train_data26485.zip  \n",
            " extracting: training_datas/train_data12496.zip  \n",
            " extracting: training_datas/train_data11570.zip  \n",
            " extracting: training_datas/train_data8068.zip  \n",
            " extracting: training_datas/train_data5057.zip  \n",
            " extracting: training_datas/train_data12806.zip  \n",
            " extracting: training_datas/train_data1839.zip  \n",
            " extracting: training_datas/train_data4915.zip  \n",
            " extracting: training_datas/train_data16671.zip  \n",
            " extracting: training_datas/train_data17894.zip  \n",
            " extracting: training_datas/train_data4168.zip  \n",
            " extracting: training_datas/train_data12782.zip  \n",
            " extracting: training_datas/train_data18333.zip  \n",
            " extracting: training_datas/train_data26297.zip  \n",
            " extracting: training_datas/train_data15190.zip  \n",
            " extracting: training_datas/train_data17538.zip  \n",
            " extracting: training_datas/train_data6857.zip  \n",
            " extracting: training_datas/train_data13382.zip  \n",
            " extracting: training_datas/train_data22431.zip  \n",
            " extracting: training_datas/train_data16574.zip  \n",
            " extracting: training_datas/train_data30070.zip  \n",
            " extracting: training_datas/train_data25629.zip  \n",
            " extracting: training_datas/train_data29930.zip  \n",
            " extracting: training_datas/train_data1388.zip  \n",
            " extracting: training_datas/train_data5840.zip  \n",
            " extracting: training_datas/train_data13264.zip  \n",
            " extracting: training_datas/train_data12556.zip  \n",
            " extracting: training_datas/train_data26260.zip  \n",
            " extracting: training_datas/train_data19985.zip  \n",
            " extracting: training_datas/train_data5659.zip  \n",
            " extracting: training_datas/train_data20295.zip  \n",
            " extracting: training_datas/train_data2871.zip  \n",
            " extracting: training_datas/train_data16560.zip  \n",
            " extracting: training_datas/train_data16482.zip  \n",
            " extracting: training_datas/train_data26596.zip  \n",
            " extracting: training_datas/train_data18451.zip  \n",
            " extracting: training_datas/train_data1002.zip  \n",
            " extracting: training_datas/train_data4970.zip  \n",
            " extracting: training_datas/train_data21126.zip  \n",
            " extracting: training_datas/train_data11105.zip  \n",
            " extracting: training_datas/train_data3371.zip  \n",
            " extracting: training_datas/train_data14493.zip  \n",
            " extracting: training_datas/train_data28239.zip  \n",
            " extracting: training_datas/train_data30258.zip  \n",
            " extracting: training_datas/train_data18433.zip  \n",
            " extracting: training_datas/train_data3560.zip  \n",
            " extracting: training_datas/train_data19718.zip  \n",
            " extracting: training_datas/train_data14968.zip  \n",
            " extracting: training_datas/train_data30065.zip  \n",
            " extracting: training_datas/train_data250.zip  \n",
            " extracting: training_datas/train_data20502.zip  \n",
            " extracting: training_datas/train_data1290.zip  \n",
            " extracting: training_datas/train_data16513.zip  \n",
            " extracting: training_datas/train_data3677.zip  \n",
            " extracting: training_datas/train_data20641.zip  \n",
            " extracting: training_datas/train_data14526.zip  \n",
            " extracting: training_datas/train_data23243.zip  \n",
            " extracting: training_datas/train_data5231.zip  \n",
            " extracting: training_datas/train_data17540.zip  \n",
            " extracting: training_datas/train_data14644.zip  \n",
            " extracting: training_datas/train_data335.zip  \n",
            " extracting: training_datas/train_data17988.zip  \n",
            " extracting: training_datas/train_data5412.zip  \n",
            " extracting: training_datas/train_data29372.zip  \n",
            " extracting: training_datas/train_data20989.zip  \n",
            " extracting: training_datas/train_data11600.zip  \n",
            " extracting: training_datas/train_data11793.zip  \n",
            " extracting: training_datas/train_data3260.zip  \n",
            " extracting: training_datas/train_data10801.zip  \n",
            " extracting: training_datas/train_data22889.zip  \n",
            " extracting: training_datas/train_data13715.zip  \n",
            " extracting: training_datas/train_data9521.zip  \n",
            " extracting: training_datas/train_data2755.zip  \n",
            " extracting: training_datas/train_data29790.zip  \n",
            " extracting: training_datas/train_data14310.zip  \n",
            " extracting: training_datas/train_data5507.zip  \n",
            " extracting: training_datas/train_data22018.zip  \n",
            " extracting: training_datas/train_data7343.zip  \n",
            " extracting: training_datas/train_data22791.zip  \n",
            " extracting: training_datas/train_data19484.zip  \n",
            " extracting: training_datas/train_data18027.zip  \n",
            " extracting: training_datas/train_data14556.zip  \n",
            " extracting: training_datas/train_data16843.zip  \n",
            " extracting: training_datas/train_data19170.zip  \n",
            " extracting: training_datas/train_data29906.zip  \n",
            " extracting: training_datas/train_data26554.zip  \n",
            " extracting: training_datas/train_data13033.zip  \n",
            " extracting: training_datas/train_data1395.zip  \n",
            " extracting: training_datas/train_data12833.zip  \n",
            " extracting: training_datas/train_data69.zip  \n",
            " extracting: training_datas/train_data13670.zip  \n",
            " extracting: training_datas/train_data13373.zip  \n",
            " extracting: training_datas/train_data9286.zip  \n",
            " extracting: training_datas/train_data17141.zip  \n",
            " extracting: training_datas/train_data20773.zip  \n",
            " extracting: training_datas/train_data22350.zip  \n",
            " extracting: training_datas/train_data27209.zip  \n",
            " extracting: training_datas/train_data28575.zip  \n",
            " extracting: training_datas/train_data30128.zip  \n",
            " extracting: training_datas/train_data17789.zip  \n",
            " extracting: training_datas/train_data6937.zip  \n",
            " extracting: training_datas/train_data25121.zip  \n",
            " extracting: training_datas/train_data939.zip  \n",
            " extracting: training_datas/train_data16801.zip  \n",
            " extracting: training_datas/train_data27231.zip  \n",
            " extracting: training_datas/train_data23426.zip  \n",
            " extracting: training_datas/train_data24553.zip  \n",
            " extracting: training_datas/train_data1077.zip  \n",
            " extracting: training_datas/train_data2715.zip  \n",
            " extracting: training_datas/train_data12071.zip  \n",
            " extracting: training_datas/train_data8138.zip  \n",
            " extracting: training_datas/train_data11170.zip  \n",
            " extracting: training_datas/train_data4834.zip  \n",
            " extracting: training_datas/train_data24849.zip  \n",
            " extracting: training_datas/train_data24182.zip  \n",
            " extracting: training_datas/train_data17609.zip  \n",
            " extracting: training_datas/train_data2296.zip  \n",
            " extracting: training_datas/train_data4293.zip  \n",
            " extracting: training_datas/train_data14937.zip  \n",
            " extracting: training_datas/train_data11080.zip  \n",
            " extracting: training_datas/train_data807.zip  \n",
            " extracting: training_datas/train_data2383.zip  \n",
            " extracting: training_datas/train_data22983.zip  \n",
            " extracting: training_datas/train_data19079.zip  \n",
            " extracting: training_datas/train_data28955.zip  \n",
            " extracting: training_datas/train_data16145.zip  \n",
            " extracting: training_datas/train_data3443.zip  \n",
            " extracting: training_datas/train_data14549.zip  \n",
            " extracting: training_datas/train_data2603.zip  \n",
            " extracting: training_datas/train_data15155.zip  \n",
            " extracting: training_datas/train_data28489.zip  \n",
            " extracting: training_datas/train_data4783.zip  \n",
            " extracting: training_datas/train_data3251.zip  \n",
            " extracting: training_datas/train_data27061.zip  \n",
            " extracting: training_datas/train_data17707.zip  \n",
            " extracting: training_datas/train_data2403.zip  \n",
            " extracting: training_datas/train_data26588.zip  \n",
            " extracting: training_datas/train_data13903.zip  \n",
            " extracting: training_datas/train_data21952.zip  \n",
            " extracting: training_datas/train_data8590.zip  \n",
            " extracting: training_datas/train_data4689.zip  \n",
            " extracting: training_datas/train_data5674.zip  \n",
            " extracting: training_datas/train_data29857.zip  \n",
            " extracting: training_datas/train_data8519.zip  \n",
            " extracting: training_datas/train_data10621.zip  \n",
            " extracting: training_datas/train_data10640.zip  \n",
            " extracting: training_datas/train_data9913.zip  \n",
            " extracting: training_datas/train_data691.zip  \n",
            " extracting: training_datas/train_data20397.zip  \n",
            " extracting: training_datas/train_data17435.zip  \n",
            " extracting: training_datas/train_data165.zip  \n",
            " extracting: training_datas/train_data15087.zip  \n",
            " extracting: training_datas/train_data20797.zip  \n",
            " extracting: training_datas/train_data25376.zip  \n",
            " extracting: training_datas/train_data15361.zip  \n",
            " extracting: training_datas/train_data7310.zip  \n",
            " extracting: training_datas/train_data6064.zip  \n",
            " extracting: training_datas/train_data21891.zip  \n",
            " extracting: training_datas/train_data20541.zip  \n",
            " extracting: training_datas/train_data22810.zip  \n",
            " extracting: training_datas/train_data16676.zip  \n",
            " extracting: training_datas/train_data7854.zip  \n",
            " extracting: training_datas/train_data4730.zip  \n",
            " extracting: training_datas/train_data18817.zip  \n",
            " extracting: training_datas/train_data16410.zip  \n",
            " extracting: training_datas/train_data27979.zip  \n",
            " extracting: training_datas/train_data15521.zip  \n",
            " extracting: training_datas/train_data29713.zip  \n",
            " extracting: training_datas/train_data15138.zip  \n",
            " extracting: training_datas/train_data10231.zip  \n",
            " extracting: training_datas/train_data21066.zip  \n",
            " extracting: training_datas/train_data26357.zip  \n",
            " extracting: training_datas/train_data28702.zip  \n",
            " extracting: training_datas/train_data16403.zip  \n",
            " extracting: training_datas/train_data20318.zip  \n",
            " extracting: training_datas/train_data5878.zip  \n",
            " extracting: training_datas/train_data14955.zip  \n",
            " extracting: training_datas/train_data29662.zip  \n",
            " extracting: training_datas/train_data26437.zip  \n",
            " extracting: training_datas/train_data8330.zip  \n",
            " extracting: training_datas/train_data7103.zip  \n",
            " extracting: training_datas/train_data30453.zip  \n",
            " extracting: training_datas/train_data10753.zip  \n",
            " extracting: training_datas/train_data10106.zip  \n",
            " extracting: training_datas/train_data20429.zip  \n",
            " extracting: training_datas/train_data12070.zip  \n",
            " extracting: training_datas/train_data23211.zip  \n",
            " extracting: training_datas/train_data6602.zip  \n",
            " extracting: training_datas/train_data28.zip  \n",
            " extracting: training_datas/train_data10347.zip  \n",
            " extracting: training_datas/train_data22351.zip  \n",
            " extracting: training_datas/train_data20037.zip  \n",
            " extracting: training_datas/train_data22070.zip  \n",
            " extracting: training_datas/train_data6179.zip  \n",
            " extracting: training_datas/train_data3134.zip  \n",
            " extracting: training_datas/train_data21720.zip  \n",
            " extracting: training_datas/train_data22196.zip  \n",
            " extracting: training_datas/train_data2429.zip  \n",
            " extracting: training_datas/train_data23553.zip  \n",
            " extracting: training_datas/train_data28666.zip  \n",
            " extracting: training_datas/train_data27867.zip  \n",
            " extracting: training_datas/train_data468.zip  \n",
            " extracting: training_datas/train_data9987.zip  \n",
            " extracting: training_datas/train_data6164.zip  \n",
            " extracting: training_datas/train_data13253.zip  \n",
            " extracting: training_datas/train_data25615.zip  \n",
            " extracting: training_datas/train_data25055.zip  \n",
            " extracting: training_datas/train_data14141.zip  \n",
            " extracting: training_datas/train_data11295.zip  \n",
            " extracting: training_datas/train_data2550.zip  \n",
            " extracting: training_datas/train_data8069.zip  \n",
            " extracting: training_datas/train_data25377.zip  \n",
            " extracting: training_datas/train_data5993.zip  \n",
            " extracting: training_datas/train_data8477.zip  \n",
            " extracting: training_datas/train_data27059.zip  \n",
            " extracting: training_datas/train_data3471.zip  \n",
            " extracting: training_datas/train_data1347.zip  \n",
            " extracting: training_datas/train_data4933.zip  \n",
            " extracting: training_datas/train_data9560.zip  \n",
            " extracting: training_datas/train_data5094.zip  \n",
            " extracting: training_datas/train_data5135.zip  \n",
            " extracting: training_datas/train_data30172.zip  \n",
            " extracting: training_datas/train_data1479.zip  \n",
            " extracting: training_datas/train_data13947.zip  \n",
            " extracting: training_datas/train_data22416.zip  \n",
            " extracting: training_datas/train_data28113.zip  \n",
            " extracting: training_datas/train_data17299.zip  \n",
            " extracting: training_datas/train_data243.zip  \n",
            " extracting: training_datas/train_data9068.zip  \n",
            " extracting: training_datas/train_data2228.zip  \n",
            " extracting: training_datas/train_data30311.zip  \n",
            " extracting: training_datas/train_data3787.zip  \n",
            " extracting: training_datas/train_data26195.zip  \n",
            " extracting: training_datas/train_data12361.zip  \n",
            " extracting: training_datas/train_data9500.zip  \n",
            " extracting: training_datas/train_data16639.zip  \n",
            " extracting: training_datas/train_data5039.zip  \n",
            " extracting: training_datas/train_data14813.zip  \n",
            " extracting: training_datas/train_data22133.zip  \n",
            " extracting: training_datas/train_data4709.zip  \n",
            " extracting: training_datas/train_data19698.zip  \n",
            " extracting: training_datas/train_data4137.zip  \n",
            " extracting: training_datas/train_data17900.zip  \n",
            " extracting: training_datas/train_data17681.zip  \n",
            " extracting: training_datas/train_data20416.zip  \n",
            " extracting: training_datas/train_data20291.zip  \n",
            " extracting: training_datas/train_data14967.zip  \n",
            " extracting: training_datas/train_data28680.zip  \n",
            " extracting: training_datas/train_data18609.zip  \n",
            " extracting: training_datas/train_data18291.zip  \n",
            " extracting: training_datas/train_data17930.zip  \n",
            " extracting: training_datas/train_data17386.zip  \n",
            " extracting: training_datas/train_data25962.zip  \n",
            " extracting: training_datas/train_data15420.zip  \n",
            " extracting: training_datas/train_data13588.zip  \n",
            " extracting: training_datas/train_data9761.zip  \n",
            " extracting: training_datas/train_data19024.zip  \n",
            " extracting: training_datas/train_data21514.zip  \n",
            " extracting: training_datas/train_data4634.zip  \n",
            " extracting: training_datas/train_data20761.zip  \n",
            " extracting: training_datas/train_data2849.zip  \n",
            " extracting: training_datas/train_data9049.zip  \n",
            " extracting: training_datas/train_data13422.zip  \n",
            " extracting: training_datas/train_data26976.zip  \n",
            " extracting: training_datas/train_data30217.zip  \n",
            " extracting: training_datas/train_data18829.zip  \n",
            " extracting: training_datas/train_data1194.zip  \n",
            " extracting: training_datas/train_data22253.zip  \n",
            " extracting: training_datas/train_data2462.zip  \n",
            " extracting: training_datas/train_data6344.zip  \n",
            " extracting: training_datas/train_data759.zip  \n",
            " extracting: training_datas/train_data23377.zip  \n",
            " extracting: training_datas/train_data16016.zip  \n",
            " extracting: training_datas/train_data20000.zip  \n",
            " extracting: training_datas/train_data14017.zip  \n",
            " extracting: training_datas/train_data18145.zip  \n",
            " extracting: training_datas/train_data27018.zip  \n",
            " extracting: training_datas/train_data111.zip  \n",
            " extracting: training_datas/train_data5772.zip  \n",
            " extracting: training_datas/train_data1475.zip  \n",
            " extracting: training_datas/train_data953.zip  \n",
            " extracting: training_datas/train_data21892.zip  \n",
            " extracting: training_datas/train_data6774.zip  \n",
            " extracting: training_datas/train_data4790.zip  \n",
            " extracting: training_datas/train_data24646.zip  \n",
            " extracting: training_datas/train_data16626.zip  \n",
            " extracting: training_datas/train_data4475.zip  \n",
            " extracting: training_datas/train_data24525.zip  \n",
            " extracting: training_datas/train_data28803.zip  \n",
            " extracting: training_datas/train_data14171.zip  \n",
            " extracting: training_datas/train_data15883.zip  \n",
            " extracting: training_datas/train_data22181.zip  \n",
            " extracting: training_datas/train_data28020.zip  \n",
            " extracting: training_datas/train_data12995.zip  \n",
            " extracting: training_datas/train_data4628.zip  \n",
            " extracting: training_datas/train_data28387.zip  \n",
            " extracting: training_datas/train_data310.zip  \n",
            " extracting: training_datas/train_data30004.zip  \n",
            " extracting: training_datas/train_data1238.zip  \n",
            " extracting: training_datas/train_data8811.zip  \n",
            " extracting: training_datas/train_data15975.zip  \n",
            " extracting: training_datas/train_data370.zip  \n",
            " extracting: training_datas/train_data12325.zip  \n",
            " extracting: training_datas/train_data5305.zip  \n",
            " extracting: training_datas/train_data13796.zip  \n",
            " extracting: training_datas/train_data14938.zip  \n",
            " extracting: training_datas/train_data18256.zip  \n",
            " extracting: training_datas/train_data29239.zip  \n",
            " extracting: training_datas/train_data30480.zip  \n",
            " extracting: training_datas/train_data13213.zip  \n",
            " extracting: training_datas/train_data7114.zip  \n",
            " extracting: training_datas/train_data20663.zip  \n",
            " extracting: training_datas/train_data4751.zip  \n",
            " extracting: training_datas/train_data26781.zip  \n",
            " extracting: training_datas/train_data25620.zip  \n",
            " extracting: training_datas/train_data20677.zip  \n",
            " extracting: training_datas/train_data25170.zip  \n",
            " extracting: training_datas/train_data2765.zip  \n",
            " extracting: training_datas/train_data17451.zip  \n",
            " extracting: training_datas/train_data23764.zip  \n",
            " extracting: training_datas/train_data29269.zip  \n",
            " extracting: training_datas/train_data25043.zip  \n",
            " extracting: training_datas/train_data18230.zip  \n",
            " extracting: training_datas/train_data16041.zip  \n",
            " extracting: training_datas/train_data8358.zip  \n",
            " extracting: training_datas/train_data4565.zip  \n",
            " extracting: training_datas/train_data4230.zip  \n",
            " extracting: training_datas/train_data28751.zip  \n",
            " extracting: training_datas/train_data13990.zip  \n",
            " extracting: training_datas/train_data20783.zip  \n",
            " extracting: training_datas/train_data24388.zip  \n",
            " extracting: training_datas/train_data27190.zip  \n",
            " extracting: training_datas/train_data30179.zip  \n",
            " extracting: training_datas/train_data10255.zip  \n",
            " extracting: training_datas/train_data2637.zip  \n",
            " extracting: training_datas/train_data5070.zip  \n",
            " extracting: training_datas/train_data30182.zip  \n",
            " extracting: training_datas/train_data11239.zip  \n",
            " extracting: training_datas/train_data22046.zip  \n",
            " extracting: training_datas/train_data8621.zip  \n",
            " extracting: training_datas/train_data28578.zip  \n",
            " extracting: training_datas/train_data16191.zip  \n",
            " extracting: training_datas/train_data29639.zip  \n",
            " extracting: training_datas/train_data26908.zip  \n",
            " extracting: training_datas/train_data8541.zip  \n",
            " extracting: training_datas/train_data11463.zip  \n",
            " extracting: training_datas/train_data196.zip  \n",
            " extracting: training_datas/train_data17652.zip  \n",
            " extracting: training_datas/train_data8496.zip  \n",
            " extracting: training_datas/train_data9856.zip  \n",
            " extracting: training_datas/train_data26444.zip  \n",
            " extracting: training_datas/train_data8917.zip  \n",
            " extracting: training_datas/train_data11350.zip  \n",
            " extracting: training_datas/train_data8119.zip  \n",
            " extracting: training_datas/train_data27577.zip  \n",
            " extracting: training_datas/train_data28280.zip  \n",
            " extracting: training_datas/train_data24956.zip  \n",
            " extracting: training_datas/train_data1419.zip  \n",
            " extracting: training_datas/train_data22559.zip  \n",
            " extracting: training_datas/train_data28206.zip  \n",
            " extracting: training_datas/train_data14502.zip  \n",
            " extracting: training_datas/train_data12638.zip  \n",
            " extracting: training_datas/train_data6656.zip  \n",
            " extracting: training_datas/train_data7542.zip  \n",
            " extracting: training_datas/train_data9829.zip  \n",
            " extracting: training_datas/train_data11511.zip  \n",
            " extracting: training_datas/train_data23292.zip  \n",
            " extracting: training_datas/train_data18691.zip  \n",
            " extracting: training_datas/train_data28389.zip  \n",
            " extracting: training_datas/train_data3933.zip  \n",
            " extracting: training_datas/train_data8482.zip  \n",
            " extracting: training_datas/train_data22248.zip  \n",
            " extracting: training_datas/train_data17162.zip  \n",
            " extracting: training_datas/train_data10453.zip  \n",
            " extracting: training_datas/train_data28518.zip  \n",
            " extracting: training_datas/train_data24848.zip  \n",
            " extracting: training_datas/train_data2875.zip  \n",
            " extracting: training_datas/train_data21084.zip  \n",
            " extracting: training_datas/train_data8031.zip  \n",
            " extracting: training_datas/train_data28177.zip  \n",
            " extracting: training_datas/train_data10592.zip  \n",
            " extracting: training_datas/train_data20021.zip  \n",
            " extracting: training_datas/train_data16617.zip  \n",
            " extracting: training_datas/train_data18154.zip  \n",
            " extracting: training_datas/train_data1550.zip  \n",
            " extracting: training_datas/train_data900.zip  \n",
            " extracting: training_datas/train_data8074.zip  \n",
            " extracting: training_datas/train_data20706.zip  \n",
            " extracting: training_datas/train_data6203.zip  \n",
            " extracting: training_datas/train_data17898.zip  \n",
            " extracting: training_datas/train_data28775.zip  \n",
            " extracting: training_datas/train_data17099.zip  \n",
            " extracting: training_datas/train_data28084.zip  \n",
            " extracting: training_datas/train_data7749.zip  \n",
            " extracting: training_datas/train_data3690.zip  \n",
            " extracting: training_datas/train_data11634.zip  \n",
            " extracting: training_datas/train_data17572.zip  \n",
            " extracting: training_datas/train_data27767.zip  \n",
            " extracting: training_datas/train_data22671.zip  \n",
            " extracting: training_datas/train_data18162.zip  \n",
            " extracting: training_datas/train_data29654.zip  \n",
            " extracting: training_datas/train_data11886.zip  \n",
            " extracting: training_datas/train_data1084.zip  \n",
            " extracting: training_datas/train_data8587.zip  \n",
            " extracting: training_datas/train_data3286.zip  \n",
            " extracting: training_datas/train_data23736.zip  \n",
            " extracting: training_datas/train_data12194.zip  \n",
            " extracting: training_datas/train_data9817.zip  \n",
            " extracting: training_datas/train_data3766.zip  \n",
            " extracting: training_datas/train_data1953.zip  \n",
            " extracting: training_datas/train_data27563.zip  \n",
            " extracting: training_datas/train_data12198.zip  \n",
            " extracting: training_datas/train_data26362.zip  \n",
            " extracting: training_datas/train_data29982.zip  \n",
            " extracting: training_datas/train_data29643.zip  \n",
            " extracting: training_datas/train_data21135.zip  \n",
            " extracting: training_datas/train_data15214.zip  \n",
            " extracting: training_datas/train_data11100.zip  \n",
            " extracting: training_datas/train_data16387.zip  \n",
            " extracting: training_datas/train_data14334.zip  \n",
            " extracting: training_datas/train_data23662.zip  \n",
            " extracting: training_datas/train_data30387.zip  \n",
            " extracting: training_datas/train_data7511.zip  \n",
            " extracting: training_datas/train_data19023.zip  \n",
            " extracting: training_datas/train_data12617.zip  \n",
            " extracting: training_datas/train_data4617.zip  \n",
            " extracting: training_datas/train_data5714.zip  \n",
            " extracting: training_datas/train_data16152.zip  \n",
            " extracting: training_datas/train_data796.zip  \n",
            " extracting: training_datas/train_data25764.zip  \n",
            " extracting: training_datas/train_data12164.zip  \n",
            " extracting: training_datas/train_data28225.zip  \n",
            " extracting: training_datas/train_data12482.zip  \n",
            " extracting: training_datas/train_data20248.zip  \n",
            " extracting: training_datas/train_data12268.zip  \n",
            " extracting: training_datas/train_data22703.zip  \n",
            " extracting: training_datas/train_data16223.zip  \n",
            " extracting: training_datas/train_data27139.zip  \n",
            " extracting: training_datas/train_data6746.zip  \n",
            " extracting: training_datas/train_data22642.zip  \n",
            " extracting: training_datas/train_data14387.zip  \n",
            " extracting: training_datas/train_data13726.zip  \n",
            " extracting: training_datas/train_data24048.zip  \n",
            " extracting: training_datas/train_data16052.zip  \n",
            " extracting: training_datas/train_data14733.zip  \n",
            " extracting: training_datas/train_data27319.zip  \n",
            " extracting: training_datas/train_data770.zip  \n",
            " extracting: training_datas/train_data30329.zip  \n",
            " extracting: training_datas/train_data22960.zip  \n",
            " extracting: training_datas/train_data13803.zip  \n",
            " extracting: training_datas/train_data13882.zip  \n",
            " extracting: training_datas/train_data18046.zip  \n",
            " extracting: training_datas/train_data7077.zip  \n",
            " extracting: training_datas/train_data21648.zip  \n",
            " extracting: training_datas/train_data27035.zip  \n",
            " extracting: training_datas/train_data29255.zip  \n",
            " extracting: training_datas/train_data30424.zip  \n",
            " extracting: training_datas/train_data5860.zip  \n",
            " extracting: training_datas/train_data13197.zip  \n",
            " extracting: training_datas/train_data6958.zip  \n",
            " extracting: training_datas/train_data11867.zip  \n",
            " extracting: training_datas/train_data1331.zip  \n",
            " extracting: training_datas/train_data12126.zip  \n",
            " extracting: training_datas/train_data7198.zip  \n",
            " extracting: training_datas/train_data11723.zip  \n",
            " extracting: training_datas/train_data24140.zip  \n",
            " extracting: training_datas/train_data20285.zip  \n",
            " extracting: training_datas/train_data13051.zip  \n",
            " extracting: training_datas/train_data26972.zip  \n",
            " extracting: training_datas/train_data9924.zip  \n",
            " extracting: training_datas/train_data12684.zip  \n",
            " extracting: training_datas/train_data1294.zip  \n",
            " extracting: training_datas/train_data27303.zip  \n",
            " extracting: training_datas/train_data9480.zip  \n",
            " extracting: training_datas/train_data24359.zip  \n",
            " extracting: training_datas/train_data24577.zip  \n",
            " extracting: training_datas/train_data18279.zip  \n",
            " extracting: training_datas/train_data10172.zip  \n",
            " extracting: training_datas/train_data11220.zip  \n",
            " extracting: training_datas/train_data6200.zip  \n",
            " extracting: training_datas/train_data20288.zip  \n",
            " extracting: training_datas/train_data17616.zip  \n",
            " extracting: training_datas/train_data9670.zip  \n",
            " extracting: training_datas/train_data9750.zip  \n",
            " extracting: training_datas/train_data9803.zip  \n",
            " extracting: training_datas/train_data6543.zip  \n",
            " extracting: training_datas/train_data12342.zip  \n",
            " extracting: training_datas/train_data22635.zip  \n",
            " extracting: training_datas/train_data29349.zip  \n",
            " extracting: training_datas/train_data14565.zip  \n",
            " extracting: training_datas/train_data67.zip  \n",
            " extracting: training_datas/train_data26006.zip  \n",
            " extracting: training_datas/train_data3907.zip  \n",
            " extracting: training_datas/train_data25024.zip  \n",
            " extracting: training_datas/train_data2038.zip  \n",
            " extracting: training_datas/train_data23487.zip  \n",
            " extracting: training_datas/train_data22096.zip  \n",
            " extracting: training_datas/train_data20323.zip  \n",
            " extracting: training_datas/train_data1094.zip  \n",
            " extracting: training_datas/train_data14997.zip  \n",
            " extracting: training_datas/train_data9722.zip  \n",
            " extracting: training_datas/train_data28079.zip  \n",
            " extracting: training_datas/train_data1777.zip  \n",
            " extracting: training_datas/train_data653.zip  \n",
            " extracting: training_datas/train_data14434.zip  \n",
            " extracting: training_datas/train_data13683.zip  \n",
            " extracting: training_datas/train_data12272.zip  \n",
            " extracting: training_datas/train_data12603.zip  \n",
            " extracting: training_datas/train_data18504.zip  \n",
            " extracting: training_datas/train_data29214.zip  \n",
            " extracting: training_datas/train_data5211.zip  \n",
            " extracting: training_datas/train_data14321.zip  \n",
            " extracting: training_datas/train_data789.zip  \n",
            " extracting: training_datas/train_data25743.zip  \n",
            " extracting: training_datas/train_data6873.zip  \n",
            " extracting: training_datas/train_data27341.zip  \n",
            " extracting: training_datas/train_data10554.zip  \n",
            " extracting: training_datas/train_data30054.zip  \n",
            " extracting: training_datas/train_data12955.zip  \n",
            " extracting: training_datas/train_data15884.zip  \n",
            " extracting: training_datas/train_data14095.zip  \n",
            " extracting: training_datas/train_data17067.zip  \n",
            " extracting: training_datas/train_data1504.zip  \n",
            " extracting: training_datas/train_data8357.zip  \n",
            " extracting: training_datas/train_data28530.zip  \n",
            " extracting: training_datas/train_data29367.zip  \n",
            " extracting: training_datas/train_data6418.zip  \n",
            " extracting: training_datas/train_data24161.zip  \n",
            " extracting: training_datas/train_data3301.zip  \n",
            " extracting: training_datas/train_data27873.zip  \n",
            " extracting: training_datas/train_data29744.zip  \n",
            " extracting: training_datas/train_data13088.zip  \n",
            " extracting: training_datas/train_data27947.zip  \n",
            " extracting: training_datas/train_data21595.zip  \n",
            " extracting: training_datas/train_data19222.zip  \n",
            " extracting: training_datas/train_data2988.zip  \n",
            " extracting: training_datas/train_data4108.zip  \n",
            " extracting: training_datas/train_data23993.zip  \n",
            " extracting: training_datas/train_data19845.zip  \n",
            " extracting: training_datas/train_data2283.zip  \n",
            " extracting: training_datas/train_data10558.zip  \n",
            " extracting: training_datas/train_data9795.zip  \n",
            " extracting: training_datas/train_data25818.zip  \n",
            " extracting: training_datas/train_data26811.zip  \n",
            " extracting: training_datas/train_data8352.zip  \n",
            " extracting: training_datas/train_data4952.zip  \n",
            " extracting: training_datas/train_data22873.zip  \n",
            " extracting: training_datas/train_data12605.zip  \n",
            " extracting: training_datas/train_data21876.zip  \n",
            " extracting: training_datas/train_data19036.zip  \n",
            " extracting: training_datas/train_data26586.zip  \n",
            " extracting: training_datas/train_data28123.zip  \n",
            " extracting: training_datas/train_data14609.zip  \n",
            " extracting: training_datas/train_data11408.zip  \n",
            " extracting: training_datas/train_data30251.zip  \n",
            " extracting: training_datas/train_data25611.zip  \n",
            " extracting: training_datas/train_data24227.zip  \n",
            " extracting: training_datas/train_data10393.zip  \n",
            " extracting: training_datas/train_data2654.zip  \n",
            " extracting: training_datas/train_data22199.zip  \n",
            " extracting: training_datas/train_data26681.zip  \n",
            " extracting: training_datas/train_data26974.zip  \n",
            " extracting: training_datas/train_data20586.zip  \n",
            " extracting: training_datas/train_data11623.zip  \n",
            " extracting: training_datas/train_data16127.zip  \n",
            " extracting: training_datas/train_data23378.zip  \n",
            " extracting: training_datas/train_data29291.zip  \n",
            " extracting: training_datas/train_data16966.zip  \n",
            " extracting: training_datas/train_data27304.zip  \n",
            " extracting: training_datas/train_data9228.zip  \n",
            " extracting: training_datas/train_data16382.zip  \n",
            " extracting: training_datas/train_data21197.zip  \n",
            " extracting: training_datas/train_data2234.zip  \n",
            " extracting: training_datas/train_data16172.zip  \n",
            " extracting: training_datas/train_data4222.zip  \n",
            " extracting: training_datas/train_data21786.zip  \n",
            " extracting: training_datas/train_data7526.zip  \n",
            " extracting: training_datas/train_data12957.zip  \n",
            " extracting: training_datas/train_data10422.zip  \n",
            " extracting: training_datas/train_data14312.zip  \n",
            " extracting: training_datas/train_data15618.zip  \n",
            " extracting: training_datas/train_data9723.zip  \n",
            " extracting: training_datas/train_data1655.zip  \n",
            " extracting: training_datas/train_data6485.zip  \n",
            " extracting: training_datas/train_data2394.zip  \n",
            " extracting: training_datas/train_data2572.zip  \n",
            " extracting: training_datas/train_data21250.zip  \n",
            " extracting: training_datas/train_data16882.zip  \n",
            " extracting: training_datas/train_data23609.zip  \n",
            " extracting: training_datas/train_data10546.zip  \n",
            " extracting: training_datas/train_data16539.zip  \n",
            " extracting: training_datas/train_data2133.zip  \n",
            " extracting: training_datas/train_data24152.zip  \n",
            " extracting: training_datas/train_data3713.zip  \n",
            " extracting: training_datas/train_data1712.zip  \n",
            " extracting: training_datas/train_data30322.zip  \n",
            " extracting: training_datas/train_data19530.zip  \n",
            " extracting: training_datas/train_data9484.zip  \n",
            " extracting: training_datas/train_data4097.zip  \n",
            " extracting: training_datas/train_data4744.zip  \n",
            " extracting: training_datas/train_data9599.zip  \n",
            " extracting: training_datas/train_data16222.zip  \n",
            " extracting: training_datas/train_data21292.zip  \n",
            " extracting: training_datas/train_data22187.zip  \n",
            " extracting: training_datas/train_data16218.zip  \n",
            " extracting: training_datas/train_data28254.zip  \n",
            " extracting: training_datas/train_data14107.zip  \n",
            " extracting: training_datas/train_data28393.zip  \n",
            " extracting: training_datas/train_data13412.zip  \n",
            " extracting: training_datas/train_data26121.zip  \n",
            " extracting: training_datas/train_data18756.zip  \n",
            " extracting: training_datas/train_data26330.zip  \n",
            " extracting: training_datas/train_data13103.zip  \n",
            " extracting: training_datas/train_data14343.zip  \n",
            " extracting: training_datas/train_data24081.zip  \n",
            " extracting: training_datas/train_data28599.zip  \n",
            " extracting: training_datas/train_data11362.zip  \n",
            " extracting: training_datas/train_data15859.zip  \n",
            " extracting: training_datas/train_data6032.zip  \n",
            " extracting: training_datas/train_data27919.zip  \n",
            " extracting: training_datas/train_data26877.zip  \n",
            " extracting: training_datas/train_data7742.zip  \n",
            " extracting: training_datas/train_data18909.zip  \n",
            " extracting: training_datas/train_data29224.zip  \n",
            " extracting: training_datas/train_data9149.zip  \n",
            " extracting: training_datas/train_data14620.zip  \n",
            " extracting: training_datas/train_data20023.zip  \n",
            " extracting: training_datas/train_data3472.zip  \n",
            " extracting: training_datas/train_data3932.zip  \n",
            " extracting: training_datas/train_data18082.zip  \n",
            " extracting: training_datas/train_data20375.zip  \n",
            " extracting: training_datas/train_data30045.zip  \n",
            " extracting: training_datas/train_data6145.zip  \n",
            " extracting: training_datas/train_data15128.zip  \n",
            " extracting: training_datas/train_data10427.zip  \n",
            " extracting: training_datas/train_data19889.zip  \n",
            " extracting: training_datas/train_data22290.zip  \n",
            " extracting: training_datas/train_data1703.zip  \n",
            " extracting: training_datas/train_data23018.zip  \n",
            " extracting: training_datas/train_data2763.zip  \n",
            " extracting: training_datas/train_data20102.zip  \n",
            " extracting: training_datas/train_data956.zip  \n",
            " extracting: training_datas/train_data19580.zip  \n",
            " extracting: training_datas/train_data5177.zip  \n",
            " extracting: training_datas/train_data20153.zip  \n",
            " extracting: training_datas/train_data13825.zip  \n",
            " extracting: training_datas/train_data21222.zip  \n",
            " extracting: training_datas/train_data15538.zip  \n",
            " extracting: training_datas/train_data4909.zip  \n",
            " extracting: training_datas/train_data13907.zip  \n",
            " extracting: training_datas/train_data27862.zip  \n",
            " extracting: training_datas/train_data21675.zip  \n",
            " extracting: training_datas/train_data1732.zip  \n",
            " extracting: training_datas/train_data23539.zip  \n",
            " extracting: training_datas/train_data18497.zip  \n",
            " extracting: training_datas/train_data16209.zip  \n",
            " extracting: training_datas/train_data15527.zip  \n",
            " extracting: training_datas/train_data18431.zip  \n",
            " extracting: training_datas/train_data14471.zip  \n",
            " extracting: training_datas/train_data7640.zip  \n",
            " extracting: training_datas/train_data1365.zip  \n",
            " extracting: training_datas/train_data23122.zip  \n",
            " extracting: training_datas/train_data13784.zip  \n",
            " extracting: training_datas/train_data20801.zip  \n",
            " extracting: training_datas/train_data14985.zip  \n",
            " extracting: training_datas/train_data10323.zip  \n",
            " extracting: training_datas/train_data20355.zip  \n",
            " extracting: training_datas/train_data2663.zip  \n",
            " extracting: training_datas/train_data6492.zip  \n",
            " extracting: training_datas/train_data15444.zip  \n",
            " extracting: training_datas/train_data11376.zip  \n",
            " extracting: training_datas/train_data14708.zip  \n",
            " extracting: training_datas/train_data12885.zip  \n",
            " extracting: training_datas/train_data8793.zip  \n",
            " extracting: training_datas/train_data18987.zip  \n",
            " extracting: training_datas/train_data18870.zip  \n",
            " extracting: training_datas/train_data13385.zip  \n",
            " extracting: training_datas/train_data24629.zip  \n",
            " extracting: training_datas/train_data1120.zip  \n",
            " extracting: training_datas/train_data3979.zip  \n",
            " extracting: training_datas/train_data21847.zip  \n",
            " extracting: training_datas/train_data24051.zip  \n",
            " extracting: training_datas/train_data4039.zip  \n",
            " extracting: training_datas/train_data27006.zip  \n",
            " extracting: training_datas/train_data18610.zip  \n",
            " extracting: training_datas/train_data10584.zip  \n",
            " extracting: training_datas/train_data21737.zip  \n",
            " extracting: training_datas/train_data20610.zip  \n",
            " extracting: training_datas/train_data3870.zip  \n",
            " extracting: training_datas/train_data8098.zip  \n",
            " extracting: training_datas/train_data18720.zip  \n",
            " extracting: training_datas/train_data16497.zip  \n",
            " extracting: training_datas/train_data21412.zip  \n",
            " extracting: training_datas/train_data3296.zip  \n",
            " extracting: training_datas/train_data1957.zip  \n",
            " extracting: training_datas/train_data3101.zip  \n",
            " extracting: training_datas/train_data6310.zip  \n",
            " extracting: training_datas/train_data24109.zip  \n",
            " extracting: training_datas/train_data537.zip  \n",
            " extracting: training_datas/train_data3105.zip  \n",
            " extracting: training_datas/train_data8678.zip  \n",
            " extracting: training_datas/train_data1362.zip  \n",
            " extracting: training_datas/train_data24589.zip  \n",
            " extracting: training_datas/train_data6868.zip  \n",
            " extracting: training_datas/train_data25877.zip  \n",
            " extracting: training_datas/train_data10271.zip  \n",
            " extracting: training_datas/train_data9013.zip  \n",
            " extracting: training_datas/train_data30328.zip  \n",
            " extracting: training_datas/train_data18666.zip  \n",
            " extracting: training_datas/train_data7935.zip  \n",
            " extracting: training_datas/train_data11555.zip  \n",
            " extracting: training_datas/train_data2065.zip  \n",
            " extracting: training_datas/train_data16647.zip  \n",
            " extracting: training_datas/train_data15949.zip  \n",
            " extracting: training_datas/train_data27691.zip  \n",
            " extracting: training_datas/train_data23927.zip  \n",
            " extracting: training_datas/train_data28756.zip  \n",
            " extracting: training_datas/train_data29102.zip  \n",
            " extracting: training_datas/train_data24248.zip  \n",
            " extracting: training_datas/train_data25899.zip  \n",
            " extracting: training_datas/train_data20658.zip  \n",
            " extracting: training_datas/train_data9682.zip  \n",
            " extracting: training_datas/train_data23541.zip  \n",
            " extracting: training_datas/train_data17110.zip  \n",
            " extracting: training_datas/train_data218.zip  \n",
            " extracting: training_datas/train_data17595.zip  \n",
            " extracting: training_datas/train_data18510.zip  \n",
            " extracting: training_datas/train_data1417.zip  \n",
            " extracting: training_datas/train_data714.zip  \n",
            " extracting: training_datas/train_data18185.zip  \n",
            " extracting: training_datas/train_data27536.zip  \n",
            " extracting: training_datas/train_data12459.zip  \n",
            " extracting: training_datas/train_data14617.zip  \n",
            " extracting: training_datas/train_data15654.zip  \n",
            " extracting: training_datas/train_data1997.zip  \n",
            " extracting: training_datas/train_data19240.zip  \n",
            " extracting: training_datas/train_data23628.zip  \n",
            " extracting: training_datas/train_data16987.zip  \n",
            " extracting: training_datas/train_data8898.zip  \n",
            " extracting: training_datas/train_data5650.zip  \n",
            " extracting: training_datas/train_data12584.zip  \n",
            " extracting: training_datas/train_data10070.zip  \n",
            " extracting: training_datas/train_data8516.zip  \n",
            " extracting: training_datas/train_data24026.zip  \n",
            " extracting: training_datas/train_data26662.zip  \n",
            " extracting: training_datas/train_data16131.zip  \n",
            " extracting: training_datas/train_data7388.zip  \n",
            " extracting: training_datas/train_data21516.zip  \n",
            " extracting: training_datas/train_data17477.zip  \n",
            " extracting: training_datas/train_data30131.zip  \n",
            " extracting: training_datas/train_data3306.zip  \n",
            " extracting: training_datas/train_data24399.zip  \n",
            " extracting: training_datas/train_data18981.zip  \n",
            " extracting: training_datas/train_data11346.zip  \n",
            " extracting: training_datas/train_data5293.zip  \n",
            " extracting: training_datas/train_data22803.zip  \n",
            " extracting: training_datas/train_data7369.zip  \n",
            " extracting: training_datas/train_data17325.zip  \n",
            " extracting: training_datas/train_data25810.zip  \n",
            " extracting: training_datas/train_data10043.zip  \n",
            " extracting: training_datas/train_data2883.zip  \n",
            " extracting: training_datas/train_data28326.zip  \n",
            " extracting: training_datas/train_data8577.zip  \n",
            " extracting: training_datas/train_data30064.zip  \n",
            " extracting: training_datas/train_data9830.zip  \n",
            " extracting: training_datas/train_data21688.zip  \n",
            " extracting: training_datas/train_data22057.zip  \n",
            " extracting: training_datas/train_data8072.zip  \n",
            " extracting: training_datas/train_data27396.zip  \n",
            " extracting: training_datas/train_data8701.zip  \n",
            " extracting: training_datas/train_data3232.zip  \n",
            " extracting: training_datas/train_data28932.zip  \n",
            " extracting: training_datas/train_data3633.zip  \n",
            " extracting: training_datas/train_data15440.zip  \n",
            " extracting: training_datas/train_data637.zip  \n",
            " extracting: training_datas/train_data2775.zip  \n",
            " extracting: training_datas/train_data11012.zip  \n",
            " extracting: training_datas/train_data21766.zip  \n",
            " extracting: training_datas/train_data5690.zip  \n",
            " extracting: training_datas/train_data96.zip  \n",
            " extracting: training_datas/train_data4290.zip  \n",
            " extracting: training_datas/train_data392.zip  \n",
            " extracting: training_datas/train_data12134.zip  \n",
            " extracting: training_datas/train_data6477.zip  \n",
            " extracting: training_datas/train_data3295.zip  \n",
            " extracting: training_datas/train_data6717.zip  \n",
            " extracting: training_datas/train_data28457.zip  \n",
            " extracting: training_datas/train_data25108.zip  \n",
            " extracting: training_datas/train_data29668.zip  \n",
            " extracting: training_datas/train_data26095.zip  \n",
            " extracting: training_datas/train_data19687.zip  \n",
            " extracting: training_datas/train_data22566.zip  \n",
            " extracting: training_datas/train_data19113.zip  \n",
            " extracting: training_datas/train_data5826.zip  \n",
            " extracting: training_datas/train_data5409.zip  \n",
            " extracting: training_datas/train_data9396.zip  \n",
            " extracting: training_datas/train_data15900.zip  \n",
            " extracting: training_datas/train_data7621.zip  \n",
            " extracting: training_datas/train_data16374.zip  \n",
            " extracting: training_datas/train_data21715.zip  \n",
            " extracting: training_datas/train_data17918.zip  \n",
            " extracting: training_datas/train_data1421.zip  \n",
            " extracting: training_datas/train_data22930.zip  \n",
            " extracting: training_datas/train_data6142.zip  \n",
            " extracting: training_datas/train_data22153.zip  \n",
            " extracting: training_datas/train_data10750.zip  \n",
            " extracting: training_datas/train_data7550.zip  \n",
            " extracting: training_datas/train_data15866.zip  \n",
            " extracting: training_datas/train_data3950.zip  \n",
            " extracting: training_datas/train_data22941.zip  \n",
            " extracting: training_datas/train_data13434.zip  \n",
            " extracting: training_datas/train_data15581.zip  \n",
            " extracting: training_datas/train_data23726.zip  \n",
            " extracting: training_datas/train_data7728.zip  \n",
            " extracting: training_datas/train_data5736.zip  \n",
            " extracting: training_datas/train_data10562.zip  \n",
            " extracting: training_datas/train_data19122.zip  \n",
            " extracting: training_datas/train_data19811.zip  \n",
            " extracting: training_datas/train_data19243.zip  \n",
            " extracting: training_datas/train_data6126.zip  \n",
            " extracting: training_datas/train_data23840.zip  \n",
            " extracting: training_datas/train_data29852.zip  \n",
            " extracting: training_datas/train_data21159.zip  \n",
            " extracting: training_datas/train_data4605.zip  \n",
            " extracting: training_datas/train_data26979.zip  \n",
            " extracting: training_datas/train_data9499.zip  \n",
            " extracting: training_datas/train_data2303.zip  \n",
            " extracting: training_datas/train_data20585.zip  \n",
            " extracting: training_datas/train_data23875.zip  \n",
            " extracting: training_datas/train_data29786.zip  \n",
            " extracting: training_datas/train_data992.zip  \n",
            " extracting: training_datas/train_data24274.zip  \n",
            " extracting: training_datas/train_data21177.zip  \n",
            " extracting: training_datas/train_data1104.zip  \n",
            " extracting: training_datas/train_data8927.zip  \n",
            " extracting: training_datas/train_data27516.zip  \n",
            " extracting: training_datas/train_data18958.zip  \n",
            " extracting: training_datas/train_data17612.zip  \n",
            " extracting: training_datas/train_data5706.zip  \n",
            " extracting: training_datas/train_data30256.zip  \n",
            " extracting: training_datas/train_data4920.zip  \n",
            " extracting: training_datas/train_data26902.zip  \n",
            " extracting: training_datas/train_data8176.zip  \n",
            " extracting: training_datas/train_data11107.zip  \n",
            " extracting: training_datas/train_data27830.zip  \n",
            " extracting: training_datas/train_data11583.zip  \n",
            " extracting: training_datas/train_data2067.zip  \n",
            " extracting: training_datas/train_data142.zip  \n",
            " extracting: training_datas/train_data20635.zip  \n",
            " extracting: training_datas/train_data19198.zip  \n",
            " extracting: training_datas/train_data1615.zip  \n",
            " extracting: training_datas/train_data5266.zip  \n",
            " extracting: training_datas/train_data3665.zip  \n",
            " extracting: training_datas/train_data8807.zip  \n",
            " extracting: training_datas/train_data5020.zip  \n",
            " extracting: training_datas/train_data3559.zip  \n",
            " extracting: training_datas/train_data4152.zip  \n",
            " extracting: training_datas/train_data24332.zip  \n",
            " extracting: training_datas/train_data29527.zip  \n",
            " extracting: training_datas/train_data10326.zip  \n",
            " extracting: training_datas/train_data3981.zip  \n",
            " extracting: training_datas/train_data24334.zip  \n",
            " extracting: training_datas/train_data22692.zip  \n",
            " extracting: training_datas/train_data26709.zip  \n",
            " extracting: training_datas/train_data24996.zip  \n",
            " extracting: training_datas/train_data9083.zip  \n",
            " extracting: training_datas/train_data20128.zip  \n",
            " extracting: training_datas/train_data14494.zip  \n",
            " extracting: training_datas/train_data19022.zip  \n",
            " extracting: training_datas/train_data1538.zip  \n",
            " extracting: training_datas/train_data19912.zip  \n",
            " extracting: training_datas/train_data23920.zip  \n",
            " extracting: training_datas/train_data13986.zip  \n",
            " extracting: training_datas/train_data26452.zip  \n",
            " extracting: training_datas/train_data26927.zip  \n",
            " extracting: training_datas/train_data16654.zip  \n",
            " extracting: training_datas/train_data24276.zip  \n",
            " extracting: training_datas/train_data4587.zip  \n",
            " extracting: training_datas/train_data10246.zip  \n",
            " extracting: training_datas/train_data8549.zip  \n",
            " extracting: training_datas/train_data26763.zip  \n",
            " extracting: training_datas/train_data3808.zip  \n",
            " extracting: training_datas/train_data3018.zip  \n",
            " extracting: training_datas/train_data30079.zip  \n",
            " extracting: training_datas/train_data24056.zip  \n",
            " extracting: training_datas/train_data11567.zip  \n",
            " extracting: training_datas/train_data3968.zip  \n",
            " extracting: training_datas/train_data16830.zip  \n",
            " extracting: training_datas/train_data15267.zip  \n",
            " extracting: training_datas/train_data18732.zip  \n",
            " extracting: training_datas/train_data26096.zip  \n",
            " extracting: training_datas/train_data29054.zip  \n",
            " extracting: training_datas/train_data9689.zip  \n",
            " extracting: training_datas/train_data23939.zip  \n",
            " extracting: training_datas/train_data10622.zip  \n",
            " extracting: training_datas/train_data6007.zip  \n",
            " extracting: training_datas/train_data27350.zip  \n",
            " extracting: training_datas/train_data3951.zip  \n",
            " extracting: training_datas/train_data1442.zip  \n",
            " extracting: training_datas/train_data15348.zip  \n",
            " extracting: training_datas/train_data12675.zip  \n",
            " extracting: training_datas/train_data23259.zip  \n",
            " extracting: training_datas/train_data850.zip  \n",
            " extracting: training_datas/train_data20129.zip  \n",
            " extracting: training_datas/train_data20120.zip  \n",
            " extracting: training_datas/train_data7532.zip  \n",
            " extracting: training_datas/train_data3242.zip  \n",
            " extracting: training_datas/train_data28320.zip  \n",
            " extracting: training_datas/train_data17556.zip  \n",
            " extracting: training_datas/train_data2432.zip  \n",
            " extracting: training_datas/train_data26708.zip  \n",
            " extracting: training_datas/train_data4043.zip  \n",
            " extracting: training_datas/train_data20728.zip  \n",
            " extracting: training_datas/train_data17147.zip  \n",
            " extracting: training_datas/train_data17237.zip  \n",
            " extracting: training_datas/train_data2983.zip  \n",
            " extracting: training_datas/train_data2162.zip  \n",
            " extracting: training_datas/train_data1503.zip  \n",
            " extracting: training_datas/train_data14649.zip  \n",
            " extracting: training_datas/train_data11188.zip  \n",
            " extracting: training_datas/train_data24083.zip  \n",
            " extracting: training_datas/train_data18827.zip  \n",
            " extracting: training_datas/train_data8010.zip  \n",
            " extracting: training_datas/train_data26001.zip  \n",
            " extracting: training_datas/train_data2194.zip  \n",
            " extracting: training_datas/train_data10025.zip  \n",
            " extracting: training_datas/train_data9119.zip  \n",
            " extracting: training_datas/train_data14695.zip  \n",
            " extracting: training_datas/train_data4945.zip  \n",
            " extracting: training_datas/train_data29138.zip  \n",
            " extracting: training_datas/train_data25888.zip  \n",
            " extracting: training_datas/train_data17668.zip  \n",
            " extracting: training_datas/train_data28910.zip  \n",
            " extracting: training_datas/train_data11011.zip  \n",
            " extracting: training_datas/train_data18098.zip  \n",
            " extracting: training_datas/train_data14804.zip  \n",
            " extracting: training_datas/train_data29624.zip  \n",
            " extracting: training_datas/train_data27966.zip  \n",
            " extracting: training_datas/train_data7451.zip  \n",
            " extracting: training_datas/train_data7864.zip  \n",
            " extracting: training_datas/train_data3384.zip  \n",
            " extracting: training_datas/train_data23102.zip  \n",
            " extracting: training_datas/train_data16153.zip  \n",
            " extracting: training_datas/train_data6787.zip  \n",
            " extracting: training_datas/train_data17721.zip  \n",
            " extracting: training_datas/train_data21025.zip  \n",
            " extracting: training_datas/train_data26202.zip  \n",
            " extracting: training_datas/train_data10927.zip  \n",
            " extracting: training_datas/train_data613.zip  \n",
            " extracting: training_datas/train_data29528.zip  \n",
            " extracting: training_datas/train_data3899.zip  \n",
            " extracting: training_datas/train_data190.zip  \n",
            " extracting: training_datas/train_data20189.zip  \n",
            " extracting: training_datas/train_data23630.zip  \n",
            " extracting: training_datas/train_data15984.zip  \n",
            " extracting: training_datas/train_data22397.zip  \n",
            " extracting: training_datas/train_data14754.zip  \n",
            " extracting: training_datas/train_data17573.zip  \n",
            " extracting: training_datas/train_data4856.zip  \n",
            " extracting: training_datas/train_data18241.zip  \n",
            " extracting: training_datas/train_data14405.zip  \n",
            " extracting: training_datas/train_data15240.zip  \n",
            " extracting: training_datas/train_data29729.zip  \n",
            " extracting: training_datas/train_data13591.zip  \n",
            " extracting: training_datas/train_data2493.zip  \n",
            " extracting: training_datas/train_data1112.zip  \n",
            " extracting: training_datas/train_data9771.zip  \n",
            " extracting: training_datas/train_data11617.zip  \n",
            " extracting: training_datas/train_data25941.zip  \n",
            " extracting: training_datas/train_data18197.zip  \n",
            " extracting: training_datas/train_data11225.zip  \n",
            " extracting: training_datas/train_data28151.zip  \n",
            " extracting: training_datas/train_data14331.zip  \n",
            " extracting: training_datas/train_data3237.zip  \n",
            " extracting: training_datas/train_data2095.zip  \n",
            " extracting: training_datas/train_data18311.zip  \n",
            " extracting: training_datas/train_data22953.zip  \n",
            " extracting: training_datas/train_data14974.zip  \n",
            " extracting: training_datas/train_data29640.zip  \n",
            " extracting: training_datas/train_data12948.zip  \n",
            " extracting: training_datas/train_data26556.zip  \n",
            " extracting: training_datas/train_data18151.zip  \n",
            " extracting: training_datas/train_data26161.zip  \n",
            " extracting: training_datas/train_data359.zip  \n",
            " extracting: training_datas/train_data27834.zip  \n",
            " extracting: training_datas/train_data4608.zip  \n",
            " extracting: training_datas/train_data14388.zip  \n",
            " extracting: training_datas/train_data20417.zip  \n",
            " extracting: training_datas/train_data9963.zip  \n",
            " extracting: training_datas/train_data3524.zip  \n",
            " extracting: training_datas/train_data9988.zip  \n",
            " extracting: training_datas/train_data29931.zip  \n",
            " extracting: training_datas/train_data17617.zip  \n",
            " extracting: training_datas/train_data5418.zip  \n",
            " extracting: training_datas/train_data30100.zip  \n",
            " extracting: training_datas/train_data1095.zip  \n",
            " extracting: training_datas/train_data26532.zip  \n",
            " extracting: training_datas/train_data14602.zip  \n",
            " extracting: training_datas/train_data26501.zip  \n",
            " extracting: training_datas/train_data6618.zip  \n",
            " extracting: training_datas/train_data2511.zip  \n",
            " extracting: training_datas/train_data8184.zip  \n",
            " extracting: training_datas/train_data18273.zip  \n",
            " extracting: training_datas/train_data9935.zip  \n",
            " extracting: training_datas/train_data21435.zip  \n",
            " extracting: training_datas/train_data10169.zip  \n",
            " extracting: training_datas/train_data29289.zip  \n",
            " extracting: training_datas/train_data12149.zip  \n",
            " extracting: training_datas/train_data23449.zip  \n",
            " extracting: training_datas/train_data10936.zip  \n",
            " extracting: training_datas/train_data23502.zip  \n",
            " extracting: training_datas/train_data3961.zip  \n",
            " extracting: training_datas/train_data12824.zip  \n",
            " extracting: training_datas/train_data14156.zip  \n",
            " extracting: training_datas/train_data29208.zip  \n",
            " extracting: training_datas/train_data26228.zip  \n",
            " extracting: training_datas/train_data17910.zip  \n",
            " extracting: training_datas/train_data4032.zip  \n",
            " extracting: training_datas/train_data21484.zip  \n",
            " extracting: training_datas/train_data19524.zip  \n",
            " extracting: training_datas/train_data24186.zip  \n",
            " extracting: training_datas/train_data19553.zip  \n",
            " extracting: training_datas/train_data17187.zip  \n",
            " extracting: training_datas/train_data547.zip  \n",
            " extracting: training_datas/train_data27961.zip  \n",
            " extracting: training_datas/train_data8756.zip  \n",
            " extracting: training_datas/train_data5928.zip  \n",
            " extracting: training_datas/train_data17473.zip  \n",
            " extracting: training_datas/train_data12858.zip  \n",
            " extracting: training_datas/train_data5607.zip  \n",
            " extracting: training_datas/train_data16563.zip  \n",
            " extracting: training_datas/train_data4003.zip  \n",
            " extracting: training_datas/train_data885.zip  \n",
            " extracting: training_datas/train_data21546.zip  \n",
            " extracting: training_datas/train_data454.zip  \n",
            " extracting: training_datas/train_data11826.zip  \n",
            " extracting: training_datas/train_data7555.zip  \n",
            " extracting: training_datas/train_data17596.zip  \n",
            " extracting: training_datas/train_data29547.zip  \n",
            " extracting: training_datas/train_data2732.zip  \n",
            " extracting: training_datas/train_data13609.zip  \n",
            " extracting: training_datas/train_data7493.zip  \n",
            " extracting: training_datas/train_data3122.zip  \n",
            " extracting: training_datas/train_data20670.zip  \n",
            " extracting: training_datas/train_data26075.zip  \n",
            " extracting: training_datas/train_data8353.zip  \n",
            " extracting: training_datas/train_data10586.zip  \n",
            " extracting: training_datas/train_data15359.zip  \n",
            " extracting: training_datas/train_data17410.zip  \n",
            " extracting: training_datas/train_data3497.zip  \n",
            " extracting: training_datas/train_data1270.zip  \n",
            " extracting: training_datas/train_data29331.zip  \n",
            " extracting: training_datas/train_data7122.zip  \n",
            " extracting: training_datas/train_data25900.zip  \n",
            " extracting: training_datas/train_data3380.zip  \n",
            " extracting: training_datas/train_data2873.zip  \n",
            " extracting: training_datas/train_data24231.zip  \n",
            " extracting: training_datas/train_data25320.zip  \n",
            " extracting: training_datas/train_data18755.zip  \n",
            " extracting: training_datas/train_data22289.zip  \n",
            " extracting: training_datas/train_data5891.zip  \n",
            " extracting: training_datas/train_data7082.zip  \n",
            " extracting: training_datas/train_data2546.zip  \n",
            " extracting: training_datas/train_data22242.zip  \n",
            " extracting: training_datas/train_data16600.zip  \n",
            " extracting: training_datas/train_data4831.zip  \n",
            " extracting: training_datas/train_data1400.zip  \n",
            " extracting: training_datas/train_data6082.zip  \n",
            " extracting: training_datas/train_data24262.zip  \n",
            " extracting: training_datas/train_data16282.zip  \n",
            " extracting: training_datas/train_data29923.zip  \n",
            " extracting: training_datas/train_data4452.zip  \n",
            " extracting: training_datas/train_data6806.zip  \n",
            " extracting: training_datas/train_data24702.zip  \n",
            " extracting: training_datas/train_data16251.zip  \n",
            " extracting: training_datas/train_data28963.zip  \n",
            " extracting: training_datas/train_data25431.zip  \n",
            " extracting: training_datas/train_data20597.zip  \n",
            " extracting: training_datas/train_data7869.zip  \n",
            " extracting: training_datas/train_data25682.zip  \n",
            " extracting: training_datas/train_data19701.zip  \n",
            " extracting: training_datas/train_data7736.zip  \n",
            " extracting: training_datas/train_data14143.zip  \n",
            " extracting: training_datas/train_data28645.zip  \n",
            " extracting: training_datas/train_data16335.zip  \n",
            " extracting: training_datas/train_data6555.zip  \n",
            " extracting: training_datas/train_data740.zip  \n",
            " extracting: training_datas/train_data20335.zip  \n",
            " extracting: training_datas/train_data21986.zip  \n",
            " extracting: training_datas/train_data29711.zip  \n",
            " extracting: training_datas/train_data4533.zip  \n",
            " extracting: training_datas/train_data24247.zip  \n",
            " extracting: training_datas/train_data8891.zip  \n",
            " extracting: training_datas/train_data3844.zip  \n",
            " extracting: training_datas/train_data27584.zip  \n",
            " extracting: training_datas/train_data25187.zip  \n",
            " extracting: training_datas/train_data2632.zip  \n",
            " extracting: training_datas/train_data15875.zip  \n",
            " extracting: training_datas/train_data15357.zip  \n",
            " extracting: training_datas/train_data19497.zip  \n",
            " extracting: training_datas/train_data28807.zip  \n",
            " extracting: training_datas/train_data9758.zip  \n",
            " extracting: training_datas/train_data10829.zip  \n",
            " extracting: training_datas/train_data16193.zip  \n",
            " extracting: training_datas/train_data28965.zip  \n",
            " extracting: training_datas/train_data11794.zip  \n",
            " extracting: training_datas/train_data27560.zip  \n",
            " extracting: training_datas/train_data23399.zip  \n",
            " extracting: training_datas/train_data22180.zip  \n",
            " extracting: training_datas/train_data11082.zip  \n",
            " extracting: training_datas/train_data26052.zip  \n",
            " extracting: training_datas/train_data2398.zip  \n",
            " extracting: training_datas/train_data28700.zip  \n",
            " extracting: training_datas/train_data3970.zip  \n",
            " extracting: training_datas/train_data4713.zip  \n",
            " extracting: training_datas/train_data25924.zip  \n",
            " extracting: training_datas/train_data19233.zip  \n",
            " extracting: training_datas/train_data9591.zip  \n",
            " extracting: training_datas/train_data14451.zip  \n",
            " extracting: training_datas/train_data9890.zip  \n",
            " extracting: training_datas/train_data18804.zip  \n",
            " extracting: training_datas/train_data27620.zip  \n",
            " extracting: training_datas/train_data19413.zip  \n",
            " extracting: training_datas/train_data2966.zip  \n",
            " extracting: training_datas/train_data3362.zip  \n",
            " extracting: training_datas/train_data23140.zip  \n",
            " extracting: training_datas/train_data7414.zip  \n",
            " extracting: training_datas/train_data18741.zip  \n",
            " extracting: training_datas/train_data15339.zip  \n",
            " extracting: training_datas/train_data9974.zip  \n",
            " extracting: training_datas/train_data15956.zip  \n",
            " extracting: training_datas/train_data12318.zip  \n",
            " extracting: training_datas/train_data4316.zip  \n",
            " extracting: training_datas/train_data15224.zip  \n",
            " extracting: training_datas/train_data17044.zip  \n",
            " extracting: training_datas/train_data10102.zip  \n",
            " extracting: training_datas/train_data28191.zip  \n",
            " extracting: training_datas/train_data10912.zip  \n",
            " extracting: training_datas/train_data3347.zip  \n",
            " extracting: training_datas/train_data6757.zip  \n",
            " extracting: training_datas/train_data20434.zip  \n",
            " extracting: training_datas/train_data23087.zip  \n",
            " extracting: training_datas/train_data18386.zip  \n",
            " extracting: training_datas/train_data13894.zip  \n",
            " extracting: training_datas/train_data16473.zip  \n",
            " extracting: training_datas/train_data27598.zip  \n",
            " extracting: training_datas/train_data6592.zip  \n",
            " extracting: training_datas/train_data20745.zip  \n",
            " extracting: training_datas/train_data14702.zip  \n",
            " extracting: training_datas/train_data9009.zip  \n",
            " extracting: training_datas/train_data28439.zip  \n",
            " extracting: training_datas/train_data28446.zip  \n",
            " extracting: training_datas/train_data6682.zip  \n",
            " extracting: training_datas/train_data22298.zip  \n",
            " extracting: training_datas/train_data8191.zip  \n",
            " extracting: training_datas/train_data14031.zip  \n",
            " extracting: training_datas/train_data10098.zip  \n",
            " extracting: training_datas/train_data16110.zip  \n",
            " extracting: training_datas/train_data5698.zip  \n",
            " extracting: training_datas/train_data14007.zip  \n",
            " extracting: training_datas/train_data25359.zip  \n",
            " extracting: training_datas/train_data13777.zip  \n",
            " extracting: training_datas/train_data24279.zip  \n",
            " extracting: training_datas/train_data3572.zip  \n",
            " extracting: training_datas/train_data2993.zip  \n",
            " extracting: training_datas/train_data13304.zip  \n",
            " extracting: training_datas/train_data16201.zip  \n",
            " extracting: training_datas/train_data14258.zip  \n",
            " extracting: training_datas/train_data14501.zip  \n",
            " extracting: training_datas/train_data12876.zip  \n",
            " extracting: training_datas/train_data27748.zip  \n",
            " extracting: training_datas/train_data2737.zip  \n",
            " extracting: training_datas/train_data6674.zip  \n",
            " extracting: training_datas/train_data18789.zip  \n",
            " extracting: training_datas/train_data14829.zip  \n",
            " extracting: training_datas/train_data9379.zip  \n",
            " extracting: training_datas/train_data27787.zip  \n",
            " extracting: training_datas/train_data10163.zip  \n",
            " extracting: training_datas/train_data2345.zip  \n",
            " extracting: training_datas/train_data21957.zip  \n",
            " extracting: training_datas/train_data23874.zip  \n",
            " extracting: training_datas/train_data1711.zip  \n",
            " extracting: training_datas/train_data23187.zip  \n",
            " extracting: training_datas/train_data13764.zip  \n",
            " extracting: training_datas/train_data24061.zip  \n",
            " extracting: training_datas/train_data9655.zip  \n",
            " extracting: training_datas/train_data10718.zip  \n",
            " extracting: training_datas/train_data21900.zip  \n",
            " extracting: training_datas/train_data20182.zip  \n",
            " extracting: training_datas/train_data7273.zip  \n",
            " extracting: training_datas/train_data8457.zip  \n",
            " extracting: training_datas/train_data25403.zip  \n",
            " extracting: training_datas/train_data7048.zip  \n",
            " extracting: training_datas/train_data14185.zip  \n",
            " extracting: training_datas/train_data25142.zip  \n",
            " extracting: training_datas/train_data27587.zip  \n",
            " extracting: training_datas/train_data5939.zip  \n",
            " extracting: training_datas/train_data25113.zip  \n",
            " extracting: training_datas/train_data26721.zip  \n",
            " extracting: training_datas/train_data13739.zip  \n",
            " extracting: training_datas/train_data22280.zip  \n",
            " extracting: training_datas/train_data27643.zip  \n",
            " extracting: training_datas/train_data29747.zip  \n",
            " extracting: training_datas/train_data16185.zip  \n",
            " extracting: training_datas/train_data19799.zip  \n",
            " extracting: training_datas/train_data24498.zip  \n",
            " extracting: training_datas/train_data8910.zip  \n",
            " extracting: training_datas/train_data15824.zip  \n",
            " extracting: training_datas/train_data23226.zip  \n",
            " extracting: training_datas/train_data9788.zip  \n",
            " extracting: training_datas/train_data25227.zip  \n",
            " extracting: training_datas/train_data14148.zip  \n",
            " extracting: training_datas/train_data27143.zip  \n",
            " extracting: training_datas/train_data1561.zip  \n",
            " extracting: training_datas/train_data15994.zip  \n",
            " extracting: training_datas/train_data19414.zip  \n",
            " extracting: training_datas/train_data25060.zip  \n",
            " extracting: training_datas/train_data12729.zip  \n",
            " extracting: training_datas/train_data5827.zip  \n",
            " extracting: training_datas/train_data4224.zip  \n",
            " extracting: training_datas/train_data19780.zip  \n",
            " extracting: training_datas/train_data12112.zip  \n",
            " extracting: training_datas/train_data6306.zip  \n",
            " extracting: training_datas/train_data29733.zip  \n",
            " extracting: training_datas/train_data29240.zip  \n",
            " extracting: training_datas/train_data28991.zip  \n",
            " extracting: training_datas/train_data24245.zip  \n",
            " extracting: training_datas/train_data10100.zip  \n",
            " extracting: training_datas/train_data16059.zip  \n",
            " extracting: training_datas/train_data12060.zip  \n",
            " extracting: training_datas/train_data2442.zip  \n",
            " extracting: training_datas/train_data17251.zip  \n",
            " extracting: training_datas/train_data29454.zip  \n",
            " extracting: training_datas/train_data4609.zip  \n",
            " extracting: training_datas/train_data25869.zip  \n",
            " extracting: training_datas/train_data19937.zip  \n",
            " extracting: training_datas/train_data27971.zip  \n",
            " extracting: training_datas/train_data10116.zip  \n",
            " extracting: training_datas/train_data12374.zip  \n",
            " extracting: training_datas/train_data3809.zip  \n",
            " extracting: training_datas/train_data15281.zip  \n",
            " extracting: training_datas/train_data18323.zip  \n",
            " extracting: training_datas/train_data16661.zip  \n",
            " extracting: training_datas/train_data1725.zip  \n",
            " extracting: training_datas/train_data25048.zip  \n",
            " extracting: training_datas/train_data622.zip  \n",
            " extracting: training_datas/train_data14606.zip  \n",
            " extracting: training_datas/train_data19641.zip  \n",
            " extracting: training_datas/train_data10511.zip  \n",
            " extracting: training_datas/train_data12422.zip  \n",
            " extracting: training_datas/train_data9381.zip  \n",
            " extracting: training_datas/train_data18168.zip  \n",
            " extracting: training_datas/train_data17874.zip  \n",
            " extracting: training_datas/train_data19364.zip  \n",
            " extracting: training_datas/train_data12750.zip  \n",
            " extracting: training_datas/train_data20307.zip  \n",
            " extracting: training_datas/train_data6561.zip  \n",
            " extracting: training_datas/train_data20364.zip  \n",
            " extracting: training_datas/train_data20887.zip  \n",
            " extracting: training_datas/train_data30356.zip  \n",
            " extracting: training_datas/train_data26502.zip  \n",
            " extracting: training_datas/train_data27804.zip  \n",
            " extracting: training_datas/train_data17980.zip  \n",
            " extracting: training_datas/train_data1653.zip  \n",
            " extracting: training_datas/train_data8903.zip  \n",
            " extracting: training_datas/train_data20271.zip  \n",
            " extracting: training_datas/train_data21725.zip  \n",
            " extracting: training_datas/train_data6233.zip  \n",
            " extracting: training_datas/train_data28277.zip  \n",
            " extracting: training_datas/train_data12930.zip  \n",
            " extracting: training_datas/train_data17341.zip  \n",
            " extracting: training_datas/train_data10359.zip  \n",
            " extracting: training_datas/train_data1629.zip  \n",
            " extracting: training_datas/train_data21667.zip  \n",
            " extracting: training_datas/train_data29739.zip  \n",
            " extracting: training_datas/train_data1636.zip  \n",
            " extracting: training_datas/train_data15962.zip  \n",
            " extracting: training_datas/train_data2087.zip  \n",
            " extracting: training_datas/train_data28033.zip  \n",
            " extracting: training_datas/train_data9061.zip  \n",
            " extracting: training_datas/train_data9593.zip  \n",
            " extracting: training_datas/train_data8550.zip  \n",
            " extracting: training_datas/train_data24584.zip  \n",
            " extracting: training_datas/train_data11966.zip  \n",
            " extracting: training_datas/train_data6735.zip  \n",
            " extracting: training_datas/train_data3225.zip  \n",
            " extracting: training_datas/train_data7943.zip  \n",
            " extracting: training_datas/train_data25349.zip  \n",
            " extracting: training_datas/train_data4363.zip  \n",
            " extracting: training_datas/train_data22876.zip  \n",
            " extracting: training_datas/train_data26654.zip  \n",
            " extracting: training_datas/train_data363.zip  \n",
            " extracting: training_datas/train_data13219.zip  \n",
            " extracting: training_datas/train_data26543.zip  \n",
            " extracting: training_datas/train_data1195.zip  \n",
            " extracting: training_datas/train_data13892.zip  \n",
            " extracting: training_datas/train_data13162.zip  \n",
            " extracting: training_datas/train_data12875.zip  \n",
            " extracting: training_datas/train_data12404.zip  \n",
            " extracting: training_datas/train_data12213.zip  \n",
            " extracting: training_datas/train_data2882.zip  \n",
            " extracting: training_datas/train_data29434.zip  \n",
            " extracting: training_datas/train_data19098.zip  \n",
            " extracting: training_datas/train_data22087.zip  \n",
            " extracting: training_datas/train_data2132.zip  \n",
            " extracting: training_datas/train_data20560.zip  \n",
            " extracting: training_datas/train_data3454.zip  \n",
            " extracting: training_datas/train_data11183.zip  \n",
            " extracting: training_datas/train_data10091.zip  \n",
            " extracting: training_datas/train_data21062.zip  \n",
            " extracting: training_datas/train_data17718.zip  \n",
            " extracting: training_datas/train_data27411.zip  \n",
            " extracting: training_datas/train_data22880.zip  \n",
            " extracting: training_datas/train_data5875.zip  \n",
            " extracting: training_datas/train_data9144.zip  \n",
            " extracting: training_datas/train_data3858.zip  \n",
            " extracting: training_datas/train_data18810.zip  \n",
            " extracting: training_datas/train_data12322.zip  \n",
            " extracting: training_datas/train_data13345.zip  \n",
            " extracting: training_datas/train_data25623.zip  \n",
            " extracting: training_datas/train_data14890.zip  \n",
            " extracting: training_datas/train_data24958.zip  \n",
            " extracting: training_datas/train_data12419.zip  \n",
            " extracting: training_datas/train_data11423.zip  \n",
            " extracting: training_datas/train_data15292.zip  \n",
            " extracting: training_datas/train_data24576.zip  \n",
            " extracting: training_datas/train_data8755.zip  \n",
            " extracting: training_datas/train_data5158.zip  \n",
            " extracting: training_datas/train_data18455.zip  \n",
            " extracting: training_datas/train_data5534.zip  \n",
            " extracting: training_datas/train_data4762.zip  \n",
            " extracting: training_datas/train_data28341.zip  \n",
            " extracting: training_datas/train_data8223.zip  \n",
            " extracting: training_datas/train_data11092.zip  \n",
            " extracting: training_datas/train_data20093.zip  \n",
            " extracting: training_datas/train_data23823.zip  \n",
            " extracting: training_datas/train_data17458.zip  \n",
            " extracting: training_datas/train_data12809.zip  \n",
            " extracting: training_datas/train_data4620.zip  \n",
            " extracting: training_datas/train_data22146.zip  \n",
            " extracting: training_datas/train_data18563.zip  \n",
            " extracting: training_datas/train_data3840.zip  \n",
            " extracting: training_datas/train_data26732.zip  \n",
            " extracting: training_datas/train_data21800.zip  \n",
            " extracting: training_datas/train_data16468.zip  \n",
            " extracting: training_datas/train_data18352.zip  \n",
            " extracting: training_datas/train_data328.zip  \n",
            " extracting: training_datas/train_data24442.zip  \n",
            " extracting: training_datas/train_data24224.zip  \n",
            " extracting: training_datas/train_data17452.zip  \n",
            " extracting: training_datas/train_data7628.zip  \n",
            " extracting: training_datas/train_data2141.zip  \n",
            " extracting: training_datas/train_data10254.zip  \n",
            " extracting: training_datas/train_data11157.zip  \n",
            " extracting: training_datas/train_data18066.zip  \n",
            " extracting: training_datas/train_data20707.zip  \n",
            " extracting: training_datas/train_data9191.zip  \n",
            " extracting: training_datas/train_data6124.zip  \n",
            " extracting: training_datas/train_data11586.zip  \n",
            " extracting: training_datas/train_data18289.zip  \n",
            " extracting: training_datas/train_data22293.zip  \n",
            " extracting: training_datas/train_data19045.zip  \n",
            " extracting: training_datas/train_data11205.zip  \n",
            " extracting: training_datas/train_data22000.zip  \n",
            " extracting: training_datas/train_data18404.zip  \n",
            " extracting: training_datas/train_data23961.zip  \n",
            " extracting: training_datas/train_data9278.zip  \n",
            " extracting: training_datas/train_data23352.zip  \n",
            " extracting: training_datas/train_data24049.zip  \n",
            " extracting: training_datas/train_data13747.zip  \n",
            " extracting: training_datas/train_data23015.zip  \n",
            " extracting: training_datas/train_data14993.zip  \n",
            " extracting: training_datas/train_data15845.zip  \n",
            " extracting: training_datas/train_data518.zip  \n",
            " extracting: training_datas/train_data315.zip  \n",
            " extracting: training_datas/train_data11814.zip  \n",
            " extracting: training_datas/train_data877.zip  \n",
            " extracting: training_datas/train_data5897.zip  \n",
            " extracting: training_datas/train_data27722.zip  \n",
            " extracting: training_datas/train_data25171.zip  \n",
            " extracting: training_datas/train_data8905.zip  \n",
            " extracting: training_datas/train_data30385.zip  \n",
            " extracting: training_datas/train_data9155.zip  \n",
            " extracting: training_datas/train_data8969.zip  \n",
            " extracting: training_datas/train_data6695.zip  \n",
            " extracting: training_datas/train_data25281.zip  \n",
            " extracting: training_datas/train_data25584.zip  \n",
            " extracting: training_datas/train_data29905.zip  \n",
            " extracting: training_datas/train_data19409.zip  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nffBg9xnrhz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11d1f65c-a767-43a9-86c1-92440727dc9d"
      },
      "source": [
        "%cd training_datas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training_datas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6KLZgZ3rqtI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a5289b8-c209-487d-8df6-d16514e303c5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "train_data1464.zip   train_data23798.zip  train_data5503.zip\n",
            "train_data14650.zip  train_data23799.zip  train_data5504.zip\n",
            "train_data14651.zip  train_data2379.zip   train_data5505.zip\n",
            "train_data14652.zip  train_data237.zip\t  train_data5506.zip\n",
            "train_data14653.zip  train_data23800.zip  train_data5507.zip\n",
            "train_data14654.zip  train_data23801.zip  train_data5508.zip\n",
            "train_data14655.zip  train_data23802.zip  train_data5509.zip\n",
            "train_data14656.zip  train_data23803.zip  train_data550.zip\n",
            "train_data14657.zip  train_data23804.zip  train_data5510.zip\n",
            "train_data14658.zip  train_data23805.zip  train_data5511.zip\n",
            "train_data14659.zip  train_data23806.zip  train_data5512.zip\n",
            "train_data1465.zip   train_data23807.zip  train_data5513.zip\n",
            "train_data14660.zip  train_data23808.zip  train_data5514.zip\n",
            "train_data14661.zip  train_data23809.zip  train_data5515.zip\n",
            "train_data14662.zip  train_data2380.zip   train_data5516.zip\n",
            "train_data14663.zip  train_data23810.zip  train_data5517.zip\n",
            "train_data14664.zip  train_data23811.zip  train_data5518.zip\n",
            "train_data14665.zip  train_data23812.zip  train_data5519.zip\n",
            "train_data14666.zip  train_data23813.zip  train_data551.zip\n",
            "train_data14667.zip  train_data23814.zip  train_data5520.zip\n",
            "train_data14668.zip  train_data23815.zip  train_data5521.zip\n",
            "train_data14669.zip  train_data23816.zip  train_data5522.zip\n",
            "train_data1466.zip   train_data23817.zip  train_data5523.zip\n",
            "train_data14670.zip  train_data23818.zip  train_data5524.zip\n",
            "train_data14671.zip  train_data23819.zip  train_data5525.zip\n",
            "train_data14672.zip  train_data2381.zip   train_data5526.zip\n",
            "train_data14673.zip  train_data23820.zip  train_data5527.zip\n",
            "train_data14674.zip  train_data23821.zip  train_data5528.zip\n",
            "train_data14675.zip  train_data23822.zip  train_data5529.zip\n",
            "train_data14676.zip  train_data23823.zip  train_data552.zip\n",
            "train_data14677.zip  train_data23824.zip  train_data5530.zip\n",
            "train_data14678.zip  train_data23825.zip  train_data5531.zip\n",
            "train_data14679.zip  train_data23826.zip  train_data5532.zip\n",
            "train_data1467.zip   train_data23827.zip  train_data5533.zip\n",
            "train_data14680.zip  train_data23828.zip  train_data5534.zip\n",
            "train_data14681.zip  train_data23829.zip  train_data5535.zip\n",
            "train_data14682.zip  train_data2382.zip   train_data5536.zip\n",
            "train_data14683.zip  train_data23830.zip  train_data5537.zip\n",
            "train_data14684.zip  train_data23831.zip  train_data5538.zip\n",
            "train_data14685.zip  train_data23832.zip  train_data5539.zip\n",
            "train_data14686.zip  train_data23833.zip  train_data553.zip\n",
            "train_data14687.zip  train_data23834.zip  train_data5540.zip\n",
            "train_data14688.zip  train_data23835.zip  train_data5541.zip\n",
            "train_data14689.zip  train_data23836.zip  train_data5542.zip\n",
            "train_data1468.zip   train_data23837.zip  train_data5543.zip\n",
            "train_data14690.zip  train_data23838.zip  train_data5544.zip\n",
            "train_data14691.zip  train_data23839.zip  train_data5545.zip\n",
            "train_data14692.zip  train_data2383.zip   train_data5546.zip\n",
            "train_data14693.zip  train_data23840.zip  train_data5547.zip\n",
            "train_data14694.zip  train_data23841.zip  train_data5548.zip\n",
            "train_data14695.zip  train_data23842.zip  train_data5549.zip\n",
            "train_data14696.zip  train_data23843.zip  train_data554.zip\n",
            "train_data14697.zip  train_data23844.zip  train_data5550.zip\n",
            "train_data14698.zip  train_data23845.zip  train_data5551.zip\n",
            "train_data14699.zip  train_data23846.zip  train_data5552.zip\n",
            "train_data1469.zip   train_data23847.zip  train_data5553.zip\n",
            "train_data146.zip    train_data23848.zip  train_data5554.zip\n",
            "train_data14700.zip  train_data23849.zip  train_data5555.zip\n",
            "train_data14701.zip  train_data2384.zip   train_data5556.zip\n",
            "train_data14702.zip  train_data23850.zip  train_data5557.zip\n",
            "train_data14703.zip  train_data23851.zip  train_data5558.zip\n",
            "train_data14704.zip  train_data23852.zip  train_data5559.zip\n",
            "train_data14705.zip  train_data23853.zip  train_data555.zip\n",
            "train_data14706.zip  train_data23854.zip  train_data5560.zip\n",
            "train_data14707.zip  train_data23855.zip  train_data5561.zip\n",
            "train_data14708.zip  train_data23856.zip  train_data5562.zip\n",
            "train_data14709.zip  train_data23857.zip  train_data5563.zip\n",
            "train_data1470.zip   train_data23858.zip  train_data5564.zip\n",
            "train_data14710.zip  train_data23859.zip  train_data5565.zip\n",
            "train_data14711.zip  train_data2385.zip   train_data5566.zip\n",
            "train_data14712.zip  train_data23860.zip  train_data5567.zip\n",
            "train_data14713.zip  train_data23861.zip  train_data5568.zip\n",
            "train_data14714.zip  train_data23862.zip  train_data5569.zip\n",
            "train_data14715.zip  train_data23863.zip  train_data556.zip\n",
            "train_data14716.zip  train_data23864.zip  train_data5570.zip\n",
            "train_data14717.zip  train_data23865.zip  train_data5571.zip\n",
            "train_data14718.zip  train_data23866.zip  train_data5572.zip\n",
            "train_data14719.zip  train_data23867.zip  train_data5573.zip\n",
            "train_data1471.zip   train_data23868.zip  train_data5574.zip\n",
            "train_data14720.zip  train_data23869.zip  train_data5575.zip\n",
            "train_data14721.zip  train_data2386.zip   train_data5576.zip\n",
            "train_data14722.zip  train_data23870.zip  train_data5577.zip\n",
            "train_data14723.zip  train_data23871.zip  train_data5578.zip\n",
            "train_data14724.zip  train_data23872.zip  train_data5579.zip\n",
            "train_data14725.zip  train_data23873.zip  train_data557.zip\n",
            "train_data14726.zip  train_data23874.zip  train_data5580.zip\n",
            "train_data14727.zip  train_data23875.zip  train_data5581.zip\n",
            "train_data14728.zip  train_data23876.zip  train_data5582.zip\n",
            "train_data14729.zip  train_data23877.zip  train_data5583.zip\n",
            "train_data1472.zip   train_data23878.zip  train_data5584.zip\n",
            "train_data14730.zip  train_data23879.zip  train_data5585.zip\n",
            "train_data14731.zip  train_data2387.zip   train_data5586.zip\n",
            "train_data14732.zip  train_data23880.zip  train_data5587.zip\n",
            "train_data14733.zip  train_data23881.zip  train_data5588.zip\n",
            "train_data14734.zip  train_data23882.zip  train_data5589.zip\n",
            "train_data14735.zip  train_data23883.zip  train_data558.zip\n",
            "train_data14736.zip  train_data23884.zip  train_data5590.zip\n",
            "train_data14737.zip  train_data23885.zip  train_data5591.zip\n",
            "train_data14738.zip  train_data23886.zip  train_data5592.zip\n",
            "train_data14739.zip  train_data23887.zip  train_data5593.zip\n",
            "train_data1473.zip   train_data23888.zip  train_data5594.zip\n",
            "train_data14740.zip  train_data23889.zip  train_data5595.zip\n",
            "train_data14741.zip  train_data2388.zip   train_data5596.zip\n",
            "train_data14742.zip  train_data23890.zip  train_data5597.zip\n",
            "train_data14743.zip  train_data23891.zip  train_data5598.zip\n",
            "train_data14744.zip  train_data23892.zip  train_data5599.zip\n",
            "train_data14745.zip  train_data23893.zip  train_data559.zip\n",
            "train_data14746.zip  train_data23894.zip  train_data55.zip\n",
            "train_data14747.zip  train_data23895.zip  train_data5600.zip\n",
            "train_data14748.zip  train_data23896.zip  train_data5601.zip\n",
            "train_data14749.zip  train_data23897.zip  train_data5602.zip\n",
            "train_data1474.zip   train_data23898.zip  train_data5603.zip\n",
            "train_data14750.zip  train_data23899.zip  train_data5604.zip\n",
            "train_data14751.zip  train_data2389.zip   train_data5605.zip\n",
            "train_data14752.zip  train_data238.zip\t  train_data5606.zip\n",
            "train_data14753.zip  train_data23900.zip  train_data5607.zip\n",
            "train_data14754.zip  train_data23901.zip  train_data5608.zip\n",
            "train_data14755.zip  train_data23902.zip  train_data5609.zip\n",
            "train_data14756.zip  train_data23903.zip  train_data560.zip\n",
            "train_data14757.zip  train_data23904.zip  train_data5610.zip\n",
            "train_data14758.zip  train_data23905.zip  train_data5611.zip\n",
            "train_data14759.zip  train_data23906.zip  train_data5612.zip\n",
            "train_data1475.zip   train_data23907.zip  train_data5613.zip\n",
            "train_data14760.zip  train_data23908.zip  train_data5614.zip\n",
            "train_data14761.zip  train_data23909.zip  train_data5615.zip\n",
            "train_data14762.zip  train_data2390.zip   train_data5616.zip\n",
            "train_data14763.zip  train_data23910.zip  train_data5617.zip\n",
            "train_data14764.zip  train_data23911.zip  train_data5618.zip\n",
            "train_data14765.zip  train_data23912.zip  train_data5619.zip\n",
            "train_data14766.zip  train_data23913.zip  train_data561.zip\n",
            "train_data14767.zip  train_data23914.zip  train_data5620.zip\n",
            "train_data14768.zip  train_data23915.zip  train_data5621.zip\n",
            "train_data14769.zip  train_data23916.zip  train_data5622.zip\n",
            "train_data1476.zip   train_data23917.zip  train_data5623.zip\n",
            "train_data14770.zip  train_data23918.zip  train_data5624.zip\n",
            "train_data14771.zip  train_data23919.zip  train_data5625.zip\n",
            "train_data14772.zip  train_data2391.zip   train_data5626.zip\n",
            "train_data14773.zip  train_data23920.zip  train_data5627.zip\n",
            "train_data14774.zip  train_data23921.zip  train_data5628.zip\n",
            "train_data14775.zip  train_data23922.zip  train_data5629.zip\n",
            "train_data14776.zip  train_data23923.zip  train_data562.zip\n",
            "train_data14777.zip  train_data23924.zip  train_data5630.zip\n",
            "train_data14778.zip  train_data23925.zip  train_data5631.zip\n",
            "train_data14779.zip  train_data23926.zip  train_data5632.zip\n",
            "train_data1477.zip   train_data23927.zip  train_data5633.zip\n",
            "train_data14780.zip  train_data23928.zip  train_data5634.zip\n",
            "train_data14781.zip  train_data23929.zip  train_data5635.zip\n",
            "train_data14782.zip  train_data2392.zip   train_data5636.zip\n",
            "train_data14783.zip  train_data23930.zip  train_data5637.zip\n",
            "train_data14784.zip  train_data23931.zip  train_data5638.zip\n",
            "train_data14785.zip  train_data23932.zip  train_data5639.zip\n",
            "train_data14786.zip  train_data23933.zip  train_data563.zip\n",
            "train_data14787.zip  train_data23934.zip  train_data5640.zip\n",
            "train_data14788.zip  train_data23935.zip  train_data5641.zip\n",
            "train_data14789.zip  train_data23936.zip  train_data5642.zip\n",
            "train_data1478.zip   train_data23937.zip  train_data5643.zip\n",
            "train_data14790.zip  train_data23938.zip  train_data5644.zip\n",
            "train_data14791.zip  train_data23939.zip  train_data5645.zip\n",
            "train_data14792.zip  train_data2393.zip   train_data5646.zip\n",
            "train_data14793.zip  train_data23940.zip  train_data5647.zip\n",
            "train_data14794.zip  train_data23941.zip  train_data5648.zip\n",
            "train_data14795.zip  train_data23942.zip  train_data5649.zip\n",
            "train_data14796.zip  train_data23943.zip  train_data564.zip\n",
            "train_data14797.zip  train_data23944.zip  train_data5650.zip\n",
            "train_data14798.zip  train_data23945.zip  train_data5651.zip\n",
            "train_data14799.zip  train_data23946.zip  train_data5652.zip\n",
            "train_data1479.zip   train_data23947.zip  train_data5653.zip\n",
            "train_data147.zip    train_data23948.zip  train_data5654.zip\n",
            "train_data14800.zip  train_data23949.zip  train_data5655.zip\n",
            "train_data14801.zip  train_data2394.zip   train_data5656.zip\n",
            "train_data14802.zip  train_data23950.zip  train_data5657.zip\n",
            "train_data14803.zip  train_data23951.zip  train_data5658.zip\n",
            "train_data14804.zip  train_data23952.zip  train_data5659.zip\n",
            "train_data14805.zip  train_data23953.zip  train_data565.zip\n",
            "train_data14806.zip  train_data23954.zip  train_data5660.zip\n",
            "train_data14807.zip  train_data23955.zip  train_data5661.zip\n",
            "train_data14808.zip  train_data23956.zip  train_data5662.zip\n",
            "train_data14809.zip  train_data23957.zip  train_data5663.zip\n",
            "train_data1480.zip   train_data23958.zip  train_data5664.zip\n",
            "train_data14810.zip  train_data23959.zip  train_data5665.zip\n",
            "train_data14811.zip  train_data2395.zip   train_data5666.zip\n",
            "train_data14812.zip  train_data23960.zip  train_data5667.zip\n",
            "train_data14813.zip  train_data23961.zip  train_data5668.zip\n",
            "train_data14814.zip  train_data23962.zip  train_data5669.zip\n",
            "train_data14815.zip  train_data23963.zip  train_data566.zip\n",
            "train_data14816.zip  train_data23964.zip  train_data5670.zip\n",
            "train_data14817.zip  train_data23965.zip  train_data5671.zip\n",
            "train_data14818.zip  train_data23966.zip  train_data5672.zip\n",
            "train_data14819.zip  train_data23967.zip  train_data5673.zip\n",
            "train_data1481.zip   train_data23968.zip  train_data5674.zip\n",
            "train_data14820.zip  train_data23969.zip  train_data5675.zip\n",
            "train_data14821.zip  train_data2396.zip   train_data5676.zip\n",
            "train_data14822.zip  train_data23970.zip  train_data5677.zip\n",
            "train_data14823.zip  train_data23971.zip  train_data5678.zip\n",
            "train_data14824.zip  train_data23972.zip  train_data5679.zip\n",
            "train_data14825.zip  train_data23973.zip  train_data567.zip\n",
            "train_data14826.zip  train_data23974.zip  train_data5680.zip\n",
            "train_data14827.zip  train_data23975.zip  train_data5681.zip\n",
            "train_data14828.zip  train_data23976.zip  train_data5682.zip\n",
            "train_data14829.zip  train_data23977.zip  train_data5683.zip\n",
            "train_data1482.zip   train_data23978.zip  train_data5684.zip\n",
            "train_data14830.zip  train_data23979.zip  train_data5685.zip\n",
            "train_data14831.zip  train_data2397.zip   train_data5686.zip\n",
            "train_data14832.zip  train_data23980.zip  train_data5687.zip\n",
            "train_data14833.zip  train_data23981.zip  train_data5688.zip\n",
            "train_data14834.zip  train_data23982.zip  train_data5689.zip\n",
            "train_data14835.zip  train_data23983.zip  train_data568.zip\n",
            "train_data14836.zip  train_data23984.zip  train_data5690.zip\n",
            "train_data14837.zip  train_data23985.zip  train_data5691.zip\n",
            "train_data14838.zip  train_data23986.zip  train_data5692.zip\n",
            "train_data14839.zip  train_data23987.zip  train_data5693.zip\n",
            "train_data1483.zip   train_data23988.zip  train_data5694.zip\n",
            "train_data14840.zip  train_data23989.zip  train_data5695.zip\n",
            "train_data14841.zip  train_data2398.zip   train_data5696.zip\n",
            "train_data14842.zip  train_data23990.zip  train_data5697.zip\n",
            "train_data14843.zip  train_data23991.zip  train_data5698.zip\n",
            "train_data14844.zip  train_data23992.zip  train_data5699.zip\n",
            "train_data14845.zip  train_data23993.zip  train_data569.zip\n",
            "train_data14846.zip  train_data23994.zip  train_data56.zip\n",
            "train_data14847.zip  train_data23995.zip  train_data5700.zip\n",
            "train_data14848.zip  train_data23996.zip  train_data5701.zip\n",
            "train_data14849.zip  train_data23997.zip  train_data5702.zip\n",
            "train_data1484.zip   train_data23998.zip  train_data5703.zip\n",
            "train_data14850.zip  train_data23999.zip  train_data5704.zip\n",
            "train_data14851.zip  train_data2399.zip   train_data5705.zip\n",
            "train_data14852.zip  train_data239.zip\t  train_data5706.zip\n",
            "train_data14853.zip  train_data23.zip\t  train_data5707.zip\n",
            "train_data14854.zip  train_data24000.zip  train_data5708.zip\n",
            "train_data14855.zip  train_data24001.zip  train_data5709.zip\n",
            "train_data14856.zip  train_data24002.zip  train_data570.zip\n",
            "train_data14857.zip  train_data24003.zip  train_data5710.zip\n",
            "train_data14858.zip  train_data24004.zip  train_data5711.zip\n",
            "train_data14859.zip  train_data24005.zip  train_data5712.zip\n",
            "train_data1485.zip   train_data24006.zip  train_data5713.zip\n",
            "train_data14860.zip  train_data24007.zip  train_data5714.zip\n",
            "train_data14861.zip  train_data24008.zip  train_data5715.zip\n",
            "train_data14862.zip  train_data24009.zip  train_data5716.zip\n",
            "train_data14863.zip  train_data2400.zip   train_data5717.zip\n",
            "train_data14864.zip  train_data24010.zip  train_data5718.zip\n",
            "train_data14865.zip  train_data24011.zip  train_data5719.zip\n",
            "train_data14866.zip  train_data24012.zip  train_data571.zip\n",
            "train_data14867.zip  train_data24013.zip  train_data5720.zip\n",
            "train_data14868.zip  train_data24014.zip  train_data5721.zip\n",
            "train_data14869.zip  train_data24015.zip  train_data5722.zip\n",
            "train_data1486.zip   train_data24016.zip  train_data5723.zip\n",
            "train_data14870.zip  train_data24017.zip  train_data5724.zip\n",
            "train_data14871.zip  train_data24018.zip  train_data5725.zip\n",
            "train_data14872.zip  train_data24019.zip  train_data5726.zip\n",
            "train_data14873.zip  train_data2401.zip   train_data5727.zip\n",
            "train_data14874.zip  train_data24020.zip  train_data5728.zip\n",
            "train_data14875.zip  train_data24021.zip  train_data5729.zip\n",
            "train_data14876.zip  train_data24022.zip  train_data572.zip\n",
            "train_data14877.zip  train_data24023.zip  train_data5730.zip\n",
            "train_data14878.zip  train_data24024.zip  train_data5731.zip\n",
            "train_data14879.zip  train_data24025.zip  train_data5732.zip\n",
            "train_data1487.zip   train_data24026.zip  train_data5733.zip\n",
            "train_data14880.zip  train_data24027.zip  train_data5734.zip\n",
            "train_data14881.zip  train_data24028.zip  train_data5735.zip\n",
            "train_data14882.zip  train_data24029.zip  train_data5736.zip\n",
            "train_data14883.zip  train_data2402.zip   train_data5737.zip\n",
            "train_data14884.zip  train_data24030.zip  train_data5738.zip\n",
            "train_data14885.zip  train_data24031.zip  train_data5739.zip\n",
            "train_data14886.zip  train_data24032.zip  train_data573.zip\n",
            "train_data14887.zip  train_data24033.zip  train_data5740.zip\n",
            "train_data14888.zip  train_data24034.zip  train_data5741.zip\n",
            "train_data14889.zip  train_data24035.zip  train_data5742.zip\n",
            "train_data1488.zip   train_data24036.zip  train_data5743.zip\n",
            "train_data14890.zip  train_data24037.zip  train_data5744.zip\n",
            "train_data14891.zip  train_data24038.zip  train_data5745.zip\n",
            "train_data14892.zip  train_data24039.zip  train_data5746.zip\n",
            "train_data14893.zip  train_data2403.zip   train_data5747.zip\n",
            "train_data14894.zip  train_data24040.zip  train_data5748.zip\n",
            "train_data14895.zip  train_data24041.zip  train_data5749.zip\n",
            "train_data14896.zip  train_data24042.zip  train_data574.zip\n",
            "train_data14897.zip  train_data24043.zip  train_data5750.zip\n",
            "train_data14898.zip  train_data24044.zip  train_data5751.zip\n",
            "train_data14899.zip  train_data24045.zip  train_data5752.zip\n",
            "train_data1489.zip   train_data24046.zip  train_data5753.zip\n",
            "train_data148.zip    train_data24047.zip  train_data5754.zip\n",
            "train_data14900.zip  train_data24048.zip  train_data5755.zip\n",
            "train_data14901.zip  train_data24049.zip  train_data5756.zip\n",
            "train_data14902.zip  train_data2404.zip   train_data5757.zip\n",
            "train_data14903.zip  train_data24050.zip  train_data5758.zip\n",
            "train_data14904.zip  train_data24051.zip  train_data5759.zip\n",
            "train_data14905.zip  train_data24052.zip  train_data575.zip\n",
            "train_data14906.zip  train_data24053.zip  train_data5760.zip\n",
            "train_data14907.zip  train_data24054.zip  train_data5761.zip\n",
            "train_data14908.zip  train_data24055.zip  train_data5762.zip\n",
            "train_data14909.zip  train_data24056.zip  train_data5763.zip\n",
            "train_data1490.zip   train_data24057.zip  train_data5764.zip\n",
            "train_data14910.zip  train_data24058.zip  train_data5765.zip\n",
            "train_data14911.zip  train_data24059.zip  train_data5766.zip\n",
            "train_data14912.zip  train_data2405.zip   train_data5767.zip\n",
            "train_data14913.zip  train_data24060.zip  train_data5768.zip\n",
            "train_data14914.zip  train_data24061.zip  train_data5769.zip\n",
            "train_data14915.zip  train_data24062.zip  train_data576.zip\n",
            "train_data14916.zip  train_data24063.zip  train_data5770.zip\n",
            "train_data14917.zip  train_data24064.zip  train_data5771.zip\n",
            "train_data14918.zip  train_data24065.zip  train_data5772.zip\n",
            "train_data14919.zip  train_data24066.zip  train_data5773.zip\n",
            "train_data1491.zip   train_data24067.zip  train_data5774.zip\n",
            "train_data14920.zip  train_data24068.zip  train_data5775.zip\n",
            "train_data14921.zip  train_data24069.zip  train_data5776.zip\n",
            "train_data14922.zip  train_data2406.zip   train_data5777.zip\n",
            "train_data14923.zip  train_data24070.zip  train_data5778.zip\n",
            "train_data14924.zip  train_data24071.zip  train_data5779.zip\n",
            "train_data14925.zip  train_data24072.zip  train_data577.zip\n",
            "train_data14926.zip  train_data24073.zip  train_data5780.zip\n",
            "train_data14927.zip  train_data24074.zip  train_data5781.zip\n",
            "train_data14928.zip  train_data24075.zip  train_data5782.zip\n",
            "train_data14929.zip  train_data24076.zip  train_data5783.zip\n",
            "train_data1492.zip   train_data24077.zip  train_data5784.zip\n",
            "train_data14930.zip  train_data24078.zip  train_data5785.zip\n",
            "train_data14931.zip  train_data24079.zip  train_data5786.zip\n",
            "train_data14932.zip  train_data2407.zip   train_data5787.zip\n",
            "train_data14933.zip  train_data24080.zip  train_data5788.zip\n",
            "train_data14934.zip  train_data24081.zip  train_data5789.zip\n",
            "train_data14935.zip  train_data24082.zip  train_data578.zip\n",
            "train_data14936.zip  train_data24083.zip  train_data5790.zip\n",
            "train_data14937.zip  train_data24084.zip  train_data5791.zip\n",
            "train_data14938.zip  train_data24085.zip  train_data5792.zip\n",
            "train_data14939.zip  train_data24086.zip  train_data5793.zip\n",
            "train_data1493.zip   train_data24087.zip  train_data5794.zip\n",
            "train_data14940.zip  train_data24088.zip  train_data5795.zip\n",
            "train_data14941.zip  train_data24089.zip  train_data5796.zip\n",
            "train_data14942.zip  train_data2408.zip   train_data5797.zip\n",
            "train_data14943.zip  train_data24090.zip  train_data5798.zip\n",
            "train_data14944.zip  train_data24091.zip  train_data5799.zip\n",
            "train_data14945.zip  train_data24092.zip  train_data579.zip\n",
            "train_data14946.zip  train_data24093.zip  train_data57.zip\n",
            "train_data14947.zip  train_data24094.zip  train_data5800.zip\n",
            "train_data14948.zip  train_data24095.zip  train_data5801.zip\n",
            "train_data14949.zip  train_data24096.zip  train_data5802.zip\n",
            "train_data1494.zip   train_data24097.zip  train_data5803.zip\n",
            "train_data14950.zip  train_data24098.zip  train_data5804.zip\n",
            "train_data14951.zip  train_data24099.zip  train_data5805.zip\n",
            "train_data14952.zip  train_data2409.zip   train_data5806.zip\n",
            "train_data14953.zip  train_data240.zip\t  train_data5807.zip\n",
            "train_data14954.zip  train_data24100.zip  train_data5808.zip\n",
            "train_data14955.zip  train_data24101.zip  train_data5809.zip\n",
            "train_data14956.zip  train_data24102.zip  train_data580.zip\n",
            "train_data14957.zip  train_data24103.zip  train_data5810.zip\n",
            "train_data14958.zip  train_data24104.zip  train_data5811.zip\n",
            "train_data14959.zip  train_data24105.zip  train_data5812.zip\n",
            "train_data1495.zip   train_data24106.zip  train_data5813.zip\n",
            "train_data14960.zip  train_data24107.zip  train_data5814.zip\n",
            "train_data14961.zip  train_data24108.zip  train_data5815.zip\n",
            "train_data14962.zip  train_data24109.zip  train_data5816.zip\n",
            "train_data14963.zip  train_data2410.zip   train_data5817.zip\n",
            "train_data14964.zip  train_data24110.zip  train_data5818.zip\n",
            "train_data14965.zip  train_data24111.zip  train_data5819.zip\n",
            "train_data14966.zip  train_data24112.zip  train_data581.zip\n",
            "train_data14967.zip  train_data24113.zip  train_data5820.zip\n",
            "train_data14968.zip  train_data24114.zip  train_data5821.zip\n",
            "train_data14969.zip  train_data24115.zip  train_data5822.zip\n",
            "train_data1496.zip   train_data24116.zip  train_data5823.zip\n",
            "train_data14970.zip  train_data24117.zip  train_data5824.zip\n",
            "train_data14971.zip  train_data24118.zip  train_data5825.zip\n",
            "train_data14972.zip  train_data24119.zip  train_data5826.zip\n",
            "train_data14973.zip  train_data2411.zip   train_data5827.zip\n",
            "train_data14974.zip  train_data24120.zip  train_data5828.zip\n",
            "train_data14975.zip  train_data24121.zip  train_data5829.zip\n",
            "train_data14976.zip  train_data24122.zip  train_data582.zip\n",
            "train_data14977.zip  train_data24123.zip  train_data5830.zip\n",
            "train_data14978.zip  train_data24124.zip  train_data5831.zip\n",
            "train_data14979.zip  train_data24125.zip  train_data5832.zip\n",
            "train_data1497.zip   train_data24126.zip  train_data5833.zip\n",
            "train_data14980.zip  train_data24127.zip  train_data5834.zip\n",
            "train_data14981.zip  train_data24128.zip  train_data5835.zip\n",
            "train_data14982.zip  train_data24129.zip  train_data5836.zip\n",
            "train_data14983.zip  train_data2412.zip   train_data5837.zip\n",
            "train_data14984.zip  train_data24130.zip  train_data5838.zip\n",
            "train_data14985.zip  train_data24131.zip  train_data5839.zip\n",
            "train_data14986.zip  train_data24132.zip  train_data583.zip\n",
            "train_data14987.zip  train_data24133.zip  train_data5840.zip\n",
            "train_data14988.zip  train_data24134.zip  train_data5841.zip\n",
            "train_data14989.zip  train_data24135.zip  train_data5842.zip\n",
            "train_data1498.zip   train_data24136.zip  train_data5843.zip\n",
            "train_data14990.zip  train_data24137.zip  train_data5844.zip\n",
            "train_data14991.zip  train_data24138.zip  train_data5845.zip\n",
            "train_data14992.zip  train_data24139.zip  train_data5846.zip\n",
            "train_data14993.zip  train_data2413.zip   train_data5847.zip\n",
            "train_data14994.zip  train_data24140.zip  train_data5848.zip\n",
            "train_data14995.zip  train_data24141.zip  train_data5849.zip\n",
            "train_data14996.zip  train_data24142.zip  train_data584.zip\n",
            "train_data14997.zip  train_data24143.zip  train_data5850.zip\n",
            "train_data14998.zip  train_data24144.zip  train_data5851.zip\n",
            "train_data14999.zip  train_data24145.zip  train_data5852.zip\n",
            "train_data1499.zip   train_data24146.zip  train_data5853.zip\n",
            "train_data149.zip    train_data24147.zip  train_data5854.zip\n",
            "train_data14.zip     train_data24148.zip  train_data5855.zip\n",
            "train_data15000.zip  train_data24149.zip  train_data5856.zip\n",
            "train_data15001.zip  train_data2414.zip   train_data5857.zip\n",
            "train_data15002.zip  train_data24150.zip  train_data5858.zip\n",
            "train_data15003.zip  train_data24151.zip  train_data5859.zip\n",
            "train_data15004.zip  train_data24152.zip  train_data585.zip\n",
            "train_data15005.zip  train_data24153.zip  train_data5860.zip\n",
            "train_data15006.zip  train_data24154.zip  train_data5861.zip\n",
            "train_data15007.zip  train_data24155.zip  train_data5862.zip\n",
            "train_data15008.zip  train_data24156.zip  train_data5863.zip\n",
            "train_data15009.zip  train_data24157.zip  train_data5864.zip\n",
            "train_data1500.zip   train_data24158.zip  train_data5865.zip\n",
            "train_data15010.zip  train_data24159.zip  train_data5866.zip\n",
            "train_data15011.zip  train_data2415.zip   train_data5867.zip\n",
            "train_data15012.zip  train_data24160.zip  train_data5868.zip\n",
            "train_data15013.zip  train_data24161.zip  train_data5869.zip\n",
            "train_data15014.zip  train_data24162.zip  train_data586.zip\n",
            "train_data15015.zip  train_data24163.zip  train_data5870.zip\n",
            "train_data15016.zip  train_data24164.zip  train_data5871.zip\n",
            "train_data15017.zip  train_data24165.zip  train_data5872.zip\n",
            "train_data15018.zip  train_data24166.zip  train_data5873.zip\n",
            "train_data15019.zip  train_data24167.zip  train_data5874.zip\n",
            "train_data1501.zip   train_data24168.zip  train_data5875.zip\n",
            "train_data15020.zip  train_data24169.zip  train_data5876.zip\n",
            "train_data15021.zip  train_data2416.zip   train_data5877.zip\n",
            "train_data15022.zip  train_data24170.zip  train_data5878.zip\n",
            "train_data15023.zip  train_data24171.zip  train_data5879.zip\n",
            "train_data15024.zip  train_data24172.zip  train_data587.zip\n",
            "train_data15025.zip  train_data24173.zip  train_data5880.zip\n",
            "train_data15026.zip  train_data24174.zip  train_data5881.zip\n",
            "train_data15027.zip  train_data24175.zip  train_data5882.zip\n",
            "train_data15028.zip  train_data24176.zip  train_data5883.zip\n",
            "train_data15029.zip  train_data24177.zip  train_data5884.zip\n",
            "train_data1502.zip   train_data24178.zip  train_data5885.zip\n",
            "train_data15030.zip  train_data24179.zip  train_data5886.zip\n",
            "train_data15031.zip  train_data2417.zip   train_data5887.zip\n",
            "train_data15032.zip  train_data24180.zip  train_data5888.zip\n",
            "train_data15033.zip  train_data24181.zip  train_data5889.zip\n",
            "train_data15034.zip  train_data24182.zip  train_data588.zip\n",
            "train_data15035.zip  train_data24183.zip  train_data5890.zip\n",
            "train_data15036.zip  train_data24184.zip  train_data5891.zip\n",
            "train_data15037.zip  train_data24185.zip  train_data5892.zip\n",
            "train_data15038.zip  train_data24186.zip  train_data5893.zip\n",
            "train_data15039.zip  train_data24187.zip  train_data5894.zip\n",
            "train_data1503.zip   train_data24188.zip  train_data5895.zip\n",
            "train_data15040.zip  train_data24189.zip  train_data5896.zip\n",
            "train_data15041.zip  train_data2418.zip   train_data5897.zip\n",
            "train_data15042.zip  train_data24190.zip  train_data5898.zip\n",
            "train_data15043.zip  train_data24191.zip  train_data5899.zip\n",
            "train_data15044.zip  train_data24192.zip  train_data589.zip\n",
            "train_data15045.zip  train_data24193.zip  train_data58.zip\n",
            "train_data15046.zip  train_data24194.zip  train_data5900.zip\n",
            "train_data15047.zip  train_data24195.zip  train_data5901.zip\n",
            "train_data15048.zip  train_data24196.zip  train_data5902.zip\n",
            "train_data15049.zip  train_data24197.zip  train_data5903.zip\n",
            "train_data1504.zip   train_data24198.zip  train_data5904.zip\n",
            "train_data15050.zip  train_data24199.zip  train_data5905.zip\n",
            "train_data15051.zip  train_data2419.zip   train_data5906.zip\n",
            "train_data15052.zip  train_data241.zip\t  train_data5907.zip\n",
            "train_data15053.zip  train_data24200.zip  train_data5908.zip\n",
            "train_data15054.zip  train_data24201.zip  train_data5909.zip\n",
            "train_data15055.zip  train_data24202.zip  train_data590.zip\n",
            "train_data15056.zip  train_data24203.zip  train_data5910.zip\n",
            "train_data15057.zip  train_data24204.zip  train_data5911.zip\n",
            "train_data15058.zip  train_data24205.zip  train_data5912.zip\n",
            "train_data15059.zip  train_data24206.zip  train_data5913.zip\n",
            "train_data1505.zip   train_data24207.zip  train_data5914.zip\n",
            "train_data15060.zip  train_data24208.zip  train_data5915.zip\n",
            "train_data15061.zip  train_data24209.zip  train_data5916.zip\n",
            "train_data15062.zip  train_data2420.zip   train_data5917.zip\n",
            "train_data15063.zip  train_data24210.zip  train_data5918.zip\n",
            "train_data15064.zip  train_data24211.zip  train_data5919.zip\n",
            "train_data15065.zip  train_data24212.zip  train_data591.zip\n",
            "train_data15066.zip  train_data24213.zip  train_data5920.zip\n",
            "train_data15067.zip  train_data24214.zip  train_data5921.zip\n",
            "train_data15068.zip  train_data24215.zip  train_data5922.zip\n",
            "train_data15069.zip  train_data24216.zip  train_data5923.zip\n",
            "train_data1506.zip   train_data24217.zip  train_data5924.zip\n",
            "train_data15070.zip  train_data24218.zip  train_data5925.zip\n",
            "train_data15071.zip  train_data24219.zip  train_data5926.zip\n",
            "train_data15072.zip  train_data2421.zip   train_data5927.zip\n",
            "train_data15073.zip  train_data24220.zip  train_data5928.zip\n",
            "train_data15074.zip  train_data24221.zip  train_data5929.zip\n",
            "train_data15075.zip  train_data24222.zip  train_data592.zip\n",
            "train_data15076.zip  train_data24223.zip  train_data5930.zip\n",
            "train_data15077.zip  train_data24224.zip  train_data5931.zip\n",
            "train_data15078.zip  train_data24225.zip  train_data5932.zip\n",
            "train_data15079.zip  train_data24226.zip  train_data5933.zip\n",
            "train_data1507.zip   train_data24227.zip  train_data5934.zip\n",
            "train_data15080.zip  train_data24228.zip  train_data5935.zip\n",
            "train_data15081.zip  train_data24229.zip  train_data5936.zip\n",
            "train_data15082.zip  train_data2422.zip   train_data5937.zip\n",
            "train_data15083.zip  train_data24230.zip  train_data5938.zip\n",
            "train_data15084.zip  train_data24231.zip  train_data5939.zip\n",
            "train_data15085.zip  train_data24232.zip  train_data593.zip\n",
            "train_data15086.zip  train_data24233.zip  train_data5940.zip\n",
            "train_data15087.zip  train_data24234.zip  train_data5941.zip\n",
            "train_data15088.zip  train_data24235.zip  train_data5942.zip\n",
            "train_data15089.zip  train_data24236.zip  train_data5943.zip\n",
            "train_data1508.zip   train_data24237.zip  train_data5944.zip\n",
            "train_data15090.zip  train_data24238.zip  train_data5945.zip\n",
            "train_data15091.zip  train_data24239.zip  train_data5946.zip\n",
            "train_data15092.zip  train_data2423.zip   train_data5947.zip\n",
            "train_data15093.zip  train_data24240.zip  train_data5948.zip\n",
            "train_data15094.zip  train_data24241.zip  train_data5949.zip\n",
            "train_data15095.zip  train_data24242.zip  train_data594.zip\n",
            "train_data15096.zip  train_data24243.zip  train_data5950.zip\n",
            "train_data15097.zip  train_data24244.zip  train_data5951.zip\n",
            "train_data15098.zip  train_data24245.zip  train_data5952.zip\n",
            "train_data15099.zip  train_data24246.zip  train_data5953.zip\n",
            "train_data1509.zip   train_data24247.zip  train_data5954.zip\n",
            "train_data150.zip    train_data24248.zip  train_data5955.zip\n",
            "train_data15100.zip  train_data24249.zip  train_data5956.zip\n",
            "train_data15101.zip  train_data2424.zip   train_data5957.zip\n",
            "train_data15102.zip  train_data24250.zip  train_data5958.zip\n",
            "train_data15103.zip  train_data24251.zip  train_data5959.zip\n",
            "train_data15104.zip  train_data24252.zip  train_data595.zip\n",
            "train_data15105.zip  train_data24253.zip  train_data5960.zip\n",
            "train_data15106.zip  train_data24254.zip  train_data5961.zip\n",
            "train_data15107.zip  train_data24255.zip  train_data5962.zip\n",
            "train_data15108.zip  train_data24256.zip  train_data5963.zip\n",
            "train_data15109.zip  train_data24257.zip  train_data5964.zip\n",
            "train_data1510.zip   train_data24258.zip  train_data5965.zip\n",
            "train_data15110.zip  train_data24259.zip  train_data5966.zip\n",
            "train_data15111.zip  train_data2425.zip   train_data5967.zip\n",
            "train_data15112.zip  train_data24260.zip  train_data5968.zip\n",
            "train_data15113.zip  train_data24261.zip  train_data5969.zip\n",
            "train_data15114.zip  train_data24262.zip  train_data596.zip\n",
            "train_data15115.zip  train_data24263.zip  train_data5970.zip\n",
            "train_data15116.zip  train_data24264.zip  train_data5971.zip\n",
            "train_data15117.zip  train_data24265.zip  train_data5972.zip\n",
            "train_data15118.zip  train_data24266.zip  train_data5973.zip\n",
            "train_data15119.zip  train_data24267.zip  train_data5974.zip\n",
            "train_data1511.zip   train_data24268.zip  train_data5975.zip\n",
            "train_data15120.zip  train_data24269.zip  train_data5976.zip\n",
            "train_data15121.zip  train_data2426.zip   train_data5977.zip\n",
            "train_data15122.zip  train_data24270.zip  train_data5978.zip\n",
            "train_data15123.zip  train_data24271.zip  train_data5979.zip\n",
            "train_data15124.zip  train_data24272.zip  train_data597.zip\n",
            "train_data15125.zip  train_data24273.zip  train_data5980.zip\n",
            "train_data15126.zip  train_data24274.zip  train_data5981.zip\n",
            "train_data15127.zip  train_data24275.zip  train_data5982.zip\n",
            "train_data15128.zip  train_data24276.zip  train_data5983.zip\n",
            "train_data15129.zip  train_data24277.zip  train_data5984.zip\n",
            "train_data1512.zip   train_data24278.zip  train_data5985.zip\n",
            "train_data15130.zip  train_data24279.zip  train_data5986.zip\n",
            "train_data15131.zip  train_data2427.zip   train_data5987.zip\n",
            "train_data15132.zip  train_data24280.zip  train_data5988.zip\n",
            "train_data15133.zip  train_data24281.zip  train_data5989.zip\n",
            "train_data15134.zip  train_data24282.zip  train_data598.zip\n",
            "train_data15135.zip  train_data24283.zip  train_data5990.zip\n",
            "train_data15136.zip  train_data24284.zip  train_data5991.zip\n",
            "train_data15137.zip  train_data24285.zip  train_data5992.zip\n",
            "train_data15138.zip  train_data24286.zip  train_data5993.zip\n",
            "train_data15139.zip  train_data24287.zip  train_data5994.zip\n",
            "train_data1513.zip   train_data24288.zip  train_data5995.zip\n",
            "train_data15140.zip  train_data24289.zip  train_data5996.zip\n",
            "train_data15141.zip  train_data2428.zip   train_data5997.zip\n",
            "train_data15142.zip  train_data24290.zip  train_data5998.zip\n",
            "train_data15143.zip  train_data24291.zip  train_data5999.zip\n",
            "train_data15144.zip  train_data24292.zip  train_data599.zip\n",
            "train_data15145.zip  train_data24293.zip  train_data59.zip\n",
            "train_data15146.zip  train_data24294.zip  train_data5.zip\n",
            "train_data15147.zip  train_data24295.zip  train_data6000.zip\n",
            "train_data15148.zip  train_data24296.zip  train_data6001.zip\n",
            "train_data15149.zip  train_data24297.zip  train_data6002.zip\n",
            "train_data1514.zip   train_data24298.zip  train_data6003.zip\n",
            "train_data15150.zip  train_data24299.zip  train_data6004.zip\n",
            "train_data15151.zip  train_data2429.zip   train_data6005.zip\n",
            "train_data15152.zip  train_data242.zip\t  train_data6006.zip\n",
            "train_data15153.zip  train_data24300.zip  train_data6007.zip\n",
            "train_data15154.zip  train_data24301.zip  train_data6008.zip\n",
            "train_data15155.zip  train_data24302.zip  train_data6009.zip\n",
            "train_data15156.zip  train_data24303.zip  train_data600.zip\n",
            "train_data15157.zip  train_data24304.zip  train_data6010.zip\n",
            "train_data15158.zip  train_data24305.zip  train_data6011.zip\n",
            "train_data15159.zip  train_data24306.zip  train_data6012.zip\n",
            "train_data1515.zip   train_data24307.zip  train_data6013.zip\n",
            "train_data15160.zip  train_data24308.zip  train_data6014.zip\n",
            "train_data15161.zip  train_data24309.zip  train_data6015.zip\n",
            "train_data15162.zip  train_data2430.zip   train_data6016.zip\n",
            "train_data15163.zip  train_data24310.zip  train_data6017.zip\n",
            "train_data15164.zip  train_data24311.zip  train_data6018.zip\n",
            "train_data15165.zip  train_data24312.zip  train_data6019.zip\n",
            "train_data15166.zip  train_data24313.zip  train_data601.zip\n",
            "train_data15167.zip  train_data24314.zip  train_data6020.zip\n",
            "train_data15168.zip  train_data24315.zip  train_data6021.zip\n",
            "train_data15169.zip  train_data24316.zip  train_data6022.zip\n",
            "train_data1516.zip   train_data24317.zip  train_data6023.zip\n",
            "train_data15170.zip  train_data24318.zip  train_data6024.zip\n",
            "train_data15171.zip  train_data24319.zip  train_data6025.zip\n",
            "train_data15172.zip  train_data2431.zip   train_data6026.zip\n",
            "train_data15173.zip  train_data24320.zip  train_data6027.zip\n",
            "train_data15174.zip  train_data24321.zip  train_data6028.zip\n",
            "train_data15175.zip  train_data24322.zip  train_data6029.zip\n",
            "train_data15176.zip  train_data24323.zip  train_data602.zip\n",
            "train_data15177.zip  train_data24324.zip  train_data6030.zip\n",
            "train_data15178.zip  train_data24325.zip  train_data6031.zip\n",
            "train_data15179.zip  train_data24326.zip  train_data6032.zip\n",
            "train_data1517.zip   train_data24327.zip  train_data6033.zip\n",
            "train_data15180.zip  train_data24328.zip  train_data6034.zip\n",
            "train_data15181.zip  train_data24329.zip  train_data6035.zip\n",
            "train_data15182.zip  train_data2432.zip   train_data6036.zip\n",
            "train_data15183.zip  train_data24330.zip  train_data6037.zip\n",
            "train_data15184.zip  train_data24331.zip  train_data6038.zip\n",
            "train_data15185.zip  train_data24332.zip  train_data6039.zip\n",
            "train_data15186.zip  train_data24333.zip  train_data603.zip\n",
            "train_data15187.zip  train_data24334.zip  train_data6040.zip\n",
            "train_data15188.zip  train_data24335.zip  train_data6041.zip\n",
            "train_data15189.zip  train_data24336.zip  train_data6042.zip\n",
            "train_data1518.zip   train_data24337.zip  train_data6043.zip\n",
            "train_data15190.zip  train_data24338.zip  train_data6044.zip\n",
            "train_data15191.zip  train_data24339.zip  train_data6045.zip\n",
            "train_data15192.zip  train_data2433.zip   train_data6046.zip\n",
            "train_data15193.zip  train_data24340.zip  train_data6047.zip\n",
            "train_data15194.zip  train_data24341.zip  train_data6048.zip\n",
            "train_data15195.zip  train_data24342.zip  train_data6049.zip\n",
            "train_data15196.zip  train_data24343.zip  train_data604.zip\n",
            "train_data15197.zip  train_data24344.zip  train_data6050.zip\n",
            "train_data15198.zip  train_data24345.zip  train_data6051.zip\n",
            "train_data15199.zip  train_data24346.zip  train_data6052.zip\n",
            "train_data1519.zip   train_data24347.zip  train_data6053.zip\n",
            "train_data151.zip    train_data24348.zip  train_data6054.zip\n",
            "train_data15200.zip  train_data24349.zip  train_data6055.zip\n",
            "train_data15201.zip  train_data2434.zip   train_data6056.zip\n",
            "train_data15202.zip  train_data24350.zip  train_data6057.zip\n",
            "train_data15203.zip  train_data24351.zip  train_data6058.zip\n",
            "train_data15204.zip  train_data24352.zip  train_data6059.zip\n",
            "train_data15205.zip  train_data24353.zip  train_data605.zip\n",
            "train_data15206.zip  train_data24354.zip  train_data6060.zip\n",
            "train_data15207.zip  train_data24355.zip  train_data6061.zip\n",
            "train_data15208.zip  train_data24356.zip  train_data6062.zip\n",
            "train_data15209.zip  train_data24357.zip  train_data6063.zip\n",
            "train_data1520.zip   train_data24358.zip  train_data6064.zip\n",
            "train_data15210.zip  train_data24359.zip  train_data6065.zip\n",
            "train_data15211.zip  train_data2435.zip   train_data6066.zip\n",
            "train_data15212.zip  train_data24360.zip  train_data6067.zip\n",
            "train_data15213.zip  train_data24361.zip  train_data6068.zip\n",
            "train_data15214.zip  train_data24362.zip  train_data6069.zip\n",
            "train_data15215.zip  train_data24363.zip  train_data606.zip\n",
            "train_data15216.zip  train_data24364.zip  train_data6070.zip\n",
            "train_data15217.zip  train_data24365.zip  train_data6071.zip\n",
            "train_data15218.zip  train_data24366.zip  train_data6072.zip\n",
            "train_data15219.zip  train_data24367.zip  train_data6073.zip\n",
            "train_data1521.zip   train_data24368.zip  train_data6074.zip\n",
            "train_data15220.zip  train_data24369.zip  train_data6075.zip\n",
            "train_data15221.zip  train_data2436.zip   train_data6076.zip\n",
            "train_data15222.zip  train_data24370.zip  train_data6077.zip\n",
            "train_data15223.zip  train_data24371.zip  train_data6078.zip\n",
            "train_data15224.zip  train_data24372.zip  train_data6079.zip\n",
            "train_data15225.zip  train_data24373.zip  train_data607.zip\n",
            "train_data15226.zip  train_data24374.zip  train_data6080.zip\n",
            "train_data15227.zip  train_data24375.zip  train_data6081.zip\n",
            "train_data15228.zip  train_data24376.zip  train_data6082.zip\n",
            "train_data15229.zip  train_data24377.zip  train_data6083.zip\n",
            "train_data1522.zip   train_data24378.zip  train_data6084.zip\n",
            "train_data15230.zip  train_data24379.zip  train_data6085.zip\n",
            "train_data15231.zip  train_data2437.zip   train_data6086.zip\n",
            "train_data15232.zip  train_data24380.zip  train_data6087.zip\n",
            "train_data15233.zip  train_data24381.zip  train_data6088.zip\n",
            "train_data15234.zip  train_data24382.zip  train_data6089.zip\n",
            "train_data15235.zip  train_data24383.zip  train_data608.zip\n",
            "train_data15236.zip  train_data24384.zip  train_data6090.zip\n",
            "train_data15237.zip  train_data24385.zip  train_data6091.zip\n",
            "train_data15238.zip  train_data24386.zip  train_data6092.zip\n",
            "train_data15239.zip  train_data24387.zip  train_data6093.zip\n",
            "train_data1523.zip   train_data24388.zip  train_data6094.zip\n",
            "train_data15240.zip  train_data24389.zip  train_data6095.zip\n",
            "train_data15241.zip  train_data2438.zip   train_data6096.zip\n",
            "train_data15242.zip  train_data24390.zip  train_data6097.zip\n",
            "train_data15243.zip  train_data24391.zip  train_data6098.zip\n",
            "train_data15244.zip  train_data24392.zip  train_data6099.zip\n",
            "train_data15245.zip  train_data24393.zip  train_data609.zip\n",
            "train_data15246.zip  train_data24394.zip  train_data60.zip\n",
            "train_data15247.zip  train_data24395.zip  train_data6100.zip\n",
            "train_data15248.zip  train_data24396.zip  train_data6101.zip\n",
            "train_data15249.zip  train_data24397.zip  train_data6102.zip\n",
            "train_data1524.zip   train_data24398.zip  train_data6103.zip\n",
            "train_data15250.zip  train_data24399.zip  train_data6104.zip\n",
            "train_data15251.zip  train_data2439.zip   train_data6105.zip\n",
            "train_data15252.zip  train_data243.zip\t  train_data6106.zip\n",
            "train_data15253.zip  train_data24400.zip  train_data6107.zip\n",
            "train_data15254.zip  train_data24401.zip  train_data6108.zip\n",
            "train_data15255.zip  train_data24402.zip  train_data6109.zip\n",
            "train_data15256.zip  train_data24403.zip  train_data610.zip\n",
            "train_data15257.zip  train_data24404.zip  train_data6110.zip\n",
            "train_data15258.zip  train_data24405.zip  train_data6111.zip\n",
            "train_data15259.zip  train_data24406.zip  train_data6112.zip\n",
            "train_data1525.zip   train_data24407.zip  train_data6113.zip\n",
            "train_data15260.zip  train_data24408.zip  train_data6114.zip\n",
            "train_data15261.zip  train_data24409.zip  train_data6115.zip\n",
            "train_data15262.zip  train_data2440.zip   train_data6116.zip\n",
            "train_data15263.zip  train_data24410.zip  train_data6117.zip\n",
            "train_data15264.zip  train_data24411.zip  train_data6118.zip\n",
            "train_data15265.zip  train_data24412.zip  train_data6119.zip\n",
            "train_data15266.zip  train_data24413.zip  train_data611.zip\n",
            "train_data15267.zip  train_data24414.zip  train_data6120.zip\n",
            "train_data15268.zip  train_data24415.zip  train_data6121.zip\n",
            "train_data15269.zip  train_data24416.zip  train_data6122.zip\n",
            "train_data1526.zip   train_data24417.zip  train_data6123.zip\n",
            "train_data15270.zip  train_data24418.zip  train_data6124.zip\n",
            "train_data15271.zip  train_data24419.zip  train_data6125.zip\n",
            "train_data15272.zip  train_data2441.zip   train_data6126.zip\n",
            "train_data15273.zip  train_data24420.zip  train_data6127.zip\n",
            "train_data15274.zip  train_data24421.zip  train_data6128.zip\n",
            "train_data15275.zip  train_data24422.zip  train_data6129.zip\n",
            "train_data15276.zip  train_data24423.zip  train_data612.zip\n",
            "train_data15277.zip  train_data24424.zip  train_data6130.zip\n",
            "train_data15278.zip  train_data24425.zip  train_data6131.zip\n",
            "train_data15279.zip  train_data24426.zip  train_data6132.zip\n",
            "train_data1527.zip   train_data24427.zip  train_data6133.zip\n",
            "train_data15280.zip  train_data24428.zip  train_data6134.zip\n",
            "train_data15281.zip  train_data24429.zip  train_data6135.zip\n",
            "train_data15282.zip  train_data2442.zip   train_data6136.zip\n",
            "train_data15283.zip  train_data24430.zip  train_data6137.zip\n",
            "train_data15284.zip  train_data24431.zip  train_data6138.zip\n",
            "train_data15285.zip  train_data24432.zip  train_data6139.zip\n",
            "train_data15286.zip  train_data24433.zip  train_data613.zip\n",
            "train_data15287.zip  train_data24434.zip  train_data6140.zip\n",
            "train_data15288.zip  train_data24435.zip  train_data6141.zip\n",
            "train_data15289.zip  train_data24436.zip  train_data6142.zip\n",
            "train_data1528.zip   train_data24437.zip  train_data6143.zip\n",
            "train_data15290.zip  train_data24438.zip  train_data6144.zip\n",
            "train_data15291.zip  train_data24439.zip  train_data6145.zip\n",
            "train_data15292.zip  train_data2443.zip   train_data6146.zip\n",
            "train_data15293.zip  train_data24440.zip  train_data6147.zip\n",
            "train_data15294.zip  train_data24441.zip  train_data6148.zip\n",
            "train_data15295.zip  train_data24442.zip  train_data6149.zip\n",
            "train_data15296.zip  train_data24443.zip  train_data614.zip\n",
            "train_data15297.zip  train_data24444.zip  train_data6150.zip\n",
            "train_data15298.zip  train_data24445.zip  train_data6151.zip\n",
            "train_data15299.zip  train_data24446.zip  train_data6152.zip\n",
            "train_data1529.zip   train_data24447.zip  train_data6153.zip\n",
            "train_data152.zip    train_data24448.zip  train_data6154.zip\n",
            "train_data15300.zip  train_data24449.zip  train_data6155.zip\n",
            "train_data15301.zip  train_data2444.zip   train_data6156.zip\n",
            "train_data15302.zip  train_data24450.zip  train_data6157.zip\n",
            "train_data15303.zip  train_data24451.zip  train_data6158.zip\n",
            "train_data15304.zip  train_data24452.zip  train_data6159.zip\n",
            "train_data15305.zip  train_data24453.zip  train_data615.zip\n",
            "train_data15306.zip  train_data24454.zip  train_data6160.zip\n",
            "train_data15307.zip  train_data24455.zip  train_data6161.zip\n",
            "train_data15308.zip  train_data24456.zip  train_data6162.zip\n",
            "train_data15309.zip  train_data24457.zip  train_data6163.zip\n",
            "train_data1530.zip   train_data24458.zip  train_data6164.zip\n",
            "train_data15310.zip  train_data24459.zip  train_data6165.zip\n",
            "train_data15311.zip  train_data2445.zip   train_data6166.zip\n",
            "train_data15312.zip  train_data24460.zip  train_data6167.zip\n",
            "train_data15313.zip  train_data24461.zip  train_data6168.zip\n",
            "train_data15314.zip  train_data24462.zip  train_data6169.zip\n",
            "train_data15315.zip  train_data24463.zip  train_data616.zip\n",
            "train_data15316.zip  train_data24464.zip  train_data6170.zip\n",
            "train_data15317.zip  train_data24465.zip  train_data6171.zip\n",
            "train_data15318.zip  train_data24466.zip  train_data6172.zip\n",
            "train_data15319.zip  train_data24467.zip  train_data6173.zip\n",
            "train_data1531.zip   train_data24468.zip  train_data6174.zip\n",
            "train_data15320.zip  train_data24469.zip  train_data6175.zip\n",
            "train_data15321.zip  train_data2446.zip   train_data6176.zip\n",
            "train_data15322.zip  train_data24470.zip  train_data6177.zip\n",
            "train_data15323.zip  train_data24471.zip  train_data6178.zip\n",
            "train_data15324.zip  train_data24472.zip  train_data6179.zip\n",
            "train_data15325.zip  train_data24473.zip  train_data617.zip\n",
            "train_data15326.zip  train_data24474.zip  train_data6180.zip\n",
            "train_data15327.zip  train_data24475.zip  train_data6181.zip\n",
            "train_data15328.zip  train_data24476.zip  train_data6182.zip\n",
            "train_data15329.zip  train_data24477.zip  train_data6183.zip\n",
            "train_data1532.zip   train_data24478.zip  train_data6184.zip\n",
            "train_data15330.zip  train_data24479.zip  train_data6185.zip\n",
            "train_data15331.zip  train_data2447.zip   train_data6186.zip\n",
            "train_data15332.zip  train_data24480.zip  train_data6187.zip\n",
            "train_data15333.zip  train_data24481.zip  train_data6188.zip\n",
            "train_data15334.zip  train_data24482.zip  train_data6189.zip\n",
            "train_data15335.zip  train_data24483.zip  train_data618.zip\n",
            "train_data15336.zip  train_data24484.zip  train_data6190.zip\n",
            "train_data15337.zip  train_data24485.zip  train_data6191.zip\n",
            "train_data15338.zip  train_data24486.zip  train_data6192.zip\n",
            "train_data15339.zip  train_data24487.zip  train_data6193.zip\n",
            "train_data1533.zip   train_data24488.zip  train_data6194.zip\n",
            "train_data15340.zip  train_data24489.zip  train_data6195.zip\n",
            "train_data15341.zip  train_data2448.zip   train_data6196.zip\n",
            "train_data15342.zip  train_data24490.zip  train_data6197.zip\n",
            "train_data15343.zip  train_data24491.zip  train_data6198.zip\n",
            "train_data15344.zip  train_data24492.zip  train_data6199.zip\n",
            "train_data15345.zip  train_data24493.zip  train_data619.zip\n",
            "train_data15346.zip  train_data24494.zip  train_data61.zip\n",
            "train_data15347.zip  train_data24495.zip  train_data6200.zip\n",
            "train_data15348.zip  train_data24496.zip  train_data6201.zip\n",
            "train_data15349.zip  train_data24497.zip  train_data6202.zip\n",
            "train_data1534.zip   train_data24498.zip  train_data6203.zip\n",
            "train_data15350.zip  train_data24499.zip  train_data6204.zip\n",
            "train_data15351.zip  train_data2449.zip   train_data6205.zip\n",
            "train_data15352.zip  train_data244.zip\t  train_data6206.zip\n",
            "train_data15353.zip  train_data24500.zip  train_data6207.zip\n",
            "train_data15354.zip  train_data24501.zip  train_data6208.zip\n",
            "train_data15355.zip  train_data24502.zip  train_data6209.zip\n",
            "train_data15356.zip  train_data24503.zip  train_data620.zip\n",
            "train_data15357.zip  train_data24504.zip  train_data6210.zip\n",
            "train_data15358.zip  train_data24505.zip  train_data6211.zip\n",
            "train_data15359.zip  train_data24506.zip  train_data6212.zip\n",
            "train_data1535.zip   train_data24507.zip  train_data6213.zip\n",
            "train_data15360.zip  train_data24508.zip  train_data6214.zip\n",
            "train_data15361.zip  train_data24509.zip  train_data6215.zip\n",
            "train_data15362.zip  train_data2450.zip   train_data6216.zip\n",
            "train_data15363.zip  train_data24510.zip  train_data6217.zip\n",
            "train_data15364.zip  train_data24511.zip  train_data6218.zip\n",
            "train_data15365.zip  train_data24512.zip  train_data6219.zip\n",
            "train_data15366.zip  train_data24513.zip  train_data621.zip\n",
            "train_data15367.zip  train_data24514.zip  train_data6220.zip\n",
            "train_data15368.zip  train_data24515.zip  train_data6221.zip\n",
            "train_data15369.zip  train_data24516.zip  train_data6222.zip\n",
            "train_data1536.zip   train_data24517.zip  train_data6223.zip\n",
            "train_data15370.zip  train_data24518.zip  train_data6224.zip\n",
            "train_data15371.zip  train_data24519.zip  train_data6225.zip\n",
            "train_data15372.zip  train_data2451.zip   train_data6226.zip\n",
            "train_data15373.zip  train_data24520.zip  train_data6227.zip\n",
            "train_data15374.zip  train_data24521.zip  train_data6228.zip\n",
            "train_data15375.zip  train_data24522.zip  train_data6229.zip\n",
            "train_data15376.zip  train_data24523.zip  train_data622.zip\n",
            "train_data15377.zip  train_data24524.zip  train_data6230.zip\n",
            "train_data15378.zip  train_data24525.zip  train_data6231.zip\n",
            "train_data15379.zip  train_data24526.zip  train_data6232.zip\n",
            "train_data1537.zip   train_data24527.zip  train_data6233.zip\n",
            "train_data15380.zip  train_data24528.zip  train_data6234.zip\n",
            "train_data15381.zip  train_data24529.zip  train_data6235.zip\n",
            "train_data15382.zip  train_data2452.zip   train_data6236.zip\n",
            "train_data15383.zip  train_data24530.zip  train_data6237.zip\n",
            "train_data15384.zip  train_data24531.zip  train_data6238.zip\n",
            "train_data15385.zip  train_data24532.zip  train_data6239.zip\n",
            "train_data15386.zip  train_data24533.zip  train_data623.zip\n",
            "train_data15387.zip  train_data24534.zip  train_data6240.zip\n",
            "train_data15388.zip  train_data24535.zip  train_data6241.zip\n",
            "train_data15389.zip  train_data24536.zip  train_data6242.zip\n",
            "train_data1538.zip   train_data24537.zip  train_data6243.zip\n",
            "train_data15390.zip  train_data24538.zip  train_data6244.zip\n",
            "train_data15391.zip  train_data24539.zip  train_data6245.zip\n",
            "train_data15392.zip  train_data2453.zip   train_data6246.zip\n",
            "train_data15393.zip  train_data24540.zip  train_data6247.zip\n",
            "train_data15394.zip  train_data24541.zip  train_data6248.zip\n",
            "train_data15395.zip  train_data24542.zip  train_data6249.zip\n",
            "train_data15396.zip  train_data24543.zip  train_data624.zip\n",
            "train_data15397.zip  train_data24544.zip  train_data6250.zip\n",
            "train_data15398.zip  train_data24545.zip  train_data6251.zip\n",
            "train_data15399.zip  train_data24546.zip  train_data6252.zip\n",
            "train_data1539.zip   train_data24547.zip  train_data6253.zip\n",
            "train_data153.zip    train_data24548.zip  train_data6254.zip\n",
            "train_data15400.zip  train_data24549.zip  train_data6255.zip\n",
            "train_data15401.zip  train_data2454.zip   train_data6256.zip\n",
            "train_data15402.zip  train_data24550.zip  train_data6257.zip\n",
            "train_data15403.zip  train_data24551.zip  train_data6258.zip\n",
            "train_data15404.zip  train_data24552.zip  train_data6259.zip\n",
            "train_data15405.zip  train_data24553.zip  train_data625.zip\n",
            "train_data15406.zip  train_data24554.zip  train_data6260.zip\n",
            "train_data15407.zip  train_data24555.zip  train_data6261.zip\n",
            "train_data15408.zip  train_data24556.zip  train_data6262.zip\n",
            "train_data15409.zip  train_data24557.zip  train_data6263.zip\n",
            "train_data1540.zip   train_data24558.zip  train_data6264.zip\n",
            "train_data15410.zip  train_data24559.zip  train_data6265.zip\n",
            "train_data15411.zip  train_data2455.zip   train_data6266.zip\n",
            "train_data15412.zip  train_data24560.zip  train_data6267.zip\n",
            "train_data15413.zip  train_data24561.zip  train_data6268.zip\n",
            "train_data15414.zip  train_data24562.zip  train_data6269.zip\n",
            "train_data15415.zip  train_data24563.zip  train_data626.zip\n",
            "train_data15416.zip  train_data24564.zip  train_data6270.zip\n",
            "train_data15417.zip  train_data24565.zip  train_data6271.zip\n",
            "train_data15418.zip  train_data24566.zip  train_data6272.zip\n",
            "train_data15419.zip  train_data24567.zip  train_data6273.zip\n",
            "train_data1541.zip   train_data24568.zip  train_data6274.zip\n",
            "train_data15420.zip  train_data24569.zip  train_data6275.zip\n",
            "train_data15421.zip  train_data2456.zip   train_data6276.zip\n",
            "train_data15422.zip  train_data24570.zip  train_data6277.zip\n",
            "train_data15423.zip  train_data24571.zip  train_data6278.zip\n",
            "train_data15424.zip  train_data24572.zip  train_data6279.zip\n",
            "train_data15425.zip  train_data24573.zip  train_data627.zip\n",
            "train_data15426.zip  train_data24574.zip  train_data6280.zip\n",
            "train_data15427.zip  train_data24575.zip  train_data6281.zip\n",
            "train_data15428.zip  train_data24576.zip  train_data6282.zip\n",
            "train_data15429.zip  train_data24577.zip  train_data6283.zip\n",
            "train_data1542.zip   train_data24578.zip  train_data6284.zip\n",
            "train_data15430.zip  train_data24579.zip  train_data6285.zip\n",
            "train_data15431.zip  train_data2457.zip   train_data6286.zip\n",
            "train_data15432.zip  train_data24580.zip  train_data6287.zip\n",
            "train_data15433.zip  train_data24581.zip  train_data6288.zip\n",
            "train_data15434.zip  train_data24582.zip  train_data6289.zip\n",
            "train_data15435.zip  train_data24583.zip  train_data628.zip\n",
            "train_data15436.zip  train_data24584.zip  train_data6290.zip\n",
            "train_data15437.zip  train_data24585.zip  train_data6291.zip\n",
            "train_data15438.zip  train_data24586.zip  train_data6292.zip\n",
            "train_data15439.zip  train_data24587.zip  train_data6293.zip\n",
            "train_data1543.zip   train_data24588.zip  train_data6294.zip\n",
            "train_data15440.zip  train_data24589.zip  train_data6295.zip\n",
            "train_data15441.zip  train_data2458.zip   train_data6296.zip\n",
            "train_data15442.zip  train_data24590.zip  train_data6297.zip\n",
            "train_data15443.zip  train_data24591.zip  train_data6298.zip\n",
            "train_data15444.zip  train_data24592.zip  train_data6299.zip\n",
            "train_data15445.zip  train_data24593.zip  train_data629.zip\n",
            "train_data15446.zip  train_data24594.zip  train_data62.zip\n",
            "train_data15447.zip  train_data24595.zip  train_data6300.zip\n",
            "train_data15448.zip  train_data24596.zip  train_data6301.zip\n",
            "train_data15449.zip  train_data24597.zip  train_data6302.zip\n",
            "train_data1544.zip   train_data24598.zip  train_data6303.zip\n",
            "train_data15450.zip  train_data24599.zip  train_data6304.zip\n",
            "train_data15451.zip  train_data2459.zip   train_data6305.zip\n",
            "train_data15452.zip  train_data245.zip\t  train_data6306.zip\n",
            "train_data15453.zip  train_data24600.zip  train_data6307.zip\n",
            "train_data15454.zip  train_data24601.zip  train_data6308.zip\n",
            "train_data15455.zip  train_data24602.zip  train_data6309.zip\n",
            "train_data15456.zip  train_data24603.zip  train_data630.zip\n",
            "train_data15457.zip  train_data24604.zip  train_data6310.zip\n",
            "train_data15458.zip  train_data24605.zip  train_data6311.zip\n",
            "train_data15459.zip  train_data24606.zip  train_data6312.zip\n",
            "train_data1545.zip   train_data24607.zip  train_data6313.zip\n",
            "train_data15460.zip  train_data24608.zip  train_data6314.zip\n",
            "train_data15461.zip  train_data24609.zip  train_data6315.zip\n",
            "train_data15462.zip  train_data2460.zip   train_data6316.zip\n",
            "train_data15463.zip  train_data24610.zip  train_data6317.zip\n",
            "train_data15464.zip  train_data24611.zip  train_data6318.zip\n",
            "train_data15465.zip  train_data24612.zip  train_data6319.zip\n",
            "train_data15466.zip  train_data24613.zip  train_data631.zip\n",
            "train_data15467.zip  train_data24614.zip  train_data6320.zip\n",
            "train_data15468.zip  train_data24615.zip  train_data6321.zip\n",
            "train_data15469.zip  train_data24616.zip  train_data6322.zip\n",
            "train_data1546.zip   train_data24617.zip  train_data6323.zip\n",
            "train_data15470.zip  train_data24618.zip  train_data6324.zip\n",
            "train_data15471.zip  train_data24619.zip  train_data6325.zip\n",
            "train_data15472.zip  train_data2461.zip   train_data6326.zip\n",
            "train_data15473.zip  train_data24620.zip  train_data6327.zip\n",
            "train_data15474.zip  train_data24621.zip  train_data6328.zip\n",
            "train_data15475.zip  train_data24622.zip  train_data6329.zip\n",
            "train_data15476.zip  train_data24623.zip  train_data632.zip\n",
            "train_data15477.zip  train_data24624.zip  train_data6330.zip\n",
            "train_data15478.zip  train_data24625.zip  train_data6331.zip\n",
            "train_data15479.zip  train_data24626.zip  train_data6332.zip\n",
            "train_data1547.zip   train_data24627.zip  train_data6333.zip\n",
            "train_data15480.zip  train_data24628.zip  train_data6334.zip\n",
            "train_data15481.zip  train_data24629.zip  train_data6335.zip\n",
            "train_data15482.zip  train_data2462.zip   train_data6336.zip\n",
            "train_data15483.zip  train_data24630.zip  train_data6337.zip\n",
            "train_data15484.zip  train_data24631.zip  train_data6338.zip\n",
            "train_data15485.zip  train_data24632.zip  train_data6339.zip\n",
            "train_data15486.zip  train_data24633.zip  train_data633.zip\n",
            "train_data15487.zip  train_data24634.zip  train_data6340.zip\n",
            "train_data15488.zip  train_data24635.zip  train_data6341.zip\n",
            "train_data15489.zip  train_data24636.zip  train_data6342.zip\n",
            "train_data1548.zip   train_data24637.zip  train_data6343.zip\n",
            "train_data15490.zip  train_data24638.zip  train_data6344.zip\n",
            "train_data15491.zip  train_data24639.zip  train_data6345.zip\n",
            "train_data15492.zip  train_data2463.zip   train_data6346.zip\n",
            "train_data15493.zip  train_data24640.zip  train_data6347.zip\n",
            "train_data15494.zip  train_data24641.zip  train_data6348.zip\n",
            "train_data15495.zip  train_data24642.zip  train_data6349.zip\n",
            "train_data15496.zip  train_data24643.zip  train_data634.zip\n",
            "train_data15497.zip  train_data24644.zip  train_data6350.zip\n",
            "train_data15498.zip  train_data24645.zip  train_data6351.zip\n",
            "train_data15499.zip  train_data24646.zip  train_data6352.zip\n",
            "train_data1549.zip   train_data24647.zip  train_data6353.zip\n",
            "train_data154.zip    train_data24648.zip  train_data6354.zip\n",
            "train_data15500.zip  train_data24649.zip  train_data6355.zip\n",
            "train_data15501.zip  train_data2464.zip   train_data6356.zip\n",
            "train_data15502.zip  train_data24650.zip  train_data6357.zip\n",
            "train_data15503.zip  train_data24651.zip  train_data6358.zip\n",
            "train_data15504.zip  train_data24652.zip  train_data6359.zip\n",
            "train_data15505.zip  train_data24653.zip  train_data635.zip\n",
            "train_data15506.zip  train_data24654.zip  train_data6360.zip\n",
            "train_data15507.zip  train_data24655.zip  train_data6361.zip\n",
            "train_data15508.zip  train_data24656.zip  train_data6362.zip\n",
            "train_data15509.zip  train_data24657.zip  train_data6363.zip\n",
            "train_data1550.zip   train_data24658.zip  train_data6364.zip\n",
            "train_data15510.zip  train_data24659.zip  train_data6365.zip\n",
            "train_data15511.zip  train_data2465.zip   train_data6366.zip\n",
            "train_data15512.zip  train_data24660.zip  train_data6367.zip\n",
            "train_data15513.zip  train_data24661.zip  train_data6368.zip\n",
            "train_data15514.zip  train_data24662.zip  train_data6369.zip\n",
            "train_data15515.zip  train_data24663.zip  train_data636.zip\n",
            "train_data15516.zip  train_data24664.zip  train_data6370.zip\n",
            "train_data15517.zip  train_data24665.zip  train_data6371.zip\n",
            "train_data15518.zip  train_data24666.zip  train_data6372.zip\n",
            "train_data15519.zip  train_data24667.zip  train_data6373.zip\n",
            "train_data1551.zip   train_data24668.zip  train_data6374.zip\n",
            "train_data15520.zip  train_data24669.zip  train_data6375.zip\n",
            "train_data15521.zip  train_data2466.zip   train_data6376.zip\n",
            "train_data15522.zip  train_data24670.zip  train_data6377.zip\n",
            "train_data15523.zip  train_data24671.zip  train_data6378.zip\n",
            "train_data15524.zip  train_data24672.zip  train_data6379.zip\n",
            "train_data15525.zip  train_data24673.zip  train_data637.zip\n",
            "train_data15526.zip  train_data24674.zip  train_data6380.zip\n",
            "train_data15527.zip  train_data24675.zip  train_data6381.zip\n",
            "train_data15528.zip  train_data24676.zip  train_data6382.zip\n",
            "train_data15529.zip  train_data24677.zip  train_data6383.zip\n",
            "train_data1552.zip   train_data24678.zip  train_data6384.zip\n",
            "train_data15530.zip  train_data24679.zip  train_data6385.zip\n",
            "train_data15531.zip  train_data2467.zip   train_data6386.zip\n",
            "train_data15532.zip  train_data24680.zip  train_data6387.zip\n",
            "train_data15533.zip  train_data24681.zip  train_data6388.zip\n",
            "train_data15534.zip  train_data24682.zip  train_data6389.zip\n",
            "train_data15535.zip  train_data24683.zip  train_data638.zip\n",
            "train_data15536.zip  train_data24684.zip  train_data6390.zip\n",
            "train_data15537.zip  train_data24685.zip  train_data6391.zip\n",
            "train_data15538.zip  train_data24686.zip  train_data6392.zip\n",
            "train_data15539.zip  train_data24687.zip  train_data6393.zip\n",
            "train_data1553.zip   train_data24688.zip  train_data6394.zip\n",
            "train_data15540.zip  train_data24689.zip  train_data6395.zip\n",
            "train_data15541.zip  train_data2468.zip   train_data6396.zip\n",
            "train_data15542.zip  train_data24690.zip  train_data6397.zip\n",
            "train_data15543.zip  train_data24691.zip  train_data6398.zip\n",
            "train_data15544.zip  train_data24692.zip  train_data6399.zip\n",
            "train_data15545.zip  train_data24693.zip  train_data639.zip\n",
            "train_data15546.zip  train_data24694.zip  train_data63.zip\n",
            "train_data15547.zip  train_data24695.zip  train_data6400.zip\n",
            "train_data15548.zip  train_data24696.zip  train_data6401.zip\n",
            "train_data15549.zip  train_data24697.zip  train_data6402.zip\n",
            "train_data1554.zip   train_data24698.zip  train_data6403.zip\n",
            "train_data15550.zip  train_data24699.zip  train_data6404.zip\n",
            "train_data15551.zip  train_data2469.zip   train_data6405.zip\n",
            "train_data15552.zip  train_data246.zip\t  train_data6406.zip\n",
            "train_data15553.zip  train_data24700.zip  train_data6407.zip\n",
            "train_data15554.zip  train_data24701.zip  train_data6408.zip\n",
            "train_data15555.zip  train_data24702.zip  train_data6409.zip\n",
            "train_data15556.zip  train_data24703.zip  train_data640.zip\n",
            "train_data15557.zip  train_data24704.zip  train_data6410.zip\n",
            "train_data15558.zip  train_data24705.zip  train_data6411.zip\n",
            "train_data15559.zip  train_data24706.zip  train_data6412.zip\n",
            "train_data1555.zip   train_data24707.zip  train_data6413.zip\n",
            "train_data15560.zip  train_data24708.zip  train_data6414.zip\n",
            "train_data15561.zip  train_data24709.zip  train_data6415.zip\n",
            "train_data15562.zip  train_data2470.zip   train_data6416.zip\n",
            "train_data15563.zip  train_data24710.zip  train_data6417.zip\n",
            "train_data15564.zip  train_data24711.zip  train_data6418.zip\n",
            "train_data15565.zip  train_data24712.zip  train_data6419.zip\n",
            "train_data15566.zip  train_data24713.zip  train_data641.zip\n",
            "train_data15567.zip  train_data24714.zip  train_data6420.zip\n",
            "train_data15568.zip  train_data24715.zip  train_data6421.zip\n",
            "train_data15569.zip  train_data24716.zip  train_data6422.zip\n",
            "train_data1556.zip   train_data24717.zip  train_data6423.zip\n",
            "train_data15570.zip  train_data24718.zip  train_data6424.zip\n",
            "train_data15571.zip  train_data24719.zip  train_data6425.zip\n",
            "train_data15572.zip  train_data2471.zip   train_data6426.zip\n",
            "train_data15573.zip  train_data24720.zip  train_data6427.zip\n",
            "train_data15574.zip  train_data24721.zip  train_data6428.zip\n",
            "train_data15575.zip  train_data24722.zip  train_data6429.zip\n",
            "train_data15576.zip  train_data24723.zip  train_data642.zip\n",
            "train_data15577.zip  train_data24724.zip  train_data6430.zip\n",
            "train_data15578.zip  train_data24725.zip  train_data6431.zip\n",
            "train_data15579.zip  train_data24726.zip  train_data6432.zip\n",
            "train_data1557.zip   train_data24727.zip  train_data6433.zip\n",
            "train_data15580.zip  train_data24728.zip  train_data6434.zip\n",
            "train_data15581.zip  train_data24729.zip  train_data6435.zip\n",
            "train_data15582.zip  train_data2472.zip   train_data6436.zip\n",
            "train_data15583.zip  train_data24730.zip  train_data6437.zip\n",
            "train_data15584.zip  train_data24731.zip  train_data6438.zip\n",
            "train_data15585.zip  train_data24732.zip  train_data6439.zip\n",
            "train_data15586.zip  train_data24733.zip  train_data643.zip\n",
            "train_data15587.zip  train_data24734.zip  train_data6440.zip\n",
            "train_data15588.zip  train_data24735.zip  train_data6441.zip\n",
            "train_data15589.zip  train_data24736.zip  train_data6442.zip\n",
            "train_data1558.zip   train_data24737.zip  train_data6443.zip\n",
            "train_data15590.zip  train_data24738.zip  train_data6444.zip\n",
            "train_data15591.zip  train_data24739.zip  train_data6445.zip\n",
            "train_data15592.zip  train_data2473.zip   train_data6446.zip\n",
            "train_data15593.zip  train_data24740.zip  train_data6447.zip\n",
            "train_data15594.zip  train_data24741.zip  train_data6448.zip\n",
            "train_data15595.zip  train_data24742.zip  train_data6449.zip\n",
            "train_data15596.zip  train_data24743.zip  train_data644.zip\n",
            "train_data15597.zip  train_data24744.zip  train_data6450.zip\n",
            "train_data15598.zip  train_data24745.zip  train_data6451.zip\n",
            "train_data15599.zip  train_data24746.zip  train_data6452.zip\n",
            "train_data1559.zip   train_data24747.zip  train_data6453.zip\n",
            "train_data155.zip    train_data24748.zip  train_data6454.zip\n",
            "train_data15600.zip  train_data24749.zip  train_data6455.zip\n",
            "train_data15601.zip  train_data2474.zip   train_data6456.zip\n",
            "train_data15602.zip  train_data24750.zip  train_data6457.zip\n",
            "train_data15603.zip  train_data24751.zip  train_data6458.zip\n",
            "train_data15604.zip  train_data24752.zip  train_data6459.zip\n",
            "train_data15605.zip  train_data24753.zip  train_data645.zip\n",
            "train_data15606.zip  train_data24754.zip  train_data6460.zip\n",
            "train_data15607.zip  train_data24755.zip  train_data6461.zip\n",
            "train_data15608.zip  train_data24756.zip  train_data6462.zip\n",
            "train_data15609.zip  train_data24757.zip  train_data6463.zip\n",
            "train_data1560.zip   train_data24758.zip  train_data6464.zip\n",
            "train_data15610.zip  train_data24759.zip  train_data6465.zip\n",
            "train_data15611.zip  train_data2475.zip   train_data6466.zip\n",
            "train_data15612.zip  train_data24760.zip  train_data6467.zip\n",
            "train_data15613.zip  train_data24761.zip  train_data6468.zip\n",
            "train_data15614.zip  train_data24762.zip  train_data6469.zip\n",
            "train_data15615.zip  train_data24763.zip  train_data646.zip\n",
            "train_data15616.zip  train_data24764.zip  train_data6470.zip\n",
            "train_data15617.zip  train_data24765.zip  train_data6471.zip\n",
            "train_data15618.zip  train_data24766.zip  train_data6472.zip\n",
            "train_data15619.zip  train_data24767.zip  train_data6473.zip\n",
            "train_data1561.zip   train_data24768.zip  train_data6474.zip\n",
            "train_data15620.zip  train_data24769.zip  train_data6475.zip\n",
            "train_data15621.zip  train_data2476.zip   train_data6476.zip\n",
            "train_data15622.zip  train_data24770.zip  train_data6477.zip\n",
            "train_data15623.zip  train_data24771.zip  train_data6478.zip\n",
            "train_data15624.zip  train_data24772.zip  train_data6479.zip\n",
            "train_data15625.zip  train_data24773.zip  train_data647.zip\n",
            "train_data15626.zip  train_data24774.zip  train_data6480.zip\n",
            "train_data15627.zip  train_data24775.zip  train_data6481.zip\n",
            "train_data15628.zip  train_data24776.zip  train_data6482.zip\n",
            "train_data15629.zip  train_data24777.zip  train_data6483.zip\n",
            "train_data1562.zip   train_data24778.zip  train_data6484.zip\n",
            "train_data15630.zip  train_data24779.zip  train_data6485.zip\n",
            "train_data15631.zip  train_data2477.zip   train_data6486.zip\n",
            "train_data15632.zip  train_data24780.zip  train_data6487.zip\n",
            "train_data15633.zip  train_data24781.zip  train_data6488.zip\n",
            "train_data15634.zip  train_data24782.zip  train_data6489.zip\n",
            "train_data15635.zip  train_data24783.zip  train_data648.zip\n",
            "train_data15636.zip  train_data24784.zip  train_data6490.zip\n",
            "train_data15637.zip  train_data24785.zip  train_data6491.zip\n",
            "train_data15638.zip  train_data24786.zip  train_data6492.zip\n",
            "train_data15639.zip  train_data24787.zip  train_data6493.zip\n",
            "train_data1563.zip   train_data24788.zip  train_data6494.zip\n",
            "train_data15640.zip  train_data24789.zip  train_data6495.zip\n",
            "train_data15641.zip  train_data2478.zip   train_data6496.zip\n",
            "train_data15642.zip  train_data24790.zip  train_data6497.zip\n",
            "train_data15643.zip  train_data24791.zip  train_data6498.zip\n",
            "train_data15644.zip  train_data24792.zip  train_data6499.zip\n",
            "train_data15645.zip  train_data24793.zip  train_data649.zip\n",
            "train_data15646.zip  train_data24794.zip  train_data64.zip\n",
            "train_data15647.zip  train_data24795.zip  train_data6500.zip\n",
            "train_data15648.zip  train_data24796.zip  train_data6501.zip\n",
            "train_data15649.zip  train_data24797.zip  train_data6502.zip\n",
            "train_data1564.zip   train_data24798.zip  train_data6503.zip\n",
            "train_data15650.zip  train_data24799.zip  train_data6504.zip\n",
            "train_data15651.zip  train_data2479.zip   train_data6505.zip\n",
            "train_data15652.zip  train_data247.zip\t  train_data6506.zip\n",
            "train_data15653.zip  train_data24800.zip  train_data6507.zip\n",
            "train_data15654.zip  train_data24801.zip  train_data6508.zip\n",
            "train_data15655.zip  train_data24802.zip  train_data6509.zip\n",
            "train_data15656.zip  train_data24803.zip  train_data650.zip\n",
            "train_data15657.zip  train_data24804.zip  train_data6510.zip\n",
            "train_data15658.zip  train_data24805.zip  train_data6511.zip\n",
            "train_data15659.zip  train_data24806.zip  train_data6512.zip\n",
            "train_data1565.zip   train_data24807.zip  train_data6513.zip\n",
            "train_data15660.zip  train_data24808.zip  train_data6514.zip\n",
            "train_data15661.zip  train_data24809.zip  train_data6515.zip\n",
            "train_data15662.zip  train_data2480.zip   train_data6516.zip\n",
            "train_data15663.zip  train_data24810.zip  train_data6517.zip\n",
            "train_data15664.zip  train_data24811.zip  train_data6518.zip\n",
            "train_data15665.zip  train_data24812.zip  train_data6519.zip\n",
            "train_data15666.zip  train_data24813.zip  train_data651.zip\n",
            "train_data15667.zip  train_data24814.zip  train_data6520.zip\n",
            "train_data15668.zip  train_data24815.zip  train_data6521.zip\n",
            "train_data15669.zip  train_data24816.zip  train_data6522.zip\n",
            "train_data1566.zip   train_data24817.zip  train_data6523.zip\n",
            "train_data15670.zip  train_data24818.zip  train_data6524.zip\n",
            "train_data15671.zip  train_data24819.zip  train_data6525.zip\n",
            "train_data15672.zip  train_data2481.zip   train_data6526.zip\n",
            "train_data15673.zip  train_data24820.zip  train_data6527.zip\n",
            "train_data15674.zip  train_data24821.zip  train_data6528.zip\n",
            "train_data15675.zip  train_data24822.zip  train_data6529.zip\n",
            "train_data15676.zip  train_data24823.zip  train_data652.zip\n",
            "train_data15677.zip  train_data24824.zip  train_data6530.zip\n",
            "train_data15678.zip  train_data24825.zip  train_data6531.zip\n",
            "train_data15679.zip  train_data24826.zip  train_data6532.zip\n",
            "train_data1567.zip   train_data24827.zip  train_data6533.zip\n",
            "train_data15680.zip  train_data24828.zip  train_data6534.zip\n",
            "train_data15681.zip  train_data24829.zip  train_data6535.zip\n",
            "train_data15682.zip  train_data2482.zip   train_data6536.zip\n",
            "train_data15683.zip  train_data24830.zip  train_data6537.zip\n",
            "train_data15684.zip  train_data24831.zip  train_data6538.zip\n",
            "train_data15685.zip  train_data24832.zip  train_data6539.zip\n",
            "train_data15686.zip  train_data24833.zip  train_data653.zip\n",
            "train_data15687.zip  train_data24834.zip  train_data6540.zip\n",
            "train_data15688.zip  train_data24835.zip  train_data6541.zip\n",
            "train_data15689.zip  train_data24836.zip  train_data6542.zip\n",
            "train_data1568.zip   train_data24837.zip  train_data6543.zip\n",
            "train_data15690.zip  train_data24838.zip  train_data6544.zip\n",
            "train_data15691.zip  train_data24839.zip  train_data6545.zip\n",
            "train_data15692.zip  train_data2483.zip   train_data6546.zip\n",
            "train_data15693.zip  train_data24840.zip  train_data6547.zip\n",
            "train_data15694.zip  train_data24841.zip  train_data6548.zip\n",
            "train_data15695.zip  train_data24842.zip  train_data6549.zip\n",
            "train_data15696.zip  train_data24843.zip  train_data654.zip\n",
            "train_data15697.zip  train_data24844.zip  train_data6550.zip\n",
            "train_data15698.zip  train_data24845.zip  train_data6551.zip\n",
            "train_data15699.zip  train_data24846.zip  train_data6552.zip\n",
            "train_data1569.zip   train_data24847.zip  train_data6553.zip\n",
            "train_data156.zip    train_data24848.zip  train_data6554.zip\n",
            "train_data15700.zip  train_data24849.zip  train_data6555.zip\n",
            "train_data15701.zip  train_data2484.zip   train_data6556.zip\n",
            "train_data15702.zip  train_data24850.zip  train_data6557.zip\n",
            "train_data15703.zip  train_data24851.zip  train_data6558.zip\n",
            "train_data15704.zip  train_data24852.zip  train_data6559.zip\n",
            "train_data15705.zip  train_data24853.zip  train_data655.zip\n",
            "train_data15706.zip  train_data24854.zip  train_data6560.zip\n",
            "train_data15707.zip  train_data24855.zip  train_data6561.zip\n",
            "train_data15708.zip  train_data24856.zip  train_data6562.zip\n",
            "train_data15709.zip  train_data24857.zip  train_data6563.zip\n",
            "train_data1570.zip   train_data24858.zip  train_data6564.zip\n",
            "train_data15710.zip  train_data24859.zip  train_data6565.zip\n",
            "train_data15711.zip  train_data2485.zip   train_data6566.zip\n",
            "train_data15712.zip  train_data24860.zip  train_data6567.zip\n",
            "train_data15713.zip  train_data24861.zip  train_data6568.zip\n",
            "train_data15714.zip  train_data24862.zip  train_data6569.zip\n",
            "train_data15715.zip  train_data24863.zip  train_data656.zip\n",
            "train_data15716.zip  train_data24864.zip  train_data6570.zip\n",
            "train_data15717.zip  train_data24865.zip  train_data6571.zip\n",
            "train_data15718.zip  train_data24866.zip  train_data6572.zip\n",
            "train_data15719.zip  train_data24867.zip  train_data6573.zip\n",
            "train_data1571.zip   train_data24868.zip  train_data6574.zip\n",
            "train_data15720.zip  train_data24869.zip  train_data6575.zip\n",
            "train_data15721.zip  train_data2486.zip   train_data6576.zip\n",
            "train_data15722.zip  train_data24870.zip  train_data6577.zip\n",
            "train_data15723.zip  train_data24871.zip  train_data6578.zip\n",
            "train_data15724.zip  train_data24872.zip  train_data6579.zip\n",
            "train_data15725.zip  train_data24873.zip  train_data657.zip\n",
            "train_data15726.zip  train_data24874.zip  train_data6580.zip\n",
            "train_data15727.zip  train_data24875.zip  train_data6581.zip\n",
            "train_data15728.zip  train_data24876.zip  train_data6582.zip\n",
            "train_data15729.zip  train_data24877.zip  train_data6583.zip\n",
            "train_data1572.zip   train_data24878.zip  train_data6584.zip\n",
            "train_data15730.zip  train_data24879.zip  train_data6585.zip\n",
            "train_data15731.zip  train_data2487.zip   train_data6586.zip\n",
            "train_data15732.zip  train_data24880.zip  train_data6587.zip\n",
            "train_data15733.zip  train_data24881.zip  train_data6588.zip\n",
            "train_data15734.zip  train_data24882.zip  train_data6589.zip\n",
            "train_data15735.zip  train_data24883.zip  train_data658.zip\n",
            "train_data15736.zip  train_data24884.zip  train_data6590.zip\n",
            "train_data15737.zip  train_data24885.zip  train_data6591.zip\n",
            "train_data15738.zip  train_data24886.zip  train_data6592.zip\n",
            "train_data15739.zip  train_data24887.zip  train_data6593.zip\n",
            "train_data1573.zip   train_data24888.zip  train_data6594.zip\n",
            "train_data15740.zip  train_data24889.zip  train_data6595.zip\n",
            "train_data15741.zip  train_data2488.zip   train_data6596.zip\n",
            "train_data15742.zip  train_data24890.zip  train_data6597.zip\n",
            "train_data15743.zip  train_data24891.zip  train_data6598.zip\n",
            "train_data15744.zip  train_data24892.zip  train_data6599.zip\n",
            "train_data15745.zip  train_data24893.zip  train_data659.zip\n",
            "train_data15746.zip  train_data24894.zip  train_data65.zip\n",
            "train_data15747.zip  train_data24895.zip  train_data6600.zip\n",
            "train_data15748.zip  train_data24896.zip  train_data6601.zip\n",
            "train_data15749.zip  train_data24897.zip  train_data6602.zip\n",
            "train_data1574.zip   train_data24898.zip  train_data6603.zip\n",
            "train_data15750.zip  train_data24899.zip  train_data6604.zip\n",
            "train_data15751.zip  train_data2489.zip   train_data6605.zip\n",
            "train_data15752.zip  train_data248.zip\t  train_data6606.zip\n",
            "train_data15753.zip  train_data24900.zip  train_data6607.zip\n",
            "train_data15754.zip  train_data24901.zip  train_data6608.zip\n",
            "train_data15755.zip  train_data24902.zip  train_data6609.zip\n",
            "train_data15756.zip  train_data24903.zip  train_data660.zip\n",
            "train_data15757.zip  train_data24904.zip  train_data6610.zip\n",
            "train_data15758.zip  train_data24905.zip  train_data6611.zip\n",
            "train_data15759.zip  train_data24906.zip  train_data6612.zip\n",
            "train_data1575.zip   train_data24907.zip  train_data6613.zip\n",
            "train_data15760.zip  train_data24908.zip  train_data6614.zip\n",
            "train_data15761.zip  train_data24909.zip  train_data6615.zip\n",
            "train_data15762.zip  train_data2490.zip   train_data6616.zip\n",
            "train_data15763.zip  train_data24910.zip  train_data6617.zip\n",
            "train_data15764.zip  train_data24911.zip  train_data6618.zip\n",
            "train_data15765.zip  train_data24912.zip  train_data6619.zip\n",
            "train_data15766.zip  train_data24913.zip  train_data661.zip\n",
            "train_data15767.zip  train_data24914.zip  train_data6620.zip\n",
            "train_data15768.zip  train_data24915.zip  train_data6621.zip\n",
            "train_data15769.zip  train_data24916.zip  train_data6622.zip\n",
            "train_data1576.zip   train_data24917.zip  train_data6623.zip\n",
            "train_data15770.zip  train_data24918.zip  train_data6624.zip\n",
            "train_data15771.zip  train_data24919.zip  train_data6625.zip\n",
            "train_data15772.zip  train_data2491.zip   train_data6626.zip\n",
            "train_data15773.zip  train_data24920.zip  train_data6627.zip\n",
            "train_data15774.zip  train_data24921.zip  train_data6628.zip\n",
            "train_data15775.zip  train_data24922.zip  train_data6629.zip\n",
            "train_data15776.zip  train_data24923.zip  train_data662.zip\n",
            "train_data15777.zip  train_data24924.zip  train_data6630.zip\n",
            "train_data15778.zip  train_data24925.zip  train_data6631.zip\n",
            "train_data15779.zip  train_data24926.zip  train_data6632.zip\n",
            "train_data1577.zip   train_data24927.zip  train_data6633.zip\n",
            "train_data15780.zip  train_data24928.zip  train_data6634.zip\n",
            "train_data15781.zip  train_data24929.zip  train_data6635.zip\n",
            "train_data15782.zip  train_data2492.zip   train_data6636.zip\n",
            "train_data15783.zip  train_data24930.zip  train_data6637.zip\n",
            "train_data15784.zip  train_data24931.zip  train_data6638.zip\n",
            "train_data15785.zip  train_data24932.zip  train_data6639.zip\n",
            "train_data15786.zip  train_data24933.zip  train_data663.zip\n",
            "train_data15787.zip  train_data24934.zip  train_data6640.zip\n",
            "train_data15788.zip  train_data24935.zip  train_data6641.zip\n",
            "train_data15789.zip  train_data24936.zip  train_data6642.zip\n",
            "train_data1578.zip   train_data24937.zip  train_data6643.zip\n",
            "train_data15790.zip  train_data24938.zip  train_data6644.zip\n",
            "train_data15791.zip  train_data24939.zip  train_data6645.zip\n",
            "train_data15792.zip  train_data2493.zip   train_data6646.zip\n",
            "train_data15793.zip  train_data24940.zip  train_data6647.zip\n",
            "train_data15794.zip  train_data24941.zip  train_data6648.zip\n",
            "train_data15795.zip  train_data24942.zip  train_data6649.zip\n",
            "train_data15796.zip  train_data24943.zip  train_data664.zip\n",
            "train_data15797.zip  train_data24944.zip  train_data6650.zip\n",
            "train_data15798.zip  train_data24945.zip  train_data6651.zip\n",
            "train_data15799.zip  train_data24946.zip  train_data6652.zip\n",
            "train_data1579.zip   train_data24947.zip  train_data6653.zip\n",
            "train_data157.zip    train_data24948.zip  train_data6654.zip\n",
            "train_data15800.zip  train_data24949.zip  train_data6655.zip\n",
            "train_data15801.zip  train_data2494.zip   train_data6656.zip\n",
            "train_data15802.zip  train_data24950.zip  train_data6657.zip\n",
            "train_data15803.zip  train_data24951.zip  train_data6658.zip\n",
            "train_data15804.zip  train_data24952.zip  train_data6659.zip\n",
            "train_data15805.zip  train_data24953.zip  train_data665.zip\n",
            "train_data15806.zip  train_data24954.zip  train_data6660.zip\n",
            "train_data15807.zip  train_data24955.zip  train_data6661.zip\n",
            "train_data15808.zip  train_data24956.zip  train_data6662.zip\n",
            "train_data15809.zip  train_data24957.zip  train_data6663.zip\n",
            "train_data1580.zip   train_data24958.zip  train_data6664.zip\n",
            "train_data15810.zip  train_data24959.zip  train_data6665.zip\n",
            "train_data15811.zip  train_data2495.zip   train_data6666.zip\n",
            "train_data15812.zip  train_data24960.zip  train_data6667.zip\n",
            "train_data15813.zip  train_data24961.zip  train_data6668.zip\n",
            "train_data15814.zip  train_data24962.zip  train_data6669.zip\n",
            "train_data15815.zip  train_data24963.zip  train_data666.zip\n",
            "train_data15816.zip  train_data24964.zip  train_data6670.zip\n",
            "train_data15817.zip  train_data24965.zip  train_data6671.zip\n",
            "train_data15818.zip  train_data24966.zip  train_data6672.zip\n",
            "train_data15819.zip  train_data24967.zip  train_data6673.zip\n",
            "train_data1581.zip   train_data24968.zip  train_data6674.zip\n",
            "train_data15820.zip  train_data24969.zip  train_data6675.zip\n",
            "train_data15821.zip  train_data2496.zip   train_data6676.zip\n",
            "train_data15822.zip  train_data24970.zip  train_data6677.zip\n",
            "train_data15823.zip  train_data24971.zip  train_data6678.zip\n",
            "train_data15824.zip  train_data24972.zip  train_data6679.zip\n",
            "train_data15825.zip  train_data24973.zip  train_data667.zip\n",
            "train_data15826.zip  train_data24974.zip  train_data6680.zip\n",
            "train_data15827.zip  train_data24975.zip  train_data6681.zip\n",
            "train_data15828.zip  train_data24976.zip  train_data6682.zip\n",
            "train_data15829.zip  train_data24977.zip  train_data6683.zip\n",
            "train_data1582.zip   train_data24978.zip  train_data6684.zip\n",
            "train_data15830.zip  train_data24979.zip  train_data6685.zip\n",
            "train_data15831.zip  train_data2497.zip   train_data6686.zip\n",
            "train_data15832.zip  train_data24980.zip  train_data6687.zip\n",
            "train_data15833.zip  train_data24981.zip  train_data6688.zip\n",
            "train_data15834.zip  train_data24982.zip  train_data6689.zip\n",
            "train_data15835.zip  train_data24983.zip  train_data668.zip\n",
            "train_data15836.zip  train_data24984.zip  train_data6690.zip\n",
            "train_data15837.zip  train_data24985.zip  train_data6691.zip\n",
            "train_data15838.zip  train_data24986.zip  train_data6692.zip\n",
            "train_data15839.zip  train_data24987.zip  train_data6693.zip\n",
            "train_data1583.zip   train_data24988.zip  train_data6694.zip\n",
            "train_data15840.zip  train_data24989.zip  train_data6695.zip\n",
            "train_data15841.zip  train_data2498.zip   train_data6696.zip\n",
            "train_data15842.zip  train_data24990.zip  train_data6697.zip\n",
            "train_data15843.zip  train_data24991.zip  train_data6698.zip\n",
            "train_data15844.zip  train_data24992.zip  train_data6699.zip\n",
            "train_data15845.zip  train_data24993.zip  train_data669.zip\n",
            "train_data15846.zip  train_data24994.zip  train_data66.zip\n",
            "train_data15847.zip  train_data24995.zip  train_data6700.zip\n",
            "train_data15848.zip  train_data24996.zip  train_data6701.zip\n",
            "train_data15849.zip  train_data24997.zip  train_data6702.zip\n",
            "train_data1584.zip   train_data24998.zip  train_data6703.zip\n",
            "train_data15850.zip  train_data24999.zip  train_data6704.zip\n",
            "train_data15851.zip  train_data2499.zip   train_data6705.zip\n",
            "train_data15852.zip  train_data249.zip\t  train_data6706.zip\n",
            "train_data15853.zip  train_data24.zip\t  train_data6707.zip\n",
            "train_data15854.zip  train_data25000.zip  train_data6708.zip\n",
            "train_data15855.zip  train_data25001.zip  train_data6709.zip\n",
            "train_data15856.zip  train_data25002.zip  train_data670.zip\n",
            "train_data15857.zip  train_data25003.zip  train_data6710.zip\n",
            "train_data15858.zip  train_data25004.zip  train_data6711.zip\n",
            "train_data15859.zip  train_data25005.zip  train_data6712.zip\n",
            "train_data1585.zip   train_data25006.zip  train_data6713.zip\n",
            "train_data15860.zip  train_data25007.zip  train_data6714.zip\n",
            "train_data15861.zip  train_data25008.zip  train_data6715.zip\n",
            "train_data15862.zip  train_data25009.zip  train_data6716.zip\n",
            "train_data15863.zip  train_data2500.zip   train_data6717.zip\n",
            "train_data15864.zip  train_data25010.zip  train_data6718.zip\n",
            "train_data15865.zip  train_data25011.zip  train_data6719.zip\n",
            "train_data15866.zip  train_data25012.zip  train_data671.zip\n",
            "train_data15867.zip  train_data25013.zip  train_data6720.zip\n",
            "train_data15868.zip  train_data25014.zip  train_data6721.zip\n",
            "train_data15869.zip  train_data25015.zip  train_data6722.zip\n",
            "train_data1586.zip   train_data25016.zip  train_data6723.zip\n",
            "train_data15870.zip  train_data25017.zip  train_data6724.zip\n",
            "train_data15871.zip  train_data25018.zip  train_data6725.zip\n",
            "train_data15872.zip  train_data25019.zip  train_data6726.zip\n",
            "train_data15873.zip  train_data2501.zip   train_data6727.zip\n",
            "train_data15874.zip  train_data25020.zip  train_data6728.zip\n",
            "train_data15875.zip  train_data25021.zip  train_data6729.zip\n",
            "train_data15876.zip  train_data25022.zip  train_data672.zip\n",
            "train_data15877.zip  train_data25023.zip  train_data6730.zip\n",
            "train_data15878.zip  train_data25024.zip  train_data6731.zip\n",
            "train_data15879.zip  train_data25025.zip  train_data6732.zip\n",
            "train_data1587.zip   train_data25026.zip  train_data6733.zip\n",
            "train_data15880.zip  train_data25027.zip  train_data6734.zip\n",
            "train_data15881.zip  train_data25028.zip  train_data6735.zip\n",
            "train_data15882.zip  train_data25029.zip  train_data6736.zip\n",
            "train_data15883.zip  train_data2502.zip   train_data6737.zip\n",
            "train_data15884.zip  train_data25030.zip  train_data6738.zip\n",
            "train_data15885.zip  train_data25031.zip  train_data6739.zip\n",
            "train_data15886.zip  train_data25032.zip  train_data673.zip\n",
            "train_data15887.zip  train_data25033.zip  train_data6740.zip\n",
            "train_data15888.zip  train_data25034.zip  train_data6741.zip\n",
            "train_data15889.zip  train_data25035.zip  train_data6742.zip\n",
            "train_data1588.zip   train_data25036.zip  train_data6743.zip\n",
            "train_data15890.zip  train_data25037.zip  train_data6744.zip\n",
            "train_data15891.zip  train_data25038.zip  train_data6745.zip\n",
            "train_data15892.zip  train_data25039.zip  train_data6746.zip\n",
            "train_data15893.zip  train_data2503.zip   train_data6747.zip\n",
            "train_data15894.zip  train_data25040.zip  train_data6748.zip\n",
            "train_data15895.zip  train_data25041.zip  train_data6749.zip\n",
            "train_data15896.zip  train_data25042.zip  train_data674.zip\n",
            "train_data15897.zip  train_data25043.zip  train_data6750.zip\n",
            "train_data15898.zip  train_data25044.zip  train_data6751.zip\n",
            "train_data15899.zip  train_data25045.zip  train_data6752.zip\n",
            "train_data1589.zip   train_data25046.zip  train_data6753.zip\n",
            "train_data158.zip    train_data25047.zip  train_data6754.zip\n",
            "train_data15900.zip  train_data25048.zip  train_data6755.zip\n",
            "train_data15901.zip  train_data25049.zip  train_data6756.zip\n",
            "train_data15902.zip  train_data2504.zip   train_data6757.zip\n",
            "train_data15903.zip  train_data25050.zip  train_data6758.zip\n",
            "train_data15904.zip  train_data25051.zip  train_data6759.zip\n",
            "train_data15905.zip  train_data25052.zip  train_data675.zip\n",
            "train_data15906.zip  train_data25053.zip  train_data6760.zip\n",
            "train_data15907.zip  train_data25054.zip  train_data6761.zip\n",
            "train_data15908.zip  train_data25055.zip  train_data6762.zip\n",
            "train_data15909.zip  train_data25056.zip  train_data6763.zip\n",
            "train_data1590.zip   train_data25057.zip  train_data6764.zip\n",
            "train_data15910.zip  train_data25058.zip  train_data6765.zip\n",
            "train_data15911.zip  train_data25059.zip  train_data6766.zip\n",
            "train_data15912.zip  train_data2505.zip   train_data6767.zip\n",
            "train_data15913.zip  train_data25060.zip  train_data6768.zip\n",
            "train_data15914.zip  train_data25061.zip  train_data6769.zip\n",
            "train_data15915.zip  train_data25062.zip  train_data676.zip\n",
            "train_data15916.zip  train_data25063.zip  train_data6770.zip\n",
            "train_data15917.zip  train_data25064.zip  train_data6771.zip\n",
            "train_data15918.zip  train_data25065.zip  train_data6772.zip\n",
            "train_data15919.zip  train_data25066.zip  train_data6773.zip\n",
            "train_data1591.zip   train_data25067.zip  train_data6774.zip\n",
            "train_data15920.zip  train_data25068.zip  train_data6775.zip\n",
            "train_data15921.zip  train_data25069.zip  train_data6776.zip\n",
            "train_data15922.zip  train_data2506.zip   train_data6777.zip\n",
            "train_data15923.zip  train_data25070.zip  train_data6778.zip\n",
            "train_data15924.zip  train_data25071.zip  train_data6779.zip\n",
            "train_data15925.zip  train_data25072.zip  train_data677.zip\n",
            "train_data15926.zip  train_data25073.zip  train_data6780.zip\n",
            "train_data15927.zip  train_data25074.zip  train_data6781.zip\n",
            "train_data15928.zip  train_data25075.zip  train_data6782.zip\n",
            "train_data15929.zip  train_data25076.zip  train_data6783.zip\n",
            "train_data1592.zip   train_data25077.zip  train_data6784.zip\n",
            "train_data15930.zip  train_data25078.zip  train_data6785.zip\n",
            "train_data15931.zip  train_data25079.zip  train_data6786.zip\n",
            "train_data15932.zip  train_data2507.zip   train_data6787.zip\n",
            "train_data15933.zip  train_data25080.zip  train_data6788.zip\n",
            "train_data15934.zip  train_data25081.zip  train_data6789.zip\n",
            "train_data15935.zip  train_data25082.zip  train_data678.zip\n",
            "train_data15936.zip  train_data25083.zip  train_data6790.zip\n",
            "train_data15937.zip  train_data25084.zip  train_data6791.zip\n",
            "train_data15938.zip  train_data25085.zip  train_data6792.zip\n",
            "train_data15939.zip  train_data25086.zip  train_data6793.zip\n",
            "train_data1593.zip   train_data25087.zip  train_data6794.zip\n",
            "train_data15940.zip  train_data25088.zip  train_data6795.zip\n",
            "train_data15941.zip  train_data25089.zip  train_data6796.zip\n",
            "train_data15942.zip  train_data2508.zip   train_data6797.zip\n",
            "train_data15943.zip  train_data25090.zip  train_data6798.zip\n",
            "train_data15944.zip  train_data25091.zip  train_data6799.zip\n",
            "train_data15945.zip  train_data25092.zip  train_data679.zip\n",
            "train_data15946.zip  train_data25093.zip  train_data67.zip\n",
            "train_data15947.zip  train_data25094.zip  train_data6800.zip\n",
            "train_data15948.zip  train_data25095.zip  train_data6801.zip\n",
            "train_data15949.zip  train_data25096.zip  train_data6802.zip\n",
            "train_data1594.zip   train_data25097.zip  train_data6803.zip\n",
            "train_data15950.zip  train_data25098.zip  train_data6804.zip\n",
            "train_data15951.zip  train_data25099.zip  train_data6805.zip\n",
            "train_data15952.zip  train_data2509.zip   train_data6806.zip\n",
            "train_data15953.zip  train_data250.zip\t  train_data6807.zip\n",
            "train_data15954.zip  train_data25100.zip  train_data6808.zip\n",
            "train_data15955.zip  train_data25101.zip  train_data6809.zip\n",
            "train_data15956.zip  train_data25102.zip  train_data680.zip\n",
            "train_data15957.zip  train_data25103.zip  train_data6810.zip\n",
            "train_data15958.zip  train_data25104.zip  train_data6811.zip\n",
            "train_data15959.zip  train_data25105.zip  train_data6812.zip\n",
            "train_data1595.zip   train_data25106.zip  train_data6813.zip\n",
            "train_data15960.zip  train_data25107.zip  train_data6814.zip\n",
            "train_data15961.zip  train_data25108.zip  train_data6815.zip\n",
            "train_data15962.zip  train_data25109.zip  train_data6816.zip\n",
            "train_data15963.zip  train_data2510.zip   train_data6817.zip\n",
            "train_data15964.zip  train_data25110.zip  train_data6818.zip\n",
            "train_data15965.zip  train_data25111.zip  train_data6819.zip\n",
            "train_data15966.zip  train_data25112.zip  train_data681.zip\n",
            "train_data15967.zip  train_data25113.zip  train_data6820.zip\n",
            "train_data15968.zip  train_data25114.zip  train_data6821.zip\n",
            "train_data15969.zip  train_data25115.zip  train_data6822.zip\n",
            "train_data1596.zip   train_data25116.zip  train_data6823.zip\n",
            "train_data15970.zip  train_data25117.zip  train_data6824.zip\n",
            "train_data15971.zip  train_data25118.zip  train_data6825.zip\n",
            "train_data15972.zip  train_data25119.zip  train_data6826.zip\n",
            "train_data15973.zip  train_data2511.zip   train_data6827.zip\n",
            "train_data15974.zip  train_data25120.zip  train_data6828.zip\n",
            "train_data15975.zip  train_data25121.zip  train_data6829.zip\n",
            "train_data15976.zip  train_data25122.zip  train_data682.zip\n",
            "train_data15977.zip  train_data25123.zip  train_data6830.zip\n",
            "train_data15978.zip  train_data25124.zip  train_data6831.zip\n",
            "train_data15979.zip  train_data25125.zip  train_data6832.zip\n",
            "train_data1597.zip   train_data25126.zip  train_data6833.zip\n",
            "train_data15980.zip  train_data25127.zip  train_data6834.zip\n",
            "train_data15981.zip  train_data25128.zip  train_data6835.zip\n",
            "train_data15982.zip  train_data25129.zip  train_data6836.zip\n",
            "train_data15983.zip  train_data2512.zip   train_data6837.zip\n",
            "train_data15984.zip  train_data25130.zip  train_data6838.zip\n",
            "train_data15985.zip  train_data25131.zip  train_data6839.zip\n",
            "train_data15986.zip  train_data25132.zip  train_data683.zip\n",
            "train_data15987.zip  train_data25133.zip  train_data6840.zip\n",
            "train_data15988.zip  train_data25134.zip  train_data6841.zip\n",
            "train_data15989.zip  train_data25135.zip  train_data6842.zip\n",
            "train_data1598.zip   train_data25136.zip  train_data6843.zip\n",
            "train_data15990.zip  train_data25137.zip  train_data6844.zip\n",
            "train_data15991.zip  train_data25138.zip  train_data6845.zip\n",
            "train_data15992.zip  train_data25139.zip  train_data6846.zip\n",
            "train_data15993.zip  train_data2513.zip   train_data6847.zip\n",
            "train_data15994.zip  train_data25140.zip  train_data6848.zip\n",
            "train_data15995.zip  train_data25141.zip  train_data6849.zip\n",
            "train_data15996.zip  train_data25142.zip  train_data684.zip\n",
            "train_data15997.zip  train_data25143.zip  train_data6850.zip\n",
            "train_data15998.zip  train_data25144.zip  train_data6851.zip\n",
            "train_data15999.zip  train_data25145.zip  train_data6852.zip\n",
            "train_data1599.zip   train_data25146.zip  train_data6853.zip\n",
            "train_data159.zip    train_data25147.zip  train_data6854.zip\n",
            "train_data15.zip     train_data25148.zip  train_data6855.zip\n",
            "train_data16000.zip  train_data25149.zip  train_data6856.zip\n",
            "train_data16001.zip  train_data2514.zip   train_data6857.zip\n",
            "train_data16002.zip  train_data25150.zip  train_data6858.zip\n",
            "train_data16003.zip  train_data25151.zip  train_data6859.zip\n",
            "train_data16004.zip  train_data25152.zip  train_data685.zip\n",
            "train_data16005.zip  train_data25153.zip  train_data6860.zip\n",
            "train_data16006.zip  train_data25154.zip  train_data6861.zip\n",
            "train_data16007.zip  train_data25155.zip  train_data6862.zip\n",
            "train_data16008.zip  train_data25156.zip  train_data6863.zip\n",
            "train_data16009.zip  train_data25157.zip  train_data6864.zip\n",
            "train_data1600.zip   train_data25158.zip  train_data6865.zip\n",
            "train_data16010.zip  train_data25159.zip  train_data6866.zip\n",
            "train_data16011.zip  train_data2515.zip   train_data6867.zip\n",
            "train_data16012.zip  train_data25160.zip  train_data6868.zip\n",
            "train_data16013.zip  train_data25161.zip  train_data6869.zip\n",
            "train_data16014.zip  train_data25162.zip  train_data686.zip\n",
            "train_data16015.zip  train_data25163.zip  train_data6870.zip\n",
            "train_data16016.zip  train_data25164.zip  train_data6871.zip\n",
            "train_data16017.zip  train_data25165.zip  train_data6872.zip\n",
            "train_data16018.zip  train_data25166.zip  train_data6873.zip\n",
            "train_data16019.zip  train_data25167.zip  train_data6874.zip\n",
            "train_data1601.zip   train_data25168.zip  train_data6875.zip\n",
            "train_data16020.zip  train_data25169.zip  train_data6876.zip\n",
            "train_data16021.zip  train_data2516.zip   train_data6877.zip\n",
            "train_data16022.zip  train_data25170.zip  train_data6878.zip\n",
            "train_data16023.zip  train_data25171.zip  train_data6879.zip\n",
            "train_data16024.zip  train_data25172.zip  train_data687.zip\n",
            "train_data16025.zip  train_data25173.zip  train_data6880.zip\n",
            "train_data16026.zip  train_data25174.zip  train_data6881.zip\n",
            "train_data16027.zip  train_data25175.zip  train_data6882.zip\n",
            "train_data16028.zip  train_data25176.zip  train_data6883.zip\n",
            "train_data16029.zip  train_data25177.zip  train_data6884.zip\n",
            "train_data1602.zip   train_data25178.zip  train_data6885.zip\n",
            "train_data16030.zip  train_data25179.zip  train_data6886.zip\n",
            "train_data16031.zip  train_data2517.zip   train_data6887.zip\n",
            "train_data16032.zip  train_data25180.zip  train_data6888.zip\n",
            "train_data16033.zip  train_data25181.zip  train_data6889.zip\n",
            "train_data16034.zip  train_data25182.zip  train_data688.zip\n",
            "train_data16035.zip  train_data25183.zip  train_data6890.zip\n",
            "train_data16036.zip  train_data25184.zip  train_data6891.zip\n",
            "train_data16037.zip  train_data25185.zip  train_data6892.zip\n",
            "train_data16038.zip  train_data25186.zip  train_data6893.zip\n",
            "train_data16039.zip  train_data25187.zip  train_data6894.zip\n",
            "train_data1603.zip   train_data25188.zip  train_data6895.zip\n",
            "train_data16040.zip  train_data25189.zip  train_data6896.zip\n",
            "train_data16041.zip  train_data2518.zip   train_data6897.zip\n",
            "train_data16042.zip  train_data25190.zip  train_data6898.zip\n",
            "train_data16043.zip  train_data25191.zip  train_data6899.zip\n",
            "train_data16044.zip  train_data25192.zip  train_data689.zip\n",
            "train_data16045.zip  train_data25193.zip  train_data68.zip\n",
            "train_data16046.zip  train_data25194.zip  train_data6900.zip\n",
            "train_data16047.zip  train_data25195.zip  train_data6901.zip\n",
            "train_data16048.zip  train_data25196.zip  train_data6902.zip\n",
            "train_data16049.zip  train_data25197.zip  train_data6903.zip\n",
            "train_data1604.zip   train_data25198.zip  train_data6904.zip\n",
            "train_data16050.zip  train_data25199.zip  train_data6905.zip\n",
            "train_data16051.zip  train_data2519.zip   train_data6906.zip\n",
            "train_data16052.zip  train_data251.zip\t  train_data6907.zip\n",
            "train_data16053.zip  train_data25200.zip  train_data6908.zip\n",
            "train_data16054.zip  train_data25201.zip  train_data6909.zip\n",
            "train_data16055.zip  train_data25202.zip  train_data690.zip\n",
            "train_data16056.zip  train_data25203.zip  train_data6910.zip\n",
            "train_data16057.zip  train_data25204.zip  train_data6911.zip\n",
            "train_data16058.zip  train_data25205.zip  train_data6912.zip\n",
            "train_data16059.zip  train_data25206.zip  train_data6913.zip\n",
            "train_data1605.zip   train_data25207.zip  train_data6914.zip\n",
            "train_data16060.zip  train_data25208.zip  train_data6915.zip\n",
            "train_data16061.zip  train_data25209.zip  train_data6916.zip\n",
            "train_data16062.zip  train_data2520.zip   train_data6917.zip\n",
            "train_data16063.zip  train_data25210.zip  train_data6918.zip\n",
            "train_data16064.zip  train_data25211.zip  train_data6919.zip\n",
            "train_data16065.zip  train_data25212.zip  train_data691.zip\n",
            "train_data16066.zip  train_data25213.zip  train_data6920.zip\n",
            "train_data16067.zip  train_data25214.zip  train_data6921.zip\n",
            "train_data16068.zip  train_data25215.zip  train_data6922.zip\n",
            "train_data16069.zip  train_data25216.zip  train_data6923.zip\n",
            "train_data1606.zip   train_data25217.zip  train_data6924.zip\n",
            "train_data16070.zip  train_data25218.zip  train_data6925.zip\n",
            "train_data16071.zip  train_data25219.zip  train_data6926.zip\n",
            "train_data16072.zip  train_data2521.zip   train_data6927.zip\n",
            "train_data16073.zip  train_data25220.zip  train_data6928.zip\n",
            "train_data16074.zip  train_data25221.zip  train_data6929.zip\n",
            "train_data16075.zip  train_data25222.zip  train_data692.zip\n",
            "train_data16076.zip  train_data25223.zip  train_data6930.zip\n",
            "train_data16077.zip  train_data25224.zip  train_data6931.zip\n",
            "train_data16078.zip  train_data25225.zip  train_data6932.zip\n",
            "train_data16079.zip  train_data25226.zip  train_data6933.zip\n",
            "train_data1607.zip   train_data25227.zip  train_data6934.zip\n",
            "train_data16080.zip  train_data25228.zip  train_data6935.zip\n",
            "train_data16081.zip  train_data25229.zip  train_data6936.zip\n",
            "train_data16082.zip  train_data2522.zip   train_data6937.zip\n",
            "train_data16083.zip  train_data25230.zip  train_data6938.zip\n",
            "train_data16084.zip  train_data25231.zip  train_data6939.zip\n",
            "train_data16085.zip  train_data25232.zip  train_data693.zip\n",
            "train_data16086.zip  train_data25233.zip  train_data6940.zip\n",
            "train_data16087.zip  train_data25234.zip  train_data6941.zip\n",
            "train_data16088.zip  train_data25235.zip  train_data6942.zip\n",
            "train_data16089.zip  train_data25236.zip  train_data6943.zip\n",
            "train_data1608.zip   train_data25237.zip  train_data6944.zip\n",
            "train_data16090.zip  train_data25238.zip  train_data6945.zip\n",
            "train_data16091.zip  train_data25239.zip  train_data6946.zip\n",
            "train_data16092.zip  train_data2523.zip   train_data6947.zip\n",
            "train_data16093.zip  train_data25240.zip  train_data6948.zip\n",
            "train_data16094.zip  train_data25241.zip  train_data6949.zip\n",
            "train_data16095.zip  train_data25242.zip  train_data694.zip\n",
            "train_data16096.zip  train_data25243.zip  train_data6950.zip\n",
            "train_data16097.zip  train_data25244.zip  train_data6951.zip\n",
            "train_data16098.zip  train_data25245.zip  train_data6952.zip\n",
            "train_data16099.zip  train_data25246.zip  train_data6953.zip\n",
            "train_data1609.zip   train_data25247.zip  train_data6954.zip\n",
            "train_data160.zip    train_data25248.zip  train_data6955.zip\n",
            "train_data16100.zip  train_data25249.zip  train_data6956.zip\n",
            "train_data16101.zip  train_data2524.zip   train_data6957.zip\n",
            "train_data16102.zip  train_data25250.zip  train_data6958.zip\n",
            "train_data16103.zip  train_data25251.zip  train_data6959.zip\n",
            "train_data16104.zip  train_data25252.zip  train_data695.zip\n",
            "train_data16105.zip  train_data25253.zip  train_data6960.zip\n",
            "train_data16106.zip  train_data25254.zip  train_data6961.zip\n",
            "train_data16107.zip  train_data25255.zip  train_data6962.zip\n",
            "train_data16108.zip  train_data25256.zip  train_data6963.zip\n",
            "train_data16109.zip  train_data25257.zip  train_data6964.zip\n",
            "train_data1610.zip   train_data25258.zip  train_data6965.zip\n",
            "train_data16110.zip  train_data25259.zip  train_data6966.zip\n",
            "train_data16111.zip  train_data2525.zip   train_data6967.zip\n",
            "train_data16112.zip  train_data25260.zip  train_data6968.zip\n",
            "train_data16113.zip  train_data25261.zip  train_data6969.zip\n",
            "train_data16114.zip  train_data25262.zip  train_data696.zip\n",
            "train_data16115.zip  train_data25263.zip  train_data6970.zip\n",
            "train_data16116.zip  train_data25264.zip  train_data6971.zip\n",
            "train_data16117.zip  train_data25265.zip  train_data6972.zip\n",
            "train_data16118.zip  train_data25266.zip  train_data6973.zip\n",
            "train_data16119.zip  train_data25267.zip  train_data6974.zip\n",
            "train_data1611.zip   train_data25268.zip  train_data6975.zip\n",
            "train_data16120.zip  train_data25269.zip  train_data6976.zip\n",
            "train_data16121.zip  train_data2526.zip   train_data6977.zip\n",
            "train_data16122.zip  train_data25270.zip  train_data6978.zip\n",
            "train_data16123.zip  train_data25271.zip  train_data6979.zip\n",
            "train_data16124.zip  train_data25272.zip  train_data697.zip\n",
            "train_data16125.zip  train_data25273.zip  train_data6980.zip\n",
            "train_data16126.zip  train_data25274.zip  train_data6981.zip\n",
            "train_data16127.zip  train_data25275.zip  train_data6982.zip\n",
            "train_data16128.zip  train_data25276.zip  train_data6983.zip\n",
            "train_data16129.zip  train_data25277.zip  train_data6984.zip\n",
            "train_data1612.zip   train_data25278.zip  train_data6985.zip\n",
            "train_data16130.zip  train_data25279.zip  train_data6986.zip\n",
            "train_data16131.zip  train_data2527.zip   train_data6987.zip\n",
            "train_data16132.zip  train_data25280.zip  train_data6988.zip\n",
            "train_data16133.zip  train_data25281.zip  train_data6989.zip\n",
            "train_data16134.zip  train_data25282.zip  train_data698.zip\n",
            "train_data16135.zip  train_data25283.zip  train_data6990.zip\n",
            "train_data16136.zip  train_data25284.zip  train_data6991.zip\n",
            "train_data16137.zip  train_data25285.zip  train_data6992.zip\n",
            "train_data16138.zip  train_data25286.zip  train_data6993.zip\n",
            "train_data16139.zip  train_data25287.zip  train_data6994.zip\n",
            "train_data1613.zip   train_data25288.zip  train_data6995.zip\n",
            "train_data16140.zip  train_data25289.zip  train_data6996.zip\n",
            "train_data16141.zip  train_data2528.zip   train_data6997.zip\n",
            "train_data16142.zip  train_data25290.zip  train_data6998.zip\n",
            "train_data16143.zip  train_data25291.zip  train_data6999.zip\n",
            "train_data16144.zip  train_data25292.zip  train_data699.zip\n",
            "train_data16145.zip  train_data25293.zip  train_data69.zip\n",
            "train_data16146.zip  train_data25294.zip  train_data6.zip\n",
            "train_data16147.zip  train_data25295.zip  train_data7000.zip\n",
            "train_data16148.zip  train_data25296.zip  train_data7001.zip\n",
            "train_data16149.zip  train_data25297.zip  train_data7002.zip\n",
            "train_data1614.zip   train_data25298.zip  train_data7003.zip\n",
            "train_data16150.zip  train_data25299.zip  train_data7004.zip\n",
            "train_data16151.zip  train_data2529.zip   train_data7005.zip\n",
            "train_data16152.zip  train_data252.zip\t  train_data7006.zip\n",
            "train_data16153.zip  train_data25300.zip  train_data7007.zip\n",
            "train_data16154.zip  train_data25301.zip  train_data7008.zip\n",
            "train_data16155.zip  train_data25302.zip  train_data7009.zip\n",
            "train_data16156.zip  train_data25303.zip  train_data700.zip\n",
            "train_data16157.zip  train_data25304.zip  train_data7010.zip\n",
            "train_data16158.zip  train_data25305.zip  train_data7011.zip\n",
            "train_data16159.zip  train_data25306.zip  train_data7012.zip\n",
            "train_data1615.zip   train_data25307.zip  train_data7013.zip\n",
            "train_data16160.zip  train_data25308.zip  train_data7014.zip\n",
            "train_data16161.zip  train_data25309.zip  train_data7015.zip\n",
            "train_data16162.zip  train_data2530.zip   train_data7016.zip\n",
            "train_data16163.zip  train_data25310.zip  train_data7017.zip\n",
            "train_data16164.zip  train_data25311.zip  train_data7018.zip\n",
            "train_data16165.zip  train_data25312.zip  train_data7019.zip\n",
            "train_data16166.zip  train_data25313.zip  train_data701.zip\n",
            "train_data16167.zip  train_data25314.zip  train_data7020.zip\n",
            "train_data16168.zip  train_data25315.zip  train_data7021.zip\n",
            "train_data16169.zip  train_data25316.zip  train_data7022.zip\n",
            "train_data1616.zip   train_data25317.zip  train_data7023.zip\n",
            "train_data16170.zip  train_data25318.zip  train_data7024.zip\n",
            "train_data16171.zip  train_data25319.zip  train_data7025.zip\n",
            "train_data16172.zip  train_data2531.zip   train_data7026.zip\n",
            "train_data16173.zip  train_data25320.zip  train_data7027.zip\n",
            "train_data16174.zip  train_data25321.zip  train_data7028.zip\n",
            "train_data16175.zip  train_data25322.zip  train_data7029.zip\n",
            "train_data16176.zip  train_data25323.zip  train_data702.zip\n",
            "train_data16177.zip  train_data25324.zip  train_data7030.zip\n",
            "train_data16178.zip  train_data25325.zip  train_data7031.zip\n",
            "train_data16179.zip  train_data25326.zip  train_data7032.zip\n",
            "train_data1617.zip   train_data25327.zip  train_data7033.zip\n",
            "train_data16180.zip  train_data25328.zip  train_data7034.zip\n",
            "train_data16181.zip  train_data25329.zip  train_data7035.zip\n",
            "train_data16182.zip  train_data2532.zip   train_data7036.zip\n",
            "train_data16183.zip  train_data25330.zip  train_data7037.zip\n",
            "train_data16184.zip  train_data25331.zip  train_data7038.zip\n",
            "train_data16185.zip  train_data25332.zip  train_data7039.zip\n",
            "train_data16186.zip  train_data25333.zip  train_data703.zip\n",
            "train_data16187.zip  train_data25334.zip  train_data7040.zip\n",
            "train_data16188.zip  train_data25335.zip  train_data7041.zip\n",
            "train_data16189.zip  train_data25336.zip  train_data7042.zip\n",
            "train_data1618.zip   train_data25337.zip  train_data7043.zip\n",
            "train_data16190.zip  train_data25338.zip  train_data7044.zip\n",
            "train_data16191.zip  train_data25339.zip  train_data7045.zip\n",
            "train_data16192.zip  train_data2533.zip   train_data7046.zip\n",
            "train_data16193.zip  train_data25340.zip  train_data7047.zip\n",
            "train_data16194.zip  train_data25341.zip  train_data7048.zip\n",
            "train_data16195.zip  train_data25342.zip  train_data7049.zip\n",
            "train_data16196.zip  train_data25343.zip  train_data704.zip\n",
            "train_data16197.zip  train_data25344.zip  train_data7050.zip\n",
            "train_data16198.zip  train_data25345.zip  train_data7051.zip\n",
            "train_data16199.zip  train_data25346.zip  train_data7052.zip\n",
            "train_data1619.zip   train_data25347.zip  train_data7053.zip\n",
            "train_data161.zip    train_data25348.zip  train_data7054.zip\n",
            "train_data16200.zip  train_data25349.zip  train_data7055.zip\n",
            "train_data16201.zip  train_data2534.zip   train_data7056.zip\n",
            "train_data16202.zip  train_data25350.zip  train_data7057.zip\n",
            "train_data16203.zip  train_data25351.zip  train_data7058.zip\n",
            "train_data16204.zip  train_data25352.zip  train_data7059.zip\n",
            "train_data16205.zip  train_data25353.zip  train_data705.zip\n",
            "train_data16206.zip  train_data25354.zip  train_data7060.zip\n",
            "train_data16207.zip  train_data25355.zip  train_data7061.zip\n",
            "train_data16208.zip  train_data25356.zip  train_data7062.zip\n",
            "train_data16209.zip  train_data25357.zip  train_data7063.zip\n",
            "train_data1620.zip   train_data25358.zip  train_data7064.zip\n",
            "train_data16210.zip  train_data25359.zip  train_data7065.zip\n",
            "train_data16211.zip  train_data2535.zip   train_data7066.zip\n",
            "train_data16212.zip  train_data25360.zip  train_data7067.zip\n",
            "train_data16213.zip  train_data25361.zip  train_data7068.zip\n",
            "train_data16214.zip  train_data25362.zip  train_data7069.zip\n",
            "train_data16215.zip  train_data25363.zip  train_data706.zip\n",
            "train_data16216.zip  train_data25364.zip  train_data7070.zip\n",
            "train_data16217.zip  train_data25365.zip  train_data7071.zip\n",
            "train_data16218.zip  train_data25366.zip  train_data7072.zip\n",
            "train_data16219.zip  train_data25367.zip  train_data7073.zip\n",
            "train_data1621.zip   train_data25368.zip  train_data7074.zip\n",
            "train_data16220.zip  train_data25369.zip  train_data7075.zip\n",
            "train_data16221.zip  train_data2536.zip   train_data7076.zip\n",
            "train_data16222.zip  train_data25370.zip  train_data7077.zip\n",
            "train_data16223.zip  train_data25371.zip  train_data7078.zip\n",
            "train_data16224.zip  train_data25372.zip  train_data7079.zip\n",
            "train_data16225.zip  train_data25373.zip  train_data707.zip\n",
            "train_data16226.zip  train_data25374.zip  train_data7080.zip\n",
            "train_data16227.zip  train_data25375.zip  train_data7081.zip\n",
            "train_data16228.zip  train_data25376.zip  train_data7082.zip\n",
            "train_data16229.zip  train_data25377.zip  train_data7083.zip\n",
            "train_data1622.zip   train_data25378.zip  train_data7084.zip\n",
            "train_data16230.zip  train_data25379.zip  train_data7085.zip\n",
            "train_data16231.zip  train_data2537.zip   train_data7086.zip\n",
            "train_data16232.zip  train_data25380.zip  train_data7087.zip\n",
            "train_data16233.zip  train_data25381.zip  train_data7088.zip\n",
            "train_data16234.zip  train_data25382.zip  train_data7089.zip\n",
            "train_data16235.zip  train_data25383.zip  train_data708.zip\n",
            "train_data16236.zip  train_data25384.zip  train_data7090.zip\n",
            "train_data16237.zip  train_data25385.zip  train_data7091.zip\n",
            "train_data16238.zip  train_data25386.zip  train_data7092.zip\n",
            "train_data16239.zip  train_data25387.zip  train_data7093.zip\n",
            "train_data1623.zip   train_data25388.zip  train_data7094.zip\n",
            "train_data16240.zip  train_data25389.zip  train_data7095.zip\n",
            "train_data16241.zip  train_data2538.zip   train_data7096.zip\n",
            "train_data16242.zip  train_data25390.zip  train_data7097.zip\n",
            "train_data16243.zip  train_data25391.zip  train_data7098.zip\n",
            "train_data16244.zip  train_data25392.zip  train_data7099.zip\n",
            "train_data16245.zip  train_data25393.zip  train_data709.zip\n",
            "train_data16246.zip  train_data25394.zip  train_data70.zip\n",
            "train_data16247.zip  train_data25395.zip  train_data7100.zip\n",
            "train_data16248.zip  train_data25396.zip  train_data7101.zip\n",
            "train_data16249.zip  train_data25397.zip  train_data7102.zip\n",
            "train_data1624.zip   train_data25398.zip  train_data7103.zip\n",
            "train_data16250.zip  train_data25399.zip  train_data7104.zip\n",
            "train_data16251.zip  train_data2539.zip   train_data7105.zip\n",
            "train_data16252.zip  train_data253.zip\t  train_data7106.zip\n",
            "train_data16253.zip  train_data25400.zip  train_data7107.zip\n",
            "train_data16254.zip  train_data25401.zip  train_data7108.zip\n",
            "train_data16255.zip  train_data25402.zip  train_data7109.zip\n",
            "train_data16256.zip  train_data25403.zip  train_data710.zip\n",
            "train_data16257.zip  train_data25404.zip  train_data7110.zip\n",
            "train_data16258.zip  train_data25405.zip  train_data7111.zip\n",
            "train_data16259.zip  train_data25406.zip  train_data7112.zip\n",
            "train_data1625.zip   train_data25407.zip  train_data7113.zip\n",
            "train_data16260.zip  train_data25408.zip  train_data7114.zip\n",
            "train_data16261.zip  train_data25409.zip  train_data7115.zip\n",
            "train_data16262.zip  train_data2540.zip   train_data7116.zip\n",
            "train_data16263.zip  train_data25410.zip  train_data7117.zip\n",
            "train_data16264.zip  train_data25411.zip  train_data7118.zip\n",
            "train_data16265.zip  train_data25412.zip  train_data7119.zip\n",
            "train_data16266.zip  train_data25413.zip  train_data711.zip\n",
            "train_data16267.zip  train_data25414.zip  train_data7120.zip\n",
            "train_data16268.zip  train_data25415.zip  train_data7121.zip\n",
            "train_data16269.zip  train_data25416.zip  train_data7122.zip\n",
            "train_data1626.zip   train_data25417.zip  train_data7123.zip\n",
            "train_data16270.zip  train_data25418.zip  train_data7124.zip\n",
            "train_data16271.zip  train_data25419.zip  train_data7125.zip\n",
            "train_data16272.zip  train_data2541.zip   train_data7126.zip\n",
            "train_data16273.zip  train_data25420.zip  train_data7127.zip\n",
            "train_data16274.zip  train_data25421.zip  train_data7128.zip\n",
            "train_data16275.zip  train_data25422.zip  train_data7129.zip\n",
            "train_data16276.zip  train_data25423.zip  train_data712.zip\n",
            "train_data16277.zip  train_data25424.zip  train_data7130.zip\n",
            "train_data16278.zip  train_data25425.zip  train_data7131.zip\n",
            "train_data16279.zip  train_data25426.zip  train_data7132.zip\n",
            "train_data1627.zip   train_data25427.zip  train_data7133.zip\n",
            "train_data16280.zip  train_data25428.zip  train_data7134.zip\n",
            "train_data16281.zip  train_data25429.zip  train_data7135.zip\n",
            "train_data16282.zip  train_data2542.zip   train_data7136.zip\n",
            "train_data16283.zip  train_data25430.zip  train_data7137.zip\n",
            "train_data16284.zip  train_data25431.zip  train_data7138.zip\n",
            "train_data16285.zip  train_data25432.zip  train_data7139.zip\n",
            "train_data16286.zip  train_data25433.zip  train_data713.zip\n",
            "train_data16287.zip  train_data25434.zip  train_data7140.zip\n",
            "train_data16288.zip  train_data25435.zip  train_data7141.zip\n",
            "train_data16289.zip  train_data25436.zip  train_data7142.zip\n",
            "train_data1628.zip   train_data25437.zip  train_data7143.zip\n",
            "train_data16290.zip  train_data25438.zip  train_data7144.zip\n",
            "train_data16291.zip  train_data25439.zip  train_data7145.zip\n",
            "train_data16292.zip  train_data2543.zip   train_data7146.zip\n",
            "train_data16293.zip  train_data25440.zip  train_data7147.zip\n",
            "train_data16294.zip  train_data25441.zip  train_data7148.zip\n",
            "train_data16295.zip  train_data25442.zip  train_data7149.zip\n",
            "train_data16296.zip  train_data25443.zip  train_data714.zip\n",
            "train_data16297.zip  train_data25444.zip  train_data7150.zip\n",
            "train_data16298.zip  train_data25445.zip  train_data7151.zip\n",
            "train_data16299.zip  train_data25446.zip  train_data7152.zip\n",
            "train_data1629.zip   train_data25447.zip  train_data7153.zip\n",
            "train_data162.zip    train_data25448.zip  train_data7154.zip\n",
            "train_data16300.zip  train_data25449.zip  train_data7155.zip\n",
            "train_data16301.zip  train_data2544.zip   train_data7156.zip\n",
            "train_data16302.zip  train_data25450.zip  train_data7157.zip\n",
            "train_data16303.zip  train_data25451.zip  train_data7158.zip\n",
            "train_data16304.zip  train_data25452.zip  train_data7159.zip\n",
            "train_data16305.zip  train_data25453.zip  train_data715.zip\n",
            "train_data16306.zip  train_data25454.zip  train_data7160.zip\n",
            "train_data16307.zip  train_data25455.zip  train_data7161.zip\n",
            "train_data16308.zip  train_data25456.zip  train_data7162.zip\n",
            "train_data16309.zip  train_data25457.zip  train_data7163.zip\n",
            "train_data1630.zip   train_data25458.zip  train_data7164.zip\n",
            "train_data16310.zip  train_data25459.zip  train_data7165.zip\n",
            "train_data16311.zip  train_data2545.zip   train_data7166.zip\n",
            "train_data16312.zip  train_data25460.zip  train_data7167.zip\n",
            "train_data16313.zip  train_data25461.zip  train_data7168.zip\n",
            "train_data16314.zip  train_data25462.zip  train_data7169.zip\n",
            "train_data16315.zip  train_data25463.zip  train_data716.zip\n",
            "train_data16316.zip  train_data25464.zip  train_data7170.zip\n",
            "train_data16317.zip  train_data25465.zip  train_data7171.zip\n",
            "train_data16318.zip  train_data25466.zip  train_data7172.zip\n",
            "train_data16319.zip  train_data25467.zip  train_data7173.zip\n",
            "train_data1631.zip   train_data25468.zip  train_data7174.zip\n",
            "train_data16320.zip  train_data25469.zip  train_data7175.zip\n",
            "train_data16321.zip  train_data2546.zip   train_data7176.zip\n",
            "train_data16322.zip  train_data25470.zip  train_data7177.zip\n",
            "train_data16323.zip  train_data25471.zip  train_data7178.zip\n",
            "train_data16324.zip  train_data25472.zip  train_data7179.zip\n",
            "train_data16325.zip  train_data25473.zip  train_data717.zip\n",
            "train_data16326.zip  train_data25474.zip  train_data7180.zip\n",
            "train_data16327.zip  train_data25475.zip  train_data7181.zip\n",
            "train_data16328.zip  train_data25476.zip  train_data7182.zip\n",
            "train_data16329.zip  train_data25477.zip  train_data7183.zip\n",
            "train_data1632.zip   train_data25478.zip  train_data7184.zip\n",
            "train_data16330.zip  train_data25479.zip  train_data7185.zip\n",
            "train_data16331.zip  train_data2547.zip   train_data7186.zip\n",
            "train_data16332.zip  train_data25480.zip  train_data7187.zip\n",
            "train_data16333.zip  train_data25481.zip  train_data7188.zip\n",
            "train_data16334.zip  train_data25482.zip  train_data7189.zip\n",
            "train_data16335.zip  train_data25483.zip  train_data718.zip\n",
            "train_data16336.zip  train_data25484.zip  train_data7190.zip\n",
            "train_data16337.zip  train_data25485.zip  train_data7191.zip\n",
            "train_data16338.zip  train_data25486.zip  train_data7192.zip\n",
            "train_data16339.zip  train_data25487.zip  train_data7193.zip\n",
            "train_data1633.zip   train_data25488.zip  train_data7194.zip\n",
            "train_data16340.zip  train_data25489.zip  train_data7195.zip\n",
            "train_data16341.zip  train_data2548.zip   train_data7196.zip\n",
            "train_data16342.zip  train_data25490.zip  train_data7197.zip\n",
            "train_data16343.zip  train_data25491.zip  train_data7198.zip\n",
            "train_data16344.zip  train_data25492.zip  train_data7199.zip\n",
            "train_data16345.zip  train_data25493.zip  train_data719.zip\n",
            "train_data16346.zip  train_data25494.zip  train_data71.zip\n",
            "train_data16347.zip  train_data25495.zip  train_data7200.zip\n",
            "train_data16348.zip  train_data25496.zip  train_data7201.zip\n",
            "train_data16349.zip  train_data25497.zip  train_data7202.zip\n",
            "train_data1634.zip   train_data25498.zip  train_data7203.zip\n",
            "train_data16350.zip  train_data25499.zip  train_data7204.zip\n",
            "train_data16351.zip  train_data2549.zip   train_data7205.zip\n",
            "train_data16352.zip  train_data254.zip\t  train_data7206.zip\n",
            "train_data16353.zip  train_data25500.zip  train_data7207.zip\n",
            "train_data16354.zip  train_data25501.zip  train_data7208.zip\n",
            "train_data16355.zip  train_data25502.zip  train_data7209.zip\n",
            "train_data16356.zip  train_data25503.zip  train_data720.zip\n",
            "train_data16357.zip  train_data25504.zip  train_data7210.zip\n",
            "train_data16358.zip  train_data25505.zip  train_data7211.zip\n",
            "train_data16359.zip  train_data25506.zip  train_data7212.zip\n",
            "train_data1635.zip   train_data25507.zip  train_data7213.zip\n",
            "train_data16360.zip  train_data25508.zip  train_data7214.zip\n",
            "train_data16361.zip  train_data25509.zip  train_data7215.zip\n",
            "train_data16362.zip  train_data2550.zip   train_data7216.zip\n",
            "train_data16363.zip  train_data25510.zip  train_data7217.zip\n",
            "train_data16364.zip  train_data25511.zip  train_data7218.zip\n",
            "train_data16365.zip  train_data25512.zip  train_data7219.zip\n",
            "train_data16366.zip  train_data25513.zip  train_data721.zip\n",
            "train_data16367.zip  train_data25514.zip  train_data7220.zip\n",
            "train_data16368.zip  train_data25515.zip  train_data7221.zip\n",
            "train_data16369.zip  train_data25516.zip  train_data7222.zip\n",
            "train_data1636.zip   train_data25517.zip  train_data7223.zip\n",
            "train_data16370.zip  train_data25518.zip  train_data7224.zip\n",
            "train_data16371.zip  train_data25519.zip  train_data7225.zip\n",
            "train_data16372.zip  train_data2551.zip   train_data7226.zip\n",
            "train_data16373.zip  train_data25520.zip  train_data7227.zip\n",
            "train_data16374.zip  train_data25521.zip  train_data7228.zip\n",
            "train_data16375.zip  train_data25522.zip  train_data7229.zip\n",
            "train_data16376.zip  train_data25523.zip  train_data722.zip\n",
            "train_data16377.zip  train_data25524.zip  train_data7230.zip\n",
            "train_data16378.zip  train_data25525.zip  train_data7231.zip\n",
            "train_data16379.zip  train_data25526.zip  train_data7232.zip\n",
            "train_data1637.zip   train_data25527.zip  train_data7233.zip\n",
            "train_data16380.zip  train_data25528.zip  train_data7234.zip\n",
            "train_data16381.zip  train_data25529.zip  train_data7235.zip\n",
            "train_data16382.zip  train_data2552.zip   train_data7236.zip\n",
            "train_data16383.zip  train_data25530.zip  train_data7237.zip\n",
            "train_data16384.zip  train_data25531.zip  train_data7238.zip\n",
            "train_data16385.zip  train_data25532.zip  train_data7239.zip\n",
            "train_data16386.zip  train_data25533.zip  train_data723.zip\n",
            "train_data16387.zip  train_data25534.zip  train_data7240.zip\n",
            "train_data16388.zip  train_data25535.zip  train_data7241.zip\n",
            "train_data16389.zip  train_data25536.zip  train_data7242.zip\n",
            "train_data1638.zip   train_data25537.zip  train_data7243.zip\n",
            "train_data16390.zip  train_data25538.zip  train_data7244.zip\n",
            "train_data16391.zip  train_data25539.zip  train_data7245.zip\n",
            "train_data16392.zip  train_data2553.zip   train_data7246.zip\n",
            "train_data16393.zip  train_data25540.zip  train_data7247.zip\n",
            "train_data16394.zip  train_data25541.zip  train_data7248.zip\n",
            "train_data16395.zip  train_data25542.zip  train_data7249.zip\n",
            "train_data16396.zip  train_data25543.zip  train_data724.zip\n",
            "train_data16397.zip  train_data25544.zip  train_data7250.zip\n",
            "train_data16398.zip  train_data25545.zip  train_data7251.zip\n",
            "train_data16399.zip  train_data25546.zip  train_data7252.zip\n",
            "train_data1639.zip   train_data25547.zip  train_data7253.zip\n",
            "train_data163.zip    train_data25548.zip  train_data7254.zip\n",
            "train_data16400.zip  train_data25549.zip  train_data7255.zip\n",
            "train_data16401.zip  train_data2554.zip   train_data7256.zip\n",
            "train_data16402.zip  train_data25550.zip  train_data7257.zip\n",
            "train_data16403.zip  train_data25551.zip  train_data7258.zip\n",
            "train_data16404.zip  train_data25552.zip  train_data7259.zip\n",
            "train_data16405.zip  train_data25553.zip  train_data725.zip\n",
            "train_data16406.zip  train_data25554.zip  train_data7260.zip\n",
            "train_data16407.zip  train_data25555.zip  train_data7261.zip\n",
            "train_data16408.zip  train_data25556.zip  train_data7262.zip\n",
            "train_data16409.zip  train_data25557.zip  train_data7263.zip\n",
            "train_data1640.zip   train_data25558.zip  train_data7264.zip\n",
            "train_data16410.zip  train_data25559.zip  train_data7265.zip\n",
            "train_data16411.zip  train_data2555.zip   train_data7266.zip\n",
            "train_data16412.zip  train_data25560.zip  train_data7267.zip\n",
            "train_data16413.zip  train_data25561.zip  train_data7268.zip\n",
            "train_data16414.zip  train_data25562.zip  train_data7269.zip\n",
            "train_data16415.zip  train_data25563.zip  train_data726.zip\n",
            "train_data16416.zip  train_data25564.zip  train_data7270.zip\n",
            "train_data16417.zip  train_data25565.zip  train_data7271.zip\n",
            "train_data16418.zip  train_data25566.zip  train_data7272.zip\n",
            "train_data16419.zip  train_data25567.zip  train_data7273.zip\n",
            "train_data1641.zip   train_data25568.zip  train_data7274.zip\n",
            "train_data16420.zip  train_data25569.zip  train_data7275.zip\n",
            "train_data16421.zip  train_data2556.zip   train_data7276.zip\n",
            "train_data16422.zip  train_data25570.zip  train_data7277.zip\n",
            "train_data16423.zip  train_data25571.zip  train_data7278.zip\n",
            "train_data16424.zip  train_data25572.zip  train_data7279.zip\n",
            "train_data16425.zip  train_data25573.zip  train_data727.zip\n",
            "train_data16426.zip  train_data25574.zip  train_data7280.zip\n",
            "train_data16427.zip  train_data25575.zip  train_data7281.zip\n",
            "train_data16428.zip  train_data25576.zip  train_data7282.zip\n",
            "train_data16429.zip  train_data25577.zip  train_data7283.zip\n",
            "train_data1642.zip   train_data25578.zip  train_data7284.zip\n",
            "train_data16430.zip  train_data25579.zip  train_data7285.zip\n",
            "train_data16431.zip  train_data2557.zip   train_data7286.zip\n",
            "train_data16432.zip  train_data25580.zip  train_data7287.zip\n",
            "train_data16433.zip  train_data25581.zip  train_data7288.zip\n",
            "train_data16434.zip  train_data25582.zip  train_data7289.zip\n",
            "train_data16435.zip  train_data25583.zip  train_data728.zip\n",
            "train_data16436.zip  train_data25584.zip  train_data7290.zip\n",
            "train_data16437.zip  train_data25585.zip  train_data7291.zip\n",
            "train_data16438.zip  train_data25586.zip  train_data7292.zip\n",
            "train_data16439.zip  train_data25587.zip  train_data7293.zip\n",
            "train_data1643.zip   train_data25588.zip  train_data7294.zip\n",
            "train_data16440.zip  train_data25589.zip  train_data7295.zip\n",
            "train_data16441.zip  train_data2558.zip   train_data7296.zip\n",
            "train_data16442.zip  train_data25590.zip  train_data7297.zip\n",
            "train_data16443.zip  train_data25591.zip  train_data7298.zip\n",
            "train_data16444.zip  train_data25592.zip  train_data7299.zip\n",
            "train_data16445.zip  train_data25593.zip  train_data729.zip\n",
            "train_data16446.zip  train_data25594.zip  train_data72.zip\n",
            "train_data16447.zip  train_data25595.zip  train_data7300.zip\n",
            "train_data16448.zip  train_data25596.zip  train_data7301.zip\n",
            "train_data16449.zip  train_data25597.zip  train_data7302.zip\n",
            "train_data1644.zip   train_data25598.zip  train_data7303.zip\n",
            "train_data16450.zip  train_data25599.zip  train_data7304.zip\n",
            "train_data16451.zip  train_data2559.zip   train_data7305.zip\n",
            "train_data16452.zip  train_data255.zip\t  train_data7306.zip\n",
            "train_data16453.zip  train_data25600.zip  train_data7307.zip\n",
            "train_data16454.zip  train_data25601.zip  train_data7308.zip\n",
            "train_data16455.zip  train_data25602.zip  train_data7309.zip\n",
            "train_data16456.zip  train_data25603.zip  train_data730.zip\n",
            "train_data16457.zip  train_data25604.zip  train_data7310.zip\n",
            "train_data16458.zip  train_data25605.zip  train_data7311.zip\n",
            "train_data16459.zip  train_data25606.zip  train_data7312.zip\n",
            "train_data1645.zip   train_data25607.zip  train_data7313.zip\n",
            "train_data16460.zip  train_data25608.zip  train_data7314.zip\n",
            "train_data16461.zip  train_data25609.zip  train_data7315.zip\n",
            "train_data16462.zip  train_data2560.zip   train_data7316.zip\n",
            "train_data16463.zip  train_data25610.zip  train_data7317.zip\n",
            "train_data16464.zip  train_data25611.zip  train_data7318.zip\n",
            "train_data16465.zip  train_data25612.zip  train_data7319.zip\n",
            "train_data16466.zip  train_data25613.zip  train_data731.zip\n",
            "train_data16467.zip  train_data25614.zip  train_data7320.zip\n",
            "train_data16468.zip  train_data25615.zip  train_data7321.zip\n",
            "train_data16469.zip  train_data25616.zip  train_data7322.zip\n",
            "train_data1646.zip   train_data25617.zip  train_data7323.zip\n",
            "train_data16470.zip  train_data25618.zip  train_data7324.zip\n",
            "train_data16471.zip  train_data25619.zip  train_data7325.zip\n",
            "train_data16472.zip  train_data2561.zip   train_data7326.zip\n",
            "train_data16473.zip  train_data25620.zip  train_data7327.zip\n",
            "train_data16474.zip  train_data25621.zip  train_data7328.zip\n",
            "train_data16475.zip  train_data25622.zip  train_data7329.zip\n",
            "train_data16476.zip  train_data25623.zip  train_data732.zip\n",
            "train_data16477.zip  train_data25624.zip  train_data7330.zip\n",
            "train_data16478.zip  train_data25625.zip  train_data7331.zip\n",
            "train_data16479.zip  train_data25626.zip  train_data7332.zip\n",
            "train_data1647.zip   train_data25627.zip  train_data7333.zip\n",
            "train_data16480.zip  train_data25628.zip  train_data7334.zip\n",
            "train_data16481.zip  train_data25629.zip  train_data7335.zip\n",
            "train_data16482.zip  train_data2562.zip   train_data7336.zip\n",
            "train_data16483.zip  train_data25630.zip  train_data7337.zip\n",
            "train_data16484.zip  train_data25631.zip  train_data7338.zip\n",
            "train_data16485.zip  train_data25632.zip  train_data7339.zip\n",
            "train_data16486.zip  train_data25633.zip  train_data733.zip\n",
            "train_data16487.zip  train_data25634.zip  train_data7340.zip\n",
            "train_data16488.zip  train_data25635.zip  train_data7341.zip\n",
            "train_data16489.zip  train_data25636.zip  train_data7342.zip\n",
            "train_data1648.zip   train_data25637.zip  train_data7343.zip\n",
            "train_data16490.zip  train_data25638.zip  train_data7344.zip\n",
            "train_data16491.zip  train_data25639.zip  train_data7345.zip\n",
            "train_data16492.zip  train_data2563.zip   train_data7346.zip\n",
            "train_data16493.zip  train_data25640.zip  train_data7347.zip\n",
            "train_data16494.zip  train_data25641.zip  train_data7348.zip\n",
            "train_data16495.zip  train_data25642.zip  train_data7349.zip\n",
            "train_data16496.zip  train_data25643.zip  train_data734.zip\n",
            "train_data16497.zip  train_data25644.zip  train_data7350.zip\n",
            "train_data16498.zip  train_data25645.zip  train_data7351.zip\n",
            "train_data16499.zip  train_data25646.zip  train_data7352.zip\n",
            "train_data1649.zip   train_data25647.zip  train_data7353.zip\n",
            "train_data164.zip    train_data25648.zip  train_data7354.zip\n",
            "train_data16500.zip  train_data25649.zip  train_data7355.zip\n",
            "train_data16501.zip  train_data2564.zip   train_data7356.zip\n",
            "train_data16502.zip  train_data25650.zip  train_data7357.zip\n",
            "train_data16503.zip  train_data25651.zip  train_data7358.zip\n",
            "train_data16504.zip  train_data25652.zip  train_data7359.zip\n",
            "train_data16505.zip  train_data25653.zip  train_data735.zip\n",
            "train_data16506.zip  train_data25654.zip  train_data7360.zip\n",
            "train_data16507.zip  train_data25655.zip  train_data7361.zip\n",
            "train_data16508.zip  train_data25656.zip  train_data7362.zip\n",
            "train_data16509.zip  train_data25657.zip  train_data7363.zip\n",
            "train_data1650.zip   train_data25658.zip  train_data7364.zip\n",
            "train_data16510.zip  train_data25659.zip  train_data7365.zip\n",
            "train_data16511.zip  train_data2565.zip   train_data7366.zip\n",
            "train_data16512.zip  train_data25660.zip  train_data7367.zip\n",
            "train_data16513.zip  train_data25661.zip  train_data7368.zip\n",
            "train_data16514.zip  train_data25662.zip  train_data7369.zip\n",
            "train_data16515.zip  train_data25663.zip  train_data736.zip\n",
            "train_data16516.zip  train_data25664.zip  train_data7370.zip\n",
            "train_data16517.zip  train_data25665.zip  train_data7371.zip\n",
            "train_data16518.zip  train_data25666.zip  train_data7372.zip\n",
            "train_data16519.zip  train_data25667.zip  train_data7373.zip\n",
            "train_data1651.zip   train_data25668.zip  train_data7374.zip\n",
            "train_data16520.zip  train_data25669.zip  train_data7375.zip\n",
            "train_data16521.zip  train_data2566.zip   train_data7376.zip\n",
            "train_data16522.zip  train_data25670.zip  train_data7377.zip\n",
            "train_data16523.zip  train_data25671.zip  train_data7378.zip\n",
            "train_data16524.zip  train_data25672.zip  train_data7379.zip\n",
            "train_data16525.zip  train_data25673.zip  train_data737.zip\n",
            "train_data16526.zip  train_data25674.zip  train_data7380.zip\n",
            "train_data16527.zip  train_data25675.zip  train_data7381.zip\n",
            "train_data16528.zip  train_data25676.zip  train_data7382.zip\n",
            "train_data16529.zip  train_data25677.zip  train_data7383.zip\n",
            "train_data1652.zip   train_data25678.zip  train_data7384.zip\n",
            "train_data16530.zip  train_data25679.zip  train_data7385.zip\n",
            "train_data16531.zip  train_data2567.zip   train_data7386.zip\n",
            "train_data16532.zip  train_data25680.zip  train_data7387.zip\n",
            "train_data16533.zip  train_data25681.zip  train_data7388.zip\n",
            "train_data16534.zip  train_data25682.zip  train_data7389.zip\n",
            "train_data16535.zip  train_data25683.zip  train_data738.zip\n",
            "train_data16536.zip  train_data25684.zip  train_data7390.zip\n",
            "train_data16537.zip  train_data25685.zip  train_data7391.zip\n",
            "train_data16538.zip  train_data25686.zip  train_data7392.zip\n",
            "train_data16539.zip  train_data25687.zip  train_data7393.zip\n",
            "train_data1653.zip   train_data25688.zip  train_data7394.zip\n",
            "train_data16540.zip  train_data25689.zip  train_data7395.zip\n",
            "train_data16541.zip  train_data2568.zip   train_data7396.zip\n",
            "train_data16542.zip  train_data25690.zip  train_data7397.zip\n",
            "train_data16543.zip  train_data25691.zip  train_data7398.zip\n",
            "train_data16544.zip  train_data25692.zip  train_data7399.zip\n",
            "train_data16545.zip  train_data25693.zip  train_data739.zip\n",
            "train_data16546.zip  train_data25694.zip  train_data73.zip\n",
            "train_data16547.zip  train_data25695.zip  train_data7400.zip\n",
            "train_data16548.zip  train_data25696.zip  train_data7401.zip\n",
            "train_data16549.zip  train_data25697.zip  train_data7402.zip\n",
            "train_data1654.zip   train_data25698.zip  train_data7403.zip\n",
            "train_data16550.zip  train_data25699.zip  train_data7404.zip\n",
            "train_data16551.zip  train_data2569.zip   train_data7405.zip\n",
            "train_data16552.zip  train_data256.zip\t  train_data7406.zip\n",
            "train_data16553.zip  train_data25700.zip  train_data7407.zip\n",
            "train_data16554.zip  train_data25701.zip  train_data7408.zip\n",
            "train_data16555.zip  train_data25702.zip  train_data7409.zip\n",
            "train_data16556.zip  train_data25703.zip  train_data740.zip\n",
            "train_data16557.zip  train_data25704.zip  train_data7410.zip\n",
            "train_data16558.zip  train_data25705.zip  train_data7411.zip\n",
            "train_data16559.zip  train_data25706.zip  train_data7412.zip\n",
            "train_data1655.zip   train_data25707.zip  train_data7413.zip\n",
            "train_data16560.zip  train_data25708.zip  train_data7414.zip\n",
            "train_data16561.zip  train_data25709.zip  train_data7415.zip\n",
            "train_data16562.zip  train_data2570.zip   train_data7416.zip\n",
            "train_data16563.zip  train_data25710.zip  train_data7417.zip\n",
            "train_data16564.zip  train_data25711.zip  train_data7418.zip\n",
            "train_data16565.zip  train_data25712.zip  train_data7419.zip\n",
            "train_data16566.zip  train_data25713.zip  train_data741.zip\n",
            "train_data16567.zip  train_data25714.zip  train_data7420.zip\n",
            "train_data16568.zip  train_data25715.zip  train_data7421.zip\n",
            "train_data16569.zip  train_data25716.zip  train_data7422.zip\n",
            "train_data1656.zip   train_data25717.zip  train_data7423.zip\n",
            "train_data16570.zip  train_data25718.zip  train_data7424.zip\n",
            "train_data16571.zip  train_data25719.zip  train_data7425.zip\n",
            "train_data16572.zip  train_data2571.zip   train_data7426.zip\n",
            "train_data16573.zip  train_data25720.zip  train_data7427.zip\n",
            "train_data16574.zip  train_data25721.zip  train_data7428.zip\n",
            "train_data16575.zip  train_data25722.zip  train_data7429.zip\n",
            "train_data16576.zip  train_data25723.zip  train_data742.zip\n",
            "train_data16577.zip  train_data25724.zip  train_data7430.zip\n",
            "train_data16578.zip  train_data25725.zip  train_data7431.zip\n",
            "train_data16579.zip  train_data25726.zip  train_data7432.zip\n",
            "train_data1657.zip   train_data25727.zip  train_data7433.zip\n",
            "train_data16580.zip  train_data25728.zip  train_data7434.zip\n",
            "train_data16581.zip  train_data25729.zip  train_data7435.zip\n",
            "train_data16582.zip  train_data2572.zip   train_data7436.zip\n",
            "train_data16583.zip  train_data25730.zip  train_data7437.zip\n",
            "train_data16584.zip  train_data25731.zip  train_data7438.zip\n",
            "train_data16585.zip  train_data25732.zip  train_data7439.zip\n",
            "train_data16586.zip  train_data25733.zip  train_data743.zip\n",
            "train_data16587.zip  train_data25734.zip  train_data7440.zip\n",
            "train_data16588.zip  train_data25735.zip  train_data7441.zip\n",
            "train_data16589.zip  train_data25736.zip  train_data7442.zip\n",
            "train_data1658.zip   train_data25737.zip  train_data7443.zip\n",
            "train_data16590.zip  train_data25738.zip  train_data7444.zip\n",
            "train_data16591.zip  train_data25739.zip  train_data7445.zip\n",
            "train_data16592.zip  train_data2573.zip   train_data7446.zip\n",
            "train_data16593.zip  train_data25740.zip  train_data7447.zip\n",
            "train_data16594.zip  train_data25741.zip  train_data7448.zip\n",
            "train_data16595.zip  train_data25742.zip  train_data7449.zip\n",
            "train_data16596.zip  train_data25743.zip  train_data744.zip\n",
            "train_data16597.zip  train_data25744.zip  train_data7450.zip\n",
            "train_data16598.zip  train_data25745.zip  train_data7451.zip\n",
            "train_data16599.zip  train_data25746.zip  train_data7452.zip\n",
            "train_data1659.zip   train_data25747.zip  train_data7453.zip\n",
            "train_data165.zip    train_data25748.zip  train_data7454.zip\n",
            "train_data16600.zip  train_data25749.zip  train_data7455.zip\n",
            "train_data16601.zip  train_data2574.zip   train_data7456.zip\n",
            "train_data16602.zip  train_data25750.zip  train_data7457.zip\n",
            "train_data16603.zip  train_data25751.zip  train_data7458.zip\n",
            "train_data16604.zip  train_data25752.zip  train_data7459.zip\n",
            "train_data16605.zip  train_data25753.zip  train_data745.zip\n",
            "train_data16606.zip  train_data25754.zip  train_data7460.zip\n",
            "train_data16607.zip  train_data25755.zip  train_data7461.zip\n",
            "train_data16608.zip  train_data25756.zip  train_data7462.zip\n",
            "train_data16609.zip  train_data25757.zip  train_data7463.zip\n",
            "train_data1660.zip   train_data25758.zip  train_data7464.zip\n",
            "train_data16610.zip  train_data25759.zip  train_data7465.zip\n",
            "train_data16611.zip  train_data2575.zip   train_data7466.zip\n",
            "train_data16612.zip  train_data25760.zip  train_data7467.zip\n",
            "train_data16613.zip  train_data25761.zip  train_data7468.zip\n",
            "train_data16614.zip  train_data25762.zip  train_data7469.zip\n",
            "train_data16615.zip  train_data25763.zip  train_data746.zip\n",
            "train_data16616.zip  train_data25764.zip  train_data7470.zip\n",
            "train_data16617.zip  train_data25765.zip  train_data7471.zip\n",
            "train_data16618.zip  train_data25766.zip  train_data7472.zip\n",
            "train_data16619.zip  train_data25767.zip  train_data7473.zip\n",
            "train_data1661.zip   train_data25768.zip  train_data7474.zip\n",
            "train_data16620.zip  train_data25769.zip  train_data7475.zip\n",
            "train_data16621.zip  train_data2576.zip   train_data7476.zip\n",
            "train_data16622.zip  train_data25770.zip  train_data7477.zip\n",
            "train_data16623.zip  train_data25771.zip  train_data7478.zip\n",
            "train_data16624.zip  train_data25772.zip  train_data7479.zip\n",
            "train_data16625.zip  train_data25773.zip  train_data747.zip\n",
            "train_data16626.zip  train_data25774.zip  train_data7480.zip\n",
            "train_data16627.zip  train_data25775.zip  train_data7481.zip\n",
            "train_data16628.zip  train_data25776.zip  train_data7482.zip\n",
            "train_data16629.zip  train_data25777.zip  train_data7483.zip\n",
            "train_data1662.zip   train_data25778.zip  train_data7484.zip\n",
            "train_data16630.zip  train_data25779.zip  train_data7485.zip\n",
            "train_data16631.zip  train_data2577.zip   train_data7486.zip\n",
            "train_data16632.zip  train_data25780.zip  train_data7487.zip\n",
            "train_data16633.zip  train_data25781.zip  train_data7488.zip\n",
            "train_data16634.zip  train_data25782.zip  train_data7489.zip\n",
            "train_data16635.zip  train_data25783.zip  train_data748.zip\n",
            "train_data16636.zip  train_data25784.zip  train_data7490.zip\n",
            "train_data16637.zip  train_data25785.zip  train_data7491.zip\n",
            "train_data16638.zip  train_data25786.zip  train_data7492.zip\n",
            "train_data16639.zip  train_data25787.zip  train_data7493.zip\n",
            "train_data1663.zip   train_data25788.zip  train_data7494.zip\n",
            "train_data16640.zip  train_data25789.zip  train_data7495.zip\n",
            "train_data16641.zip  train_data2578.zip   train_data7496.zip\n",
            "train_data16642.zip  train_data25790.zip  train_data7497.zip\n",
            "train_data16643.zip  train_data25791.zip  train_data7498.zip\n",
            "train_data16644.zip  train_data25792.zip  train_data7499.zip\n",
            "train_data16645.zip  train_data25793.zip  train_data749.zip\n",
            "train_data16646.zip  train_data25794.zip  train_data74.zip\n",
            "train_data16647.zip  train_data25795.zip  train_data7500.zip\n",
            "train_data16648.zip  train_data25796.zip  train_data7501.zip\n",
            "train_data16649.zip  train_data25797.zip  train_data7502.zip\n",
            "train_data1664.zip   train_data25798.zip  train_data7503.zip\n",
            "train_data16650.zip  train_data25799.zip  train_data7504.zip\n",
            "train_data16651.zip  train_data2579.zip   train_data7505.zip\n",
            "train_data16652.zip  train_data257.zip\t  train_data7506.zip\n",
            "train_data16653.zip  train_data25800.zip  train_data7507.zip\n",
            "train_data16654.zip  train_data25801.zip  train_data7508.zip\n",
            "train_data16655.zip  train_data25802.zip  train_data7509.zip\n",
            "train_data16656.zip  train_data25803.zip  train_data750.zip\n",
            "train_data16657.zip  train_data25804.zip  train_data7510.zip\n",
            "train_data16658.zip  train_data25805.zip  train_data7511.zip\n",
            "train_data16659.zip  train_data25806.zip  train_data7512.zip\n",
            "train_data1665.zip   train_data25807.zip  train_data7513.zip\n",
            "train_data16660.zip  train_data25808.zip  train_data7514.zip\n",
            "train_data16661.zip  train_data25809.zip  train_data7515.zip\n",
            "train_data16662.zip  train_data2580.zip   train_data7516.zip\n",
            "train_data16663.zip  train_data25810.zip  train_data7517.zip\n",
            "train_data16664.zip  train_data25811.zip  train_data7518.zip\n",
            "train_data16665.zip  train_data25812.zip  train_data7519.zip\n",
            "train_data16666.zip  train_data25813.zip  train_data751.zip\n",
            "train_data16667.zip  train_data25814.zip  train_data7520.zip\n",
            "train_data16668.zip  train_data25815.zip  train_data7521.zip\n",
            "train_data16669.zip  train_data25816.zip  train_data7522.zip\n",
            "train_data1666.zip   train_data25817.zip  train_data7523.zip\n",
            "train_data16670.zip  train_data25818.zip  train_data7524.zip\n",
            "train_data16671.zip  train_data25819.zip  train_data7525.zip\n",
            "train_data16672.zip  train_data2581.zip   train_data7526.zip\n",
            "train_data16673.zip  train_data25820.zip  train_data7527.zip\n",
            "train_data16674.zip  train_data25821.zip  train_data7528.zip\n",
            "train_data16675.zip  train_data25822.zip  train_data7529.zip\n",
            "train_data16676.zip  train_data25823.zip  train_data752.zip\n",
            "train_data16677.zip  train_data25824.zip  train_data7530.zip\n",
            "train_data16678.zip  train_data25825.zip  train_data7531.zip\n",
            "train_data16679.zip  train_data25826.zip  train_data7532.zip\n",
            "train_data1667.zip   train_data25827.zip  train_data7533.zip\n",
            "train_data16680.zip  train_data25828.zip  train_data7534.zip\n",
            "train_data16681.zip  train_data25829.zip  train_data7535.zip\n",
            "train_data16682.zip  train_data2582.zip   train_data7536.zip\n",
            "train_data16683.zip  train_data25830.zip  train_data7537.zip\n",
            "train_data16684.zip  train_data25831.zip  train_data7538.zip\n",
            "train_data16685.zip  train_data25832.zip  train_data7539.zip\n",
            "train_data16686.zip  train_data25833.zip  train_data753.zip\n",
            "train_data16687.zip  train_data25834.zip  train_data7540.zip\n",
            "train_data16688.zip  train_data25835.zip  train_data7541.zip\n",
            "train_data16689.zip  train_data25836.zip  train_data7542.zip\n",
            "train_data1668.zip   train_data25837.zip  train_data7543.zip\n",
            "train_data16690.zip  train_data25838.zip  train_data7544.zip\n",
            "train_data16691.zip  train_data25839.zip  train_data7545.zip\n",
            "train_data16692.zip  train_data2583.zip   train_data7546.zip\n",
            "train_data16693.zip  train_data25840.zip  train_data7547.zip\n",
            "train_data16694.zip  train_data25841.zip  train_data7548.zip\n",
            "train_data16695.zip  train_data25842.zip  train_data7549.zip\n",
            "train_data16696.zip  train_data25843.zip  train_data754.zip\n",
            "train_data16697.zip  train_data25844.zip  train_data7550.zip\n",
            "train_data16698.zip  train_data25845.zip  train_data7551.zip\n",
            "train_data16699.zip  train_data25846.zip  train_data7552.zip\n",
            "train_data1669.zip   train_data25847.zip  train_data7553.zip\n",
            "train_data166.zip    train_data25848.zip  train_data7554.zip\n",
            "train_data16700.zip  train_data25849.zip  train_data7555.zip\n",
            "train_data16701.zip  train_data2584.zip   train_data7556.zip\n",
            "train_data16702.zip  train_data25850.zip  train_data7557.zip\n",
            "train_data16703.zip  train_data25851.zip  train_data7558.zip\n",
            "train_data16704.zip  train_data25852.zip  train_data7559.zip\n",
            "train_data16705.zip  train_data25853.zip  train_data755.zip\n",
            "train_data16706.zip  train_data25854.zip  train_data7560.zip\n",
            "train_data16707.zip  train_data25855.zip  train_data7561.zip\n",
            "train_data16708.zip  train_data25856.zip  train_data7562.zip\n",
            "train_data16709.zip  train_data25857.zip  train_data7563.zip\n",
            "train_data1670.zip   train_data25858.zip  train_data7564.zip\n",
            "train_data16710.zip  train_data25859.zip  train_data7565.zip\n",
            "train_data16711.zip  train_data2585.zip   train_data7566.zip\n",
            "train_data16712.zip  train_data25860.zip  train_data7567.zip\n",
            "train_data16713.zip  train_data25861.zip  train_data7568.zip\n",
            "train_data16714.zip  train_data25862.zip  train_data7569.zip\n",
            "train_data16715.zip  train_data25863.zip  train_data756.zip\n",
            "train_data16716.zip  train_data25864.zip  train_data7570.zip\n",
            "train_data16717.zip  train_data25865.zip  train_data7571.zip\n",
            "train_data16718.zip  train_data25866.zip  train_data7572.zip\n",
            "train_data16719.zip  train_data25867.zip  train_data7573.zip\n",
            "train_data1671.zip   train_data25868.zip  train_data7574.zip\n",
            "train_data16720.zip  train_data25869.zip  train_data7575.zip\n",
            "train_data16721.zip  train_data2586.zip   train_data7576.zip\n",
            "train_data16722.zip  train_data25870.zip  train_data7577.zip\n",
            "train_data16723.zip  train_data25871.zip  train_data7578.zip\n",
            "train_data16724.zip  train_data25872.zip  train_data7579.zip\n",
            "train_data16725.zip  train_data25873.zip  train_data757.zip\n",
            "train_data16726.zip  train_data25874.zip  train_data7580.zip\n",
            "train_data16727.zip  train_data25875.zip  train_data7581.zip\n",
            "train_data16728.zip  train_data25876.zip  train_data7582.zip\n",
            "train_data16729.zip  train_data25877.zip  train_data7583.zip\n",
            "train_data1672.zip   train_data25878.zip  train_data7584.zip\n",
            "train_data16730.zip  train_data25879.zip  train_data7585.zip\n",
            "train_data16731.zip  train_data2587.zip   train_data7586.zip\n",
            "train_data16732.zip  train_data25880.zip  train_data7587.zip\n",
            "train_data16733.zip  train_data25881.zip  train_data7588.zip\n",
            "train_data16734.zip  train_data25882.zip  train_data7589.zip\n",
            "train_data16735.zip  train_data25883.zip  train_data758.zip\n",
            "train_data16736.zip  train_data25884.zip  train_data7590.zip\n",
            "train_data16737.zip  train_data25885.zip  train_data7591.zip\n",
            "train_data16738.zip  train_data25886.zip  train_data7592.zip\n",
            "train_data16739.zip  train_data25887.zip  train_data7593.zip\n",
            "train_data1673.zip   train_data25888.zip  train_data7594.zip\n",
            "train_data16740.zip  train_data25889.zip  train_data7595.zip\n",
            "train_data16741.zip  train_data2588.zip   train_data7596.zip\n",
            "train_data16742.zip  train_data25890.zip  train_data7597.zip\n",
            "train_data16743.zip  train_data25891.zip  train_data7598.zip\n",
            "train_data16744.zip  train_data25892.zip  train_data7599.zip\n",
            "train_data16745.zip  train_data25893.zip  train_data759.zip\n",
            "train_data16746.zip  train_data25894.zip  train_data75.zip\n",
            "train_data16747.zip  train_data25895.zip  train_data7600.zip\n",
            "train_data16748.zip  train_data25896.zip  train_data7601.zip\n",
            "train_data16749.zip  train_data25897.zip  train_data7602.zip\n",
            "train_data1674.zip   train_data25898.zip  train_data7603.zip\n",
            "train_data16750.zip  train_data25899.zip  train_data7604.zip\n",
            "train_data16751.zip  train_data2589.zip   train_data7605.zip\n",
            "train_data16752.zip  train_data258.zip\t  train_data7606.zip\n",
            "train_data16753.zip  train_data25900.zip  train_data7607.zip\n",
            "train_data16754.zip  train_data25901.zip  train_data7608.zip\n",
            "train_data16755.zip  train_data25902.zip  train_data7609.zip\n",
            "train_data16756.zip  train_data25903.zip  train_data760.zip\n",
            "train_data16757.zip  train_data25904.zip  train_data7610.zip\n",
            "train_data16758.zip  train_data25905.zip  train_data7611.zip\n",
            "train_data16759.zip  train_data25906.zip  train_data7612.zip\n",
            "train_data1675.zip   train_data25907.zip  train_data7613.zip\n",
            "train_data16760.zip  train_data25908.zip  train_data7614.zip\n",
            "train_data16761.zip  train_data25909.zip  train_data7615.zip\n",
            "train_data16762.zip  train_data2590.zip   train_data7616.zip\n",
            "train_data16763.zip  train_data25910.zip  train_data7617.zip\n",
            "train_data16764.zip  train_data25911.zip  train_data7618.zip\n",
            "train_data16765.zip  train_data25912.zip  train_data7619.zip\n",
            "train_data16766.zip  train_data25913.zip  train_data761.zip\n",
            "train_data16767.zip  train_data25914.zip  train_data7620.zip\n",
            "train_data16768.zip  train_data25915.zip  train_data7621.zip\n",
            "train_data16769.zip  train_data25916.zip  train_data7622.zip\n",
            "train_data1676.zip   train_data25917.zip  train_data7623.zip\n",
            "train_data16770.zip  train_data25918.zip  train_data7624.zip\n",
            "train_data16771.zip  train_data25919.zip  train_data7625.zip\n",
            "train_data16772.zip  train_data2591.zip   train_data7626.zip\n",
            "train_data16773.zip  train_data25920.zip  train_data7627.zip\n",
            "train_data16774.zip  train_data25921.zip  train_data7628.zip\n",
            "train_data16775.zip  train_data25922.zip  train_data7629.zip\n",
            "train_data16776.zip  train_data25923.zip  train_data762.zip\n",
            "train_data16777.zip  train_data25924.zip  train_data7630.zip\n",
            "train_data16778.zip  train_data25925.zip  train_data7631.zip\n",
            "train_data16779.zip  train_data25926.zip  train_data7632.zip\n",
            "train_data1677.zip   train_data25927.zip  train_data7633.zip\n",
            "train_data16780.zip  train_data25928.zip  train_data7634.zip\n",
            "train_data16781.zip  train_data25929.zip  train_data7635.zip\n",
            "train_data16782.zip  train_data2592.zip   train_data7636.zip\n",
            "train_data16783.zip  train_data25930.zip  train_data7637.zip\n",
            "train_data16784.zip  train_data25931.zip  train_data7638.zip\n",
            "train_data16785.zip  train_data25932.zip  train_data7639.zip\n",
            "train_data16786.zip  train_data25933.zip  train_data763.zip\n",
            "train_data16787.zip  train_data25934.zip  train_data7640.zip\n",
            "train_data16788.zip  train_data25935.zip  train_data7641.zip\n",
            "train_data16789.zip  train_data25936.zip  train_data7642.zip\n",
            "train_data1678.zip   train_data25937.zip  train_data7643.zip\n",
            "train_data16790.zip  train_data25938.zip  train_data7644.zip\n",
            "train_data16791.zip  train_data25939.zip  train_data7645.zip\n",
            "train_data16792.zip  train_data2593.zip   train_data7646.zip\n",
            "train_data16793.zip  train_data25940.zip  train_data7647.zip\n",
            "train_data16794.zip  train_data25941.zip  train_data7648.zip\n",
            "train_data16795.zip  train_data25942.zip  train_data7649.zip\n",
            "train_data16796.zip  train_data25943.zip  train_data764.zip\n",
            "train_data16797.zip  train_data25944.zip  train_data7650.zip\n",
            "train_data16798.zip  train_data25945.zip  train_data7651.zip\n",
            "train_data16799.zip  train_data25946.zip  train_data7652.zip\n",
            "train_data1679.zip   train_data25947.zip  train_data7653.zip\n",
            "train_data167.zip    train_data25948.zip  train_data7654.zip\n",
            "train_data16800.zip  train_data25949.zip  train_data7655.zip\n",
            "train_data16801.zip  train_data2594.zip   train_data7656.zip\n",
            "train_data16802.zip  train_data25950.zip  train_data7657.zip\n",
            "train_data16803.zip  train_data25951.zip  train_data7658.zip\n",
            "train_data16804.zip  train_data25952.zip  train_data7659.zip\n",
            "train_data16805.zip  train_data25953.zip  train_data765.zip\n",
            "train_data16806.zip  train_data25954.zip  train_data7660.zip\n",
            "train_data16807.zip  train_data25955.zip  train_data7661.zip\n",
            "train_data16808.zip  train_data25956.zip  train_data7662.zip\n",
            "train_data16809.zip  train_data25957.zip  train_data7663.zip\n",
            "train_data1680.zip   train_data25958.zip  train_data7664.zip\n",
            "train_data16810.zip  train_data25959.zip  train_data7665.zip\n",
            "train_data16811.zip  train_data2595.zip   train_data7666.zip\n",
            "train_data16812.zip  train_data25960.zip  train_data7667.zip\n",
            "train_data16813.zip  train_data25961.zip  train_data7668.zip\n",
            "train_data16814.zip  train_data25962.zip  train_data7669.zip\n",
            "train_data16815.zip  train_data25963.zip  train_data766.zip\n",
            "train_data16816.zip  train_data25964.zip  train_data7670.zip\n",
            "train_data16817.zip  train_data25965.zip  train_data7671.zip\n",
            "train_data16818.zip  train_data25966.zip  train_data7672.zip\n",
            "train_data16819.zip  train_data25967.zip  train_data7673.zip\n",
            "train_data1681.zip   train_data25968.zip  train_data7674.zip\n",
            "train_data16820.zip  train_data25969.zip  train_data7675.zip\n",
            "train_data16821.zip  train_data2596.zip   train_data7676.zip\n",
            "train_data16822.zip  train_data25970.zip  train_data7677.zip\n",
            "train_data16823.zip  train_data25971.zip  train_data7678.zip\n",
            "train_data16824.zip  train_data25972.zip  train_data7679.zip\n",
            "train_data16825.zip  train_data25973.zip  train_data767.zip\n",
            "train_data16826.zip  train_data25974.zip  train_data7680.zip\n",
            "train_data16827.zip  train_data25975.zip  train_data7681.zip\n",
            "train_data16828.zip  train_data25976.zip  train_data7682.zip\n",
            "train_data16829.zip  train_data25977.zip  train_data7683.zip\n",
            "train_data1682.zip   train_data25978.zip  train_data7684.zip\n",
            "train_data16830.zip  train_data25979.zip  train_data7685.zip\n",
            "train_data16831.zip  train_data2597.zip   train_data7686.zip\n",
            "train_data16832.zip  train_data25980.zip  train_data7687.zip\n",
            "train_data16833.zip  train_data25981.zip  train_data7688.zip\n",
            "train_data16834.zip  train_data25982.zip  train_data7689.zip\n",
            "train_data16835.zip  train_data25983.zip  train_data768.zip\n",
            "train_data16836.zip  train_data25984.zip  train_data7690.zip\n",
            "train_data16837.zip  train_data25985.zip  train_data7691.zip\n",
            "train_data16838.zip  train_data25986.zip  train_data7692.zip\n",
            "train_data16839.zip  train_data25987.zip  train_data7693.zip\n",
            "train_data1683.zip   train_data25988.zip  train_data7694.zip\n",
            "train_data16840.zip  train_data25989.zip  train_data7695.zip\n",
            "train_data16841.zip  train_data2598.zip   train_data7696.zip\n",
            "train_data16842.zip  train_data25990.zip  train_data7697.zip\n",
            "train_data16843.zip  train_data25991.zip  train_data7698.zip\n",
            "train_data16844.zip  train_data25992.zip  train_data7699.zip\n",
            "train_data16845.zip  train_data25993.zip  train_data769.zip\n",
            "train_data16846.zip  train_data25994.zip  train_data76.zip\n",
            "train_data16847.zip  train_data25995.zip  train_data7700.zip\n",
            "train_data16848.zip  train_data25996.zip  train_data7701.zip\n",
            "train_data16849.zip  train_data25997.zip  train_data7702.zip\n",
            "train_data1684.zip   train_data25998.zip  train_data7703.zip\n",
            "train_data16850.zip  train_data25999.zip  train_data7704.zip\n",
            "train_data16851.zip  train_data2599.zip   train_data7705.zip\n",
            "train_data16852.zip  train_data259.zip\t  train_data7706.zip\n",
            "train_data16853.zip  train_data25.zip\t  train_data7707.zip\n",
            "train_data16854.zip  train_data26000.zip  train_data7708.zip\n",
            "train_data16855.zip  train_data26001.zip  train_data7709.zip\n",
            "train_data16856.zip  train_data26002.zip  train_data770.zip\n",
            "train_data16857.zip  train_data26003.zip  train_data7710.zip\n",
            "train_data16858.zip  train_data26004.zip  train_data7711.zip\n",
            "train_data16859.zip  train_data26005.zip  train_data7712.zip\n",
            "train_data1685.zip   train_data26006.zip  train_data7713.zip\n",
            "train_data16860.zip  train_data26007.zip  train_data7714.zip\n",
            "train_data16861.zip  train_data26008.zip  train_data7715.zip\n",
            "train_data16862.zip  train_data26009.zip  train_data7716.zip\n",
            "train_data16863.zip  train_data2600.zip   train_data7717.zip\n",
            "train_data16864.zip  train_data26010.zip  train_data7718.zip\n",
            "train_data16865.zip  train_data26011.zip  train_data7719.zip\n",
            "train_data16866.zip  train_data26012.zip  train_data771.zip\n",
            "train_data16867.zip  train_data26013.zip  train_data7720.zip\n",
            "train_data16868.zip  train_data26014.zip  train_data7721.zip\n",
            "train_data16869.zip  train_data26015.zip  train_data7722.zip\n",
            "train_data1686.zip   train_data26016.zip  train_data7723.zip\n",
            "train_data16870.zip  train_data26017.zip  train_data7724.zip\n",
            "train_data16871.zip  train_data26018.zip  train_data7725.zip\n",
            "train_data16872.zip  train_data26019.zip  train_data7726.zip\n",
            "train_data16873.zip  train_data2601.zip   train_data7727.zip\n",
            "train_data16874.zip  train_data26020.zip  train_data7728.zip\n",
            "train_data16875.zip  train_data26021.zip  train_data7729.zip\n",
            "train_data16876.zip  train_data26022.zip  train_data772.zip\n",
            "train_data16877.zip  train_data26023.zip  train_data7730.zip\n",
            "train_data16878.zip  train_data26024.zip  train_data7731.zip\n",
            "train_data16879.zip  train_data26025.zip  train_data7732.zip\n",
            "train_data1687.zip   train_data26026.zip  train_data7733.zip\n",
            "train_data16880.zip  train_data26027.zip  train_data7734.zip\n",
            "train_data16881.zip  train_data26028.zip  train_data7735.zip\n",
            "train_data16882.zip  train_data26029.zip  train_data7736.zip\n",
            "train_data16883.zip  train_data2602.zip   train_data7737.zip\n",
            "train_data16884.zip  train_data26030.zip  train_data7738.zip\n",
            "train_data16885.zip  train_data26031.zip  train_data7739.zip\n",
            "train_data16886.zip  train_data26032.zip  train_data773.zip\n",
            "train_data16887.zip  train_data26033.zip  train_data7740.zip\n",
            "train_data16888.zip  train_data26034.zip  train_data7741.zip\n",
            "train_data16889.zip  train_data26035.zip  train_data7742.zip\n",
            "train_data1688.zip   train_data26036.zip  train_data7743.zip\n",
            "train_data16890.zip  train_data26037.zip  train_data7744.zip\n",
            "train_data16891.zip  train_data26038.zip  train_data7745.zip\n",
            "train_data16892.zip  train_data26039.zip  train_data7746.zip\n",
            "train_data16893.zip  train_data2603.zip   train_data7747.zip\n",
            "train_data16894.zip  train_data26040.zip  train_data7748.zip\n",
            "train_data16895.zip  train_data26041.zip  train_data7749.zip\n",
            "train_data16896.zip  train_data26042.zip  train_data774.zip\n",
            "train_data16897.zip  train_data26043.zip  train_data7750.zip\n",
            "train_data16898.zip  train_data26044.zip  train_data7751.zip\n",
            "train_data16899.zip  train_data26045.zip  train_data7752.zip\n",
            "train_data1689.zip   train_data26046.zip  train_data7753.zip\n",
            "train_data168.zip    train_data26047.zip  train_data7754.zip\n",
            "train_data16900.zip  train_data26048.zip  train_data7755.zip\n",
            "train_data16901.zip  train_data26049.zip  train_data7756.zip\n",
            "train_data16902.zip  train_data2604.zip   train_data7757.zip\n",
            "train_data16903.zip  train_data26050.zip  train_data7758.zip\n",
            "train_data16904.zip  train_data26051.zip  train_data7759.zip\n",
            "train_data16905.zip  train_data26052.zip  train_data775.zip\n",
            "train_data16906.zip  train_data26053.zip  train_data7760.zip\n",
            "train_data16907.zip  train_data26054.zip  train_data7761.zip\n",
            "train_data16908.zip  train_data26055.zip  train_data7762.zip\n",
            "train_data16909.zip  train_data26056.zip  train_data7763.zip\n",
            "train_data1690.zip   train_data26057.zip  train_data7764.zip\n",
            "train_data16910.zip  train_data26058.zip  train_data7765.zip\n",
            "train_data16911.zip  train_data26059.zip  train_data7766.zip\n",
            "train_data16912.zip  train_data2605.zip   train_data7767.zip\n",
            "train_data16913.zip  train_data26060.zip  train_data7768.zip\n",
            "train_data16914.zip  train_data26061.zip  train_data7769.zip\n",
            "train_data16915.zip  train_data26062.zip  train_data776.zip\n",
            "train_data16916.zip  train_data26063.zip  train_data7770.zip\n",
            "train_data16917.zip  train_data26064.zip  train_data7771.zip\n",
            "train_data16918.zip  train_data26065.zip  train_data7772.zip\n",
            "train_data16919.zip  train_data26066.zip  train_data7773.zip\n",
            "train_data1691.zip   train_data26067.zip  train_data7774.zip\n",
            "train_data16920.zip  train_data26068.zip  train_data7775.zip\n",
            "train_data16921.zip  train_data26069.zip  train_data7776.zip\n",
            "train_data16922.zip  train_data2606.zip   train_data7777.zip\n",
            "train_data16923.zip  train_data26070.zip  train_data7778.zip\n",
            "train_data16924.zip  train_data26071.zip  train_data7779.zip\n",
            "train_data16925.zip  train_data26072.zip  train_data777.zip\n",
            "train_data16926.zip  train_data26073.zip  train_data7780.zip\n",
            "train_data16927.zip  train_data26074.zip  train_data7781.zip\n",
            "train_data16928.zip  train_data26075.zip  train_data7782.zip\n",
            "train_data16929.zip  train_data26076.zip  train_data7783.zip\n",
            "train_data1692.zip   train_data26077.zip  train_data7784.zip\n",
            "train_data16930.zip  train_data26078.zip  train_data7785.zip\n",
            "train_data16931.zip  train_data26079.zip  train_data7786.zip\n",
            "train_data16932.zip  train_data2607.zip   train_data7787.zip\n",
            "train_data16933.zip  train_data26080.zip  train_data7788.zip\n",
            "train_data16934.zip  train_data26081.zip  train_data7789.zip\n",
            "train_data16935.zip  train_data26082.zip  train_data778.zip\n",
            "train_data16936.zip  train_data26083.zip  train_data7790.zip\n",
            "train_data16937.zip  train_data26084.zip  train_data7791.zip\n",
            "train_data16938.zip  train_data26085.zip  train_data7792.zip\n",
            "train_data16939.zip  train_data26086.zip  train_data7793.zip\n",
            "train_data1693.zip   train_data26087.zip  train_data7794.zip\n",
            "train_data16940.zip  train_data26088.zip  train_data7795.zip\n",
            "train_data16941.zip  train_data26089.zip  train_data7796.zip\n",
            "train_data16942.zip  train_data2608.zip   train_data7797.zip\n",
            "train_data16943.zip  train_data26090.zip  train_data7798.zip\n",
            "train_data16944.zip  train_data26091.zip  train_data7799.zip\n",
            "train_data16945.zip  train_data26092.zip  train_data779.zip\n",
            "train_data16946.zip  train_data26093.zip  train_data77.zip\n",
            "train_data16947.zip  train_data26094.zip  train_data7800.zip\n",
            "train_data16948.zip  train_data26095.zip  train_data7801.zip\n",
            "train_data16949.zip  train_data26096.zip  train_data7802.zip\n",
            "train_data1694.zip   train_data26097.zip  train_data7803.zip\n",
            "train_data16950.zip  train_data26098.zip  train_data7804.zip\n",
            "train_data16951.zip  train_data26099.zip  train_data7805.zip\n",
            "train_data16952.zip  train_data2609.zip   train_data7806.zip\n",
            "train_data16953.zip  train_data260.zip\t  train_data7807.zip\n",
            "train_data16954.zip  train_data26100.zip  train_data7808.zip\n",
            "train_data16955.zip  train_data26101.zip  train_data7809.zip\n",
            "train_data16956.zip  train_data26102.zip  train_data780.zip\n",
            "train_data16957.zip  train_data26103.zip  train_data7810.zip\n",
            "train_data16958.zip  train_data26104.zip  train_data7811.zip\n",
            "train_data16959.zip  train_data26105.zip  train_data7812.zip\n",
            "train_data1695.zip   train_data26106.zip  train_data7813.zip\n",
            "train_data16960.zip  train_data26107.zip  train_data7814.zip\n",
            "train_data16961.zip  train_data26108.zip  train_data7815.zip\n",
            "train_data16962.zip  train_data26109.zip  train_data7816.zip\n",
            "train_data16963.zip  train_data2610.zip   train_data7817.zip\n",
            "train_data16964.zip  train_data26110.zip  train_data7818.zip\n",
            "train_data16965.zip  train_data26111.zip  train_data7819.zip\n",
            "train_data16966.zip  train_data26112.zip  train_data781.zip\n",
            "train_data16967.zip  train_data26113.zip  train_data7820.zip\n",
            "train_data16968.zip  train_data26114.zip  train_data7821.zip\n",
            "train_data16969.zip  train_data26115.zip  train_data7822.zip\n",
            "train_data1696.zip   train_data26116.zip  train_data7823.zip\n",
            "train_data16970.zip  train_data26117.zip  train_data7824.zip\n",
            "train_data16971.zip  train_data26118.zip  train_data7825.zip\n",
            "train_data16972.zip  train_data26119.zip  train_data7826.zip\n",
            "train_data16973.zip  train_data2611.zip   train_data7827.zip\n",
            "train_data16974.zip  train_data26120.zip  train_data7828.zip\n",
            "train_data16975.zip  train_data26121.zip  train_data7829.zip\n",
            "train_data16976.zip  train_data26122.zip  train_data782.zip\n",
            "train_data16977.zip  train_data26123.zip  train_data7830.zip\n",
            "train_data16978.zip  train_data26124.zip  train_data7831.zip\n",
            "train_data16979.zip  train_data26125.zip  train_data7832.zip\n",
            "train_data1697.zip   train_data26126.zip  train_data7833.zip\n",
            "train_data16980.zip  train_data26127.zip  train_data7834.zip\n",
            "train_data16981.zip  train_data26128.zip  train_data7835.zip\n",
            "train_data16982.zip  train_data26129.zip  train_data7836.zip\n",
            "train_data16983.zip  train_data2612.zip   train_data7837.zip\n",
            "train_data16984.zip  train_data26130.zip  train_data7838.zip\n",
            "train_data16985.zip  train_data26131.zip  train_data7839.zip\n",
            "train_data16986.zip  train_data26132.zip  train_data783.zip\n",
            "train_data16987.zip  train_data26133.zip  train_data7840.zip\n",
            "train_data16988.zip  train_data26134.zip  train_data7841.zip\n",
            "train_data16989.zip  train_data26135.zip  train_data7842.zip\n",
            "train_data1698.zip   train_data26136.zip  train_data7843.zip\n",
            "train_data16990.zip  train_data26137.zip  train_data7844.zip\n",
            "train_data16991.zip  train_data26138.zip  train_data7845.zip\n",
            "train_data16992.zip  train_data26139.zip  train_data7846.zip\n",
            "train_data16993.zip  train_data2613.zip   train_data7847.zip\n",
            "train_data16994.zip  train_data26140.zip  train_data7848.zip\n",
            "train_data16995.zip  train_data26141.zip  train_data7849.zip\n",
            "train_data16996.zip  train_data26142.zip  train_data784.zip\n",
            "train_data16997.zip  train_data26143.zip  train_data7850.zip\n",
            "train_data16998.zip  train_data26144.zip  train_data7851.zip\n",
            "train_data16999.zip  train_data26145.zip  train_data7852.zip\n",
            "train_data1699.zip   train_data26146.zip  train_data7853.zip\n",
            "train_data169.zip    train_data26147.zip  train_data7854.zip\n",
            "train_data16.zip     train_data26148.zip  train_data7855.zip\n",
            "train_data17000.zip  train_data26149.zip  train_data7856.zip\n",
            "train_data17001.zip  train_data2614.zip   train_data7857.zip\n",
            "train_data17002.zip  train_data26150.zip  train_data7858.zip\n",
            "train_data17003.zip  train_data26151.zip  train_data7859.zip\n",
            "train_data17004.zip  train_data26152.zip  train_data785.zip\n",
            "train_data17005.zip  train_data26153.zip  train_data7860.zip\n",
            "train_data17006.zip  train_data26154.zip  train_data7861.zip\n",
            "train_data17007.zip  train_data26155.zip  train_data7862.zip\n",
            "train_data17008.zip  train_data26156.zip  train_data7863.zip\n",
            "train_data17009.zip  train_data26157.zip  train_data7864.zip\n",
            "train_data1700.zip   train_data26158.zip  train_data7865.zip\n",
            "train_data17010.zip  train_data26159.zip  train_data7866.zip\n",
            "train_data17011.zip  train_data2615.zip   train_data7867.zip\n",
            "train_data17012.zip  train_data26160.zip  train_data7868.zip\n",
            "train_data17013.zip  train_data26161.zip  train_data7869.zip\n",
            "train_data17014.zip  train_data26162.zip  train_data786.zip\n",
            "train_data17015.zip  train_data26163.zip  train_data7870.zip\n",
            "train_data17016.zip  train_data26164.zip  train_data7871.zip\n",
            "train_data17017.zip  train_data26165.zip  train_data7872.zip\n",
            "train_data17018.zip  train_data26166.zip  train_data7873.zip\n",
            "train_data17019.zip  train_data26167.zip  train_data7874.zip\n",
            "train_data1701.zip   train_data26168.zip  train_data7875.zip\n",
            "train_data17020.zip  train_data26169.zip  train_data7876.zip\n",
            "train_data17021.zip  train_data2616.zip   train_data7877.zip\n",
            "train_data17022.zip  train_data26170.zip  train_data7878.zip\n",
            "train_data17023.zip  train_data26171.zip  train_data7879.zip\n",
            "train_data17024.zip  train_data26172.zip  train_data787.zip\n",
            "train_data17025.zip  train_data26173.zip  train_data7880.zip\n",
            "train_data17026.zip  train_data26174.zip  train_data7881.zip\n",
            "train_data17027.zip  train_data26175.zip  train_data7882.zip\n",
            "train_data17028.zip  train_data26176.zip  train_data7883.zip\n",
            "train_data17029.zip  train_data26177.zip  train_data7884.zip\n",
            "train_data1702.zip   train_data26178.zip  train_data7885.zip\n",
            "train_data17030.zip  train_data26179.zip  train_data7886.zip\n",
            "train_data17031.zip  train_data2617.zip   train_data7887.zip\n",
            "train_data17032.zip  train_data26180.zip  train_data7888.zip\n",
            "train_data17033.zip  train_data26181.zip  train_data7889.zip\n",
            "train_data17034.zip  train_data26182.zip  train_data788.zip\n",
            "train_data17035.zip  train_data26183.zip  train_data7890.zip\n",
            "train_data17036.zip  train_data26184.zip  train_data7891.zip\n",
            "train_data17037.zip  train_data26185.zip  train_data7892.zip\n",
            "train_data17038.zip  train_data26186.zip  train_data7893.zip\n",
            "train_data17039.zip  train_data26187.zip  train_data7894.zip\n",
            "train_data1703.zip   train_data26188.zip  train_data7895.zip\n",
            "train_data17040.zip  train_data26189.zip  train_data7896.zip\n",
            "train_data17041.zip  train_data2618.zip   train_data7897.zip\n",
            "train_data17042.zip  train_data26190.zip  train_data7898.zip\n",
            "train_data17043.zip  train_data26191.zip  train_data7899.zip\n",
            "train_data17044.zip  train_data26192.zip  train_data789.zip\n",
            "train_data17045.zip  train_data26193.zip  train_data78.zip\n",
            "train_data17046.zip  train_data26194.zip  train_data7900.zip\n",
            "train_data17047.zip  train_data26195.zip  train_data7901.zip\n",
            "train_data17048.zip  train_data26196.zip  train_data7902.zip\n",
            "train_data17049.zip  train_data26197.zip  train_data7903.zip\n",
            "train_data1704.zip   train_data26198.zip  train_data7904.zip\n",
            "train_data17050.zip  train_data26199.zip  train_data7905.zip\n",
            "train_data17051.zip  train_data2619.zip   train_data7906.zip\n",
            "train_data17052.zip  train_data261.zip\t  train_data7907.zip\n",
            "train_data17053.zip  train_data26200.zip  train_data7908.zip\n",
            "train_data17054.zip  train_data26201.zip  train_data7909.zip\n",
            "train_data17055.zip  train_data26202.zip  train_data790.zip\n",
            "train_data17056.zip  train_data26203.zip  train_data7910.zip\n",
            "train_data17057.zip  train_data26204.zip  train_data7911.zip\n",
            "train_data17058.zip  train_data26205.zip  train_data7912.zip\n",
            "train_data17059.zip  train_data26206.zip  train_data7913.zip\n",
            "train_data1705.zip   train_data26207.zip  train_data7914.zip\n",
            "train_data17060.zip  train_data26208.zip  train_data7915.zip\n",
            "train_data17061.zip  train_data26209.zip  train_data7916.zip\n",
            "train_data17062.zip  train_data2620.zip   train_data7917.zip\n",
            "train_data17063.zip  train_data26210.zip  train_data7918.zip\n",
            "train_data17064.zip  train_data26211.zip  train_data7919.zip\n",
            "train_data17065.zip  train_data26212.zip  train_data791.zip\n",
            "train_data17066.zip  train_data26213.zip  train_data7920.zip\n",
            "train_data17067.zip  train_data26214.zip  train_data7921.zip\n",
            "train_data17068.zip  train_data26215.zip  train_data7922.zip\n",
            "train_data17069.zip  train_data26216.zip  train_data7923.zip\n",
            "train_data1706.zip   train_data26217.zip  train_data7924.zip\n",
            "train_data17070.zip  train_data26218.zip  train_data7925.zip\n",
            "train_data17071.zip  train_data26219.zip  train_data7926.zip\n",
            "train_data17072.zip  train_data2621.zip   train_data7927.zip\n",
            "train_data17073.zip  train_data26220.zip  train_data7928.zip\n",
            "train_data17074.zip  train_data26221.zip  train_data7929.zip\n",
            "train_data17075.zip  train_data26222.zip  train_data792.zip\n",
            "train_data17076.zip  train_data26223.zip  train_data7930.zip\n",
            "train_data17077.zip  train_data26224.zip  train_data7931.zip\n",
            "train_data17078.zip  train_data26225.zip  train_data7932.zip\n",
            "train_data17079.zip  train_data26226.zip  train_data7933.zip\n",
            "train_data1707.zip   train_data26227.zip  train_data7934.zip\n",
            "train_data17080.zip  train_data26228.zip  train_data7935.zip\n",
            "train_data17081.zip  train_data26229.zip  train_data7936.zip\n",
            "train_data17082.zip  train_data2622.zip   train_data7937.zip\n",
            "train_data17083.zip  train_data26230.zip  train_data7938.zip\n",
            "train_data17084.zip  train_data26231.zip  train_data7939.zip\n",
            "train_data17085.zip  train_data26232.zip  train_data793.zip\n",
            "train_data17086.zip  train_data26233.zip  train_data7940.zip\n",
            "train_data17087.zip  train_data26234.zip  train_data7941.zip\n",
            "train_data17088.zip  train_data26235.zip  train_data7942.zip\n",
            "train_data17089.zip  train_data26236.zip  train_data7943.zip\n",
            "train_data1708.zip   train_data26237.zip  train_data7944.zip\n",
            "train_data17090.zip  train_data26238.zip  train_data7945.zip\n",
            "train_data17091.zip  train_data26239.zip  train_data7946.zip\n",
            "train_data17092.zip  train_data2623.zip   train_data7947.zip\n",
            "train_data17093.zip  train_data26240.zip  train_data7948.zip\n",
            "train_data17094.zip  train_data26241.zip  train_data7949.zip\n",
            "train_data17095.zip  train_data26242.zip  train_data794.zip\n",
            "train_data17096.zip  train_data26243.zip  train_data7950.zip\n",
            "train_data17097.zip  train_data26244.zip  train_data7951.zip\n",
            "train_data17098.zip  train_data26245.zip  train_data7952.zip\n",
            "train_data17099.zip  train_data26246.zip  train_data7953.zip\n",
            "train_data1709.zip   train_data26247.zip  train_data7954.zip\n",
            "train_data170.zip    train_data26248.zip  train_data7955.zip\n",
            "train_data17100.zip  train_data26249.zip  train_data7956.zip\n",
            "train_data17101.zip  train_data2624.zip   train_data7957.zip\n",
            "train_data17102.zip  train_data26250.zip  train_data7958.zip\n",
            "train_data17103.zip  train_data26251.zip  train_data7959.zip\n",
            "train_data17104.zip  train_data26252.zip  train_data795.zip\n",
            "train_data17105.zip  train_data26253.zip  train_data7960.zip\n",
            "train_data17106.zip  train_data26254.zip  train_data7961.zip\n",
            "train_data17107.zip  train_data26255.zip  train_data7962.zip\n",
            "train_data17108.zip  train_data26256.zip  train_data7963.zip\n",
            "train_data17109.zip  train_data26257.zip  train_data7964.zip\n",
            "train_data1710.zip   train_data26258.zip  train_data7965.zip\n",
            "train_data17110.zip  train_data26259.zip  train_data7966.zip\n",
            "train_data17111.zip  train_data2625.zip   train_data7967.zip\n",
            "train_data17112.zip  train_data26260.zip  train_data7968.zip\n",
            "train_data17113.zip  train_data26261.zip  train_data7969.zip\n",
            "train_data17114.zip  train_data26262.zip  train_data796.zip\n",
            "train_data17115.zip  train_data26263.zip  train_data7970.zip\n",
            "train_data17116.zip  train_data26264.zip  train_data7971.zip\n",
            "train_data17117.zip  train_data26265.zip  train_data7972.zip\n",
            "train_data17118.zip  train_data26266.zip  train_data7973.zip\n",
            "train_data17119.zip  train_data26267.zip  train_data7974.zip\n",
            "train_data1711.zip   train_data26268.zip  train_data7975.zip\n",
            "train_data17120.zip  train_data26269.zip  train_data7976.zip\n",
            "train_data17121.zip  train_data2626.zip   train_data7977.zip\n",
            "train_data17122.zip  train_data26270.zip  train_data7978.zip\n",
            "train_data17123.zip  train_data26271.zip  train_data7979.zip\n",
            "train_data17124.zip  train_data26272.zip  train_data797.zip\n",
            "train_data17125.zip  train_data26273.zip  train_data7980.zip\n",
            "train_data17126.zip  train_data26274.zip  train_data7981.zip\n",
            "train_data17127.zip  train_data26275.zip  train_data7982.zip\n",
            "train_data17128.zip  train_data26276.zip  train_data7983.zip\n",
            "train_data17129.zip  train_data26277.zip  train_data7984.zip\n",
            "train_data1712.zip   train_data26278.zip  train_data7985.zip\n",
            "train_data17130.zip  train_data26279.zip  train_data7986.zip\n",
            "train_data17131.zip  train_data2627.zip   train_data7987.zip\n",
            "train_data17132.zip  train_data26280.zip  train_data7988.zip\n",
            "train_data17133.zip  train_data26281.zip  train_data7989.zip\n",
            "train_data17134.zip  train_data26282.zip  train_data798.zip\n",
            "train_data17135.zip  train_data26283.zip  train_data7990.zip\n",
            "train_data17136.zip  train_data26284.zip  train_data7991.zip\n",
            "train_data17137.zip  train_data26285.zip  train_data7992.zip\n",
            "train_data17138.zip  train_data26286.zip  train_data7993.zip\n",
            "train_data17139.zip  train_data26287.zip  train_data7994.zip\n",
            "train_data1713.zip   train_data26288.zip  train_data7995.zip\n",
            "train_data17140.zip  train_data26289.zip  train_data7996.zip\n",
            "train_data17141.zip  train_data2628.zip   train_data7997.zip\n",
            "train_data17142.zip  train_data26290.zip  train_data7998.zip\n",
            "train_data17143.zip  train_data26291.zip  train_data7999.zip\n",
            "train_data17144.zip  train_data26292.zip  train_data799.zip\n",
            "train_data17145.zip  train_data26293.zip  train_data79.zip\n",
            "train_data17146.zip  train_data26294.zip  train_data7.zip\n",
            "train_data17147.zip  train_data26295.zip  train_data8000.zip\n",
            "train_data17148.zip  train_data26296.zip  train_data8001.zip\n",
            "train_data17149.zip  train_data26297.zip  train_data8002.zip\n",
            "train_data1714.zip   train_data26298.zip  train_data8003.zip\n",
            "train_data17150.zip  train_data26299.zip  train_data8004.zip\n",
            "train_data17151.zip  train_data2629.zip   train_data8005.zip\n",
            "train_data17152.zip  train_data262.zip\t  train_data8006.zip\n",
            "train_data17153.zip  train_data26300.zip  train_data8007.zip\n",
            "train_data17154.zip  train_data26301.zip  train_data8008.zip\n",
            "train_data17155.zip  train_data26302.zip  train_data8009.zip\n",
            "train_data17156.zip  train_data26303.zip  train_data800.zip\n",
            "train_data17157.zip  train_data26304.zip  train_data8010.zip\n",
            "train_data17158.zip  train_data26305.zip  train_data8011.zip\n",
            "train_data17159.zip  train_data26306.zip  train_data8012.zip\n",
            "train_data1715.zip   train_data26307.zip  train_data8013.zip\n",
            "train_data17160.zip  train_data26308.zip  train_data8014.zip\n",
            "train_data17161.zip  train_data26309.zip  train_data8015.zip\n",
            "train_data17162.zip  train_data2630.zip   train_data8016.zip\n",
            "train_data17163.zip  train_data26310.zip  train_data8017.zip\n",
            "train_data17164.zip  train_data26311.zip  train_data8018.zip\n",
            "train_data17165.zip  train_data26312.zip  train_data8019.zip\n",
            "train_data17166.zip  train_data26313.zip  train_data801.zip\n",
            "train_data17167.zip  train_data26314.zip  train_data8020.zip\n",
            "train_data17168.zip  train_data26315.zip  train_data8021.zip\n",
            "train_data17169.zip  train_data26316.zip  train_data8022.zip\n",
            "train_data1716.zip   train_data26317.zip  train_data8023.zip\n",
            "train_data17170.zip  train_data26318.zip  train_data8024.zip\n",
            "train_data17171.zip  train_data26319.zip  train_data8025.zip\n",
            "train_data17172.zip  train_data2631.zip   train_data8026.zip\n",
            "train_data17173.zip  train_data26320.zip  train_data8027.zip\n",
            "train_data17174.zip  train_data26321.zip  train_data8028.zip\n",
            "train_data17175.zip  train_data26322.zip  train_data8029.zip\n",
            "train_data17176.zip  train_data26323.zip  train_data802.zip\n",
            "train_data17177.zip  train_data26324.zip  train_data8030.zip\n",
            "train_data17178.zip  train_data26325.zip  train_data8031.zip\n",
            "train_data17179.zip  train_data26326.zip  train_data8032.zip\n",
            "train_data1717.zip   train_data26327.zip  train_data8033.zip\n",
            "train_data17180.zip  train_data26328.zip  train_data8034.zip\n",
            "train_data17181.zip  train_data26329.zip  train_data8035.zip\n",
            "train_data17182.zip  train_data2632.zip   train_data8036.zip\n",
            "train_data17183.zip  train_data26330.zip  train_data8037.zip\n",
            "train_data17184.zip  train_data26331.zip  train_data8038.zip\n",
            "train_data17185.zip  train_data26332.zip  train_data8039.zip\n",
            "train_data17186.zip  train_data26333.zip  train_data803.zip\n",
            "train_data17187.zip  train_data26334.zip  train_data8040.zip\n",
            "train_data17188.zip  train_data26335.zip  train_data8041.zip\n",
            "train_data17189.zip  train_data26336.zip  train_data8042.zip\n",
            "train_data1718.zip   train_data26337.zip  train_data8043.zip\n",
            "train_data17190.zip  train_data26338.zip  train_data8044.zip\n",
            "train_data17191.zip  train_data26339.zip  train_data8045.zip\n",
            "train_data17192.zip  train_data2633.zip   train_data8046.zip\n",
            "train_data17193.zip  train_data26340.zip  train_data8047.zip\n",
            "train_data17194.zip  train_data26341.zip  train_data8048.zip\n",
            "train_data17195.zip  train_data26342.zip  train_data8049.zip\n",
            "train_data17196.zip  train_data26343.zip  train_data804.zip\n",
            "train_data17197.zip  train_data26344.zip  train_data8050.zip\n",
            "train_data17198.zip  train_data26345.zip  train_data8051.zip\n",
            "train_data17199.zip  train_data26346.zip  train_data8052.zip\n",
            "train_data1719.zip   train_data26347.zip  train_data8053.zip\n",
            "train_data171.zip    train_data26348.zip  train_data8054.zip\n",
            "train_data17200.zip  train_data26349.zip  train_data8055.zip\n",
            "train_data17201.zip  train_data2634.zip   train_data8056.zip\n",
            "train_data17202.zip  train_data26350.zip  train_data8057.zip\n",
            "train_data17203.zip  train_data26351.zip  train_data8058.zip\n",
            "train_data17204.zip  train_data26352.zip  train_data8059.zip\n",
            "train_data17205.zip  train_data26353.zip  train_data805.zip\n",
            "train_data17206.zip  train_data26354.zip  train_data8060.zip\n",
            "train_data17207.zip  train_data26355.zip  train_data8061.zip\n",
            "train_data17208.zip  train_data26356.zip  train_data8062.zip\n",
            "train_data17209.zip  train_data26357.zip  train_data8063.zip\n",
            "train_data1720.zip   train_data26358.zip  train_data8064.zip\n",
            "train_data17210.zip  train_data26359.zip  train_data8065.zip\n",
            "train_data17211.zip  train_data2635.zip   train_data8066.zip\n",
            "train_data17212.zip  train_data26360.zip  train_data8067.zip\n",
            "train_data17213.zip  train_data26361.zip  train_data8068.zip\n",
            "train_data17214.zip  train_data26362.zip  train_data8069.zip\n",
            "train_data17215.zip  train_data26363.zip  train_data806.zip\n",
            "train_data17216.zip  train_data26364.zip  train_data8070.zip\n",
            "train_data17217.zip  train_data26365.zip  train_data8071.zip\n",
            "train_data17218.zip  train_data26366.zip  train_data8072.zip\n",
            "train_data17219.zip  train_data26367.zip  train_data8073.zip\n",
            "train_data1721.zip   train_data26368.zip  train_data8074.zip\n",
            "train_data17220.zip  train_data26369.zip  train_data8075.zip\n",
            "train_data17221.zip  train_data2636.zip   train_data8076.zip\n",
            "train_data17222.zip  train_data26370.zip  train_data8077.zip\n",
            "train_data17223.zip  train_data26371.zip  train_data8078.zip\n",
            "train_data17224.zip  train_data26372.zip  train_data8079.zip\n",
            "train_data17225.zip  train_data26373.zip  train_data807.zip\n",
            "train_data17226.zip  train_data26374.zip  train_data8080.zip\n",
            "train_data17227.zip  train_data26375.zip  train_data8081.zip\n",
            "train_data17228.zip  train_data26376.zip  train_data8082.zip\n",
            "train_data17229.zip  train_data26377.zip  train_data8083.zip\n",
            "train_data1722.zip   train_data26378.zip  train_data8084.zip\n",
            "train_data17230.zip  train_data26379.zip  train_data8085.zip\n",
            "train_data17231.zip  train_data2637.zip   train_data8086.zip\n",
            "train_data17232.zip  train_data26380.zip  train_data8087.zip\n",
            "train_data17233.zip  train_data26381.zip  train_data8088.zip\n",
            "train_data17234.zip  train_data26382.zip  train_data8089.zip\n",
            "train_data17235.zip  train_data26383.zip  train_data808.zip\n",
            "train_data17236.zip  train_data26384.zip  train_data8090.zip\n",
            "train_data17237.zip  train_data26385.zip  train_data8091.zip\n",
            "train_data17238.zip  train_data26386.zip  train_data8092.zip\n",
            "train_data17239.zip  train_data26387.zip  train_data8093.zip\n",
            "train_data1723.zip   train_data26388.zip  train_data8094.zip\n",
            "train_data17240.zip  train_data26389.zip  train_data8095.zip\n",
            "train_data17241.zip  train_data2638.zip   train_data8096.zip\n",
            "train_data17242.zip  train_data26390.zip  train_data8097.zip\n",
            "train_data17243.zip  train_data26391.zip  train_data8098.zip\n",
            "train_data17244.zip  train_data26392.zip  train_data8099.zip\n",
            "train_data17245.zip  train_data26393.zip  train_data809.zip\n",
            "train_data17246.zip  train_data26394.zip  train_data80.zip\n",
            "train_data17247.zip  train_data26395.zip  train_data8100.zip\n",
            "train_data17248.zip  train_data26396.zip  train_data8101.zip\n",
            "train_data17249.zip  train_data26397.zip  train_data8102.zip\n",
            "train_data1724.zip   train_data26398.zip  train_data8103.zip\n",
            "train_data17250.zip  train_data26399.zip  train_data8104.zip\n",
            "train_data17251.zip  train_data2639.zip   train_data8105.zip\n",
            "train_data17252.zip  train_data263.zip\t  train_data8106.zip\n",
            "train_data17253.zip  train_data26400.zip  train_data8107.zip\n",
            "train_data17254.zip  train_data26401.zip  train_data8108.zip\n",
            "train_data17255.zip  train_data26402.zip  train_data8109.zip\n",
            "train_data17256.zip  train_data26403.zip  train_data810.zip\n",
            "train_data17257.zip  train_data26404.zip  train_data8110.zip\n",
            "train_data17258.zip  train_data26405.zip  train_data8111.zip\n",
            "train_data17259.zip  train_data26406.zip  train_data8112.zip\n",
            "train_data1725.zip   train_data26407.zip  train_data8113.zip\n",
            "train_data17260.zip  train_data26408.zip  train_data8114.zip\n",
            "train_data17261.zip  train_data26409.zip  train_data8115.zip\n",
            "train_data17262.zip  train_data2640.zip   train_data8116.zip\n",
            "train_data17263.zip  train_data26410.zip  train_data8117.zip\n",
            "train_data17264.zip  train_data26411.zip  train_data8118.zip\n",
            "train_data17265.zip  train_data26412.zip  train_data8119.zip\n",
            "train_data17266.zip  train_data26413.zip  train_data811.zip\n",
            "train_data17267.zip  train_data26414.zip  train_data8120.zip\n",
            "train_data17268.zip  train_data26415.zip  train_data8121.zip\n",
            "train_data17269.zip  train_data26416.zip  train_data8122.zip\n",
            "train_data1726.zip   train_data26417.zip  train_data8123.zip\n",
            "train_data17270.zip  train_data26418.zip  train_data8124.zip\n",
            "train_data17271.zip  train_data26419.zip  train_data8125.zip\n",
            "train_data17272.zip  train_data2641.zip   train_data8126.zip\n",
            "train_data17273.zip  train_data26420.zip  train_data8127.zip\n",
            "train_data17274.zip  train_data26421.zip  train_data8128.zip\n",
            "train_data17275.zip  train_data26422.zip  train_data8129.zip\n",
            "train_data17276.zip  train_data26423.zip  train_data812.zip\n",
            "train_data17277.zip  train_data26424.zip  train_data8130.zip\n",
            "train_data17278.zip  train_data26425.zip  train_data8131.zip\n",
            "train_data17279.zip  train_data26426.zip  train_data8132.zip\n",
            "train_data1727.zip   train_data26427.zip  train_data8133.zip\n",
            "train_data17280.zip  train_data26428.zip  train_data8134.zip\n",
            "train_data17281.zip  train_data26429.zip  train_data8135.zip\n",
            "train_data17282.zip  train_data2642.zip   train_data8136.zip\n",
            "train_data17283.zip  train_data26430.zip  train_data8137.zip\n",
            "train_data17284.zip  train_data26431.zip  train_data8138.zip\n",
            "train_data17285.zip  train_data26432.zip  train_data8139.zip\n",
            "train_data17286.zip  train_data26433.zip  train_data813.zip\n",
            "train_data17287.zip  train_data26434.zip  train_data8140.zip\n",
            "train_data17288.zip  train_data26435.zip  train_data8141.zip\n",
            "train_data17289.zip  train_data26436.zip  train_data8142.zip\n",
            "train_data1728.zip   train_data26437.zip  train_data8143.zip\n",
            "train_data17290.zip  train_data26438.zip  train_data8144.zip\n",
            "train_data17291.zip  train_data26439.zip  train_data8145.zip\n",
            "train_data17292.zip  train_data2643.zip   train_data8146.zip\n",
            "train_data17293.zip  train_data26440.zip  train_data8147.zip\n",
            "train_data17294.zip  train_data26441.zip  train_data8148.zip\n",
            "train_data17295.zip  train_data26442.zip  train_data8149.zip\n",
            "train_data17296.zip  train_data26443.zip  train_data814.zip\n",
            "train_data17297.zip  train_data26444.zip  train_data8150.zip\n",
            "train_data17298.zip  train_data26445.zip  train_data8151.zip\n",
            "train_data17299.zip  train_data26446.zip  train_data8152.zip\n",
            "train_data1729.zip   train_data26447.zip  train_data8153.zip\n",
            "train_data172.zip    train_data26448.zip  train_data8154.zip\n",
            "train_data17300.zip  train_data26449.zip  train_data8155.zip\n",
            "train_data17301.zip  train_data2644.zip   train_data8156.zip\n",
            "train_data17302.zip  train_data26450.zip  train_data8157.zip\n",
            "train_data17303.zip  train_data26451.zip  train_data8158.zip\n",
            "train_data17304.zip  train_data26452.zip  train_data8159.zip\n",
            "train_data17305.zip  train_data26453.zip  train_data815.zip\n",
            "train_data17306.zip  train_data26454.zip  train_data8160.zip\n",
            "train_data17307.zip  train_data26455.zip  train_data8161.zip\n",
            "train_data17308.zip  train_data26456.zip  train_data8162.zip\n",
            "train_data17309.zip  train_data26457.zip  train_data8163.zip\n",
            "train_data1730.zip   train_data26458.zip  train_data8164.zip\n",
            "train_data17310.zip  train_data26459.zip  train_data8165.zip\n",
            "train_data17311.zip  train_data2645.zip   train_data8166.zip\n",
            "train_data17312.zip  train_data26460.zip  train_data8167.zip\n",
            "train_data17313.zip  train_data26461.zip  train_data8168.zip\n",
            "train_data17314.zip  train_data26462.zip  train_data8169.zip\n",
            "train_data17315.zip  train_data26463.zip  train_data816.zip\n",
            "train_data17316.zip  train_data26464.zip  train_data8170.zip\n",
            "train_data17317.zip  train_data26465.zip  train_data8171.zip\n",
            "train_data17318.zip  train_data26466.zip  train_data8172.zip\n",
            "train_data17319.zip  train_data26467.zip  train_data8173.zip\n",
            "train_data1731.zip   train_data26468.zip  train_data8174.zip\n",
            "train_data17320.zip  train_data26469.zip  train_data8175.zip\n",
            "train_data17321.zip  train_data2646.zip   train_data8176.zip\n",
            "train_data17322.zip  train_data26470.zip  train_data8177.zip\n",
            "train_data17323.zip  train_data26471.zip  train_data8178.zip\n",
            "train_data17324.zip  train_data26472.zip  train_data8179.zip\n",
            "train_data17325.zip  train_data26473.zip  train_data817.zip\n",
            "train_data17326.zip  train_data26474.zip  train_data8180.zip\n",
            "train_data17327.zip  train_data26475.zip  train_data8181.zip\n",
            "train_data17328.zip  train_data26476.zip  train_data8182.zip\n",
            "train_data17329.zip  train_data26477.zip  train_data8183.zip\n",
            "train_data1732.zip   train_data26478.zip  train_data8184.zip\n",
            "train_data17330.zip  train_data26479.zip  train_data8185.zip\n",
            "train_data17331.zip  train_data2647.zip   train_data8186.zip\n",
            "train_data17332.zip  train_data26480.zip  train_data8187.zip\n",
            "train_data17333.zip  train_data26481.zip  train_data8188.zip\n",
            "train_data17334.zip  train_data26482.zip  train_data8189.zip\n",
            "train_data17335.zip  train_data26483.zip  train_data818.zip\n",
            "train_data17336.zip  train_data26484.zip  train_data8190.zip\n",
            "train_data17337.zip  train_data26485.zip  train_data8191.zip\n",
            "train_data17338.zip  train_data26486.zip  train_data8192.zip\n",
            "train_data17339.zip  train_data26487.zip  train_data8193.zip\n",
            "train_data1733.zip   train_data26488.zip  train_data8194.zip\n",
            "train_data17340.zip  train_data26489.zip  train_data8195.zip\n",
            "train_data17341.zip  train_data2648.zip   train_data8196.zip\n",
            "train_data17342.zip  train_data26490.zip  train_data8197.zip\n",
            "train_data17343.zip  train_data26491.zip  train_data8198.zip\n",
            "train_data17344.zip  train_data26492.zip  train_data8199.zip\n",
            "train_data17345.zip  train_data26493.zip  train_data819.zip\n",
            "train_data17346.zip  train_data26494.zip  train_data81.zip\n",
            "train_data17347.zip  train_data26495.zip  train_data8200.zip\n",
            "train_data17348.zip  train_data26496.zip  train_data8201.zip\n",
            "train_data17349.zip  train_data26497.zip  train_data8202.zip\n",
            "train_data1734.zip   train_data26498.zip  train_data8203.zip\n",
            "train_data17350.zip  train_data26499.zip  train_data8204.zip\n",
            "train_data17351.zip  train_data2649.zip   train_data8205.zip\n",
            "train_data17352.zip  train_data264.zip\t  train_data8206.zip\n",
            "train_data17353.zip  train_data26500.zip  train_data8207.zip\n",
            "train_data17354.zip  train_data26501.zip  train_data8208.zip\n",
            "train_data17355.zip  train_data26502.zip  train_data8209.zip\n",
            "train_data17356.zip  train_data26503.zip  train_data820.zip\n",
            "train_data17357.zip  train_data26504.zip  train_data8210.zip\n",
            "train_data17358.zip  train_data26505.zip  train_data8211.zip\n",
            "train_data17359.zip  train_data26506.zip  train_data8212.zip\n",
            "train_data1735.zip   train_data26507.zip  train_data8213.zip\n",
            "train_data17360.zip  train_data26508.zip  train_data8214.zip\n",
            "train_data17361.zip  train_data26509.zip  train_data8215.zip\n",
            "train_data17362.zip  train_data2650.zip   train_data8216.zip\n",
            "train_data17363.zip  train_data26510.zip  train_data8217.zip\n",
            "train_data17364.zip  train_data26511.zip  train_data8218.zip\n",
            "train_data17365.zip  train_data26512.zip  train_data8219.zip\n",
            "train_data17366.zip  train_data26513.zip  train_data821.zip\n",
            "train_data17367.zip  train_data26514.zip  train_data8220.zip\n",
            "train_data17368.zip  train_data26515.zip  train_data8221.zip\n",
            "train_data17369.zip  train_data26516.zip  train_data8222.zip\n",
            "train_data1736.zip   train_data26517.zip  train_data8223.zip\n",
            "train_data17370.zip  train_data26518.zip  train_data8224.zip\n",
            "train_data17371.zip  train_data26519.zip  train_data8225.zip\n",
            "train_data17372.zip  train_data2651.zip   train_data8226.zip\n",
            "train_data17373.zip  train_data26520.zip  train_data8227.zip\n",
            "train_data17374.zip  train_data26521.zip  train_data8228.zip\n",
            "train_data17375.zip  train_data26522.zip  train_data8229.zip\n",
            "train_data17376.zip  train_data26523.zip  train_data822.zip\n",
            "train_data17377.zip  train_data26524.zip  train_data8230.zip\n",
            "train_data17378.zip  train_data26525.zip  train_data8231.zip\n",
            "train_data17379.zip  train_data26526.zip  train_data8232.zip\n",
            "train_data1737.zip   train_data26527.zip  train_data8233.zip\n",
            "train_data17380.zip  train_data26528.zip  train_data8234.zip\n",
            "train_data17381.zip  train_data26529.zip  train_data8235.zip\n",
            "train_data17382.zip  train_data2652.zip   train_data8236.zip\n",
            "train_data17383.zip  train_data26530.zip  train_data8237.zip\n",
            "train_data17384.zip  train_data26531.zip  train_data8238.zip\n",
            "train_data17385.zip  train_data26532.zip  train_data8239.zip\n",
            "train_data17386.zip  train_data26533.zip  train_data823.zip\n",
            "train_data17387.zip  train_data26534.zip  train_data8240.zip\n",
            "train_data17388.zip  train_data26535.zip  train_data8241.zip\n",
            "train_data17389.zip  train_data26536.zip  train_data8242.zip\n",
            "train_data1738.zip   train_data26537.zip  train_data8243.zip\n",
            "train_data17390.zip  train_data26538.zip  train_data8244.zip\n",
            "train_data17391.zip  train_data26539.zip  train_data8245.zip\n",
            "train_data17392.zip  train_data2653.zip   train_data8246.zip\n",
            "train_data17393.zip  train_data26540.zip  train_data8247.zip\n",
            "train_data17394.zip  train_data26541.zip  train_data8248.zip\n",
            "train_data17395.zip  train_data26542.zip  train_data8249.zip\n",
            "train_data17396.zip  train_data26543.zip  train_data824.zip\n",
            "train_data17397.zip  train_data26544.zip  train_data8250.zip\n",
            "train_data17398.zip  train_data26545.zip  train_data8251.zip\n",
            "train_data17399.zip  train_data26546.zip  train_data8252.zip\n",
            "train_data1739.zip   train_data26547.zip  train_data8253.zip\n",
            "train_data173.zip    train_data26548.zip  train_data8254.zip\n",
            "train_data17400.zip  train_data26549.zip  train_data8255.zip\n",
            "train_data17401.zip  train_data2654.zip   train_data8256.zip\n",
            "train_data17402.zip  train_data26550.zip  train_data8257.zip\n",
            "train_data17403.zip  train_data26551.zip  train_data8258.zip\n",
            "train_data17404.zip  train_data26552.zip  train_data8259.zip\n",
            "train_data17405.zip  train_data26553.zip  train_data825.zip\n",
            "train_data17406.zip  train_data26554.zip  train_data8260.zip\n",
            "train_data17407.zip  train_data26555.zip  train_data8261.zip\n",
            "train_data17408.zip  train_data26556.zip  train_data8262.zip\n",
            "train_data17409.zip  train_data26557.zip  train_data8263.zip\n",
            "train_data1740.zip   train_data26558.zip  train_data8264.zip\n",
            "train_data17410.zip  train_data26559.zip  train_data8265.zip\n",
            "train_data17411.zip  train_data2655.zip   train_data8266.zip\n",
            "train_data17412.zip  train_data26560.zip  train_data8267.zip\n",
            "train_data17413.zip  train_data26561.zip  train_data8268.zip\n",
            "train_data17414.zip  train_data26562.zip  train_data8269.zip\n",
            "train_data17415.zip  train_data26563.zip  train_data826.zip\n",
            "train_data17416.zip  train_data26564.zip  train_data8270.zip\n",
            "train_data17417.zip  train_data26565.zip  train_data8271.zip\n",
            "train_data17418.zip  train_data26566.zip  train_data8272.zip\n",
            "train_data17419.zip  train_data26567.zip  train_data8273.zip\n",
            "train_data1741.zip   train_data26568.zip  train_data8274.zip\n",
            "train_data17420.zip  train_data26569.zip  train_data8275.zip\n",
            "train_data17421.zip  train_data2656.zip   train_data8276.zip\n",
            "train_data17422.zip  train_data26570.zip  train_data8277.zip\n",
            "train_data17423.zip  train_data26571.zip  train_data8278.zip\n",
            "train_data17424.zip  train_data26572.zip  train_data8279.zip\n",
            "train_data17425.zip  train_data26573.zip  train_data827.zip\n",
            "train_data17426.zip  train_data26574.zip  train_data8280.zip\n",
            "train_data17427.zip  train_data26575.zip  train_data8281.zip\n",
            "train_data17428.zip  train_data26576.zip  train_data8282.zip\n",
            "train_data17429.zip  train_data26577.zip  train_data8283.zip\n",
            "train_data1742.zip   train_data26578.zip  train_data8284.zip\n",
            "train_data17430.zip  train_data26579.zip  train_data8285.zip\n",
            "train_data17431.zip  train_data2657.zip   train_data8286.zip\n",
            "train_data17432.zip  train_data26580.zip  train_data8287.zip\n",
            "train_data17433.zip  train_data26581.zip  train_data8288.zip\n",
            "train_data17434.zip  train_data26582.zip  train_data8289.zip\n",
            "train_data17435.zip  train_data26583.zip  train_data828.zip\n",
            "train_data17436.zip  train_data26584.zip  train_data8290.zip\n",
            "train_data17437.zip  train_data26585.zip  train_data8291.zip\n",
            "train_data17438.zip  train_data26586.zip  train_data8292.zip\n",
            "train_data17439.zip  train_data26587.zip  train_data8293.zip\n",
            "train_data1743.zip   train_data26588.zip  train_data8294.zip\n",
            "train_data17440.zip  train_data26589.zip  train_data8295.zip\n",
            "train_data17441.zip  train_data2658.zip   train_data8296.zip\n",
            "train_data17442.zip  train_data26590.zip  train_data8297.zip\n",
            "train_data17443.zip  train_data26591.zip  train_data8298.zip\n",
            "train_data17444.zip  train_data26592.zip  train_data8299.zip\n",
            "train_data17445.zip  train_data26593.zip  train_data829.zip\n",
            "train_data17446.zip  train_data26594.zip  train_data82.zip\n",
            "train_data17447.zip  train_data26595.zip  train_data8300.zip\n",
            "train_data17448.zip  train_data26596.zip  train_data8301.zip\n",
            "train_data17449.zip  train_data26597.zip  train_data8302.zip\n",
            "train_data1744.zip   train_data26598.zip  train_data8303.zip\n",
            "train_data17450.zip  train_data26599.zip  train_data8304.zip\n",
            "train_data17451.zip  train_data2659.zip   train_data8305.zip\n",
            "train_data17452.zip  train_data265.zip\t  train_data8306.zip\n",
            "train_data17453.zip  train_data26600.zip  train_data8307.zip\n",
            "train_data17454.zip  train_data26601.zip  train_data8308.zip\n",
            "train_data17455.zip  train_data26602.zip  train_data8309.zip\n",
            "train_data17456.zip  train_data26603.zip  train_data830.zip\n",
            "train_data17457.zip  train_data26604.zip  train_data8310.zip\n",
            "train_data17458.zip  train_data26605.zip  train_data8311.zip\n",
            "train_data17459.zip  train_data26606.zip  train_data8312.zip\n",
            "train_data1745.zip   train_data26607.zip  train_data8313.zip\n",
            "train_data17460.zip  train_data26608.zip  train_data8314.zip\n",
            "train_data17461.zip  train_data26609.zip  train_data8315.zip\n",
            "train_data17462.zip  train_data2660.zip   train_data8316.zip\n",
            "train_data17463.zip  train_data26610.zip  train_data8317.zip\n",
            "train_data17464.zip  train_data26611.zip  train_data8318.zip\n",
            "train_data17465.zip  train_data26612.zip  train_data8319.zip\n",
            "train_data17466.zip  train_data26613.zip  train_data831.zip\n",
            "train_data17467.zip  train_data26614.zip  train_data8320.zip\n",
            "train_data17468.zip  train_data26615.zip  train_data8321.zip\n",
            "train_data17469.zip  train_data26616.zip  train_data8322.zip\n",
            "train_data1746.zip   train_data26617.zip  train_data8323.zip\n",
            "train_data17470.zip  train_data26618.zip  train_data8324.zip\n",
            "train_data17471.zip  train_data26619.zip  train_data8325.zip\n",
            "train_data17472.zip  train_data2661.zip   train_data8326.zip\n",
            "train_data17473.zip  train_data26620.zip  train_data8327.zip\n",
            "train_data17474.zip  train_data26621.zip  train_data8328.zip\n",
            "train_data17475.zip  train_data26622.zip  train_data8329.zip\n",
            "train_data17476.zip  train_data26623.zip  train_data832.zip\n",
            "train_data17477.zip  train_data26624.zip  train_data8330.zip\n",
            "train_data17478.zip  train_data26625.zip  train_data8331.zip\n",
            "train_data17479.zip  train_data26626.zip  train_data8332.zip\n",
            "train_data1747.zip   train_data26627.zip  train_data8333.zip\n",
            "train_data17480.zip  train_data26628.zip  train_data8334.zip\n",
            "train_data17481.zip  train_data26629.zip  train_data8335.zip\n",
            "train_data17482.zip  train_data2662.zip   train_data8336.zip\n",
            "train_data17483.zip  train_data26630.zip  train_data8337.zip\n",
            "train_data17484.zip  train_data26631.zip  train_data8338.zip\n",
            "train_data17485.zip  train_data26632.zip  train_data8339.zip\n",
            "train_data17486.zip  train_data26633.zip  train_data833.zip\n",
            "train_data17487.zip  train_data26634.zip  train_data8340.zip\n",
            "train_data17488.zip  train_data26635.zip  train_data8341.zip\n",
            "train_data17489.zip  train_data26636.zip  train_data8342.zip\n",
            "train_data1748.zip   train_data26637.zip  train_data8343.zip\n",
            "train_data17490.zip  train_data26638.zip  train_data8344.zip\n",
            "train_data17491.zip  train_data26639.zip  train_data8345.zip\n",
            "train_data17492.zip  train_data2663.zip   train_data8346.zip\n",
            "train_data17493.zip  train_data26640.zip  train_data8347.zip\n",
            "train_data17494.zip  train_data26641.zip  train_data8348.zip\n",
            "train_data17495.zip  train_data26642.zip  train_data8349.zip\n",
            "train_data17496.zip  train_data26643.zip  train_data834.zip\n",
            "train_data17497.zip  train_data26644.zip  train_data8350.zip\n",
            "train_data17498.zip  train_data26645.zip  train_data8351.zip\n",
            "train_data17499.zip  train_data26646.zip  train_data8352.zip\n",
            "train_data1749.zip   train_data26647.zip  train_data8353.zip\n",
            "train_data174.zip    train_data26648.zip  train_data8354.zip\n",
            "train_data17500.zip  train_data26649.zip  train_data8355.zip\n",
            "train_data17501.zip  train_data2664.zip   train_data8356.zip\n",
            "train_data17502.zip  train_data26650.zip  train_data8357.zip\n",
            "train_data17503.zip  train_data26651.zip  train_data8358.zip\n",
            "train_data17504.zip  train_data26652.zip  train_data8359.zip\n",
            "train_data17505.zip  train_data26653.zip  train_data835.zip\n",
            "train_data17506.zip  train_data26654.zip  train_data8360.zip\n",
            "train_data17507.zip  train_data26655.zip  train_data8361.zip\n",
            "train_data17508.zip  train_data26656.zip  train_data8362.zip\n",
            "train_data17509.zip  train_data26657.zip  train_data8363.zip\n",
            "train_data1750.zip   train_data26658.zip  train_data8364.zip\n",
            "train_data17510.zip  train_data26659.zip  train_data8365.zip\n",
            "train_data17511.zip  train_data2665.zip   train_data8366.zip\n",
            "train_data17512.zip  train_data26660.zip  train_data8367.zip\n",
            "train_data17513.zip  train_data26661.zip  train_data8368.zip\n",
            "train_data17514.zip  train_data26662.zip  train_data8369.zip\n",
            "train_data17515.zip  train_data26663.zip  train_data836.zip\n",
            "train_data17516.zip  train_data26664.zip  train_data8370.zip\n",
            "train_data17517.zip  train_data26665.zip  train_data8371.zip\n",
            "train_data17518.zip  train_data26666.zip  train_data8372.zip\n",
            "train_data17519.zip  train_data26667.zip  train_data8373.zip\n",
            "train_data1751.zip   train_data26668.zip  train_data8374.zip\n",
            "train_data17520.zip  train_data26669.zip  train_data8375.zip\n",
            "train_data17521.zip  train_data2666.zip   train_data8376.zip\n",
            "train_data17522.zip  train_data26670.zip  train_data8377.zip\n",
            "train_data17523.zip  train_data26671.zip  train_data8378.zip\n",
            "train_data17524.zip  train_data26672.zip  train_data8379.zip\n",
            "train_data17525.zip  train_data26673.zip  train_data837.zip\n",
            "train_data17526.zip  train_data26674.zip  train_data8380.zip\n",
            "train_data17527.zip  train_data26675.zip  train_data8381.zip\n",
            "train_data17528.zip  train_data26676.zip  train_data8382.zip\n",
            "train_data17529.zip  train_data26677.zip  train_data8383.zip\n",
            "train_data1752.zip   train_data26678.zip  train_data8384.zip\n",
            "train_data17530.zip  train_data26679.zip  train_data8385.zip\n",
            "train_data17531.zip  train_data2667.zip   train_data8386.zip\n",
            "train_data17532.zip  train_data26680.zip  train_data8387.zip\n",
            "train_data17533.zip  train_data26681.zip  train_data8388.zip\n",
            "train_data17534.zip  train_data26682.zip  train_data8389.zip\n",
            "train_data17535.zip  train_data26683.zip  train_data838.zip\n",
            "train_data17536.zip  train_data26684.zip  train_data8390.zip\n",
            "train_data17537.zip  train_data26685.zip  train_data8391.zip\n",
            "train_data17538.zip  train_data26686.zip  train_data8392.zip\n",
            "train_data17539.zip  train_data26687.zip  train_data8393.zip\n",
            "train_data1753.zip   train_data26688.zip  train_data8394.zip\n",
            "train_data17540.zip  train_data26689.zip  train_data8395.zip\n",
            "train_data17541.zip  train_data2668.zip   train_data8396.zip\n",
            "train_data17542.zip  train_data26690.zip  train_data8397.zip\n",
            "train_data17543.zip  train_data26691.zip  train_data8398.zip\n",
            "train_data17544.zip  train_data26692.zip  train_data8399.zip\n",
            "train_data17545.zip  train_data26693.zip  train_data839.zip\n",
            "train_data17546.zip  train_data26694.zip  train_data83.zip\n",
            "train_data17547.zip  train_data26695.zip  train_data8400.zip\n",
            "train_data17548.zip  train_data26696.zip  train_data8401.zip\n",
            "train_data17549.zip  train_data26697.zip  train_data8402.zip\n",
            "train_data1754.zip   train_data26698.zip  train_data8403.zip\n",
            "train_data17550.zip  train_data26699.zip  train_data8404.zip\n",
            "train_data17551.zip  train_data2669.zip   train_data8405.zip\n",
            "train_data17552.zip  train_data266.zip\t  train_data8406.zip\n",
            "train_data17553.zip  train_data26700.zip  train_data8407.zip\n",
            "train_data17554.zip  train_data26701.zip  train_data8408.zip\n",
            "train_data17555.zip  train_data26702.zip  train_data8409.zip\n",
            "train_data17556.zip  train_data26703.zip  train_data840.zip\n",
            "train_data17557.zip  train_data26704.zip  train_data8410.zip\n",
            "train_data17558.zip  train_data26705.zip  train_data8411.zip\n",
            "train_data17559.zip  train_data26706.zip  train_data8412.zip\n",
            "train_data1755.zip   train_data26707.zip  train_data8413.zip\n",
            "train_data17560.zip  train_data26708.zip  train_data8414.zip\n",
            "train_data17561.zip  train_data26709.zip  train_data8415.zip\n",
            "train_data17562.zip  train_data2670.zip   train_data8416.zip\n",
            "train_data17563.zip  train_data26710.zip  train_data8417.zip\n",
            "train_data17564.zip  train_data26711.zip  train_data8418.zip\n",
            "train_data17565.zip  train_data26712.zip  train_data8419.zip\n",
            "train_data17566.zip  train_data26713.zip  train_data841.zip\n",
            "train_data17567.zip  train_data26714.zip  train_data8420.zip\n",
            "train_data17568.zip  train_data26715.zip  train_data8421.zip\n",
            "train_data17569.zip  train_data26716.zip  train_data8422.zip\n",
            "train_data1756.zip   train_data26717.zip  train_data8423.zip\n",
            "train_data17570.zip  train_data26718.zip  train_data8424.zip\n",
            "train_data17571.zip  train_data26719.zip  train_data8425.zip\n",
            "train_data17572.zip  train_data2671.zip   train_data8426.zip\n",
            "train_data17573.zip  train_data26720.zip  train_data8427.zip\n",
            "train_data17574.zip  train_data26721.zip  train_data8428.zip\n",
            "train_data17575.zip  train_data26722.zip  train_data8429.zip\n",
            "train_data17576.zip  train_data26723.zip  train_data842.zip\n",
            "train_data17577.zip  train_data26724.zip  train_data8430.zip\n",
            "train_data17578.zip  train_data26725.zip  train_data8431.zip\n",
            "train_data17579.zip  train_data26726.zip  train_data8432.zip\n",
            "train_data1757.zip   train_data26727.zip  train_data8433.zip\n",
            "train_data17580.zip  train_data26728.zip  train_data8434.zip\n",
            "train_data17581.zip  train_data26729.zip  train_data8435.zip\n",
            "train_data17582.zip  train_data2672.zip   train_data8436.zip\n",
            "train_data17583.zip  train_data26730.zip  train_data8437.zip\n",
            "train_data17584.zip  train_data26731.zip  train_data8438.zip\n",
            "train_data17585.zip  train_data26732.zip  train_data8439.zip\n",
            "train_data17586.zip  train_data26733.zip  train_data843.zip\n",
            "train_data17587.zip  train_data26734.zip  train_data8440.zip\n",
            "train_data17588.zip  train_data26735.zip  train_data8441.zip\n",
            "train_data17589.zip  train_data26736.zip  train_data8442.zip\n",
            "train_data1758.zip   train_data26737.zip  train_data8443.zip\n",
            "train_data17590.zip  train_data26738.zip  train_data8444.zip\n",
            "train_data17591.zip  train_data26739.zip  train_data8445.zip\n",
            "train_data17592.zip  train_data2673.zip   train_data8446.zip\n",
            "train_data17593.zip  train_data26740.zip  train_data8447.zip\n",
            "train_data17594.zip  train_data26741.zip  train_data8448.zip\n",
            "train_data17595.zip  train_data26742.zip  train_data8449.zip\n",
            "train_data17596.zip  train_data26743.zip  train_data844.zip\n",
            "train_data17597.zip  train_data26744.zip  train_data8450.zip\n",
            "train_data17598.zip  train_data26745.zip  train_data8451.zip\n",
            "train_data17599.zip  train_data26746.zip  train_data8452.zip\n",
            "train_data1759.zip   train_data26747.zip  train_data8453.zip\n",
            "train_data175.zip    train_data26748.zip  train_data8454.zip\n",
            "train_data17600.zip  train_data26749.zip  train_data8455.zip\n",
            "train_data17601.zip  train_data2674.zip   train_data8456.zip\n",
            "train_data17602.zip  train_data26750.zip  train_data8457.zip\n",
            "train_data17603.zip  train_data26751.zip  train_data8458.zip\n",
            "train_data17604.zip  train_data26752.zip  train_data8459.zip\n",
            "train_data17605.zip  train_data26753.zip  train_data845.zip\n",
            "train_data17606.zip  train_data26754.zip  train_data8460.zip\n",
            "train_data17607.zip  train_data26755.zip  train_data8461.zip\n",
            "train_data17608.zip  train_data26756.zip  train_data8462.zip\n",
            "train_data17609.zip  train_data26757.zip  train_data8463.zip\n",
            "train_data1760.zip   train_data26758.zip  train_data8464.zip\n",
            "train_data17610.zip  train_data26759.zip  train_data8465.zip\n",
            "train_data17611.zip  train_data2675.zip   train_data8466.zip\n",
            "train_data17612.zip  train_data26760.zip  train_data8467.zip\n",
            "train_data17613.zip  train_data26761.zip  train_data8468.zip\n",
            "train_data17614.zip  train_data26762.zip  train_data8469.zip\n",
            "train_data17615.zip  train_data26763.zip  train_data846.zip\n",
            "train_data17616.zip  train_data26764.zip  train_data8470.zip\n",
            "train_data17617.zip  train_data26765.zip  train_data8471.zip\n",
            "train_data17618.zip  train_data26766.zip  train_data8472.zip\n",
            "train_data17619.zip  train_data26767.zip  train_data8473.zip\n",
            "train_data1761.zip   train_data26768.zip  train_data8474.zip\n",
            "train_data17620.zip  train_data26769.zip  train_data8475.zip\n",
            "train_data17621.zip  train_data2676.zip   train_data8476.zip\n",
            "train_data17622.zip  train_data26770.zip  train_data8477.zip\n",
            "train_data17623.zip  train_data26771.zip  train_data8478.zip\n",
            "train_data17624.zip  train_data26772.zip  train_data8479.zip\n",
            "train_data17625.zip  train_data26773.zip  train_data847.zip\n",
            "train_data17626.zip  train_data26774.zip  train_data8480.zip\n",
            "train_data17627.zip  train_data26775.zip  train_data8481.zip\n",
            "train_data17628.zip  train_data26776.zip  train_data8482.zip\n",
            "train_data17629.zip  train_data26777.zip  train_data8483.zip\n",
            "train_data1762.zip   train_data26778.zip  train_data8484.zip\n",
            "train_data17630.zip  train_data26779.zip  train_data8485.zip\n",
            "train_data17631.zip  train_data2677.zip   train_data8486.zip\n",
            "train_data17632.zip  train_data26780.zip  train_data8487.zip\n",
            "train_data17633.zip  train_data26781.zip  train_data8488.zip\n",
            "train_data17634.zip  train_data26782.zip  train_data8489.zip\n",
            "train_data17635.zip  train_data26783.zip  train_data848.zip\n",
            "train_data17636.zip  train_data26784.zip  train_data8490.zip\n",
            "train_data17637.zip  train_data26785.zip  train_data8491.zip\n",
            "train_data17638.zip  train_data26786.zip  train_data8492.zip\n",
            "train_data17639.zip  train_data26787.zip  train_data8493.zip\n",
            "train_data1763.zip   train_data26788.zip  train_data8494.zip\n",
            "train_data17640.zip  train_data26789.zip  train_data8495.zip\n",
            "train_data17641.zip  train_data2678.zip   train_data8496.zip\n",
            "train_data17642.zip  train_data26790.zip  train_data8497.zip\n",
            "train_data17643.zip  train_data26791.zip  train_data8498.zip\n",
            "train_data17644.zip  train_data26792.zip  train_data8499.zip\n",
            "train_data17645.zip  train_data26793.zip  train_data849.zip\n",
            "train_data17646.zip  train_data26794.zip  train_data84.zip\n",
            "train_data17647.zip  train_data26795.zip  train_data8500.zip\n",
            "train_data17648.zip  train_data26796.zip  train_data8501.zip\n",
            "train_data17649.zip  train_data26797.zip  train_data8502.zip\n",
            "train_data1764.zip   train_data26798.zip  train_data8503.zip\n",
            "train_data17650.zip  train_data26799.zip  train_data8504.zip\n",
            "train_data17651.zip  train_data2679.zip   train_data8505.zip\n",
            "train_data17652.zip  train_data267.zip\t  train_data8506.zip\n",
            "train_data17653.zip  train_data26800.zip  train_data8507.zip\n",
            "train_data17654.zip  train_data26801.zip  train_data8508.zip\n",
            "train_data17655.zip  train_data26802.zip  train_data8509.zip\n",
            "train_data17656.zip  train_data26803.zip  train_data850.zip\n",
            "train_data17657.zip  train_data26804.zip  train_data8510.zip\n",
            "train_data17658.zip  train_data26805.zip  train_data8511.zip\n",
            "train_data17659.zip  train_data26806.zip  train_data8512.zip\n",
            "train_data1765.zip   train_data26807.zip  train_data8513.zip\n",
            "train_data17660.zip  train_data26808.zip  train_data8514.zip\n",
            "train_data17661.zip  train_data26809.zip  train_data8515.zip\n",
            "train_data17662.zip  train_data2680.zip   train_data8516.zip\n",
            "train_data17663.zip  train_data26810.zip  train_data8517.zip\n",
            "train_data17664.zip  train_data26811.zip  train_data8518.zip\n",
            "train_data17665.zip  train_data26812.zip  train_data8519.zip\n",
            "train_data17666.zip  train_data26813.zip  train_data851.zip\n",
            "train_data17667.zip  train_data26814.zip  train_data8520.zip\n",
            "train_data17668.zip  train_data26815.zip  train_data8521.zip\n",
            "train_data17669.zip  train_data26816.zip  train_data8522.zip\n",
            "train_data1766.zip   train_data26817.zip  train_data8523.zip\n",
            "train_data17670.zip  train_data26818.zip  train_data8524.zip\n",
            "train_data17671.zip  train_data26819.zip  train_data8525.zip\n",
            "train_data17672.zip  train_data2681.zip   train_data8526.zip\n",
            "train_data17673.zip  train_data26820.zip  train_data8527.zip\n",
            "train_data17674.zip  train_data26821.zip  train_data8528.zip\n",
            "train_data17675.zip  train_data26822.zip  train_data8529.zip\n",
            "train_data17676.zip  train_data26823.zip  train_data852.zip\n",
            "train_data17677.zip  train_data26824.zip  train_data8530.zip\n",
            "train_data17678.zip  train_data26825.zip  train_data8531.zip\n",
            "train_data17679.zip  train_data26826.zip  train_data8532.zip\n",
            "train_data1767.zip   train_data26827.zip  train_data8533.zip\n",
            "train_data17680.zip  train_data26828.zip  train_data8534.zip\n",
            "train_data17681.zip  train_data26829.zip  train_data8535.zip\n",
            "train_data17682.zip  train_data2682.zip   train_data8536.zip\n",
            "train_data17683.zip  train_data26830.zip  train_data8537.zip\n",
            "train_data17684.zip  train_data26831.zip  train_data8538.zip\n",
            "train_data17685.zip  train_data26832.zip  train_data8539.zip\n",
            "train_data17686.zip  train_data26833.zip  train_data853.zip\n",
            "train_data17687.zip  train_data26834.zip  train_data8540.zip\n",
            "train_data17688.zip  train_data26835.zip  train_data8541.zip\n",
            "train_data17689.zip  train_data26836.zip  train_data8542.zip\n",
            "train_data1768.zip   train_data26837.zip  train_data8543.zip\n",
            "train_data17690.zip  train_data26838.zip  train_data8544.zip\n",
            "train_data17691.zip  train_data26839.zip  train_data8545.zip\n",
            "train_data17692.zip  train_data2683.zip   train_data8546.zip\n",
            "train_data17693.zip  train_data26840.zip  train_data8547.zip\n",
            "train_data17694.zip  train_data26841.zip  train_data8548.zip\n",
            "train_data17695.zip  train_data26842.zip  train_data8549.zip\n",
            "train_data17696.zip  train_data26843.zip  train_data854.zip\n",
            "train_data17697.zip  train_data26844.zip  train_data8550.zip\n",
            "train_data17698.zip  train_data26845.zip  train_data8551.zip\n",
            "train_data17699.zip  train_data26846.zip  train_data8552.zip\n",
            "train_data1769.zip   train_data26847.zip  train_data8553.zip\n",
            "train_data176.zip    train_data26848.zip  train_data8554.zip\n",
            "train_data17700.zip  train_data26849.zip  train_data8555.zip\n",
            "train_data17701.zip  train_data2684.zip   train_data8556.zip\n",
            "train_data17702.zip  train_data26850.zip  train_data8557.zip\n",
            "train_data17703.zip  train_data26851.zip  train_data8558.zip\n",
            "train_data17704.zip  train_data26852.zip  train_data8559.zip\n",
            "train_data17705.zip  train_data26853.zip  train_data855.zip\n",
            "train_data17706.zip  train_data26854.zip  train_data8560.zip\n",
            "train_data17707.zip  train_data26855.zip  train_data8561.zip\n",
            "train_data17708.zip  train_data26856.zip  train_data8562.zip\n",
            "train_data17709.zip  train_data26857.zip  train_data8563.zip\n",
            "train_data1770.zip   train_data26858.zip  train_data8564.zip\n",
            "train_data17710.zip  train_data26859.zip  train_data8565.zip\n",
            "train_data17711.zip  train_data2685.zip   train_data8566.zip\n",
            "train_data17712.zip  train_data26860.zip  train_data8567.zip\n",
            "train_data17713.zip  train_data26861.zip  train_data8568.zip\n",
            "train_data17714.zip  train_data26862.zip  train_data8569.zip\n",
            "train_data17715.zip  train_data26863.zip  train_data856.zip\n",
            "train_data17716.zip  train_data26864.zip  train_data8570.zip\n",
            "train_data17717.zip  train_data26865.zip  train_data8571.zip\n",
            "train_data17718.zip  train_data26866.zip  train_data8572.zip\n",
            "train_data17719.zip  train_data26867.zip  train_data8573.zip\n",
            "train_data1771.zip   train_data26868.zip  train_data8574.zip\n",
            "train_data17720.zip  train_data26869.zip  train_data8575.zip\n",
            "train_data17721.zip  train_data2686.zip   train_data8576.zip\n",
            "train_data17722.zip  train_data26870.zip  train_data8577.zip\n",
            "train_data17723.zip  train_data26871.zip  train_data8578.zip\n",
            "train_data17724.zip  train_data26872.zip  train_data8579.zip\n",
            "train_data17725.zip  train_data26873.zip  train_data857.zip\n",
            "train_data17726.zip  train_data26874.zip  train_data8580.zip\n",
            "train_data17727.zip  train_data26875.zip  train_data8581.zip\n",
            "train_data17728.zip  train_data26876.zip  train_data8582.zip\n",
            "train_data17729.zip  train_data26877.zip  train_data8583.zip\n",
            "train_data1772.zip   train_data26878.zip  train_data8584.zip\n",
            "train_data17730.zip  train_data26879.zip  train_data8585.zip\n",
            "train_data17731.zip  train_data2687.zip   train_data8586.zip\n",
            "train_data17732.zip  train_data26880.zip  train_data8587.zip\n",
            "train_data17733.zip  train_data26881.zip  train_data8588.zip\n",
            "train_data17734.zip  train_data26882.zip  train_data8589.zip\n",
            "train_data17735.zip  train_data26883.zip  train_data858.zip\n",
            "train_data17736.zip  train_data26884.zip  train_data8590.zip\n",
            "train_data17737.zip  train_data26885.zip  train_data8591.zip\n",
            "train_data17738.zip  train_data26886.zip  train_data8592.zip\n",
            "train_data17739.zip  train_data26887.zip  train_data8593.zip\n",
            "train_data1773.zip   train_data26888.zip  train_data8594.zip\n",
            "train_data17740.zip  train_data26889.zip  train_data8595.zip\n",
            "train_data17741.zip  train_data2688.zip   train_data8596.zip\n",
            "train_data17742.zip  train_data26890.zip  train_data8597.zip\n",
            "train_data17743.zip  train_data26891.zip  train_data8598.zip\n",
            "train_data17744.zip  train_data26892.zip  train_data8599.zip\n",
            "train_data17745.zip  train_data26893.zip  train_data859.zip\n",
            "train_data17746.zip  train_data26894.zip  train_data85.zip\n",
            "train_data17747.zip  train_data26895.zip  train_data8600.zip\n",
            "train_data17748.zip  train_data26896.zip  train_data8601.zip\n",
            "train_data17749.zip  train_data26897.zip  train_data8602.zip\n",
            "train_data1774.zip   train_data26898.zip  train_data8603.zip\n",
            "train_data17750.zip  train_data26899.zip  train_data8604.zip\n",
            "train_data17751.zip  train_data2689.zip   train_data8605.zip\n",
            "train_data17752.zip  train_data268.zip\t  train_data8606.zip\n",
            "train_data17753.zip  train_data26900.zip  train_data8607.zip\n",
            "train_data17754.zip  train_data26901.zip  train_data8608.zip\n",
            "train_data17755.zip  train_data26902.zip  train_data8609.zip\n",
            "train_data17756.zip  train_data26903.zip  train_data860.zip\n",
            "train_data17757.zip  train_data26904.zip  train_data8610.zip\n",
            "train_data17758.zip  train_data26905.zip  train_data8611.zip\n",
            "train_data17759.zip  train_data26906.zip  train_data8612.zip\n",
            "train_data1775.zip   train_data26907.zip  train_data8613.zip\n",
            "train_data17760.zip  train_data26908.zip  train_data8614.zip\n",
            "train_data17761.zip  train_data26909.zip  train_data8615.zip\n",
            "train_data17762.zip  train_data2690.zip   train_data8616.zip\n",
            "train_data17763.zip  train_data26910.zip  train_data8617.zip\n",
            "train_data17764.zip  train_data26911.zip  train_data8618.zip\n",
            "train_data17765.zip  train_data26912.zip  train_data8619.zip\n",
            "train_data17766.zip  train_data26913.zip  train_data861.zip\n",
            "train_data17767.zip  train_data26914.zip  train_data8620.zip\n",
            "train_data17768.zip  train_data26915.zip  train_data8621.zip\n",
            "train_data17769.zip  train_data26916.zip  train_data8622.zip\n",
            "train_data1776.zip   train_data26917.zip  train_data8623.zip\n",
            "train_data17770.zip  train_data26918.zip  train_data8624.zip\n",
            "train_data17771.zip  train_data26919.zip  train_data8625.zip\n",
            "train_data17772.zip  train_data2691.zip   train_data8626.zip\n",
            "train_data17773.zip  train_data26920.zip  train_data8627.zip\n",
            "train_data17774.zip  train_data26921.zip  train_data8628.zip\n",
            "train_data17775.zip  train_data26922.zip  train_data8629.zip\n",
            "train_data17776.zip  train_data26923.zip  train_data862.zip\n",
            "train_data17777.zip  train_data26924.zip  train_data8630.zip\n",
            "train_data17778.zip  train_data26925.zip  train_data8631.zip\n",
            "train_data17779.zip  train_data26926.zip  train_data8632.zip\n",
            "train_data1777.zip   train_data26927.zip  train_data8633.zip\n",
            "train_data17780.zip  train_data26928.zip  train_data8634.zip\n",
            "train_data17781.zip  train_data26929.zip  train_data8635.zip\n",
            "train_data17782.zip  train_data2692.zip   train_data8636.zip\n",
            "train_data17783.zip  train_data26930.zip  train_data8637.zip\n",
            "train_data17784.zip  train_data26931.zip  train_data8638.zip\n",
            "train_data17785.zip  train_data26932.zip  train_data8639.zip\n",
            "train_data17786.zip  train_data26933.zip  train_data863.zip\n",
            "train_data17787.zip  train_data26934.zip  train_data8640.zip\n",
            "train_data17788.zip  train_data26935.zip  train_data8641.zip\n",
            "train_data17789.zip  train_data26936.zip  train_data8642.zip\n",
            "train_data1778.zip   train_data26937.zip  train_data8643.zip\n",
            "train_data17790.zip  train_data26938.zip  train_data8644.zip\n",
            "train_data17791.zip  train_data26939.zip  train_data8645.zip\n",
            "train_data17792.zip  train_data2693.zip   train_data8646.zip\n",
            "train_data17793.zip  train_data26940.zip  train_data8647.zip\n",
            "train_data17794.zip  train_data26941.zip  train_data8648.zip\n",
            "train_data17795.zip  train_data26942.zip  train_data8649.zip\n",
            "train_data17796.zip  train_data26943.zip  train_data864.zip\n",
            "train_data17797.zip  train_data26944.zip  train_data8650.zip\n",
            "train_data17798.zip  train_data26945.zip  train_data8651.zip\n",
            "train_data17799.zip  train_data26946.zip  train_data8652.zip\n",
            "train_data1779.zip   train_data26947.zip  train_data8653.zip\n",
            "train_data177.zip    train_data26948.zip  train_data8654.zip\n",
            "train_data17800.zip  train_data26949.zip  train_data8655.zip\n",
            "train_data17801.zip  train_data2694.zip   train_data8656.zip\n",
            "train_data17802.zip  train_data26950.zip  train_data8657.zip\n",
            "train_data17803.zip  train_data26951.zip  train_data8658.zip\n",
            "train_data17804.zip  train_data26952.zip  train_data8659.zip\n",
            "train_data17805.zip  train_data26953.zip  train_data865.zip\n",
            "train_data17806.zip  train_data26954.zip  train_data8660.zip\n",
            "train_data17807.zip  train_data26955.zip  train_data8661.zip\n",
            "train_data17808.zip  train_data26956.zip  train_data8662.zip\n",
            "train_data17809.zip  train_data26957.zip  train_data8663.zip\n",
            "train_data1780.zip   train_data26958.zip  train_data8664.zip\n",
            "train_data17810.zip  train_data26959.zip  train_data8665.zip\n",
            "train_data17811.zip  train_data2695.zip   train_data8666.zip\n",
            "train_data17812.zip  train_data26960.zip  train_data8667.zip\n",
            "train_data17813.zip  train_data26961.zip  train_data8668.zip\n",
            "train_data17814.zip  train_data26962.zip  train_data8669.zip\n",
            "train_data17815.zip  train_data26963.zip  train_data866.zip\n",
            "train_data17816.zip  train_data26964.zip  train_data8670.zip\n",
            "train_data17817.zip  train_data26965.zip  train_data8671.zip\n",
            "train_data17818.zip  train_data26966.zip  train_data8672.zip\n",
            "train_data17819.zip  train_data26967.zip  train_data8673.zip\n",
            "train_data1781.zip   train_data26968.zip  train_data8674.zip\n",
            "train_data17820.zip  train_data26969.zip  train_data8675.zip\n",
            "train_data17821.zip  train_data2696.zip   train_data8676.zip\n",
            "train_data17822.zip  train_data26970.zip  train_data8677.zip\n",
            "train_data17823.zip  train_data26971.zip  train_data8678.zip\n",
            "train_data17824.zip  train_data26972.zip  train_data8679.zip\n",
            "train_data17825.zip  train_data26973.zip  train_data867.zip\n",
            "train_data17826.zip  train_data26974.zip  train_data8680.zip\n",
            "train_data17827.zip  train_data26975.zip  train_data8681.zip\n",
            "train_data17828.zip  train_data26976.zip  train_data8682.zip\n",
            "train_data17829.zip  train_data26977.zip  train_data8683.zip\n",
            "train_data1782.zip   train_data26978.zip  train_data8684.zip\n",
            "train_data17830.zip  train_data26979.zip  train_data8685.zip\n",
            "train_data17831.zip  train_data2697.zip   train_data8686.zip\n",
            "train_data17832.zip  train_data26980.zip  train_data8687.zip\n",
            "train_data17833.zip  train_data26981.zip  train_data8688.zip\n",
            "train_data17834.zip  train_data26982.zip  train_data8689.zip\n",
            "train_data17835.zip  train_data26983.zip  train_data868.zip\n",
            "train_data17836.zip  train_data26984.zip  train_data8690.zip\n",
            "train_data17837.zip  train_data26985.zip  train_data8691.zip\n",
            "train_data17838.zip  train_data26986.zip  train_data8692.zip\n",
            "train_data17839.zip  train_data26987.zip  train_data8693.zip\n",
            "train_data1783.zip   train_data26988.zip  train_data8694.zip\n",
            "train_data17840.zip  train_data26989.zip  train_data8695.zip\n",
            "train_data17841.zip  train_data2698.zip   train_data8696.zip\n",
            "train_data17842.zip  train_data26990.zip  train_data8697.zip\n",
            "train_data17843.zip  train_data26991.zip  train_data8698.zip\n",
            "train_data17844.zip  train_data26992.zip  train_data8699.zip\n",
            "train_data17845.zip  train_data26993.zip  train_data869.zip\n",
            "train_data17846.zip  train_data26994.zip  train_data86.zip\n",
            "train_data17847.zip  train_data26995.zip  train_data8700.zip\n",
            "train_data17848.zip  train_data26996.zip  train_data8701.zip\n",
            "train_data17849.zip  train_data26997.zip  train_data8702.zip\n",
            "train_data1784.zip   train_data26998.zip  train_data8703.zip\n",
            "train_data17850.zip  train_data26999.zip  train_data8704.zip\n",
            "train_data17851.zip  train_data2699.zip   train_data8705.zip\n",
            "train_data17852.zip  train_data269.zip\t  train_data8706.zip\n",
            "train_data17853.zip  train_data26.zip\t  train_data8707.zip\n",
            "train_data17854.zip  train_data27000.zip  train_data8708.zip\n",
            "train_data17855.zip  train_data27001.zip  train_data8709.zip\n",
            "train_data17856.zip  train_data27002.zip  train_data870.zip\n",
            "train_data17857.zip  train_data27003.zip  train_data8710.zip\n",
            "train_data17858.zip  train_data27004.zip  train_data8711.zip\n",
            "train_data17859.zip  train_data27005.zip  train_data8712.zip\n",
            "train_data1785.zip   train_data27006.zip  train_data8713.zip\n",
            "train_data17860.zip  train_data27007.zip  train_data8714.zip\n",
            "train_data17861.zip  train_data27008.zip  train_data8715.zip\n",
            "train_data17862.zip  train_data27009.zip  train_data8716.zip\n",
            "train_data17863.zip  train_data2700.zip   train_data8717.zip\n",
            "train_data17864.zip  train_data27010.zip  train_data8718.zip\n",
            "train_data17865.zip  train_data27011.zip  train_data8719.zip\n",
            "train_data17866.zip  train_data27012.zip  train_data871.zip\n",
            "train_data17867.zip  train_data27013.zip  train_data8720.zip\n",
            "train_data17868.zip  train_data27014.zip  train_data8721.zip\n",
            "train_data17869.zip  train_data27015.zip  train_data8722.zip\n",
            "train_data1786.zip   train_data27016.zip  train_data8723.zip\n",
            "train_data17870.zip  train_data27017.zip  train_data8724.zip\n",
            "train_data17871.zip  train_data27018.zip  train_data8725.zip\n",
            "train_data17872.zip  train_data27019.zip  train_data8726.zip\n",
            "train_data17873.zip  train_data2701.zip   train_data8727.zip\n",
            "train_data17874.zip  train_data27020.zip  train_data8728.zip\n",
            "train_data17875.zip  train_data27021.zip  train_data8729.zip\n",
            "train_data17876.zip  train_data27022.zip  train_data872.zip\n",
            "train_data17877.zip  train_data27023.zip  train_data8730.zip\n",
            "train_data17878.zip  train_data27024.zip  train_data8731.zip\n",
            "train_data17879.zip  train_data27025.zip  train_data8732.zip\n",
            "train_data1787.zip   train_data27026.zip  train_data8733.zip\n",
            "train_data17880.zip  train_data27027.zip  train_data8734.zip\n",
            "train_data17881.zip  train_data27028.zip  train_data8735.zip\n",
            "train_data17882.zip  train_data27029.zip  train_data8736.zip\n",
            "train_data17883.zip  train_data2702.zip   train_data8737.zip\n",
            "train_data17884.zip  train_data27030.zip  train_data8738.zip\n",
            "train_data17885.zip  train_data27031.zip  train_data8739.zip\n",
            "train_data17886.zip  train_data27032.zip  train_data873.zip\n",
            "train_data17887.zip  train_data27033.zip  train_data8740.zip\n",
            "train_data17888.zip  train_data27034.zip  train_data8741.zip\n",
            "train_data17889.zip  train_data27035.zip  train_data8742.zip\n",
            "train_data1788.zip   train_data27036.zip  train_data8743.zip\n",
            "train_data17890.zip  train_data27037.zip  train_data8744.zip\n",
            "train_data17891.zip  train_data27038.zip  train_data8745.zip\n",
            "train_data17892.zip  train_data27039.zip  train_data8746.zip\n",
            "train_data17893.zip  train_data2703.zip   train_data8747.zip\n",
            "train_data17894.zip  train_data27040.zip  train_data8748.zip\n",
            "train_data17895.zip  train_data27041.zip  train_data8749.zip\n",
            "train_data17896.zip  train_data27042.zip  train_data874.zip\n",
            "train_data17897.zip  train_data27043.zip  train_data8750.zip\n",
            "train_data17898.zip  train_data27044.zip  train_data8751.zip\n",
            "train_data17899.zip  train_data27045.zip  train_data8752.zip\n",
            "train_data1789.zip   train_data27046.zip  train_data8753.zip\n",
            "train_data178.zip    train_data27047.zip  train_data8754.zip\n",
            "train_data17900.zip  train_data27048.zip  train_data8755.zip\n",
            "train_data17901.zip  train_data27049.zip  train_data8756.zip\n",
            "train_data17902.zip  train_data2704.zip   train_data8757.zip\n",
            "train_data17903.zip  train_data27050.zip  train_data8758.zip\n",
            "train_data17904.zip  train_data27051.zip  train_data8759.zip\n",
            "train_data17905.zip  train_data27052.zip  train_data875.zip\n",
            "train_data17906.zip  train_data27053.zip  train_data8760.zip\n",
            "train_data17907.zip  train_data27054.zip  train_data8761.zip\n",
            "train_data17908.zip  train_data27055.zip  train_data8762.zip\n",
            "train_data17909.zip  train_data27056.zip  train_data8763.zip\n",
            "train_data1790.zip   train_data27057.zip  train_data8764.zip\n",
            "train_data17910.zip  train_data27058.zip  train_data8765.zip\n",
            "train_data17911.zip  train_data27059.zip  train_data8766.zip\n",
            "train_data17912.zip  train_data2705.zip   train_data8767.zip\n",
            "train_data17913.zip  train_data27060.zip  train_data8768.zip\n",
            "train_data17914.zip  train_data27061.zip  train_data8769.zip\n",
            "train_data17915.zip  train_data27062.zip  train_data876.zip\n",
            "train_data17916.zip  train_data27063.zip  train_data8770.zip\n",
            "train_data17917.zip  train_data27064.zip  train_data8771.zip\n",
            "train_data17918.zip  train_data27065.zip  train_data8772.zip\n",
            "train_data17919.zip  train_data27066.zip  train_data8773.zip\n",
            "train_data1791.zip   train_data27067.zip  train_data8774.zip\n",
            "train_data17920.zip  train_data27068.zip  train_data8775.zip\n",
            "train_data17921.zip  train_data27069.zip  train_data8776.zip\n",
            "train_data17922.zip  train_data2706.zip   train_data8777.zip\n",
            "train_data17923.zip  train_data27070.zip  train_data8778.zip\n",
            "train_data17924.zip  train_data27071.zip  train_data8779.zip\n",
            "train_data17925.zip  train_data27072.zip  train_data877.zip\n",
            "train_data17926.zip  train_data27073.zip  train_data8780.zip\n",
            "train_data17927.zip  train_data27074.zip  train_data8781.zip\n",
            "train_data17928.zip  train_data27075.zip  train_data8782.zip\n",
            "train_data17929.zip  train_data27076.zip  train_data8783.zip\n",
            "train_data1792.zip   train_data27077.zip  train_data8784.zip\n",
            "train_data17930.zip  train_data27078.zip  train_data8785.zip\n",
            "train_data17931.zip  train_data27079.zip  train_data8786.zip\n",
            "train_data17932.zip  train_data2707.zip   train_data8787.zip\n",
            "train_data17933.zip  train_data27080.zip  train_data8788.zip\n",
            "train_data17934.zip  train_data27081.zip  train_data8789.zip\n",
            "train_data17935.zip  train_data27082.zip  train_data878.zip\n",
            "train_data17936.zip  train_data27083.zip  train_data8790.zip\n",
            "train_data17937.zip  train_data27084.zip  train_data8791.zip\n",
            "train_data17938.zip  train_data27085.zip  train_data8792.zip\n",
            "train_data17939.zip  train_data27086.zip  train_data8793.zip\n",
            "train_data1793.zip   train_data27087.zip  train_data8794.zip\n",
            "train_data17940.zip  train_data27088.zip  train_data8795.zip\n",
            "train_data17941.zip  train_data27089.zip  train_data8796.zip\n",
            "train_data17942.zip  train_data2708.zip   train_data8797.zip\n",
            "train_data17943.zip  train_data27090.zip  train_data8798.zip\n",
            "train_data17944.zip  train_data27091.zip  train_data8799.zip\n",
            "train_data17945.zip  train_data27092.zip  train_data879.zip\n",
            "train_data17946.zip  train_data27093.zip  train_data87.zip\n",
            "train_data17947.zip  train_data27094.zip  train_data8800.zip\n",
            "train_data17948.zip  train_data27095.zip  train_data8801.zip\n",
            "train_data17949.zip  train_data27096.zip  train_data8802.zip\n",
            "train_data1794.zip   train_data27097.zip  train_data8803.zip\n",
            "train_data17950.zip  train_data27098.zip  train_data8804.zip\n",
            "train_data17951.zip  train_data27099.zip  train_data8805.zip\n",
            "train_data17952.zip  train_data2709.zip   train_data8806.zip\n",
            "train_data17953.zip  train_data270.zip\t  train_data8807.zip\n",
            "train_data17954.zip  train_data27100.zip  train_data8808.zip\n",
            "train_data17955.zip  train_data27101.zip  train_data8809.zip\n",
            "train_data17956.zip  train_data27102.zip  train_data880.zip\n",
            "train_data17957.zip  train_data27103.zip  train_data8810.zip\n",
            "train_data17958.zip  train_data27104.zip  train_data8811.zip\n",
            "train_data17959.zip  train_data27105.zip  train_data8812.zip\n",
            "train_data1795.zip   train_data27106.zip  train_data8813.zip\n",
            "train_data17960.zip  train_data27107.zip  train_data8814.zip\n",
            "train_data17961.zip  train_data27108.zip  train_data8815.zip\n",
            "train_data17962.zip  train_data27109.zip  train_data8816.zip\n",
            "train_data17963.zip  train_data2710.zip   train_data8817.zip\n",
            "train_data17964.zip  train_data27110.zip  train_data8818.zip\n",
            "train_data17965.zip  train_data27111.zip  train_data8819.zip\n",
            "train_data17966.zip  train_data27112.zip  train_data881.zip\n",
            "train_data17967.zip  train_data27113.zip  train_data8820.zip\n",
            "train_data17968.zip  train_data27114.zip  train_data8821.zip\n",
            "train_data17969.zip  train_data27115.zip  train_data8822.zip\n",
            "train_data1796.zip   train_data27116.zip  train_data8823.zip\n",
            "train_data17970.zip  train_data27117.zip  train_data8824.zip\n",
            "train_data17971.zip  train_data27118.zip  train_data8825.zip\n",
            "train_data17972.zip  train_data27119.zip  train_data8826.zip\n",
            "train_data17973.zip  train_data2711.zip   train_data8827.zip\n",
            "train_data17974.zip  train_data27120.zip  train_data8828.zip\n",
            "train_data17975.zip  train_data27121.zip  train_data8829.zip\n",
            "train_data17976.zip  train_data27122.zip  train_data882.zip\n",
            "train_data17977.zip  train_data27123.zip  train_data8830.zip\n",
            "train_data17978.zip  train_data27124.zip  train_data8831.zip\n",
            "train_data17979.zip  train_data27125.zip  train_data8832.zip\n",
            "train_data1797.zip   train_data27126.zip  train_data8833.zip\n",
            "train_data17980.zip  train_data27127.zip  train_data8834.zip\n",
            "train_data17981.zip  train_data27128.zip  train_data8835.zip\n",
            "train_data17982.zip  train_data27129.zip  train_data8836.zip\n",
            "train_data17983.zip  train_data2712.zip   train_data8837.zip\n",
            "train_data17984.zip  train_data27130.zip  train_data8838.zip\n",
            "train_data17985.zip  train_data27131.zip  train_data8839.zip\n",
            "train_data17986.zip  train_data27132.zip  train_data883.zip\n",
            "train_data17987.zip  train_data27133.zip  train_data8840.zip\n",
            "train_data17988.zip  train_data27134.zip  train_data8841.zip\n",
            "train_data17989.zip  train_data27135.zip  train_data8842.zip\n",
            "train_data1798.zip   train_data27136.zip  train_data8843.zip\n",
            "train_data17990.zip  train_data27137.zip  train_data8844.zip\n",
            "train_data17991.zip  train_data27138.zip  train_data8845.zip\n",
            "train_data17992.zip  train_data27139.zip  train_data8846.zip\n",
            "train_data17993.zip  train_data2713.zip   train_data8847.zip\n",
            "train_data17994.zip  train_data27140.zip  train_data8848.zip\n",
            "train_data17995.zip  train_data27141.zip  train_data8849.zip\n",
            "train_data17996.zip  train_data27142.zip  train_data884.zip\n",
            "train_data17997.zip  train_data27143.zip  train_data8850.zip\n",
            "train_data17998.zip  train_data27144.zip  train_data8851.zip\n",
            "train_data17999.zip  train_data27145.zip  train_data8852.zip\n",
            "train_data1799.zip   train_data27146.zip  train_data8853.zip\n",
            "train_data179.zip    train_data27147.zip  train_data8854.zip\n",
            "train_data17.zip     train_data27148.zip  train_data8855.zip\n",
            "train_data18000.zip  train_data27149.zip  train_data8856.zip\n",
            "train_data18001.zip  train_data2714.zip   train_data8857.zip\n",
            "train_data18002.zip  train_data27150.zip  train_data8858.zip\n",
            "train_data18003.zip  train_data27151.zip  train_data8859.zip\n",
            "train_data18004.zip  train_data27152.zip  train_data885.zip\n",
            "train_data18005.zip  train_data27153.zip  train_data8860.zip\n",
            "train_data18006.zip  train_data27154.zip  train_data8861.zip\n",
            "train_data18007.zip  train_data27155.zip  train_data8862.zip\n",
            "train_data18008.zip  train_data27156.zip  train_data8863.zip\n",
            "train_data18009.zip  train_data27157.zip  train_data8864.zip\n",
            "train_data1800.zip   train_data27158.zip  train_data8865.zip\n",
            "train_data18010.zip  train_data27159.zip  train_data8866.zip\n",
            "train_data18011.zip  train_data2715.zip   train_data8867.zip\n",
            "train_data18012.zip  train_data27160.zip  train_data8868.zip\n",
            "train_data18013.zip  train_data27161.zip  train_data8869.zip\n",
            "train_data18014.zip  train_data27162.zip  train_data886.zip\n",
            "train_data18015.zip  train_data27163.zip  train_data8870.zip\n",
            "train_data18016.zip  train_data27164.zip  train_data8871.zip\n",
            "train_data18017.zip  train_data27165.zip  train_data8872.zip\n",
            "train_data18018.zip  train_data27166.zip  train_data8873.zip\n",
            "train_data18019.zip  train_data27167.zip  train_data8874.zip\n",
            "train_data1801.zip   train_data27168.zip  train_data8875.zip\n",
            "train_data18020.zip  train_data27169.zip  train_data8876.zip\n",
            "train_data18021.zip  train_data2716.zip   train_data8877.zip\n",
            "train_data18022.zip  train_data27170.zip  train_data8878.zip\n",
            "train_data18023.zip  train_data27171.zip  train_data8879.zip\n",
            "train_data18024.zip  train_data27172.zip  train_data887.zip\n",
            "train_data18025.zip  train_data27173.zip  train_data8880.zip\n",
            "train_data18026.zip  train_data27174.zip  train_data8881.zip\n",
            "train_data18027.zip  train_data27175.zip  train_data8882.zip\n",
            "train_data18028.zip  train_data27176.zip  train_data8883.zip\n",
            "train_data18029.zip  train_data27177.zip  train_data8884.zip\n",
            "train_data1802.zip   train_data27178.zip  train_data8885.zip\n",
            "train_data18030.zip  train_data27179.zip  train_data8886.zip\n",
            "train_data18031.zip  train_data2717.zip   train_data8887.zip\n",
            "train_data18032.zip  train_data27180.zip  train_data8888.zip\n",
            "train_data18033.zip  train_data27181.zip  train_data8889.zip\n",
            "train_data18034.zip  train_data27182.zip  train_data888.zip\n",
            "train_data18035.zip  train_data27183.zip  train_data8890.zip\n",
            "train_data18036.zip  train_data27184.zip  train_data8891.zip\n",
            "train_data18037.zip  train_data27185.zip  train_data8892.zip\n",
            "train_data18038.zip  train_data27186.zip  train_data8893.zip\n",
            "train_data18039.zip  train_data27187.zip  train_data8894.zip\n",
            "train_data1803.zip   train_data27188.zip  train_data8895.zip\n",
            "train_data18040.zip  train_data27189.zip  train_data8896.zip\n",
            "train_data18041.zip  train_data2718.zip   train_data8897.zip\n",
            "train_data18042.zip  train_data27190.zip  train_data8898.zip\n",
            "train_data18043.zip  train_data27191.zip  train_data8899.zip\n",
            "train_data18044.zip  train_data27192.zip  train_data889.zip\n",
            "train_data18045.zip  train_data27193.zip  train_data88.zip\n",
            "train_data18046.zip  train_data27194.zip  train_data8900.zip\n",
            "train_data18047.zip  train_data27195.zip  train_data8901.zip\n",
            "train_data18048.zip  train_data27196.zip  train_data8902.zip\n",
            "train_data18049.zip  train_data27197.zip  train_data8903.zip\n",
            "train_data1804.zip   train_data27198.zip  train_data8904.zip\n",
            "train_data18050.zip  train_data27199.zip  train_data8905.zip\n",
            "train_data18051.zip  train_data2719.zip   train_data8906.zip\n",
            "train_data18052.zip  train_data271.zip\t  train_data8907.zip\n",
            "train_data18053.zip  train_data27200.zip  train_data8908.zip\n",
            "train_data18054.zip  train_data27201.zip  train_data8909.zip\n",
            "train_data18055.zip  train_data27202.zip  train_data890.zip\n",
            "train_data18056.zip  train_data27203.zip  train_data8910.zip\n",
            "train_data18057.zip  train_data27204.zip  train_data8911.zip\n",
            "train_data18058.zip  train_data27205.zip  train_data8912.zip\n",
            "train_data18059.zip  train_data27206.zip  train_data8913.zip\n",
            "train_data1805.zip   train_data27207.zip  train_data8914.zip\n",
            "train_data18060.zip  train_data27208.zip  train_data8915.zip\n",
            "train_data18061.zip  train_data27209.zip  train_data8916.zip\n",
            "train_data18062.zip  train_data2720.zip   train_data8917.zip\n",
            "train_data18063.zip  train_data27210.zip  train_data8918.zip\n",
            "train_data18064.zip  train_data27211.zip  train_data8919.zip\n",
            "train_data18065.zip  train_data27212.zip  train_data891.zip\n",
            "train_data18066.zip  train_data27213.zip  train_data8920.zip\n",
            "train_data18067.zip  train_data27214.zip  train_data8921.zip\n",
            "train_data18068.zip  train_data27215.zip  train_data8922.zip\n",
            "train_data18069.zip  train_data27216.zip  train_data8923.zip\n",
            "train_data1806.zip   train_data27217.zip  train_data8924.zip\n",
            "train_data18070.zip  train_data27218.zip  train_data8925.zip\n",
            "train_data18071.zip  train_data27219.zip  train_data8926.zip\n",
            "train_data18072.zip  train_data2721.zip   train_data8927.zip\n",
            "train_data18073.zip  train_data27220.zip  train_data8928.zip\n",
            "train_data18074.zip  train_data27221.zip  train_data8929.zip\n",
            "train_data18075.zip  train_data27222.zip  train_data892.zip\n",
            "train_data18076.zip  train_data27223.zip  train_data8930.zip\n",
            "train_data18077.zip  train_data27224.zip  train_data8931.zip\n",
            "train_data18078.zip  train_data27225.zip  train_data8932.zip\n",
            "train_data18079.zip  train_data27226.zip  train_data8933.zip\n",
            "train_data1807.zip   train_data27227.zip  train_data8934.zip\n",
            "train_data18080.zip  train_data27228.zip  train_data8935.zip\n",
            "train_data18081.zip  train_data27229.zip  train_data8936.zip\n",
            "train_data18082.zip  train_data2722.zip   train_data8937.zip\n",
            "train_data18083.zip  train_data27230.zip  train_data8938.zip\n",
            "train_data18084.zip  train_data27231.zip  train_data8939.zip\n",
            "train_data18085.zip  train_data27232.zip  train_data893.zip\n",
            "train_data18086.zip  train_data27233.zip  train_data8940.zip\n",
            "train_data18087.zip  train_data27234.zip  train_data8941.zip\n",
            "train_data18088.zip  train_data27235.zip  train_data8942.zip\n",
            "train_data18089.zip  train_data27236.zip  train_data8943.zip\n",
            "train_data1808.zip   train_data27237.zip  train_data8944.zip\n",
            "train_data18090.zip  train_data27238.zip  train_data8945.zip\n",
            "train_data18091.zip  train_data27239.zip  train_data8946.zip\n",
            "train_data18092.zip  train_data2723.zip   train_data8947.zip\n",
            "train_data18093.zip  train_data27240.zip  train_data8948.zip\n",
            "train_data18094.zip  train_data27241.zip  train_data8949.zip\n",
            "train_data18095.zip  train_data27242.zip  train_data894.zip\n",
            "train_data18096.zip  train_data27243.zip  train_data8950.zip\n",
            "train_data18097.zip  train_data27244.zip  train_data8951.zip\n",
            "train_data18098.zip  train_data27245.zip  train_data8952.zip\n",
            "train_data18099.zip  train_data27246.zip  train_data8953.zip\n",
            "train_data1809.zip   train_data27247.zip  train_data8954.zip\n",
            "train_data180.zip    train_data27248.zip  train_data8955.zip\n",
            "train_data18100.zip  train_data27249.zip  train_data8956.zip\n",
            "train_data18101.zip  train_data2724.zip   train_data8957.zip\n",
            "train_data18102.zip  train_data27250.zip  train_data8958.zip\n",
            "train_data18103.zip  train_data27251.zip  train_data8959.zip\n",
            "train_data18104.zip  train_data27252.zip  train_data895.zip\n",
            "train_data18105.zip  train_data27253.zip  train_data8960.zip\n",
            "train_data18106.zip  train_data27254.zip  train_data8961.zip\n",
            "train_data18107.zip  train_data27255.zip  train_data8962.zip\n",
            "train_data18108.zip  train_data27256.zip  train_data8963.zip\n",
            "train_data18109.zip  train_data27257.zip  train_data8964.zip\n",
            "train_data1810.zip   train_data27258.zip  train_data8965.zip\n",
            "train_data18110.zip  train_data27259.zip  train_data8966.zip\n",
            "train_data18111.zip  train_data2725.zip   train_data8967.zip\n",
            "train_data18112.zip  train_data27260.zip  train_data8968.zip\n",
            "train_data18113.zip  train_data27261.zip  train_data8969.zip\n",
            "train_data18114.zip  train_data27262.zip  train_data896.zip\n",
            "train_data18115.zip  train_data27263.zip  train_data8970.zip\n",
            "train_data18116.zip  train_data27264.zip  train_data8971.zip\n",
            "train_data18117.zip  train_data27265.zip  train_data8972.zip\n",
            "train_data18118.zip  train_data27266.zip  train_data8973.zip\n",
            "train_data18119.zip  train_data27267.zip  train_data8974.zip\n",
            "train_data1811.zip   train_data27268.zip  train_data8975.zip\n",
            "train_data18120.zip  train_data27269.zip  train_data8976.zip\n",
            "train_data18121.zip  train_data2726.zip   train_data8977.zip\n",
            "train_data18122.zip  train_data27270.zip  train_data8978.zip\n",
            "train_data18123.zip  train_data27271.zip  train_data8979.zip\n",
            "train_data18124.zip  train_data27272.zip  train_data897.zip\n",
            "train_data18125.zip  train_data27273.zip  train_data8980.zip\n",
            "train_data18126.zip  train_data27274.zip  train_data8981.zip\n",
            "train_data18127.zip  train_data27275.zip  train_data8982.zip\n",
            "train_data18128.zip  train_data27276.zip  train_data8983.zip\n",
            "train_data18129.zip  train_data27277.zip  train_data8984.zip\n",
            "train_data1812.zip   train_data27278.zip  train_data8985.zip\n",
            "train_data18130.zip  train_data27279.zip  train_data8986.zip\n",
            "train_data18131.zip  train_data2727.zip   train_data8987.zip\n",
            "train_data18132.zip  train_data27280.zip  train_data8988.zip\n",
            "train_data18133.zip  train_data27281.zip  train_data8989.zip\n",
            "train_data18134.zip  train_data27282.zip  train_data898.zip\n",
            "train_data18135.zip  train_data27283.zip  train_data8990.zip\n",
            "train_data18136.zip  train_data27284.zip  train_data8991.zip\n",
            "train_data18137.zip  train_data27285.zip  train_data8992.zip\n",
            "train_data18138.zip  train_data27286.zip  train_data8993.zip\n",
            "train_data18139.zip  train_data27287.zip  train_data8994.zip\n",
            "train_data1813.zip   train_data27288.zip  train_data8995.zip\n",
            "train_data18140.zip  train_data27289.zip  train_data8996.zip\n",
            "train_data18141.zip  train_data2728.zip   train_data8997.zip\n",
            "train_data18142.zip  train_data27290.zip  train_data8998.zip\n",
            "train_data18143.zip  train_data27291.zip  train_data8999.zip\n",
            "train_data18144.zip  train_data27292.zip  train_data899.zip\n",
            "train_data18145.zip  train_data27293.zip  train_data89.zip\n",
            "train_data18146.zip  train_data27294.zip  train_data8.zip\n",
            "train_data18147.zip  train_data27295.zip  train_data9000.zip\n",
            "train_data18148.zip  train_data27296.zip  train_data9001.zip\n",
            "train_data18149.zip  train_data27297.zip  train_data9002.zip\n",
            "train_data1814.zip   train_data27298.zip  train_data9003.zip\n",
            "train_data18150.zip  train_data27299.zip  train_data9004.zip\n",
            "train_data18151.zip  train_data2729.zip   train_data9005.zip\n",
            "train_data18152.zip  train_data272.zip\t  train_data9006.zip\n",
            "train_data18153.zip  train_data27300.zip  train_data9007.zip\n",
            "train_data18154.zip  train_data27301.zip  train_data9008.zip\n",
            "train_data18155.zip  train_data27302.zip  train_data9009.zip\n",
            "train_data18156.zip  train_data27303.zip  train_data900.zip\n",
            "train_data18157.zip  train_data27304.zip  train_data9010.zip\n",
            "train_data18158.zip  train_data27305.zip  train_data9011.zip\n",
            "train_data18159.zip  train_data27306.zip  train_data9012.zip\n",
            "train_data1815.zip   train_data27307.zip  train_data9013.zip\n",
            "train_data18160.zip  train_data27308.zip  train_data9014.zip\n",
            "train_data18161.zip  train_data27309.zip  train_data9015.zip\n",
            "train_data18162.zip  train_data2730.zip   train_data9016.zip\n",
            "train_data18163.zip  train_data27310.zip  train_data9017.zip\n",
            "train_data18164.zip  train_data27311.zip  train_data9018.zip\n",
            "train_data18165.zip  train_data27312.zip  train_data9019.zip\n",
            "train_data18166.zip  train_data27313.zip  train_data901.zip\n",
            "train_data18167.zip  train_data27314.zip  train_data9020.zip\n",
            "train_data18168.zip  train_data27315.zip  train_data9021.zip\n",
            "train_data18169.zip  train_data27316.zip  train_data9022.zip\n",
            "train_data1816.zip   train_data27317.zip  train_data9023.zip\n",
            "train_data18170.zip  train_data27318.zip  train_data9024.zip\n",
            "train_data18171.zip  train_data27319.zip  train_data9025.zip\n",
            "train_data18172.zip  train_data2731.zip   train_data9026.zip\n",
            "train_data18173.zip  train_data27320.zip  train_data9027.zip\n",
            "train_data18174.zip  train_data27321.zip  train_data9028.zip\n",
            "train_data18175.zip  train_data27322.zip  train_data9029.zip\n",
            "train_data18176.zip  train_data27323.zip  train_data902.zip\n",
            "train_data18177.zip  train_data27324.zip  train_data9030.zip\n",
            "train_data18178.zip  train_data27325.zip  train_data9031.zip\n",
            "train_data18179.zip  train_data27326.zip  train_data9032.zip\n",
            "train_data1817.zip   train_data27327.zip  train_data9033.zip\n",
            "train_data18180.zip  train_data27328.zip  train_data9034.zip\n",
            "train_data18181.zip  train_data27329.zip  train_data9035.zip\n",
            "train_data18182.zip  train_data2732.zip   train_data9036.zip\n",
            "train_data18183.zip  train_data27330.zip  train_data9037.zip\n",
            "train_data18184.zip  train_data27331.zip  train_data9038.zip\n",
            "train_data18185.zip  train_data27332.zip  train_data9039.zip\n",
            "train_data18186.zip  train_data27333.zip  train_data903.zip\n",
            "train_data18187.zip  train_data27334.zip  train_data9040.zip\n",
            "train_data18188.zip  train_data27335.zip  train_data9041.zip\n",
            "train_data18189.zip  train_data27336.zip  train_data9042.zip\n",
            "train_data1818.zip   train_data27337.zip  train_data9043.zip\n",
            "train_data18190.zip  train_data27338.zip  train_data9044.zip\n",
            "train_data18191.zip  train_data27339.zip  train_data9045.zip\n",
            "train_data18192.zip  train_data2733.zip   train_data9046.zip\n",
            "train_data18193.zip  train_data27340.zip  train_data9047.zip\n",
            "train_data18194.zip  train_data27341.zip  train_data9048.zip\n",
            "train_data18195.zip  train_data27342.zip  train_data9049.zip\n",
            "train_data18196.zip  train_data27343.zip  train_data904.zip\n",
            "train_data18197.zip  train_data27344.zip  train_data9050.zip\n",
            "train_data18198.zip  train_data27345.zip  train_data9051.zip\n",
            "train_data18199.zip  train_data27346.zip  train_data9052.zip\n",
            "train_data1819.zip   train_data27347.zip  train_data9053.zip\n",
            "train_data181.zip    train_data27348.zip  train_data9054.zip\n",
            "train_data18200.zip  train_data27349.zip  train_data9055.zip\n",
            "train_data18201.zip  train_data2734.zip   train_data9056.zip\n",
            "train_data18202.zip  train_data27350.zip  train_data9057.zip\n",
            "train_data18203.zip  train_data27351.zip  train_data9058.zip\n",
            "train_data18204.zip  train_data27352.zip  train_data9059.zip\n",
            "train_data18205.zip  train_data27353.zip  train_data905.zip\n",
            "train_data18206.zip  train_data27354.zip  train_data9060.zip\n",
            "train_data18207.zip  train_data27355.zip  train_data9061.zip\n",
            "train_data18208.zip  train_data27356.zip  train_data9062.zip\n",
            "train_data18209.zip  train_data27357.zip  train_data9063.zip\n",
            "train_data1820.zip   train_data27358.zip  train_data9064.zip\n",
            "train_data18210.zip  train_data27359.zip  train_data9065.zip\n",
            "train_data18211.zip  train_data2735.zip   train_data9066.zip\n",
            "train_data18212.zip  train_data27360.zip  train_data9067.zip\n",
            "train_data18213.zip  train_data27361.zip  train_data9068.zip\n",
            "train_data18214.zip  train_data27362.zip  train_data9069.zip\n",
            "train_data18215.zip  train_data27363.zip  train_data906.zip\n",
            "train_data18216.zip  train_data27364.zip  train_data9070.zip\n",
            "train_data18217.zip  train_data27365.zip  train_data9071.zip\n",
            "train_data18218.zip  train_data27366.zip  train_data9072.zip\n",
            "train_data18219.zip  train_data27367.zip  train_data9073.zip\n",
            "train_data1821.zip   train_data27368.zip  train_data9074.zip\n",
            "train_data18220.zip  train_data27369.zip  train_data9075.zip\n",
            "train_data18221.zip  train_data2736.zip   train_data9076.zip\n",
            "train_data18222.zip  train_data27370.zip  train_data9077.zip\n",
            "train_data18223.zip  train_data27371.zip  train_data9078.zip\n",
            "train_data18224.zip  train_data27372.zip  train_data9079.zip\n",
            "train_data18225.zip  train_data27373.zip  train_data907.zip\n",
            "train_data18226.zip  train_data27374.zip  train_data9080.zip\n",
            "train_data18227.zip  train_data27375.zip  train_data9081.zip\n",
            "train_data18228.zip  train_data27376.zip  train_data9082.zip\n",
            "train_data18229.zip  train_data27377.zip  train_data9083.zip\n",
            "train_data1822.zip   train_data27378.zip  train_data9084.zip\n",
            "train_data18230.zip  train_data27379.zip  train_data9085.zip\n",
            "train_data18231.zip  train_data2737.zip   train_data9086.zip\n",
            "train_data18232.zip  train_data27380.zip  train_data9087.zip\n",
            "train_data18233.zip  train_data27381.zip  train_data9088.zip\n",
            "train_data18234.zip  train_data27382.zip  train_data9089.zip\n",
            "train_data18235.zip  train_data27383.zip  train_data908.zip\n",
            "train_data18236.zip  train_data27384.zip  train_data9090.zip\n",
            "train_data18237.zip  train_data27385.zip  train_data9091.zip\n",
            "train_data18238.zip  train_data27386.zip  train_data9092.zip\n",
            "train_data18239.zip  train_data27387.zip  train_data9093.zip\n",
            "train_data1823.zip   train_data27388.zip  train_data9094.zip\n",
            "train_data18240.zip  train_data27389.zip  train_data9095.zip\n",
            "train_data18241.zip  train_data2738.zip   train_data9096.zip\n",
            "train_data18242.zip  train_data27390.zip  train_data9097.zip\n",
            "train_data18243.zip  train_data27391.zip  train_data9098.zip\n",
            "train_data18244.zip  train_data27392.zip  train_data9099.zip\n",
            "train_data18245.zip  train_data27393.zip  train_data909.zip\n",
            "train_data18246.zip  train_data27394.zip  train_data90.zip\n",
            "train_data18247.zip  train_data27395.zip  train_data9100.zip\n",
            "train_data18248.zip  train_data27396.zip  train_data9101.zip\n",
            "train_data18249.zip  train_data27397.zip  train_data9102.zip\n",
            "train_data1824.zip   train_data27398.zip  train_data9103.zip\n",
            "train_data18250.zip  train_data27399.zip  train_data9104.zip\n",
            "train_data18251.zip  train_data2739.zip   train_data9105.zip\n",
            "train_data18252.zip  train_data273.zip\t  train_data9106.zip\n",
            "train_data18253.zip  train_data27400.zip  train_data9107.zip\n",
            "train_data18254.zip  train_data27401.zip  train_data9108.zip\n",
            "train_data18255.zip  train_data27402.zip  train_data9109.zip\n",
            "train_data18256.zip  train_data27403.zip  train_data910.zip\n",
            "train_data18257.zip  train_data27404.zip  train_data9110.zip\n",
            "train_data18258.zip  train_data27405.zip  train_data9111.zip\n",
            "train_data18259.zip  train_data27406.zip  train_data9112.zip\n",
            "train_data1825.zip   train_data27407.zip  train_data9113.zip\n",
            "train_data18260.zip  train_data27408.zip  train_data9114.zip\n",
            "train_data18261.zip  train_data27409.zip  train_data9115.zip\n",
            "train_data18262.zip  train_data2740.zip   train_data9116.zip\n",
            "train_data18263.zip  train_data27410.zip  train_data9117.zip\n",
            "train_data18264.zip  train_data27411.zip  train_data9118.zip\n",
            "train_data18265.zip  train_data27412.zip  train_data9119.zip\n",
            "train_data18266.zip  train_data27413.zip  train_data911.zip\n",
            "train_data18267.zip  train_data27414.zip  train_data9120.zip\n",
            "train_data18268.zip  train_data27415.zip  train_data9121.zip\n",
            "train_data18269.zip  train_data27416.zip  train_data9122.zip\n",
            "train_data1826.zip   train_data27417.zip  train_data9123.zip\n",
            "train_data18270.zip  train_data27418.zip  train_data9124.zip\n",
            "train_data18271.zip  train_data27419.zip  train_data9125.zip\n",
            "train_data18272.zip  train_data2741.zip   train_data9126.zip\n",
            "train_data18273.zip  train_data27420.zip  train_data9127.zip\n",
            "train_data18274.zip  train_data27421.zip  train_data9128.zip\n",
            "train_data18275.zip  train_data27422.zip  train_data9129.zip\n",
            "train_data18276.zip  train_data27423.zip  train_data912.zip\n",
            "train_data18277.zip  train_data27424.zip  train_data9130.zip\n",
            "train_data18278.zip  train_data27425.zip  train_data9131.zip\n",
            "train_data18279.zip  train_data27426.zip  train_data9132.zip\n",
            "train_data1827.zip   train_data27427.zip  train_data9133.zip\n",
            "train_data18280.zip  train_data27428.zip  train_data9134.zip\n",
            "train_data18281.zip  train_data27429.zip  train_data9135.zip\n",
            "train_data18282.zip  train_data2742.zip   train_data9136.zip\n",
            "train_data18283.zip  train_data27430.zip  train_data9137.zip\n",
            "train_data18284.zip  train_data27431.zip  train_data9138.zip\n",
            "train_data18285.zip  train_data27432.zip  train_data9139.zip\n",
            "train_data18286.zip  train_data27433.zip  train_data913.zip\n",
            "train_data18287.zip  train_data27434.zip  train_data9140.zip\n",
            "train_data18288.zip  train_data27435.zip  train_data9141.zip\n",
            "train_data18289.zip  train_data27436.zip  train_data9142.zip\n",
            "train_data1828.zip   train_data27437.zip  train_data9143.zip\n",
            "train_data18290.zip  train_data27438.zip  train_data9144.zip\n",
            "train_data18291.zip  train_data27439.zip  train_data9145.zip\n",
            "train_data18292.zip  train_data2743.zip   train_data9146.zip\n",
            "train_data18293.zip  train_data27440.zip  train_data9147.zip\n",
            "train_data18294.zip  train_data27441.zip  train_data9148.zip\n",
            "train_data18295.zip  train_data27442.zip  train_data9149.zip\n",
            "train_data18296.zip  train_data27443.zip  train_data914.zip\n",
            "train_data18297.zip  train_data27444.zip  train_data9150.zip\n",
            "train_data18298.zip  train_data27445.zip  train_data9151.zip\n",
            "train_data18299.zip  train_data27446.zip  train_data9152.zip\n",
            "train_data1829.zip   train_data27447.zip  train_data9153.zip\n",
            "train_data182.zip    train_data27448.zip  train_data9154.zip\n",
            "train_data18300.zip  train_data27449.zip  train_data9155.zip\n",
            "train_data18301.zip  train_data2744.zip   train_data9156.zip\n",
            "train_data18302.zip  train_data27450.zip  train_data9157.zip\n",
            "train_data18303.zip  train_data27451.zip  train_data9158.zip\n",
            "train_data18304.zip  train_data27452.zip  train_data9159.zip\n",
            "train_data18305.zip  train_data27453.zip  train_data915.zip\n",
            "train_data18306.zip  train_data27454.zip  train_data9160.zip\n",
            "train_data18307.zip  train_data27455.zip  train_data9161.zip\n",
            "train_data18308.zip  train_data27456.zip  train_data9162.zip\n",
            "train_data18309.zip  train_data27457.zip  train_data9163.zip\n",
            "train_data1830.zip   train_data27458.zip  train_data9164.zip\n",
            "train_data18310.zip  train_data27459.zip  train_data9165.zip\n",
            "train_data18311.zip  train_data2745.zip   train_data9166.zip\n",
            "train_data18312.zip  train_data27460.zip  train_data9167.zip\n",
            "train_data18313.zip  train_data27461.zip  train_data9168.zip\n",
            "train_data18314.zip  train_data27462.zip  train_data9169.zip\n",
            "train_data18315.zip  train_data27463.zip  train_data916.zip\n",
            "train_data18316.zip  train_data27464.zip  train_data9170.zip\n",
            "train_data18317.zip  train_data27465.zip  train_data9171.zip\n",
            "train_data18318.zip  train_data27466.zip  train_data9172.zip\n",
            "train_data18319.zip  train_data27467.zip  train_data9173.zip\n",
            "train_data1831.zip   train_data27468.zip  train_data9174.zip\n",
            "train_data18320.zip  train_data27469.zip  train_data9175.zip\n",
            "train_data18321.zip  train_data2746.zip   train_data9176.zip\n",
            "train_data18322.zip  train_data27470.zip  train_data9177.zip\n",
            "train_data18323.zip  train_data27471.zip  train_data9178.zip\n",
            "train_data18324.zip  train_data27472.zip  train_data9179.zip\n",
            "train_data18325.zip  train_data27473.zip  train_data917.zip\n",
            "train_data18326.zip  train_data27474.zip  train_data9180.zip\n",
            "train_data18327.zip  train_data27475.zip  train_data9181.zip\n",
            "train_data18328.zip  train_data27476.zip  train_data9182.zip\n",
            "train_data18329.zip  train_data27477.zip  train_data9183.zip\n",
            "train_data1832.zip   train_data27478.zip  train_data9184.zip\n",
            "train_data18330.zip  train_data27479.zip  train_data9185.zip\n",
            "train_data18331.zip  train_data2747.zip   train_data9186.zip\n",
            "train_data18332.zip  train_data27480.zip  train_data9187.zip\n",
            "train_data18333.zip  train_data27481.zip  train_data9188.zip\n",
            "train_data18334.zip  train_data27482.zip  train_data9189.zip\n",
            "train_data18335.zip  train_data27483.zip  train_data918.zip\n",
            "train_data18336.zip  train_data27484.zip  train_data9190.zip\n",
            "train_data18337.zip  train_data27485.zip  train_data9191.zip\n",
            "train_data18338.zip  train_data27486.zip  train_data9192.zip\n",
            "train_data18339.zip  train_data27487.zip  train_data9193.zip\n",
            "train_data1833.zip   train_data27488.zip  train_data9194.zip\n",
            "train_data18340.zip  train_data27489.zip  train_data9195.zip\n",
            "train_data18341.zip  train_data2748.zip   train_data9196.zip\n",
            "train_data18342.zip  train_data27490.zip  train_data9197.zip\n",
            "train_data18343.zip  train_data27491.zip  train_data9198.zip\n",
            "train_data18344.zip  train_data27492.zip  train_data9199.zip\n",
            "train_data18345.zip  train_data27493.zip  train_data919.zip\n",
            "train_data18346.zip  train_data27494.zip  train_data91.zip\n",
            "train_data18347.zip  train_data27495.zip  train_data9200.zip\n",
            "train_data18348.zip  train_data27496.zip  train_data9201.zip\n",
            "train_data18349.zip  train_data27497.zip  train_data9202.zip\n",
            "train_data1834.zip   train_data27498.zip  train_data9203.zip\n",
            "train_data18350.zip  train_data27499.zip  train_data9204.zip\n",
            "train_data18351.zip  train_data2749.zip   train_data9205.zip\n",
            "train_data18352.zip  train_data274.zip\t  train_data9206.zip\n",
            "train_data18353.zip  train_data27500.zip  train_data9207.zip\n",
            "train_data18354.zip  train_data27501.zip  train_data9208.zip\n",
            "train_data18355.zip  train_data27502.zip  train_data9209.zip\n",
            "train_data18356.zip  train_data27503.zip  train_data920.zip\n",
            "train_data18357.zip  train_data27504.zip  train_data9210.zip\n",
            "train_data18358.zip  train_data27505.zip  train_data9211.zip\n",
            "train_data18359.zip  train_data27506.zip  train_data9212.zip\n",
            "train_data1835.zip   train_data27507.zip  train_data9213.zip\n",
            "train_data18360.zip  train_data27508.zip  train_data9214.zip\n",
            "train_data18361.zip  train_data27509.zip  train_data9215.zip\n",
            "train_data18362.zip  train_data2750.zip   train_data9216.zip\n",
            "train_data18363.zip  train_data27510.zip  train_data9217.zip\n",
            "train_data18364.zip  train_data27511.zip  train_data9218.zip\n",
            "train_data18365.zip  train_data27512.zip  train_data9219.zip\n",
            "train_data18366.zip  train_data27513.zip  train_data921.zip\n",
            "train_data18367.zip  train_data27514.zip  train_data9220.zip\n",
            "train_data18368.zip  train_data27515.zip  train_data9221.zip\n",
            "train_data18369.zip  train_data27516.zip  train_data9222.zip\n",
            "train_data1836.zip   train_data27517.zip  train_data9223.zip\n",
            "train_data18370.zip  train_data27518.zip  train_data9224.zip\n",
            "train_data18371.zip  train_data27519.zip  train_data9225.zip\n",
            "train_data18372.zip  train_data2751.zip   train_data9226.zip\n",
            "train_data18373.zip  train_data27520.zip  train_data9227.zip\n",
            "train_data18374.zip  train_data27521.zip  train_data9228.zip\n",
            "train_data18375.zip  train_data27522.zip  train_data9229.zip\n",
            "train_data18376.zip  train_data27523.zip  train_data922.zip\n",
            "train_data18377.zip  train_data27524.zip  train_data9230.zip\n",
            "train_data18378.zip  train_data27525.zip  train_data9231.zip\n",
            "train_data18379.zip  train_data27526.zip  train_data9232.zip\n",
            "train_data1837.zip   train_data27527.zip  train_data9233.zip\n",
            "train_data18380.zip  train_data27528.zip  train_data9234.zip\n",
            "train_data18381.zip  train_data27529.zip  train_data9235.zip\n",
            "train_data18382.zip  train_data2752.zip   train_data9236.zip\n",
            "train_data18383.zip  train_data27530.zip  train_data9237.zip\n",
            "train_data18384.zip  train_data27531.zip  train_data9238.zip\n",
            "train_data18385.zip  train_data27532.zip  train_data9239.zip\n",
            "train_data18386.zip  train_data27533.zip  train_data923.zip\n",
            "train_data18387.zip  train_data27534.zip  train_data9240.zip\n",
            "train_data18388.zip  train_data27535.zip  train_data9241.zip\n",
            "train_data18389.zip  train_data27536.zip  train_data9242.zip\n",
            "train_data1838.zip   train_data27537.zip  train_data9243.zip\n",
            "train_data18390.zip  train_data27538.zip  train_data9244.zip\n",
            "train_data18391.zip  train_data27539.zip  train_data9245.zip\n",
            "train_data18392.zip  train_data2753.zip   train_data9246.zip\n",
            "train_data18393.zip  train_data27540.zip  train_data9247.zip\n",
            "train_data18394.zip  train_data27541.zip  train_data9248.zip\n",
            "train_data18395.zip  train_data27542.zip  train_data9249.zip\n",
            "train_data18396.zip  train_data27543.zip  train_data924.zip\n",
            "train_data18397.zip  train_data27544.zip  train_data9250.zip\n",
            "train_data18398.zip  train_data27545.zip  train_data9251.zip\n",
            "train_data18399.zip  train_data27546.zip  train_data9252.zip\n",
            "train_data1839.zip   train_data27547.zip  train_data9253.zip\n",
            "train_data183.zip    train_data27548.zip  train_data9254.zip\n",
            "train_data18400.zip  train_data27549.zip  train_data9255.zip\n",
            "train_data18401.zip  train_data2754.zip   train_data9256.zip\n",
            "train_data18402.zip  train_data27550.zip  train_data9257.zip\n",
            "train_data18403.zip  train_data27551.zip  train_data9258.zip\n",
            "train_data18404.zip  train_data27552.zip  train_data9259.zip\n",
            "train_data18405.zip  train_data27553.zip  train_data925.zip\n",
            "train_data18406.zip  train_data27554.zip  train_data9260.zip\n",
            "train_data18407.zip  train_data27555.zip  train_data9261.zip\n",
            "train_data18408.zip  train_data27556.zip  train_data9262.zip\n",
            "train_data18409.zip  train_data27557.zip  train_data9263.zip\n",
            "train_data1840.zip   train_data27558.zip  train_data9264.zip\n",
            "train_data18410.zip  train_data27559.zip  train_data9265.zip\n",
            "train_data18411.zip  train_data2755.zip   train_data9266.zip\n",
            "train_data18412.zip  train_data27560.zip  train_data9267.zip\n",
            "train_data18413.zip  train_data27561.zip  train_data9268.zip\n",
            "train_data18414.zip  train_data27562.zip  train_data9269.zip\n",
            "train_data18415.zip  train_data27563.zip  train_data926.zip\n",
            "train_data18416.zip  train_data27564.zip  train_data9270.zip\n",
            "train_data18417.zip  train_data27565.zip  train_data9271.zip\n",
            "train_data18418.zip  train_data27566.zip  train_data9272.zip\n",
            "train_data18419.zip  train_data27567.zip  train_data9273.zip\n",
            "train_data1841.zip   train_data27568.zip  train_data9274.zip\n",
            "train_data18420.zip  train_data27569.zip  train_data9275.zip\n",
            "train_data18421.zip  train_data2756.zip   train_data9276.zip\n",
            "train_data18422.zip  train_data27570.zip  train_data9277.zip\n",
            "train_data18423.zip  train_data27571.zip  train_data9278.zip\n",
            "train_data18424.zip  train_data27572.zip  train_data9279.zip\n",
            "train_data18425.zip  train_data27573.zip  train_data927.zip\n",
            "train_data18426.zip  train_data27574.zip  train_data9280.zip\n",
            "train_data18427.zip  train_data27575.zip  train_data9281.zip\n",
            "train_data18428.zip  train_data27576.zip  train_data9282.zip\n",
            "train_data18429.zip  train_data27577.zip  train_data9283.zip\n",
            "train_data1842.zip   train_data27578.zip  train_data9284.zip\n",
            "train_data18430.zip  train_data27579.zip  train_data9285.zip\n",
            "train_data18431.zip  train_data2757.zip   train_data9286.zip\n",
            "train_data18432.zip  train_data27580.zip  train_data9287.zip\n",
            "train_data18433.zip  train_data27581.zip  train_data9288.zip\n",
            "train_data18434.zip  train_data27582.zip  train_data9289.zip\n",
            "train_data18435.zip  train_data27583.zip  train_data928.zip\n",
            "train_data18436.zip  train_data27584.zip  train_data9290.zip\n",
            "train_data18437.zip  train_data27585.zip  train_data9291.zip\n",
            "train_data18438.zip  train_data27586.zip  train_data9292.zip\n",
            "train_data18439.zip  train_data27587.zip  train_data9293.zip\n",
            "train_data1843.zip   train_data27588.zip  train_data9294.zip\n",
            "train_data18440.zip  train_data27589.zip  train_data9295.zip\n",
            "train_data18441.zip  train_data2758.zip   train_data9296.zip\n",
            "train_data18442.zip  train_data27590.zip  train_data9297.zip\n",
            "train_data18443.zip  train_data27591.zip  train_data9298.zip\n",
            "train_data18444.zip  train_data27592.zip  train_data9299.zip\n",
            "train_data18445.zip  train_data27593.zip  train_data929.zip\n",
            "train_data18446.zip  train_data27594.zip  train_data92.zip\n",
            "train_data18447.zip  train_data27595.zip  train_data9300.zip\n",
            "train_data18448.zip  train_data27596.zip  train_data9301.zip\n",
            "train_data18449.zip  train_data27597.zip  train_data9302.zip\n",
            "train_data1844.zip   train_data27598.zip  train_data9303.zip\n",
            "train_data18450.zip  train_data27599.zip  train_data9304.zip\n",
            "train_data18451.zip  train_data2759.zip   train_data9305.zip\n",
            "train_data18452.zip  train_data275.zip\t  train_data9306.zip\n",
            "train_data18453.zip  train_data27600.zip  train_data9307.zip\n",
            "train_data18454.zip  train_data27601.zip  train_data9308.zip\n",
            "train_data18455.zip  train_data27602.zip  train_data9309.zip\n",
            "train_data18456.zip  train_data27603.zip  train_data930.zip\n",
            "train_data18457.zip  train_data27604.zip  train_data9310.zip\n",
            "train_data18458.zip  train_data27605.zip  train_data9311.zip\n",
            "train_data18459.zip  train_data27606.zip  train_data9312.zip\n",
            "train_data1845.zip   train_data27607.zip  train_data9313.zip\n",
            "train_data18460.zip  train_data27608.zip  train_data9314.zip\n",
            "train_data18461.zip  train_data27609.zip  train_data9315.zip\n",
            "train_data18462.zip  train_data2760.zip   train_data9316.zip\n",
            "train_data18463.zip  train_data27610.zip  train_data9317.zip\n",
            "train_data18464.zip  train_data27611.zip  train_data9318.zip\n",
            "train_data18465.zip  train_data27612.zip  train_data9319.zip\n",
            "train_data18466.zip  train_data27613.zip  train_data931.zip\n",
            "train_data18467.zip  train_data27614.zip  train_data9320.zip\n",
            "train_data18468.zip  train_data27615.zip  train_data9321.zip\n",
            "train_data18469.zip  train_data27616.zip  train_data9322.zip\n",
            "train_data1846.zip   train_data27617.zip  train_data9323.zip\n",
            "train_data18470.zip  train_data27618.zip  train_data9324.zip\n",
            "train_data18471.zip  train_data27619.zip  train_data9325.zip\n",
            "train_data18472.zip  train_data2761.zip   train_data9326.zip\n",
            "train_data18473.zip  train_data27620.zip  train_data9327.zip\n",
            "train_data18474.zip  train_data27621.zip  train_data9328.zip\n",
            "train_data18475.zip  train_data27622.zip  train_data9329.zip\n",
            "train_data18476.zip  train_data27623.zip  train_data932.zip\n",
            "train_data18477.zip  train_data27624.zip  train_data9330.zip\n",
            "train_data18478.zip  train_data27625.zip  train_data9331.zip\n",
            "train_data18479.zip  train_data27626.zip  train_data9332.zip\n",
            "train_data1847.zip   train_data27627.zip  train_data9333.zip\n",
            "train_data18480.zip  train_data27628.zip  train_data9334.zip\n",
            "train_data18481.zip  train_data27629.zip  train_data9335.zip\n",
            "train_data18482.zip  train_data2762.zip   train_data9336.zip\n",
            "train_data18483.zip  train_data27630.zip  train_data9337.zip\n",
            "train_data18484.zip  train_data27631.zip  train_data9338.zip\n",
            "train_data18485.zip  train_data27632.zip  train_data9339.zip\n",
            "train_data18486.zip  train_data27633.zip  train_data933.zip\n",
            "train_data18487.zip  train_data27634.zip  train_data9340.zip\n",
            "train_data18488.zip  train_data27635.zip  train_data9341.zip\n",
            "train_data18489.zip  train_data27636.zip  train_data9342.zip\n",
            "train_data1848.zip   train_data27637.zip  train_data9343.zip\n",
            "train_data18490.zip  train_data27638.zip  train_data9344.zip\n",
            "train_data18491.zip  train_data27639.zip  train_data9345.zip\n",
            "train_data18492.zip  train_data2763.zip   train_data9346.zip\n",
            "train_data18493.zip  train_data27640.zip  train_data9347.zip\n",
            "train_data18494.zip  train_data27641.zip  train_data9348.zip\n",
            "train_data18495.zip  train_data27642.zip  train_data9349.zip\n",
            "train_data18496.zip  train_data27643.zip  train_data934.zip\n",
            "train_data18497.zip  train_data27644.zip  train_data9350.zip\n",
            "train_data18498.zip  train_data27645.zip  train_data9351.zip\n",
            "train_data18499.zip  train_data27646.zip  train_data9352.zip\n",
            "train_data1849.zip   train_data27647.zip  train_data9353.zip\n",
            "train_data184.zip    train_data27648.zip  train_data9354.zip\n",
            "train_data18500.zip  train_data27649.zip  train_data9355.zip\n",
            "train_data18501.zip  train_data2764.zip   train_data9356.zip\n",
            "train_data18502.zip  train_data27650.zip  train_data9357.zip\n",
            "train_data18503.zip  train_data27651.zip  train_data9358.zip\n",
            "train_data18504.zip  train_data27652.zip  train_data9359.zip\n",
            "train_data18505.zip  train_data27653.zip  train_data935.zip\n",
            "train_data18506.zip  train_data27654.zip  train_data9360.zip\n",
            "train_data18507.zip  train_data27655.zip  train_data9361.zip\n",
            "train_data18508.zip  train_data27656.zip  train_data9362.zip\n",
            "train_data18509.zip  train_data27657.zip  train_data9363.zip\n",
            "train_data1850.zip   train_data27658.zip  train_data9364.zip\n",
            "train_data18510.zip  train_data27659.zip  train_data9365.zip\n",
            "train_data18511.zip  train_data2765.zip   train_data9366.zip\n",
            "train_data18512.zip  train_data27660.zip  train_data9367.zip\n",
            "train_data18513.zip  train_data27661.zip  train_data9368.zip\n",
            "train_data18514.zip  train_data27662.zip  train_data9369.zip\n",
            "train_data18515.zip  train_data27663.zip  train_data936.zip\n",
            "train_data18516.zip  train_data27664.zip  train_data9370.zip\n",
            "train_data18517.zip  train_data27665.zip  train_data9371.zip\n",
            "train_data18518.zip  train_data27666.zip  train_data9372.zip\n",
            "train_data18519.zip  train_data27667.zip  train_data9373.zip\n",
            "train_data1851.zip   train_data27668.zip  train_data9374.zip\n",
            "train_data18520.zip  train_data27669.zip  train_data9375.zip\n",
            "train_data18521.zip  train_data2766.zip   train_data9376.zip\n",
            "train_data18522.zip  train_data27670.zip  train_data9377.zip\n",
            "train_data18523.zip  train_data27671.zip  train_data9378.zip\n",
            "train_data18524.zip  train_data27672.zip  train_data9379.zip\n",
            "train_data18525.zip  train_data27673.zip  train_data937.zip\n",
            "train_data18526.zip  train_data27674.zip  train_data9380.zip\n",
            "train_data18527.zip  train_data27675.zip  train_data9381.zip\n",
            "train_data18528.zip  train_data27676.zip  train_data9382.zip\n",
            "train_data18529.zip  train_data27677.zip  train_data9383.zip\n",
            "train_data1852.zip   train_data27678.zip  train_data9384.zip\n",
            "train_data18530.zip  train_data27679.zip  train_data9385.zip\n",
            "train_data18531.zip  train_data2767.zip   train_data9386.zip\n",
            "train_data18532.zip  train_data27680.zip  train_data9387.zip\n",
            "train_data18533.zip  train_data27681.zip  train_data9388.zip\n",
            "train_data18534.zip  train_data27682.zip  train_data9389.zip\n",
            "train_data18535.zip  train_data27683.zip  train_data938.zip\n",
            "train_data18536.zip  train_data27684.zip  train_data9390.zip\n",
            "train_data18537.zip  train_data27685.zip  train_data9391.zip\n",
            "train_data18538.zip  train_data27686.zip  train_data9392.zip\n",
            "train_data18539.zip  train_data27687.zip  train_data9393.zip\n",
            "train_data1853.zip   train_data27688.zip  train_data9394.zip\n",
            "train_data18540.zip  train_data27689.zip  train_data9395.zip\n",
            "train_data18541.zip  train_data2768.zip   train_data9396.zip\n",
            "train_data18542.zip  train_data27690.zip  train_data9397.zip\n",
            "train_data18543.zip  train_data27691.zip  train_data9398.zip\n",
            "train_data18544.zip  train_data27692.zip  train_data9399.zip\n",
            "train_data18545.zip  train_data27693.zip  train_data939.zip\n",
            "train_data18546.zip  train_data27694.zip  train_data93.zip\n",
            "train_data18547.zip  train_data27695.zip  train_data9400.zip\n",
            "train_data18548.zip  train_data27696.zip  train_data9401.zip\n",
            "train_data18549.zip  train_data27697.zip  train_data9402.zip\n",
            "train_data1854.zip   train_data27698.zip  train_data9403.zip\n",
            "train_data18550.zip  train_data27699.zip  train_data9404.zip\n",
            "train_data18551.zip  train_data2769.zip   train_data9405.zip\n",
            "train_data18552.zip  train_data276.zip\t  train_data9406.zip\n",
            "train_data18553.zip  train_data27700.zip  train_data9407.zip\n",
            "train_data18554.zip  train_data27701.zip  train_data9408.zip\n",
            "train_data18555.zip  train_data27702.zip  train_data9409.zip\n",
            "train_data18556.zip  train_data27703.zip  train_data940.zip\n",
            "train_data18557.zip  train_data27704.zip  train_data9410.zip\n",
            "train_data18558.zip  train_data27705.zip  train_data9411.zip\n",
            "train_data18559.zip  train_data27706.zip  train_data9412.zip\n",
            "train_data1855.zip   train_data27707.zip  train_data9413.zip\n",
            "train_data18560.zip  train_data27708.zip  train_data9414.zip\n",
            "train_data18561.zip  train_data27709.zip  train_data9415.zip\n",
            "train_data18562.zip  train_data2770.zip   train_data9416.zip\n",
            "train_data18563.zip  train_data27710.zip  train_data9417.zip\n",
            "train_data18564.zip  train_data27711.zip  train_data9418.zip\n",
            "train_data18565.zip  train_data27712.zip  train_data9419.zip\n",
            "train_data18566.zip  train_data27713.zip  train_data941.zip\n",
            "train_data18567.zip  train_data27714.zip  train_data9420.zip\n",
            "train_data18568.zip  train_data27715.zip  train_data9421.zip\n",
            "train_data18569.zip  train_data27716.zip  train_data9422.zip\n",
            "train_data1856.zip   train_data27717.zip  train_data9423.zip\n",
            "train_data18570.zip  train_data27718.zip  train_data9424.zip\n",
            "train_data18571.zip  train_data27719.zip  train_data9425.zip\n",
            "train_data18572.zip  train_data2771.zip   train_data9426.zip\n",
            "train_data18573.zip  train_data27720.zip  train_data9427.zip\n",
            "train_data18574.zip  train_data27721.zip  train_data9428.zip\n",
            "train_data18575.zip  train_data27722.zip  train_data9429.zip\n",
            "train_data18576.zip  train_data27723.zip  train_data942.zip\n",
            "train_data18577.zip  train_data27724.zip  train_data9430.zip\n",
            "train_data18578.zip  train_data27725.zip  train_data9431.zip\n",
            "train_data18579.zip  train_data27726.zip  train_data9432.zip\n",
            "train_data1857.zip   train_data27727.zip  train_data9433.zip\n",
            "train_data18580.zip  train_data27728.zip  train_data9434.zip\n",
            "train_data18581.zip  train_data27729.zip  train_data9435.zip\n",
            "train_data18582.zip  train_data2772.zip   train_data9436.zip\n",
            "train_data18583.zip  train_data27730.zip  train_data9437.zip\n",
            "train_data18584.zip  train_data27731.zip  train_data9438.zip\n",
            "train_data18585.zip  train_data27732.zip  train_data9439.zip\n",
            "train_data18586.zip  train_data27733.zip  train_data943.zip\n",
            "train_data18587.zip  train_data27734.zip  train_data9440.zip\n",
            "train_data18588.zip  train_data27735.zip  train_data9441.zip\n",
            "train_data18589.zip  train_data27736.zip  train_data9442.zip\n",
            "train_data1858.zip   train_data27737.zip  train_data9443.zip\n",
            "train_data18590.zip  train_data27738.zip  train_data9444.zip\n",
            "train_data18591.zip  train_data27739.zip  train_data9445.zip\n",
            "train_data18592.zip  train_data2773.zip   train_data9446.zip\n",
            "train_data18593.zip  train_data27740.zip  train_data9447.zip\n",
            "train_data18594.zip  train_data27741.zip  train_data9448.zip\n",
            "train_data18595.zip  train_data27742.zip  train_data9449.zip\n",
            "train_data18596.zip  train_data27743.zip  train_data944.zip\n",
            "train_data18597.zip  train_data27744.zip  train_data9450.zip\n",
            "train_data18598.zip  train_data27745.zip  train_data9451.zip\n",
            "train_data18599.zip  train_data27746.zip  train_data9452.zip\n",
            "train_data1859.zip   train_data27747.zip  train_data9453.zip\n",
            "train_data185.zip    train_data27748.zip  train_data9454.zip\n",
            "train_data18600.zip  train_data27749.zip  train_data9455.zip\n",
            "train_data18601.zip  train_data2774.zip   train_data9456.zip\n",
            "train_data18602.zip  train_data27750.zip  train_data9457.zip\n",
            "train_data18603.zip  train_data27751.zip  train_data9458.zip\n",
            "train_data18604.zip  train_data27752.zip  train_data9459.zip\n",
            "train_data18605.zip  train_data27753.zip  train_data945.zip\n",
            "train_data18606.zip  train_data27754.zip  train_data9460.zip\n",
            "train_data18607.zip  train_data27755.zip  train_data9461.zip\n",
            "train_data18608.zip  train_data27756.zip  train_data9462.zip\n",
            "train_data18609.zip  train_data27757.zip  train_data9463.zip\n",
            "train_data1860.zip   train_data27758.zip  train_data9464.zip\n",
            "train_data18610.zip  train_data27759.zip  train_data9465.zip\n",
            "train_data18611.zip  train_data2775.zip   train_data9466.zip\n",
            "train_data18612.zip  train_data27760.zip  train_data9467.zip\n",
            "train_data18613.zip  train_data27761.zip  train_data9468.zip\n",
            "train_data18614.zip  train_data27762.zip  train_data9469.zip\n",
            "train_data18615.zip  train_data27763.zip  train_data946.zip\n",
            "train_data18616.zip  train_data27764.zip  train_data9470.zip\n",
            "train_data18617.zip  train_data27765.zip  train_data9471.zip\n",
            "train_data18618.zip  train_data27766.zip  train_data9472.zip\n",
            "train_data18619.zip  train_data27767.zip  train_data9473.zip\n",
            "train_data1861.zip   train_data27768.zip  train_data9474.zip\n",
            "train_data18620.zip  train_data27769.zip  train_data9475.zip\n",
            "train_data18621.zip  train_data2776.zip   train_data9476.zip\n",
            "train_data18622.zip  train_data27770.zip  train_data9477.zip\n",
            "train_data18623.zip  train_data27771.zip  train_data9478.zip\n",
            "train_data18624.zip  train_data27772.zip  train_data9479.zip\n",
            "train_data18625.zip  train_data27773.zip  train_data947.zip\n",
            "train_data18626.zip  train_data27774.zip  train_data9480.zip\n",
            "train_data18627.zip  train_data27775.zip  train_data9481.zip\n",
            "train_data18628.zip  train_data27776.zip  train_data9482.zip\n",
            "train_data18629.zip  train_data27777.zip  train_data9483.zip\n",
            "train_data1862.zip   train_data27778.zip  train_data9484.zip\n",
            "train_data18630.zip  train_data27779.zip  train_data9485.zip\n",
            "train_data18631.zip  train_data2777.zip   train_data9486.zip\n",
            "train_data18632.zip  train_data27780.zip  train_data9487.zip\n",
            "train_data18633.zip  train_data27781.zip  train_data9488.zip\n",
            "train_data18634.zip  train_data27782.zip  train_data9489.zip\n",
            "train_data18635.zip  train_data27783.zip  train_data948.zip\n",
            "train_data18636.zip  train_data27784.zip  train_data9490.zip\n",
            "train_data18637.zip  train_data27785.zip  train_data9491.zip\n",
            "train_data18638.zip  train_data27786.zip  train_data9492.zip\n",
            "train_data18639.zip  train_data27787.zip  train_data9493.zip\n",
            "train_data1863.zip   train_data27788.zip  train_data9494.zip\n",
            "train_data18640.zip  train_data27789.zip  train_data9495.zip\n",
            "train_data18641.zip  train_data2778.zip   train_data9496.zip\n",
            "train_data18642.zip  train_data27790.zip  train_data9497.zip\n",
            "train_data18643.zip  train_data27791.zip  train_data9498.zip\n",
            "train_data18644.zip  train_data27792.zip  train_data9499.zip\n",
            "train_data18645.zip  train_data27793.zip  train_data949.zip\n",
            "train_data18646.zip  train_data27794.zip  train_data94.zip\n",
            "train_data18647.zip  train_data27795.zip  train_data9500.zip\n",
            "train_data18648.zip  train_data27796.zip  train_data9501.zip\n",
            "train_data18649.zip  train_data27797.zip  train_data9502.zip\n",
            "train_data1864.zip   train_data27798.zip  train_data9503.zip\n",
            "train_data18650.zip  train_data27799.zip  train_data9504.zip\n",
            "train_data18651.zip  train_data2779.zip   train_data9505.zip\n",
            "train_data18652.zip  train_data277.zip\t  train_data9506.zip\n",
            "train_data18653.zip  train_data27800.zip  train_data9507.zip\n",
            "train_data18654.zip  train_data27801.zip  train_data9508.zip\n",
            "train_data18655.zip  train_data27802.zip  train_data9509.zip\n",
            "train_data18656.zip  train_data27803.zip  train_data950.zip\n",
            "train_data18657.zip  train_data27804.zip  train_data9510.zip\n",
            "train_data18658.zip  train_data27805.zip  train_data9511.zip\n",
            "train_data18659.zip  train_data27806.zip  train_data9512.zip\n",
            "train_data1865.zip   train_data27807.zip  train_data9513.zip\n",
            "train_data18660.zip  train_data27808.zip  train_data9514.zip\n",
            "train_data18661.zip  train_data27809.zip  train_data9515.zip\n",
            "train_data18662.zip  train_data2780.zip   train_data9516.zip\n",
            "train_data18663.zip  train_data27810.zip  train_data9517.zip\n",
            "train_data18664.zip  train_data27811.zip  train_data9518.zip\n",
            "train_data18665.zip  train_data27812.zip  train_data9519.zip\n",
            "train_data18666.zip  train_data27813.zip  train_data951.zip\n",
            "train_data18667.zip  train_data27814.zip  train_data9520.zip\n",
            "train_data18668.zip  train_data27815.zip  train_data9521.zip\n",
            "train_data18669.zip  train_data27816.zip  train_data9522.zip\n",
            "train_data1866.zip   train_data27817.zip  train_data9523.zip\n",
            "train_data18670.zip  train_data27818.zip  train_data9524.zip\n",
            "train_data18671.zip  train_data27819.zip  train_data9525.zip\n",
            "train_data18672.zip  train_data2781.zip   train_data9526.zip\n",
            "train_data18673.zip  train_data27820.zip  train_data9527.zip\n",
            "train_data18674.zip  train_data27821.zip  train_data9528.zip\n",
            "train_data18675.zip  train_data27822.zip  train_data9529.zip\n",
            "train_data18676.zip  train_data27823.zip  train_data952.zip\n",
            "train_data18677.zip  train_data27824.zip  train_data9530.zip\n",
            "train_data18678.zip  train_data27825.zip  train_data9531.zip\n",
            "train_data18679.zip  train_data27826.zip  train_data9532.zip\n",
            "train_data1867.zip   train_data27827.zip  train_data9533.zip\n",
            "train_data18680.zip  train_data27828.zip  train_data9534.zip\n",
            "train_data18681.zip  train_data27829.zip  train_data9535.zip\n",
            "train_data18682.zip  train_data2782.zip   train_data9536.zip\n",
            "train_data18683.zip  train_data27830.zip  train_data9537.zip\n",
            "train_data18684.zip  train_data27831.zip  train_data9538.zip\n",
            "train_data18685.zip  train_data27832.zip  train_data9539.zip\n",
            "train_data18686.zip  train_data27833.zip  train_data953.zip\n",
            "train_data18687.zip  train_data27834.zip  train_data9540.zip\n",
            "train_data18688.zip  train_data27835.zip  train_data9541.zip\n",
            "train_data18689.zip  train_data27836.zip  train_data9542.zip\n",
            "train_data1868.zip   train_data27837.zip  train_data9543.zip\n",
            "train_data18690.zip  train_data27838.zip  train_data9544.zip\n",
            "train_data18691.zip  train_data27839.zip  train_data9545.zip\n",
            "train_data18692.zip  train_data2783.zip   train_data9546.zip\n",
            "train_data18693.zip  train_data27840.zip  train_data9547.zip\n",
            "train_data18694.zip  train_data27841.zip  train_data9548.zip\n",
            "train_data18695.zip  train_data27842.zip  train_data9549.zip\n",
            "train_data18696.zip  train_data27843.zip  train_data954.zip\n",
            "train_data18697.zip  train_data27844.zip  train_data9550.zip\n",
            "train_data18698.zip  train_data27845.zip  train_data9551.zip\n",
            "train_data18699.zip  train_data27846.zip  train_data9552.zip\n",
            "train_data1869.zip   train_data27847.zip  train_data9553.zip\n",
            "train_data186.zip    train_data27848.zip  train_data9554.zip\n",
            "train_data18700.zip  train_data27849.zip  train_data9555.zip\n",
            "train_data18701.zip  train_data2784.zip   train_data9556.zip\n",
            "train_data18702.zip  train_data27850.zip  train_data9557.zip\n",
            "train_data18703.zip  train_data27851.zip  train_data9558.zip\n",
            "train_data18704.zip  train_data27852.zip  train_data9559.zip\n",
            "train_data18705.zip  train_data27853.zip  train_data955.zip\n",
            "train_data18706.zip  train_data27854.zip  train_data9560.zip\n",
            "train_data18707.zip  train_data27855.zip  train_data9561.zip\n",
            "train_data18708.zip  train_data27856.zip  train_data9562.zip\n",
            "train_data18709.zip  train_data27857.zip  train_data9563.zip\n",
            "train_data1870.zip   train_data27858.zip  train_data9564.zip\n",
            "train_data18710.zip  train_data27859.zip  train_data9565.zip\n",
            "train_data18711.zip  train_data2785.zip   train_data9566.zip\n",
            "train_data18712.zip  train_data27860.zip  train_data9567.zip\n",
            "train_data18713.zip  train_data27861.zip  train_data9568.zip\n",
            "train_data18714.zip  train_data27862.zip  train_data9569.zip\n",
            "train_data18715.zip  train_data27863.zip  train_data956.zip\n",
            "train_data18716.zip  train_data27864.zip  train_data9570.zip\n",
            "train_data18717.zip  train_data27865.zip  train_data9571.zip\n",
            "train_data18718.zip  train_data27866.zip  train_data9572.zip\n",
            "train_data18719.zip  train_data27867.zip  train_data9573.zip\n",
            "train_data1871.zip   train_data27868.zip  train_data9574.zip\n",
            "train_data18720.zip  train_data27869.zip  train_data9575.zip\n",
            "train_data18721.zip  train_data2786.zip   train_data9576.zip\n",
            "train_data18722.zip  train_data27870.zip  train_data9577.zip\n",
            "train_data18723.zip  train_data27871.zip  train_data9578.zip\n",
            "train_data18724.zip  train_data27872.zip  train_data9579.zip\n",
            "train_data18725.zip  train_data27873.zip  train_data957.zip\n",
            "train_data18726.zip  train_data27874.zip  train_data9580.zip\n",
            "train_data18727.zip  train_data27875.zip  train_data9581.zip\n",
            "train_data18728.zip  train_data27876.zip  train_data9582.zip\n",
            "train_data18729.zip  train_data27877.zip  train_data9583.zip\n",
            "train_data1872.zip   train_data27878.zip  train_data9584.zip\n",
            "train_data18730.zip  train_data27879.zip  train_data9585.zip\n",
            "train_data18731.zip  train_data2787.zip   train_data9586.zip\n",
            "train_data18732.zip  train_data27880.zip  train_data9587.zip\n",
            "train_data18733.zip  train_data27881.zip  train_data9588.zip\n",
            "train_data18734.zip  train_data27882.zip  train_data9589.zip\n",
            "train_data18735.zip  train_data27883.zip  train_data958.zip\n",
            "train_data18736.zip  train_data27884.zip  train_data9590.zip\n",
            "train_data18737.zip  train_data27885.zip  train_data9591.zip\n",
            "train_data18738.zip  train_data27886.zip  train_data9592.zip\n",
            "train_data18739.zip  train_data27887.zip  train_data9593.zip\n",
            "train_data1873.zip   train_data27888.zip  train_data9594.zip\n",
            "train_data18740.zip  train_data27889.zip  train_data9595.zip\n",
            "train_data18741.zip  train_data2788.zip   train_data9596.zip\n",
            "train_data18742.zip  train_data27890.zip  train_data9597.zip\n",
            "train_data18743.zip  train_data27891.zip  train_data9598.zip\n",
            "train_data18744.zip  train_data27892.zip  train_data9599.zip\n",
            "train_data18745.zip  train_data27893.zip  train_data959.zip\n",
            "train_data18746.zip  train_data27894.zip  train_data95.zip\n",
            "train_data18747.zip  train_data27895.zip  train_data9600.zip\n",
            "train_data18748.zip  train_data27896.zip  train_data9601.zip\n",
            "train_data18749.zip  train_data27897.zip  train_data9602.zip\n",
            "train_data1874.zip   train_data27898.zip  train_data9603.zip\n",
            "train_data18750.zip  train_data27899.zip  train_data9604.zip\n",
            "train_data18751.zip  train_data2789.zip   train_data9605.zip\n",
            "train_data18752.zip  train_data278.zip\t  train_data9606.zip\n",
            "train_data18753.zip  train_data27900.zip  train_data9607.zip\n",
            "train_data18754.zip  train_data27901.zip  train_data9608.zip\n",
            "train_data18755.zip  train_data27902.zip  train_data9609.zip\n",
            "train_data18756.zip  train_data27903.zip  train_data960.zip\n",
            "train_data18757.zip  train_data27904.zip  train_data9610.zip\n",
            "train_data18758.zip  train_data27905.zip  train_data9611.zip\n",
            "train_data18759.zip  train_data27906.zip  train_data9612.zip\n",
            "train_data1875.zip   train_data27907.zip  train_data9613.zip\n",
            "train_data18760.zip  train_data27908.zip  train_data9614.zip\n",
            "train_data18761.zip  train_data27909.zip  train_data9615.zip\n",
            "train_data18762.zip  train_data2790.zip   train_data9616.zip\n",
            "train_data18763.zip  train_data27910.zip  train_data9617.zip\n",
            "train_data18764.zip  train_data27911.zip  train_data9618.zip\n",
            "train_data18765.zip  train_data27912.zip  train_data9619.zip\n",
            "train_data18766.zip  train_data27913.zip  train_data961.zip\n",
            "train_data18767.zip  train_data27914.zip  train_data9620.zip\n",
            "train_data18768.zip  train_data27915.zip  train_data9621.zip\n",
            "train_data18769.zip  train_data27916.zip  train_data9622.zip\n",
            "train_data1876.zip   train_data27917.zip  train_data9623.zip\n",
            "train_data18770.zip  train_data27918.zip  train_data9624.zip\n",
            "train_data18771.zip  train_data27919.zip  train_data9625.zip\n",
            "train_data18772.zip  train_data2791.zip   train_data9626.zip\n",
            "train_data18773.zip  train_data27920.zip  train_data9627.zip\n",
            "train_data18774.zip  train_data27921.zip  train_data9628.zip\n",
            "train_data18775.zip  train_data27922.zip  train_data9629.zip\n",
            "train_data18776.zip  train_data27923.zip  train_data962.zip\n",
            "train_data18777.zip  train_data27924.zip  train_data9630.zip\n",
            "train_data18778.zip  train_data27925.zip  train_data9631.zip\n",
            "train_data18779.zip  train_data27926.zip  train_data9632.zip\n",
            "train_data1877.zip   train_data27927.zip  train_data9633.zip\n",
            "train_data18780.zip  train_data27928.zip  train_data9634.zip\n",
            "train_data18781.zip  train_data27929.zip  train_data9635.zip\n",
            "train_data18782.zip  train_data2792.zip   train_data9636.zip\n",
            "train_data18783.zip  train_data27930.zip  train_data9637.zip\n",
            "train_data18784.zip  train_data27931.zip  train_data9638.zip\n",
            "train_data18785.zip  train_data27932.zip  train_data9639.zip\n",
            "train_data18786.zip  train_data27933.zip  train_data963.zip\n",
            "train_data18787.zip  train_data27934.zip  train_data9640.zip\n",
            "train_data18788.zip  train_data27935.zip  train_data9641.zip\n",
            "train_data18789.zip  train_data27936.zip  train_data9642.zip\n",
            "train_data1878.zip   train_data27937.zip  train_data9643.zip\n",
            "train_data18790.zip  train_data27938.zip  train_data9644.zip\n",
            "train_data18791.zip  train_data27939.zip  train_data9645.zip\n",
            "train_data18792.zip  train_data2793.zip   train_data9646.zip\n",
            "train_data18793.zip  train_data27940.zip  train_data9647.zip\n",
            "train_data18794.zip  train_data27941.zip  train_data9648.zip\n",
            "train_data18795.zip  train_data27942.zip  train_data9649.zip\n",
            "train_data18796.zip  train_data27943.zip  train_data964.zip\n",
            "train_data18797.zip  train_data27944.zip  train_data9650.zip\n",
            "train_data18798.zip  train_data27945.zip  train_data9651.zip\n",
            "train_data18799.zip  train_data27946.zip  train_data9652.zip\n",
            "train_data1879.zip   train_data27947.zip  train_data9653.zip\n",
            "train_data187.zip    train_data27948.zip  train_data9654.zip\n",
            "train_data18800.zip  train_data27949.zip  train_data9655.zip\n",
            "train_data18801.zip  train_data2794.zip   train_data9656.zip\n",
            "train_data18802.zip  train_data27950.zip  train_data9657.zip\n",
            "train_data18803.zip  train_data27951.zip  train_data9658.zip\n",
            "train_data18804.zip  train_data27952.zip  train_data9659.zip\n",
            "train_data18805.zip  train_data27953.zip  train_data965.zip\n",
            "train_data18806.zip  train_data27954.zip  train_data9660.zip\n",
            "train_data18807.zip  train_data27955.zip  train_data9661.zip\n",
            "train_data18808.zip  train_data27956.zip  train_data9662.zip\n",
            "train_data18809.zip  train_data27957.zip  train_data9663.zip\n",
            "train_data1880.zip   train_data27958.zip  train_data9664.zip\n",
            "train_data18810.zip  train_data27959.zip  train_data9665.zip\n",
            "train_data18811.zip  train_data2795.zip   train_data9666.zip\n",
            "train_data18812.zip  train_data27960.zip  train_data9667.zip\n",
            "train_data18813.zip  train_data27961.zip  train_data9668.zip\n",
            "train_data18814.zip  train_data27962.zip  train_data9669.zip\n",
            "train_data18815.zip  train_data27963.zip  train_data966.zip\n",
            "train_data18816.zip  train_data27964.zip  train_data9670.zip\n",
            "train_data18817.zip  train_data27965.zip  train_data9671.zip\n",
            "train_data18818.zip  train_data27966.zip  train_data9672.zip\n",
            "train_data18819.zip  train_data27967.zip  train_data9673.zip\n",
            "train_data1881.zip   train_data27968.zip  train_data9674.zip\n",
            "train_data18820.zip  train_data27969.zip  train_data9675.zip\n",
            "train_data18821.zip  train_data2796.zip   train_data9676.zip\n",
            "train_data18822.zip  train_data27970.zip  train_data9677.zip\n",
            "train_data18823.zip  train_data27971.zip  train_data9678.zip\n",
            "train_data18824.zip  train_data27972.zip  train_data9679.zip\n",
            "train_data18825.zip  train_data27973.zip  train_data967.zip\n",
            "train_data18826.zip  train_data27974.zip  train_data9680.zip\n",
            "train_data18827.zip  train_data27975.zip  train_data9681.zip\n",
            "train_data18828.zip  train_data27976.zip  train_data9682.zip\n",
            "train_data18829.zip  train_data27977.zip  train_data9683.zip\n",
            "train_data1882.zip   train_data27978.zip  train_data9684.zip\n",
            "train_data18830.zip  train_data27979.zip  train_data9685.zip\n",
            "train_data18831.zip  train_data2797.zip   train_data9686.zip\n",
            "train_data18832.zip  train_data27980.zip  train_data9687.zip\n",
            "train_data18833.zip  train_data27981.zip  train_data9688.zip\n",
            "train_data18834.zip  train_data27982.zip  train_data9689.zip\n",
            "train_data18835.zip  train_data27983.zip  train_data968.zip\n",
            "train_data18836.zip  train_data27984.zip  train_data9690.zip\n",
            "train_data18837.zip  train_data27985.zip  train_data9691.zip\n",
            "train_data18838.zip  train_data27986.zip  train_data9692.zip\n",
            "train_data18839.zip  train_data27987.zip  train_data9693.zip\n",
            "train_data1883.zip   train_data27988.zip  train_data9694.zip\n",
            "train_data18840.zip  train_data27989.zip  train_data9695.zip\n",
            "train_data18841.zip  train_data2798.zip   train_data9696.zip\n",
            "train_data18842.zip  train_data27990.zip  train_data9697.zip\n",
            "train_data18843.zip  train_data27991.zip  train_data9698.zip\n",
            "train_data18844.zip  train_data27992.zip  train_data9699.zip\n",
            "train_data18845.zip  train_data27993.zip  train_data969.zip\n",
            "train_data18846.zip  train_data27994.zip  train_data96.zip\n",
            "train_data18847.zip  train_data27995.zip  train_data9700.zip\n",
            "train_data18848.zip  train_data27996.zip  train_data9701.zip\n",
            "train_data18849.zip  train_data27997.zip  train_data9702.zip\n",
            "train_data1884.zip   train_data27998.zip  train_data9703.zip\n",
            "train_data18850.zip  train_data27999.zip  train_data9704.zip\n",
            "train_data18851.zip  train_data2799.zip   train_data9705.zip\n",
            "train_data18852.zip  train_data279.zip\t  train_data9706.zip\n",
            "train_data18853.zip  train_data27.zip\t  train_data9707.zip\n",
            "train_data18854.zip  train_data28000.zip  train_data9708.zip\n",
            "train_data18855.zip  train_data28001.zip  train_data9709.zip\n",
            "train_data18856.zip  train_data28002.zip  train_data970.zip\n",
            "train_data18857.zip  train_data28003.zip  train_data9710.zip\n",
            "train_data18858.zip  train_data28004.zip  train_data9711.zip\n",
            "train_data18859.zip  train_data28005.zip  train_data9712.zip\n",
            "train_data1885.zip   train_data28006.zip  train_data9713.zip\n",
            "train_data18860.zip  train_data28007.zip  train_data9714.zip\n",
            "train_data18861.zip  train_data28008.zip  train_data9715.zip\n",
            "train_data18862.zip  train_data28009.zip  train_data9716.zip\n",
            "train_data18863.zip  train_data2800.zip   train_data9717.zip\n",
            "train_data18864.zip  train_data28010.zip  train_data9718.zip\n",
            "train_data18865.zip  train_data28011.zip  train_data9719.zip\n",
            "train_data18866.zip  train_data28012.zip  train_data971.zip\n",
            "train_data18867.zip  train_data28013.zip  train_data9720.zip\n",
            "train_data18868.zip  train_data28014.zip  train_data9721.zip\n",
            "train_data18869.zip  train_data28015.zip  train_data9722.zip\n",
            "train_data1886.zip   train_data28016.zip  train_data9723.zip\n",
            "train_data18870.zip  train_data28017.zip  train_data9724.zip\n",
            "train_data18871.zip  train_data28018.zip  train_data9725.zip\n",
            "train_data18872.zip  train_data28019.zip  train_data9726.zip\n",
            "train_data18873.zip  train_data2801.zip   train_data9727.zip\n",
            "train_data18874.zip  train_data28020.zip  train_data9728.zip\n",
            "train_data18875.zip  train_data28021.zip  train_data9729.zip\n",
            "train_data18876.zip  train_data28022.zip  train_data972.zip\n",
            "train_data18877.zip  train_data28023.zip  train_data9730.zip\n",
            "train_data18878.zip  train_data28024.zip  train_data9731.zip\n",
            "train_data18879.zip  train_data28025.zip  train_data9732.zip\n",
            "train_data1887.zip   train_data28026.zip  train_data9733.zip\n",
            "train_data18880.zip  train_data28027.zip  train_data9734.zip\n",
            "train_data18881.zip  train_data28028.zip  train_data9735.zip\n",
            "train_data18882.zip  train_data28029.zip  train_data9736.zip\n",
            "train_data18883.zip  train_data2802.zip   train_data9737.zip\n",
            "train_data18884.zip  train_data28030.zip  train_data9738.zip\n",
            "train_data18885.zip  train_data28031.zip  train_data9739.zip\n",
            "train_data18886.zip  train_data28032.zip  train_data973.zip\n",
            "train_data18887.zip  train_data28033.zip  train_data9740.zip\n",
            "train_data18888.zip  train_data28034.zip  train_data9741.zip\n",
            "train_data18889.zip  train_data28035.zip  train_data9742.zip\n",
            "train_data1888.zip   train_data28036.zip  train_data9743.zip\n",
            "train_data18890.zip  train_data28037.zip  train_data9744.zip\n",
            "train_data18891.zip  train_data28038.zip  train_data9745.zip\n",
            "train_data18892.zip  train_data28039.zip  train_data9746.zip\n",
            "train_data18893.zip  train_data2803.zip   train_data9747.zip\n",
            "train_data18894.zip  train_data28040.zip  train_data9748.zip\n",
            "train_data18895.zip  train_data28041.zip  train_data9749.zip\n",
            "train_data18896.zip  train_data28042.zip  train_data974.zip\n",
            "train_data18897.zip  train_data28043.zip  train_data9750.zip\n",
            "train_data18898.zip  train_data28044.zip  train_data9751.zip\n",
            "train_data18899.zip  train_data28045.zip  train_data9752.zip\n",
            "train_data1889.zip   train_data28046.zip  train_data9753.zip\n",
            "train_data188.zip    train_data28047.zip  train_data9754.zip\n",
            "train_data18900.zip  train_data28048.zip  train_data9755.zip\n",
            "train_data18901.zip  train_data28049.zip  train_data9756.zip\n",
            "train_data18902.zip  train_data2804.zip   train_data9757.zip\n",
            "train_data18903.zip  train_data28050.zip  train_data9758.zip\n",
            "train_data18904.zip  train_data28051.zip  train_data9759.zip\n",
            "train_data18905.zip  train_data28052.zip  train_data975.zip\n",
            "train_data18906.zip  train_data28053.zip  train_data9760.zip\n",
            "train_data18907.zip  train_data28054.zip  train_data9761.zip\n",
            "train_data18908.zip  train_data28055.zip  train_data9762.zip\n",
            "train_data18909.zip  train_data28056.zip  train_data9763.zip\n",
            "train_data1890.zip   train_data28057.zip  train_data9764.zip\n",
            "train_data18910.zip  train_data28058.zip  train_data9765.zip\n",
            "train_data18911.zip  train_data28059.zip  train_data9766.zip\n",
            "train_data18912.zip  train_data2805.zip   train_data9767.zip\n",
            "train_data18913.zip  train_data28060.zip  train_data9768.zip\n",
            "train_data18914.zip  train_data28061.zip  train_data9769.zip\n",
            "train_data18915.zip  train_data28062.zip  train_data976.zip\n",
            "train_data18916.zip  train_data28063.zip  train_data9770.zip\n",
            "train_data18917.zip  train_data28064.zip  train_data9771.zip\n",
            "train_data18918.zip  train_data28065.zip  train_data9772.zip\n",
            "train_data18919.zip  train_data28066.zip  train_data9773.zip\n",
            "train_data1891.zip   train_data28067.zip  train_data9774.zip\n",
            "train_data18920.zip  train_data28068.zip  train_data9775.zip\n",
            "train_data18921.zip  train_data28069.zip  train_data9776.zip\n",
            "train_data18922.zip  train_data2806.zip   train_data9777.zip\n",
            "train_data18923.zip  train_data28070.zip  train_data9778.zip\n",
            "train_data18924.zip  train_data28071.zip  train_data9779.zip\n",
            "train_data18925.zip  train_data28072.zip  train_data977.zip\n",
            "train_data18926.zip  train_data28073.zip  train_data9780.zip\n",
            "train_data18927.zip  train_data28074.zip  train_data9781.zip\n",
            "train_data18928.zip  train_data28075.zip  train_data9782.zip\n",
            "train_data18929.zip  train_data28076.zip  train_data9783.zip\n",
            "train_data1892.zip   train_data28077.zip  train_data9784.zip\n",
            "train_data18930.zip  train_data28078.zip  train_data9785.zip\n",
            "train_data18931.zip  train_data28079.zip  train_data9786.zip\n",
            "train_data18932.zip  train_data2807.zip   train_data9787.zip\n",
            "train_data18933.zip  train_data28080.zip  train_data9788.zip\n",
            "train_data18934.zip  train_data28081.zip  train_data9789.zip\n",
            "train_data18935.zip  train_data28082.zip  train_data978.zip\n",
            "train_data18936.zip  train_data28083.zip  train_data9790.zip\n",
            "train_data18937.zip  train_data28084.zip  train_data9791.zip\n",
            "train_data18938.zip  train_data28085.zip  train_data9792.zip\n",
            "train_data18939.zip  train_data28086.zip  train_data9793.zip\n",
            "train_data1893.zip   train_data28087.zip  train_data9794.zip\n",
            "train_data18940.zip  train_data28088.zip  train_data9795.zip\n",
            "train_data18941.zip  train_data28089.zip  train_data9796.zip\n",
            "train_data18942.zip  train_data2808.zip   train_data9797.zip\n",
            "train_data18943.zip  train_data28090.zip  train_data9798.zip\n",
            "train_data18944.zip  train_data28091.zip  train_data9799.zip\n",
            "train_data18945.zip  train_data28092.zip  train_data979.zip\n",
            "train_data18946.zip  train_data28093.zip  train_data97.zip\n",
            "train_data18947.zip  train_data28094.zip  train_data9800.zip\n",
            "train_data18948.zip  train_data28095.zip  train_data9801.zip\n",
            "train_data18949.zip  train_data28096.zip  train_data9802.zip\n",
            "train_data1894.zip   train_data28097.zip  train_data9803.zip\n",
            "train_data18950.zip  train_data28098.zip  train_data9804.zip\n",
            "train_data18951.zip  train_data28099.zip  train_data9805.zip\n",
            "train_data18952.zip  train_data2809.zip   train_data9806.zip\n",
            "train_data18953.zip  train_data280.zip\t  train_data9807.zip\n",
            "train_data18954.zip  train_data28100.zip  train_data9808.zip\n",
            "train_data18955.zip  train_data28101.zip  train_data9809.zip\n",
            "train_data18956.zip  train_data28102.zip  train_data980.zip\n",
            "train_data18957.zip  train_data28103.zip  train_data9810.zip\n",
            "train_data18958.zip  train_data28104.zip  train_data9811.zip\n",
            "train_data18959.zip  train_data28105.zip  train_data9812.zip\n",
            "train_data1895.zip   train_data28106.zip  train_data9813.zip\n",
            "train_data18960.zip  train_data28107.zip  train_data9814.zip\n",
            "train_data18961.zip  train_data28108.zip  train_data9815.zip\n",
            "train_data18962.zip  train_data28109.zip  train_data9816.zip\n",
            "train_data18963.zip  train_data2810.zip   train_data9817.zip\n",
            "train_data18964.zip  train_data28110.zip  train_data9818.zip\n",
            "train_data18965.zip  train_data28111.zip  train_data9819.zip\n",
            "train_data18966.zip  train_data28112.zip  train_data981.zip\n",
            "train_data18967.zip  train_data28113.zip  train_data9820.zip\n",
            "train_data18968.zip  train_data28114.zip  train_data9821.zip\n",
            "train_data18969.zip  train_data28115.zip  train_data9822.zip\n",
            "train_data1896.zip   train_data28116.zip  train_data9823.zip\n",
            "train_data18970.zip  train_data28117.zip  train_data9824.zip\n",
            "train_data18971.zip  train_data28118.zip  train_data9825.zip\n",
            "train_data18972.zip  train_data28119.zip  train_data9826.zip\n",
            "train_data18973.zip  train_data2811.zip   train_data9827.zip\n",
            "train_data18974.zip  train_data28120.zip  train_data9828.zip\n",
            "train_data18975.zip  train_data28121.zip  train_data9829.zip\n",
            "train_data18976.zip  train_data28122.zip  train_data982.zip\n",
            "train_data18977.zip  train_data28123.zip  train_data9830.zip\n",
            "train_data18978.zip  train_data28124.zip  train_data9831.zip\n",
            "train_data18979.zip  train_data28125.zip  train_data9832.zip\n",
            "train_data1897.zip   train_data28126.zip  train_data9833.zip\n",
            "train_data18980.zip  train_data28127.zip  train_data9834.zip\n",
            "train_data18981.zip  train_data28128.zip  train_data9835.zip\n",
            "train_data18982.zip  train_data28129.zip  train_data9836.zip\n",
            "train_data18983.zip  train_data2812.zip   train_data9837.zip\n",
            "train_data18984.zip  train_data28130.zip  train_data9838.zip\n",
            "train_data18985.zip  train_data28131.zip  train_data9839.zip\n",
            "train_data18986.zip  train_data28132.zip  train_data983.zip\n",
            "train_data18987.zip  train_data28133.zip  train_data9840.zip\n",
            "train_data18988.zip  train_data28134.zip  train_data9841.zip\n",
            "train_data18989.zip  train_data28135.zip  train_data9842.zip\n",
            "train_data1898.zip   train_data28136.zip  train_data9843.zip\n",
            "train_data18990.zip  train_data28137.zip  train_data9844.zip\n",
            "train_data18991.zip  train_data28138.zip  train_data9845.zip\n",
            "train_data18992.zip  train_data28139.zip  train_data9846.zip\n",
            "train_data18993.zip  train_data2813.zip   train_data9847.zip\n",
            "train_data18994.zip  train_data28140.zip  train_data9848.zip\n",
            "train_data18995.zip  train_data28141.zip  train_data9849.zip\n",
            "train_data18996.zip  train_data28142.zip  train_data984.zip\n",
            "train_data18997.zip  train_data28143.zip  train_data9850.zip\n",
            "train_data18998.zip  train_data28144.zip  train_data9851.zip\n",
            "train_data18999.zip  train_data28145.zip  train_data9852.zip\n",
            "train_data1899.zip   train_data28146.zip  train_data9853.zip\n",
            "train_data189.zip    train_data28147.zip  train_data9854.zip\n",
            "train_data18.zip     train_data28148.zip  train_data9855.zip\n",
            "train_data19000.zip  train_data28149.zip  train_data9856.zip\n",
            "train_data19001.zip  train_data2814.zip   train_data9857.zip\n",
            "train_data19002.zip  train_data28150.zip  train_data9858.zip\n",
            "train_data19003.zip  train_data28151.zip  train_data9859.zip\n",
            "train_data19004.zip  train_data28152.zip  train_data985.zip\n",
            "train_data19005.zip  train_data28153.zip  train_data9860.zip\n",
            "train_data19006.zip  train_data28154.zip  train_data9861.zip\n",
            "train_data19007.zip  train_data28155.zip  train_data9862.zip\n",
            "train_data19008.zip  train_data28156.zip  train_data9863.zip\n",
            "train_data19009.zip  train_data28157.zip  train_data9864.zip\n",
            "train_data1900.zip   train_data28158.zip  train_data9865.zip\n",
            "train_data19010.zip  train_data28159.zip  train_data9866.zip\n",
            "train_data19011.zip  train_data2815.zip   train_data9867.zip\n",
            "train_data19012.zip  train_data28160.zip  train_data9868.zip\n",
            "train_data19013.zip  train_data28161.zip  train_data9869.zip\n",
            "train_data19014.zip  train_data28162.zip  train_data986.zip\n",
            "train_data19015.zip  train_data28163.zip  train_data9870.zip\n",
            "train_data19016.zip  train_data28164.zip  train_data9871.zip\n",
            "train_data19017.zip  train_data28165.zip  train_data9872.zip\n",
            "train_data19018.zip  train_data28166.zip  train_data9873.zip\n",
            "train_data19019.zip  train_data28167.zip  train_data9874.zip\n",
            "train_data1901.zip   train_data28168.zip  train_data9875.zip\n",
            "train_data19020.zip  train_data28169.zip  train_data9876.zip\n",
            "train_data19021.zip  train_data2816.zip   train_data9877.zip\n",
            "train_data19022.zip  train_data28170.zip  train_data9878.zip\n",
            "train_data19023.zip  train_data28171.zip  train_data9879.zip\n",
            "train_data19024.zip  train_data28172.zip  train_data987.zip\n",
            "train_data19025.zip  train_data28173.zip  train_data9880.zip\n",
            "train_data19026.zip  train_data28174.zip  train_data9881.zip\n",
            "train_data19027.zip  train_data28175.zip  train_data9882.zip\n",
            "train_data19028.zip  train_data28176.zip  train_data9883.zip\n",
            "train_data19029.zip  train_data28177.zip  train_data9884.zip\n",
            "train_data1902.zip   train_data28178.zip  train_data9885.zip\n",
            "train_data19030.zip  train_data28179.zip  train_data9886.zip\n",
            "train_data19031.zip  train_data2817.zip   train_data9887.zip\n",
            "train_data19032.zip  train_data28180.zip  train_data9888.zip\n",
            "train_data19033.zip  train_data28181.zip  train_data9889.zip\n",
            "train_data19034.zip  train_data28182.zip  train_data988.zip\n",
            "train_data19035.zip  train_data28183.zip  train_data9890.zip\n",
            "train_data19036.zip  train_data28184.zip  train_data9891.zip\n",
            "train_data19037.zip  train_data28185.zip  train_data9892.zip\n",
            "train_data19038.zip  train_data28186.zip  train_data9893.zip\n",
            "train_data19039.zip  train_data28187.zip  train_data9894.zip\n",
            "train_data1903.zip   train_data28188.zip  train_data9895.zip\n",
            "train_data19040.zip  train_data28189.zip  train_data9896.zip\n",
            "train_data19041.zip  train_data2818.zip   train_data9897.zip\n",
            "train_data19042.zip  train_data28190.zip  train_data9898.zip\n",
            "train_data19043.zip  train_data28191.zip  train_data9899.zip\n",
            "train_data19044.zip  train_data28192.zip  train_data989.zip\n",
            "train_data19045.zip  train_data28193.zip  train_data98.zip\n",
            "train_data19046.zip  train_data28194.zip  train_data9900.zip\n",
            "train_data19047.zip  train_data28195.zip  train_data9901.zip\n",
            "train_data19048.zip  train_data28196.zip  train_data9902.zip\n",
            "train_data19049.zip  train_data28197.zip  train_data9903.zip\n",
            "train_data1904.zip   train_data28198.zip  train_data9904.zip\n",
            "train_data19050.zip  train_data28199.zip  train_data9905.zip\n",
            "train_data19051.zip  train_data2819.zip   train_data9906.zip\n",
            "train_data19052.zip  train_data281.zip\t  train_data9907.zip\n",
            "train_data19053.zip  train_data28200.zip  train_data9908.zip\n",
            "train_data19054.zip  train_data28201.zip  train_data9909.zip\n",
            "train_data19055.zip  train_data28202.zip  train_data990.zip\n",
            "train_data19056.zip  train_data28203.zip  train_data9910.zip\n",
            "train_data19057.zip  train_data28204.zip  train_data9911.zip\n",
            "train_data19058.zip  train_data28205.zip  train_data9912.zip\n",
            "train_data19059.zip  train_data28206.zip  train_data9913.zip\n",
            "train_data1905.zip   train_data28207.zip  train_data9914.zip\n",
            "train_data19060.zip  train_data28208.zip  train_data9915.zip\n",
            "train_data19061.zip  train_data28209.zip  train_data9916.zip\n",
            "train_data19062.zip  train_data2820.zip   train_data9917.zip\n",
            "train_data19063.zip  train_data28210.zip  train_data9918.zip\n",
            "train_data19064.zip  train_data28211.zip  train_data9919.zip\n",
            "train_data19065.zip  train_data28212.zip  train_data991.zip\n",
            "train_data19066.zip  train_data28213.zip  train_data9920.zip\n",
            "train_data19067.zip  train_data28214.zip  train_data9921.zip\n",
            "train_data19068.zip  train_data28215.zip  train_data9922.zip\n",
            "train_data19069.zip  train_data28216.zip  train_data9923.zip\n",
            "train_data1906.zip   train_data28217.zip  train_data9924.zip\n",
            "train_data19070.zip  train_data28218.zip  train_data9925.zip\n",
            "train_data19071.zip  train_data28219.zip  train_data9926.zip\n",
            "train_data19072.zip  train_data2821.zip   train_data9927.zip\n",
            "train_data19073.zip  train_data28220.zip  train_data9928.zip\n",
            "train_data19074.zip  train_data28221.zip  train_data9929.zip\n",
            "train_data19075.zip  train_data28222.zip  train_data992.zip\n",
            "train_data19076.zip  train_data28223.zip  train_data9930.zip\n",
            "train_data19077.zip  train_data28224.zip  train_data9931.zip\n",
            "train_data19078.zip  train_data28225.zip  train_data9932.zip\n",
            "train_data19079.zip  train_data28226.zip  train_data9933.zip\n",
            "train_data1907.zip   train_data28227.zip  train_data9934.zip\n",
            "train_data19080.zip  train_data28228.zip  train_data9935.zip\n",
            "train_data19081.zip  train_data28229.zip  train_data9936.zip\n",
            "train_data19082.zip  train_data2822.zip   train_data9937.zip\n",
            "train_data19083.zip  train_data28230.zip  train_data9938.zip\n",
            "train_data19084.zip  train_data28231.zip  train_data9939.zip\n",
            "train_data19085.zip  train_data28232.zip  train_data993.zip\n",
            "train_data19086.zip  train_data28233.zip  train_data9940.zip\n",
            "train_data19087.zip  train_data28234.zip  train_data9941.zip\n",
            "train_data19088.zip  train_data28235.zip  train_data9942.zip\n",
            "train_data19089.zip  train_data28236.zip  train_data9943.zip\n",
            "train_data1908.zip   train_data28237.zip  train_data9944.zip\n",
            "train_data19090.zip  train_data28238.zip  train_data9945.zip\n",
            "train_data19091.zip  train_data28239.zip  train_data9946.zip\n",
            "train_data19092.zip  train_data2823.zip   train_data9947.zip\n",
            "train_data19093.zip  train_data28240.zip  train_data9948.zip\n",
            "train_data19094.zip  train_data28241.zip  train_data9949.zip\n",
            "train_data19095.zip  train_data28242.zip  train_data994.zip\n",
            "train_data19096.zip  train_data28243.zip  train_data9950.zip\n",
            "train_data19097.zip  train_data28244.zip  train_data9951.zip\n",
            "train_data19098.zip  train_data28245.zip  train_data9952.zip\n",
            "train_data19099.zip  train_data28246.zip  train_data9953.zip\n",
            "train_data1909.zip   train_data28247.zip  train_data9954.zip\n",
            "train_data190.zip    train_data28248.zip  train_data9955.zip\n",
            "train_data19100.zip  train_data28249.zip  train_data9956.zip\n",
            "train_data19101.zip  train_data2824.zip   train_data9957.zip\n",
            "train_data19102.zip  train_data28250.zip  train_data9958.zip\n",
            "train_data19103.zip  train_data28251.zip  train_data9959.zip\n",
            "train_data19104.zip  train_data28252.zip  train_data995.zip\n",
            "train_data19105.zip  train_data28253.zip  train_data9960.zip\n",
            "train_data19106.zip  train_data28254.zip  train_data9961.zip\n",
            "train_data19107.zip  train_data28255.zip  train_data9962.zip\n",
            "train_data19108.zip  train_data28256.zip  train_data9963.zip\n",
            "train_data19109.zip  train_data28257.zip  train_data9964.zip\n",
            "train_data1910.zip   train_data28258.zip  train_data9965.zip\n",
            "train_data19110.zip  train_data28259.zip  train_data9966.zip\n",
            "train_data19111.zip  train_data2825.zip   train_data9967.zip\n",
            "train_data19112.zip  train_data28260.zip  train_data9968.zip\n",
            "train_data19113.zip  train_data28261.zip  train_data9969.zip\n",
            "train_data19114.zip  train_data28262.zip  train_data996.zip\n",
            "train_data19115.zip  train_data28263.zip  train_data9970.zip\n",
            "train_data19116.zip  train_data28264.zip  train_data9971.zip\n",
            "train_data19117.zip  train_data28265.zip  train_data9972.zip\n",
            "train_data19118.zip  train_data28266.zip  train_data9973.zip\n",
            "train_data19119.zip  train_data28267.zip  train_data9974.zip\n",
            "train_data1911.zip   train_data28268.zip  train_data9975.zip\n",
            "train_data19120.zip  train_data28269.zip  train_data9976.zip\n",
            "train_data19121.zip  train_data2826.zip   train_data9977.zip\n",
            "train_data19122.zip  train_data28270.zip  train_data9978.zip\n",
            "train_data19123.zip  train_data28271.zip  train_data9979.zip\n",
            "train_data19124.zip  train_data28272.zip  train_data997.zip\n",
            "train_data19125.zip  train_data28273.zip  train_data9980.zip\n",
            "train_data19126.zip  train_data28274.zip  train_data9981.zip\n",
            "train_data19127.zip  train_data28275.zip  train_data9982.zip\n",
            "train_data19128.zip  train_data28276.zip  train_data9983.zip\n",
            "train_data19129.zip  train_data28277.zip  train_data9984.zip\n",
            "train_data1912.zip   train_data28278.zip  train_data9985.zip\n",
            "train_data19130.zip  train_data28279.zip  train_data9986.zip\n",
            "train_data19131.zip  train_data2827.zip   train_data9987.zip\n",
            "train_data19132.zip  train_data28280.zip  train_data9988.zip\n",
            "train_data19133.zip  train_data28281.zip  train_data9989.zip\n",
            "train_data19134.zip  train_data28282.zip  train_data998.zip\n",
            "train_data19135.zip  train_data28283.zip  train_data9990.zip\n",
            "train_data19136.zip  train_data28284.zip  train_data9991.zip\n",
            "train_data19137.zip  train_data28285.zip  train_data9992.zip\n",
            "train_data19138.zip  train_data28286.zip  train_data9993.zip\n",
            "train_data19139.zip  train_data28287.zip  train_data9994.zip\n",
            "train_data1913.zip   train_data28288.zip  train_data9995.zip\n",
            "train_data19140.zip  train_data28289.zip  train_data9996.zip\n",
            "train_data19141.zip  train_data2828.zip   train_data9997.zip\n",
            "train_data19142.zip  train_data28290.zip  train_data9998.zip\n",
            "train_data19143.zip  train_data28291.zip  train_data9999.zip\n",
            "train_data19144.zip  train_data28292.zip  train_data999.zip\n",
            "train_data19145.zip  train_data28293.zip  train_data99.zip\n",
            "train_data19146.zip  train_data28294.zip  train_data9.zip\n",
            "train_data19147.zip  train_data28295.zip\n",
            "train_data19148.zip  train_data28296.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoAdpHY1OXwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import os \n",
        "from itertools import cycle\n",
        "color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
        "\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    \"\"\"\n",
        "    目的：メモリサイズの削減\n",
        "    df: メモリを削減したい DataFrame (pandas.DataFrame)\n",
        "    verbose: 実行時に、メモリ削減の情報を出力するかどうかを指定(bool)\n",
        "\n",
        "    ■ 基本思想\n",
        "    【前提知識】\n",
        "    pandas で作成したデータフレームのうち数値データは、特に dtype を指定しない場合\n",
        "    int64 または float64 でデータを作成するので、\n",
        "    実際のデータよりもこの型が大きいと余計なメモリサイズを確保してしまう。\n",
        "\n",
        "    【処理内容】\n",
        "    (1) 入力された DataFrame の column の型を全てチェック(for loop)\n",
        "    (2) その型が大きい数値データ(int16~int64, float16~float64)ならば、\n",
        "        そのデータフレームの最大値・最小値をチェック。\n",
        "        現在処理中のカラムを、上記の最大値・最小値を表せる必要最低限の型に変換する。\n",
        "        int と floatに分けて処理。\n",
        "\n",
        "    ────────────────────────────────────────────────────────────────────────\n",
        "    【変更履歴】\n",
        "    2020/06/06:\n",
        "    ■ 35行目\n",
        "    ifのネストが深かったので、リファクタ。\n",
        "    Early Continueを入れたので可読性が向上(したはず)。\n",
        "\n",
        "    ■ 46行目・71行目(置き換え・追加)\n",
        "    説明変数(関数?)で置き換え。\n",
        "    columnのtypeがintであるか否かを判定する関数を噛ませている。\n",
        "    (返り値はbool値)\n",
        "    \"\"\"\n",
        "\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    # main loop    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "\n",
        "        if col_type not in numerics: \n",
        "            continue # Early continue if column type is not numeric\n",
        "        \n",
        "        c_min = df[col].min()\n",
        "        c_max = df[col].max()\n",
        "\n",
        "        if IsInt(col_type):\n",
        "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                df[col] = df[col].astype(np.int8)\n",
        "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                df[col] = df[col].astype(np.int16)\n",
        "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                df[col] = df[col].astype(np.int32)\n",
        "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                df[col] = df[col].astype(np.int64)  \n",
        "        else:\n",
        "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                df[col] = df[col].astype(np.float16)\n",
        "            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                df[col] = df[col].astype(np.float32)\n",
        "            else:\n",
        "                df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    if verbose: \n",
        "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def IsInt(col_type):\n",
        "    return str(col_type)[:3] == 'int'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgMQu6yHza8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "zipからデータ読み出し。\n",
        "展開しないのでディスク容量も圧迫せず済む\n",
        "6/17: 追記\n",
        "\n",
        "myzip.extract(f_name) が、カレントディレクトリに圧縮ファイルを展開してしまう。\n",
        "→ バグにつながっていた。\n",
        "\n",
        "【対処法】\n",
        "ファイル展開用のフォルダを作成し、そこへ展開した後、生成されたcsvは削除するコードを追加。\n",
        "\n",
        "※ このコードの考え方を、ReccurentTrainGeneratorへ応用\n",
        "\n",
        "\"\"\"\n",
        "import pickle\n",
        "import zipfile\n",
        "NUM_ITEMS = 30490\n",
        "DATA_PATH = \"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas_onehot/training_datas\"\n",
        "\n",
        "def train_data_from_pickle_generator(num=NUM_ITEMS, datapath=DATA_PATH):\n",
        "    listdir = os.listdir(datapath)\n",
        "    #listdir.sort()\n",
        "\n",
        "    for i in range(len(listdir)):\n",
        "\n",
        "        if i > num:\n",
        "            break\n",
        "\n",
        "        with zipfile.ZipFile(datapath + \"/\" + listdir[i]) as tmpzip:\n",
        "            filelist = tmpzip.namelist()\n",
        "\n",
        "            df = pickle.loads(tmpzip.read(filelist[0]))\n",
        "            #df = reduce_mem_usage(df, verbose=False)\n",
        "            df = df.fillna(0)\n",
        "            array = df.values\n",
        "        \n",
        "            yield array"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yFZU7X6BltK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpg = train_data_from_pickle_generator(datapath=\"./training_datas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNcqdMkPBt1y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "d2b06532-eb19-45d9-a7f4-c587641c5fdb"
      },
      "source": [
        "next(tpg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 2.83984375,\n",
              "        2.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 2.83984375,\n",
              "        2.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 2.83984375,\n",
              "        1.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.5       , 2.6796875 ,\n",
              "        1.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.5       , 2.6796875 ,\n",
              "        6.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.53333333, 2.6796875 ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48lrS5YrwJG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import Sequence\n",
        "from keras.models import Sequential\n",
        "\n",
        "\"\"\"\n",
        "model.fit_generatorを使うためのユーザ定義関数\n",
        "※ generator を使わないとメモリが死ぬ\n",
        "\"\"\"\n",
        "class ReccurentTrainGenerator(Sequence):\n",
        "    def _resetindices(self):\n",
        "        \"\"\"\n",
        "        バッチ生成用のインデックスをランダムに出力\n",
        "        \"\"\"\n",
        "        self.num_called = 0\n",
        "\n",
        "        all_idx = np.random.permutation(np.arange(self.num_batches))\n",
        "        remain_idx = np.random.choice(np.arange(self.num_batches),\n",
        "                                      size=(self.steps_per_epoch*self.batch_size-len(all_idx)),\n",
        "                                      replace=False)\n",
        "        \n",
        "        self.indices = np.hstack([all_idx, remain_idx]).reshape(self.steps_per_epoch, self.batch_size)\n",
        "\n",
        "    def __init__(self, DataPath, batch_size, InputSteps=28, OutputSteps=28, delay=1, normalize_factor=None, sample_indices=np.arange(0, 30490)):\n",
        "        \"\"\"\n",
        "        【入力】\n",
        "        InputTensor: 入力データ(説明変数) データ数(\"HOBBIES_1_...\"などに対応) × データ点数(時系列方向のデータ数) × 特徴量数 のndarray\n",
        "                     ※ 正解ラベルも、この時系列データからとるのでこれだけ入力すればOK\n",
        "                     ※ 今回は、引数 DataPathの先に圧縮してあるファイル(pickle)を都度解凍して利用する \n",
        "        batch_size: バッチサイズ(例えば、timestepが5として、時刻0~4までのデータ、1~5までのデータ、...、10~14までのデータ、\n",
        "                                をひとまとめにして1データとみなすとする。RNNの場合はこのサイズがバッチサイズに対応する。)\n",
        "        InputSteps: リカレント層に食わせるデータを、何ステップ前までのデータにするか\n",
        "        OutputSteps: リカレント層からの出力(予測ステップ数)の設定値\n",
        "        delay: 目的変数をどの程度遅らせるか？(予測ステップのスタート位置をどの程度後ろにずらすか)\n",
        "        normalize_factor: 正規化する際のスケーリングをどの程度にするか\n",
        "\n",
        "        6/16: 正解ラベル作成について、ラベルが間違っている可能性あり。\n",
        "        6/17: 要素数を選択できるようにする (引数 num_samplesでも作る？)\n",
        "        【構成案】\n",
        "        sklearn.model_selection.KFold などで得たインデックスを流用できる形にする。\n",
        "        ⇒ インデックスの配列をself.sample_indicesに突っ込み、その組を並び替える形で使用\n",
        "        → _resetindicesなども修正対象\n",
        "        \"\"\"\n",
        "        # データファイル名リストの取得\n",
        "        self.datapath = DataPath\n",
        "        self.listdir = os.listdir(DataPath)\n",
        "        self.sample_indices = sample_indices\n",
        "\n",
        "        with zipfile.ZipFile(self.datapath + \"/\" + self.listdir[sample_indices[0]]) as tmpzip:\n",
        "            filelist = tmpzip.namelist()\n",
        "\n",
        "            df = pickle.loads(tmpzip.read(filelist[0]))\n",
        "            #df = reduce_mem_usage(df, verbose=False)\n",
        "            df = df.fillna(0)\n",
        "\n",
        "        # 現在のエポックでバッチ生成の対象となっているデータ系列\n",
        "        self.now_data = df.values\n",
        "\n",
        "        # 各種パラメータ\n",
        "        self.num_datas = len(self.sample_indices)\n",
        "        self.len_sequence = df.shape[0]\n",
        "        self.num_features = df.shape[1]\n",
        "        self.batch_size = batch_size\n",
        "        self.input_steps = InputSteps\n",
        "        self.output_steps = OutputSteps\n",
        "        self.delay = delay \n",
        "\n",
        "        # 各データ系列に対し、バッチサイズいくつ作れるか計算するのに必要な値\n",
        "        self.len_requied_per_batch = InputSteps + (batch_size-1) + (delay-1) + OutputSteps # 訓練データと正解データを作るために必要なサイズ \n",
        "        self.num_batches = self.len_sequence - self.len_requied_per_batch + 1              # 作れるバッチの数\n",
        "\n",
        "        # 1エポック当たりのステップ数\n",
        "        self.steps_per_epoch = int(np.ceil(self.len_sequence / float(batch_size)))\n",
        "        \n",
        "        # バッチ生成用の乱数初期化\n",
        "        self._resetindices()\n",
        "\n",
        "        # データ取得用インデックス生成\n",
        "        self.data_idx = self._reset_dataset_indices(self.num_datas)\n",
        "        self.num_epoch = 0\n",
        "\n",
        "        self.normalize_factor = normalize_factor\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        1エポックあたりのステップ数をリターン\n",
        "        \"\"\"\n",
        "        return self.steps_per_epoch\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        データをバッチにまとめて出力\n",
        "        \"\"\"\n",
        "        indices_temp = self.indices[idx] # indices は (steps_per_epoch, batchsize)の array\n",
        "\n",
        "        batch_x = np.array([self.now_data[i:i+self.input_steps] for i in indices_temp])\n",
        "        batch_y = np.array([self.now_data[i+self.input_steps+(self.delay-1):i+self.input_steps+(self.delay-1)+self.output_steps, -1] for i in indices_temp]).reshape(self.batch_size, self.output_steps, 1)\n",
        "\n",
        "        if self.num_called == (self.steps_per_epoch-1):\n",
        "            self._resetindices()\n",
        "        else:\n",
        "            self.num_called += 1\n",
        "\n",
        "        if self.normalize_factor:\n",
        "            batch_x = batch_x / self.normalize_factor\n",
        "            batch_y = batch_y / self.normalize_factor\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"\n",
        "        Epoch 終了ごとにデータセットを入れ替える\n",
        "        (データセット：\"HOBBIES_1_...\"などに対応)\n",
        "\n",
        "        6/19: 修正\n",
        "        self.now_data が self.nowdata になっていたせいでデータセットが入れ替わっていなかった。\n",
        "        6/21: 修正\n",
        "        next_data_idx に与えるデータが、範囲外のインデックスを指定し得たので修正。\n",
        "        \"\"\"\n",
        "        next_data_idx = self.data_idx[self.num_epoch]\n",
        "        self.num_epoch += 1\n",
        "\n",
        "        if self.num_epoch == self.num_datas-1:\n",
        "            self.num_epoch = 0\n",
        "            self.data_idx = self._reset_dataset_indices(self.num_datas)\n",
        "\n",
        "        with zipfile.ZipFile(self.datapath + \"/\" + self.listdir[self.sample_indices[next_data_idx]]) as tmpzip:\n",
        "            filelist = tmpzip.namelist()\n",
        "\n",
        "            tmp_df = pickle.loads(tmpzip.read(filelist[0]))\n",
        "            tmp_df = tmp_df.fillna(0)\n",
        "            self.now_data = tmp_df.values\n",
        "\n",
        "    def _reset_dataset_indices(self, num_datas):\n",
        "        \"\"\"\n",
        "        Epoch毎に入れ替えるデータのインデックスをランダムにするためのメソッド\n",
        "        \"\"\"\n",
        "        return np.random.permutation(np.arange(num_datas))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQzxdHHH8gpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.losses import Loss\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 自作 Loss RMSSE 正しく動いているかは要確認\n",
        "\n",
        "def RMSSE_loss(y_true, y_pred):\n",
        "    y_shape = tf.shape(y_true)\n",
        "    sum = tf.reduce_sum(y_true[0])\n",
        "    sum = tf.add(sum, tf.reduce_sum(y_true[1:][-1]))\n",
        "\n",
        "    n = tf.subtract(tf.add(y_shape[0], y_shape[1]), 1)\n",
        "    n = tf.cast(n, tf.float32)\n",
        "    denominator = tf.divide(sum, tf.subtract(n, 1))\n",
        "\n",
        "    # 0除算のガード\n",
        "    denominator = tf.cond(denominator < 1e-10, lambda: 0.001, lambda: denominator)\n",
        "\n",
        "    numerator = tf.reduce_mean((y_true - y_pred)**2)\n",
        "\n",
        "    return tf.divide(numerator, denominator)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5jxZeS59aEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "A = np.arange(0,10).reshape(10,1)\n",
        "B = [float(num) for num in A]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA-eKs4T9qzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "943458c7-28b9-414a-ef48-44035ccad12d"
      },
      "source": [
        "B"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9Q5eflf0Oq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 動作未チェック\n",
        "\n",
        "from sklearn import preprocessing, metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM,Dropout\n",
        "from keras.layers import RepeatVector,TimeDistributed, BatchNormalization\n",
        "from numpy import array\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "\"\"\"\n",
        "仮のモデル\n",
        "ハイパーパラメータを引数にとれるよう改造すべき？\n",
        "※ チューニングができるように\n",
        "\"\"\"\n",
        "def build_model():\n",
        "    timesteps = 28\n",
        "    delay = 1\n",
        "\n",
        "    n_out_seq_length = 28\n",
        "    num_y = 1\n",
        "\n",
        "#    train_generator = train_data_from_pickle_generator(num=1)\n",
        "    train_generator = train_data_from_pickle_generator(num=1, datapath=\"./training_datas\") \n",
        "    x_shape = next(train_generator).shape\n",
        "    print(x_shape)\n",
        "\n",
        "    len_sequence, num_features = x_shape\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(LSTM(256, activation='relu', batch_input_shape=(None, timesteps, num_features), return_sequences=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(RepeatVector(28))\n",
        "    model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))  \n",
        "    model.add(TimeDistributed(Dense(delay, activation=\"relu\")))   # num_y means the shape of y,in some problem(like translate), it can be many.\n",
        "                                                #In that case, you should set the  activation= 'softmax'\n",
        "    \n",
        "    RMSpropOptimizer = RMSprop(lr=0.001, clipnorm=1)\n",
        "#    model.compile(optimizer=RMSpropOptimizer, loss='mean_squared_error', metrics=[\"accuracy\"])\n",
        "    model.compile(optimizer=RMSpropOptimizer, loss=RMSSE_loss, metrics=[\"accuracy\"])    \n",
        "    #model.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV6jnj130VQB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "ce1a2d55-fcf7-4b4d-bde8-bc03ded8be63"
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1941, 70)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 256)               334848    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 28, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 28, 64)            82176     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 64)            256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 28, 64)            0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 28, 1)             65        \n",
            "=================================================================\n",
            "Total params: 418,369\n",
            "Trainable params: 417,729\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rg9ueCc0XdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DATA_PATH = \"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas_onehot/training_datas\"\n",
        "#DATA_PATH = \"./training_datas.zip\"\n",
        "DATA_PATH = \"./training_datas\"\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=5)\n",
        "#train_cv_idx, valid_cv_idx =  next(kfold.split(np.arange(0,5000)))\n",
        "#train_cv_idx, valid_cv_idx =  next(kfold.split(np.arange(5000,10000)))\n",
        "#train_cv_idx, valid_cv_idx =  next(kfold.split(np.arange(10000,15000)))\n",
        "#train_cv_idx, valid_cv_idx =  next(kfold.split(np.arange(15000,20000)))\n",
        "#train_cv_idx, valid_cv_idx =  next(kfold.split(np.arange(20000,25000)))\n",
        "#train_cv_idx, valid_cv_idx =  next(kfold.split(np.arange(25000,30490)))\n",
        "\n",
        "\"\"\"\n",
        "GPU使えるときの設定\n",
        "なぜか2週目ではデータがバグったのか、predictの結果が nan になる。要検証\n",
        "\"\"\"\n",
        "#train_cv_idx, valid_cv_idx =  next(kfold.split(np.arange(0,30490)))\n",
        "\n",
        "RTG = ReccurentTrainGenerator(DataPath=DATA_PATH, batch_size=516, InputSteps=28, sample_indices=train_cv_idx)\n",
        "Validation_RTG = ReccurentTrainGenerator(DataPath=DATA_PATH, batch_size=516, InputSteps=28, sample_indices=valid_cv_idx)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2JcfwDlHOeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#続きから学習するときはこのセルを実行\n",
        "from keras.models import load_model\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 自作 Loss RMSSE 正しく動いているかは要確認\n",
        "\n",
        "def RMSSE_loss(y_true, y_pred):\n",
        "    y_shape = tf.shape(y_true)\n",
        "    sum = tf.reduce_sum(y_true[0])\n",
        "    sum = tf.add(sum, tf.reduce_sum(y_true[1:][-1]))\n",
        "\n",
        "    n = tf.subtract(tf.add(y_shape[0], y_shape[1]), 1)\n",
        "    n = tf.cast(n, tf.float32)\n",
        "    denominator = tf.divide(sum, tf.subtract(n, 1))\n",
        "\n",
        "    # 0除算のガード\n",
        "    denominator = tf.cond(denominator < 1e-10, lambda: 0.001, lambda: denominator)\n",
        "\n",
        "    numerator = tf.reduce_mean((y_true - y_pred)**2)\n",
        "\n",
        "    return tf.divide(numerator, denominator)\n",
        "\n",
        "model = load_model(\"./drive/My Drive/kaggle/m5-forecasting/datas/LSTM_model.h5\", custom_objects={\"RMSSE_loss\": RMSSE_loss})"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlgibjZm1Vw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22147743-73e9-4498-eeb8-4ffd6c477494"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Early-stopping: patienceはもう少し大きくとる？\n",
        "#early_stopping = EarlyStopping(patience=500, verbose=1) \n",
        "model_checkpoint = ModelCheckpoint(filepath=\"./drive/My Drive/kaggle/m5-forecasting/datas/LSTM_model.h5\")\n",
        "\n",
        "history = model.fit_generator(RTG, epochs=len(train_cv_idx), verbose=1, validation_data=Validation_RTG, callbacks=[model_checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "Epoch 8153/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 403.2544 - accuracy: 0.1630 - val_loss: 44.0964 - val_accuracy: 0.0686\n",
            "Epoch 8154/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 6.5192 - accuracy: 0.9966 - val_loss: 273.1946 - val_accuracy: 0.0263\n",
            "Epoch 8155/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 15.2370 - accuracy: 0.2833 - val_loss: 2997.5576 - val_accuracy: 0.0302\n",
            "Epoch 8156/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 14.0620 - accuracy: 0.4802 - val_loss: 2990.9353 - val_accuracy: 0.0348\n",
            "Epoch 8157/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 14.6346 - accuracy: 0.9717 - val_loss: 3610.0161 - val_accuracy: 0.0656\n",
            "Epoch 8158/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 17.2395 - accuracy: 0.7814 - val_loss: 305.5828 - val_accuracy: 0.0419\n",
            "Epoch 8159/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 14.3390 - accuracy: 0.5152 - val_loss: 94.0546 - val_accuracy: 0.0325\n",
            "Epoch 8160/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 22.7089 - accuracy: 0.5521 - val_loss: 14.9421 - val_accuracy: 0.0694\n",
            "Epoch 8161/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 16.8318 - accuracy: 0.2838 - val_loss: 17.8360 - val_accuracy: 0.1476\n",
            "Epoch 8162/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 16.1872 - accuracy: 0.7539 - val_loss: 20.9902 - val_accuracy: 0.2089\n",
            "Epoch 8163/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 34.1636 - accuracy: 0.7629 - val_loss: 46.4455 - val_accuracy: 0.0649\n",
            "Epoch 8164/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 20.6020 - accuracy: 0.9805 - val_loss: 408.2020 - val_accuracy: 0.0343\n",
            "Epoch 8165/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 29.7598 - accuracy: 0.9139 - val_loss: 84.8205 - val_accuracy: 0.0461\n",
            "Epoch 8166/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 11.7809 - accuracy: 0.7662 - val_loss: 9199.7539 - val_accuracy: 0.0342\n",
            "Epoch 8167/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 16.4354 - accuracy: 0.4223 - val_loss: 74.0891 - val_accuracy: 0.1376\n",
            "Epoch 8168/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 21.2290 - accuracy: 0.3842 - val_loss: 608.5978 - val_accuracy: 0.0189\n",
            "Epoch 8169/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 18.1987 - accuracy: 0.3940 - val_loss: 37.0586 - val_accuracy: 0.0785\n",
            "Epoch 8170/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 23.1981 - accuracy: 0.6743 - val_loss: 1483.1746 - val_accuracy: 0.0284\n",
            "Epoch 8171/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 26.6050 - accuracy: 0.2158 - val_loss: 14.2739 - val_accuracy: 0.1733\n",
            "Epoch 8172/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 29.6942 - accuracy: 0.2364 - val_loss: 25.8631 - val_accuracy: 0.0667\n",
            "Epoch 8173/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 118.1457 - val_accuracy: 0.0718\n",
            "Epoch 8174/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 70.6223 - accuracy: 0.8070 - val_loss: 1558.5712 - val_accuracy: 0.0908\n",
            "Epoch 8175/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 217.8517 - accuracy: 0.7353 - val_loss: 58.7602 - val_accuracy: 0.0886\n",
            "Epoch 8176/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 10.1408 - accuracy: 0.6304 - val_loss: 25.7826 - val_accuracy: 0.0974\n",
            "Epoch 8177/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 7.8067 - accuracy: 0.7141 - val_loss: 41.8458 - val_accuracy: 0.1073\n",
            "Epoch 8178/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 19.2785 - accuracy: 0.5733 - val_loss: 79.6332 - val_accuracy: 0.1200\n",
            "Epoch 8179/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 44.7042 - accuracy: 0.2899 - val_loss: 2349.5576 - val_accuracy: 0.0568\n",
            "Epoch 8180/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 8.3505 - accuracy: 0.6659 - val_loss: 121.6843 - val_accuracy: 0.0973\n",
            "Epoch 8181/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 17.2263 - accuracy: 0.5187 - val_loss: 2179.5452 - val_accuracy: 0.0590\n",
            "Epoch 8182/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 2236.7109 - accuracy: 0.8816 - val_loss: 17.0241 - val_accuracy: 0.2897\n",
            "Epoch 8183/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 1268.0741 - val_accuracy: 0.0568\n",
            "Epoch 8184/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 864.6784 - accuracy: 0.5157 - val_loss: 21.5661 - val_accuracy: 0.1413\n",
            "Epoch 8185/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 172.0185 - accuracy: 0.8866 - val_loss: 1176.5861 - val_accuracy: 0.0257\n",
            "Epoch 8186/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 190.6036 - accuracy: 0.9662 - val_loss: 83.8701 - val_accuracy: 0.0971\n",
            "Epoch 8187/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 40.5775 - accuracy: 0.3798 - val_loss: 40.4610 - val_accuracy: 0.1975\n",
            "Epoch 8188/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 107.0665 - accuracy: 0.8639 - val_loss: 18.8075 - val_accuracy: 0.1817\n",
            "Epoch 8189/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 24.9302 - accuracy: 0.2217 - val_loss: 248.7903 - val_accuracy: 0.1523\n",
            "Epoch 8190/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 52.3221 - accuracy: 0.7322 - val_loss: 70.0197 - val_accuracy: 0.0765\n",
            "Epoch 8191/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 71.7620 - accuracy: 0.2098 - val_loss: 38.6069 - val_accuracy: 0.0877\n",
            "Epoch 8192/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 38.5919 - accuracy: 0.2766 - val_loss: 35.4566 - val_accuracy: 0.0881\n",
            "Epoch 8193/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 24.5132 - accuracy: 0.8521 - val_loss: 1686.5020 - val_accuracy: 0.0698\n",
            "Epoch 8194/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 86.4493 - accuracy: 0.9022 - val_loss: 19.6276 - val_accuracy: 0.0897\n",
            "Epoch 8195/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 222.4537 - accuracy: 0.7019 - val_loss: 1245.3065 - val_accuracy: 0.1055\n",
            "Epoch 8196/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 37.1587 - accuracy: 0.1326 - val_loss: 23.0015 - val_accuracy: 0.1705\n",
            "Epoch 8197/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 13.4362 - accuracy: 0.3506 - val_loss: 22.1558 - val_accuracy: 0.1599\n",
            "Epoch 8198/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 33.2374 - accuracy: 0.4651 - val_loss: 1987.6885 - val_accuracy: 0.1226\n",
            "Epoch 8199/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 11.0559 - accuracy: 0.2987 - val_loss: 39.8194 - val_accuracy: 0.2596\n",
            "Epoch 8200/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 14.1633 - accuracy: 0.9659 - val_loss: 46.0505 - val_accuracy: 0.0880\n",
            "Epoch 8201/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 18.4963 - accuracy: 0.4618 - val_loss: 16.2652 - val_accuracy: 0.2281\n",
            "Epoch 8202/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 12.3676 - accuracy: 0.5758 - val_loss: 67.0065 - val_accuracy: 0.1285\n",
            "Epoch 8203/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 25.7047 - accuracy: 0.1688 - val_loss: 880.7748 - val_accuracy: 0.1421\n",
            "Epoch 8204/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 15.9792 - accuracy: 0.9701 - val_loss: 25.2322 - val_accuracy: 0.1910\n",
            "Epoch 8205/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 8.4894 - accuracy: 0.9911 - val_loss: 987.8320 - val_accuracy: 0.1169\n",
            "Epoch 8206/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 13.2942 - accuracy: 0.9041 - val_loss: 141.1034 - val_accuracy: 0.1044\n",
            "Epoch 8207/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 54.8323 - val_accuracy: 0.1062\n",
            "Epoch 8208/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 27.1073 - accuracy: 0.1588 - val_loss: 31.8563 - val_accuracy: 0.1108\n",
            "Epoch 8209/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 52.8615 - accuracy: 0.8725 - val_loss: 36.7626 - val_accuracy: 0.2419\n",
            "Epoch 8210/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 11.3062 - accuracy: 0.4037 - val_loss: 33.8801 - val_accuracy: 0.1891\n",
            "Epoch 8211/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 16.8075 - accuracy: 0.2995 - val_loss: 1488.7968 - val_accuracy: 0.0413\n",
            "Epoch 8212/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 14.6046 - accuracy: 0.5138 - val_loss: 32.3221 - val_accuracy: 0.0925\n",
            "Epoch 8213/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 8.7580 - accuracy: 0.9652 - val_loss: 33.4170 - val_accuracy: 0.2142\n",
            "Epoch 8214/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 29.3002 - accuracy: 0.3542 - val_loss: 44.1615 - val_accuracy: 0.0634\n",
            "Epoch 8215/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 13.4354 - accuracy: 0.4344 - val_loss: 680.2554 - val_accuracy: 0.0949\n",
            "Epoch 8216/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 142.0787 - accuracy: 0.5636 - val_loss: 50.4341 - val_accuracy: 0.2109\n",
            "Epoch 8217/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 10.3041 - accuracy: 0.4765 - val_loss: 535.9200 - val_accuracy: 0.1205\n",
            "Epoch 8218/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 23.3000 - accuracy: 0.9477 - val_loss: 13.9255 - val_accuracy: 0.3258\n",
            "Epoch 8219/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 14.8450 - accuracy: 0.8634 - val_loss: 48.3566 - val_accuracy: 0.2205\n",
            "Epoch 8220/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 13.9046 - accuracy: 0.7513 - val_loss: 728.7266 - val_accuracy: 0.0687\n",
            "Epoch 8221/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 239.4153 - accuracy: 0.7758 - val_loss: 16.9524 - val_accuracy: 0.2089\n",
            "Epoch 8222/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 7.9833 - accuracy: 0.9120 - val_loss: 545.8583 - val_accuracy: 0.1278\n",
            "Epoch 8223/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 22.2376 - accuracy: 0.6036 - val_loss: 11.0916 - val_accuracy: 0.2761\n",
            "Epoch 8224/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 12.6488 - accuracy: 0.5631 - val_loss: 16.4983 - val_accuracy: 0.2108\n",
            "Epoch 8225/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 219.0101 - accuracy: 0.9116 - val_loss: 645.5146 - val_accuracy: 0.1277\n",
            "Epoch 8226/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 29.3203 - accuracy: 0.8354 - val_loss: 352.6538 - val_accuracy: 0.1531\n",
            "Epoch 8227/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 11.1161 - accuracy: 0.7188 - val_loss: 708.6475 - val_accuracy: 0.2553\n",
            "Epoch 8228/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 10.7600 - accuracy: 0.4426 - val_loss: 6.7997 - val_accuracy: 0.2689\n",
            "Epoch 8229/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 477.8909 - accuracy: 0.8801 - val_loss: 372.7146 - val_accuracy: 0.7243\n",
            "Epoch 8230/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 204.6158 - accuracy: 0.1376 - val_loss: 41.9100 - val_accuracy: 0.1072\n",
            "Epoch 8231/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 16.6767 - accuracy: 0.8461 - val_loss: 23.2645 - val_accuracy: 0.2222\n",
            "Epoch 8232/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 21.2081 - accuracy: 0.3413 - val_loss: 24.5861 - val_accuracy: 0.2099\n",
            "Epoch 8233/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 18.5504 - accuracy: 0.4791 - val_loss: 16.8830 - val_accuracy: 0.2057\n",
            "Epoch 8234/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 41.7527 - accuracy: 0.8936 - val_loss: 35.8634 - val_accuracy: 0.2280\n",
            "Epoch 8235/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 15.6458 - accuracy: 0.9044 - val_loss: 17.1329 - val_accuracy: 0.1809\n",
            "Epoch 8236/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 11.7342 - accuracy: 0.6308 - val_loss: 84125.5547 - val_accuracy: 0.3311\n",
            "Epoch 8237/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 41.0984 - accuracy: 0.2411 - val_loss: 13.8688 - val_accuracy: 0.2274\n",
            "Epoch 8238/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 847.3970 - accuracy: 0.6275 - val_loss: 71.4500 - val_accuracy: 0.0923\n",
            "Epoch 8239/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 16.8393 - accuracy: 0.8647 - val_loss: 20.1823 - val_accuracy: 0.3131\n",
            "Epoch 8240/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 14.7359 - accuracy: 0.8117 - val_loss: 689.4572 - val_accuracy: 0.1346\n",
            "Epoch 8241/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 20.5070 - accuracy: 0.9341 - val_loss: 29.8516 - val_accuracy: 0.1740\n",
            "Epoch 8242/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 100.1954 - accuracy: 0.8818 - val_loss: 6.1768 - val_accuracy: 0.5464\n",
            "Epoch 8243/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 90.9348 - accuracy: 0.2023 - val_loss: 13.6416 - val_accuracy: 0.4822\n",
            "Epoch 8244/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 79.7365 - accuracy: 0.7393 - val_loss: 239.2805 - val_accuracy: 0.8562\n",
            "Epoch 8245/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 25.0518 - accuracy: 0.5190 - val_loss: 22.3685 - val_accuracy: 0.2051\n",
            "Epoch 8246/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 37.5804 - accuracy: 0.2082 - val_loss: 16.0888 - val_accuracy: 0.6628\n",
            "Epoch 8247/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 101.2554 - accuracy: 0.9141 - val_loss: 262.4973 - val_accuracy: 0.7110\n",
            "Epoch 8248/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 93.2490 - accuracy: 0.4841 - val_loss: 40.9521 - val_accuracy: 0.1058\n",
            "Epoch 8249/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 57.0397 - accuracy: 0.2530 - val_loss: 11.4476 - val_accuracy: 0.2322\n",
            "Epoch 8250/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 5.4599 - accuracy: 0.9951 - val_loss: 9.6120 - val_accuracy: 0.2822\n",
            "Epoch 8251/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 19.5649 - accuracy: 0.9897 - val_loss: 17.1812 - val_accuracy: 0.2186\n",
            "Epoch 8252/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 634.3093 - accuracy: 0.2929 - val_loss: 487.3921 - val_accuracy: 0.1837\n",
            "Epoch 8253/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 959.7841 - val_accuracy: 0.1560\n",
            "Epoch 8254/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 25.2659 - accuracy: 0.9880 - val_loss: 499.8437 - val_accuracy: 0.1436\n",
            "Epoch 8255/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 18.8551 - accuracy: 0.9075 - val_loss: 134.8817 - val_accuracy: 0.1528\n",
            "Epoch 8256/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 99.9718 - accuracy: 0.8282 - val_loss: 5337.5425 - val_accuracy: 0.0411\n",
            "Epoch 8257/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 19.2909 - accuracy: 0.9804 - val_loss: 718.1248 - val_accuracy: 0.0674\n",
            "Epoch 8258/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 397.1933 - accuracy: 0.5152 - val_loss: 17.7243 - val_accuracy: 0.1952\n",
            "Epoch 8259/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 770.7819 - accuracy: 0.5467 - val_loss: 4079.4177 - val_accuracy: 0.1029\n",
            "Epoch 8260/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 10.9570 - accuracy: 0.7714 - val_loss: 145.7010 - val_accuracy: 0.0861\n",
            "Epoch 8261/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 10.9102 - accuracy: 0.3022 - val_loss: 10.1930 - val_accuracy: 0.2358\n",
            "Epoch 8262/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 45.9292 - accuracy: 0.1455 - val_loss: 117.2181 - val_accuracy: 0.2015\n",
            "Epoch 8263/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 124.7029 - accuracy: 0.8684 - val_loss: 474.1455 - val_accuracy: 0.1043\n",
            "Epoch 8264/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 287.0167 - accuracy: 0.5653 - val_loss: 12.3616 - val_accuracy: 0.1710\n",
            "Epoch 8265/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 29.3154 - accuracy: 0.3772 - val_loss: 14.0487 - val_accuracy: 0.2833\n",
            "Epoch 8266/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 3.4438 - accuracy: 0.9986 - val_loss: 4307.8159 - val_accuracy: 0.1384\n",
            "Epoch 8267/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 21.8928 - accuracy: 0.9103 - val_loss: 15.0985 - val_accuracy: 0.6288\n",
            "Epoch 8268/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 14.3645 - accuracy: 0.3165 - val_loss: 16.3060 - val_accuracy: 0.2879\n",
            "Epoch 8269/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 23.3728 - accuracy: 0.1986 - val_loss: 1915.9280 - val_accuracy: 0.1919\n",
            "Epoch 8270/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 61.2825 - accuracy: 0.9193 - val_loss: 42.3664 - val_accuracy: 0.2216\n",
            "Epoch 8271/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 32.9527 - accuracy: 0.9634 - val_loss: 10.5929 - val_accuracy: 0.3529\n",
            "Epoch 8272/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 138.9503 - accuracy: 0.7127 - val_loss: 12.5559 - val_accuracy: 0.2715\n",
            "Epoch 8273/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 23.6232 - accuracy: 0.9759 - val_loss: 35.5887 - val_accuracy: 0.1454\n",
            "Epoch 8274/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 12.5185 - accuracy: 0.5185 - val_loss: 360.9223 - val_accuracy: 0.5024\n",
            "Epoch 8275/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 163.6201 - accuracy: 0.8607 - val_loss: 16.0613 - val_accuracy: 0.0996\n",
            "Epoch 8276/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 212.9562 - accuracy: 0.9329 - val_loss: 158.5031 - val_accuracy: 0.0787\n",
            "Epoch 8277/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 33.1427 - accuracy: 0.9476 - val_loss: 20.6442 - val_accuracy: 0.2993\n",
            "Epoch 8278/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 80.5295 - accuracy: 0.1985 - val_loss: 69.9809 - val_accuracy: 0.2585\n",
            "Epoch 8279/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 88.9614 - accuracy: 0.9249 - val_loss: 454.9068 - val_accuracy: 0.2487\n",
            "Epoch 8280/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 12.6208 - accuracy: 0.5658 - val_loss: 16.9116 - val_accuracy: 0.2434\n",
            "Epoch 8281/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 45.1596 - accuracy: 0.1577 - val_loss: 16.1607 - val_accuracy: 0.2683\n",
            "Epoch 8282/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 727.1996 - accuracy: 0.6304 - val_loss: 22.6096 - val_accuracy: 0.7231\n",
            "Epoch 8283/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 20.7734 - accuracy: 0.2514 - val_loss: 8.9099 - val_accuracy: 0.7127\n",
            "Epoch 8284/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 987.4060 - accuracy: 0.3629 - val_loss: 38.1967 - val_accuracy: 0.1249\n",
            "Epoch 8285/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 535.3003 - accuracy: 0.6936 - val_loss: 407.7971 - val_accuracy: 0.6945\n",
            "Epoch 8286/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 10.1017 - accuracy: 0.9785 - val_loss: 7.0373 - val_accuracy: 0.2864\n",
            "Epoch 8287/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 125.9999 - accuracy: 0.8354 - val_loss: 185.6645 - val_accuracy: 0.6302\n",
            "Epoch 8288/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 25.5197 - accuracy: 0.9747 - val_loss: 31.7366 - val_accuracy: 0.2143\n",
            "Epoch 8289/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 106.7910 - accuracy: 0.9210 - val_loss: 1179.6293 - val_accuracy: 0.8043\n",
            "Epoch 8290/24392\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 19.2638 - accuracy: 0.4319 - val_loss: 21.1647 - val_accuracy: 0.1899\n",
            "Epoch 8291/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 41.6215 - accuracy: 0.8998 - val_loss: 9.9007 - val_accuracy: 0.4396\n",
            "Epoch 8292/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 13.9054 - accuracy: 0.2966 - val_loss: 37.4396 - val_accuracy: 0.2703\n",
            "Epoch 8293/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 18.1956 - accuracy: 0.2259 - val_loss: 23.5946 - val_accuracy: 0.5256\n",
            "Epoch 8294/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 42.7832 - accuracy: 0.9900 - val_loss: 972.9741 - val_accuracy: 0.3351\n",
            "Epoch 8295/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 30.2486 - accuracy: 0.3640 - val_loss: 15.1030 - val_accuracy: 0.2517\n",
            "Epoch 8296/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 13.0652 - accuracy: 0.4509 - val_loss: 19.3373 - val_accuracy: 0.5383\n",
            "Epoch 8297/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 139.0970 - accuracy: 0.8764 - val_loss: 14.7734 - val_accuracy: 0.2205\n",
            "Epoch 8298/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 432.2522 - accuracy: 0.8223 - val_loss: 32.7092 - val_accuracy: 0.4723\n",
            "Epoch 8299/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 10.7394 - accuracy: 0.6955 - val_loss: 18.6208 - val_accuracy: 0.2517\n",
            "Epoch 8300/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 34.0268 - accuracy: 0.9151 - val_loss: 11.7492 - val_accuracy: 0.2027\n",
            "Epoch 8301/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 113.0010 - accuracy: 0.8389 - val_loss: 119.1971 - val_accuracy: 0.6209\n",
            "Epoch 8302/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 11.9022 - accuracy: 0.7769 - val_loss: 348.1382 - val_accuracy: 0.6225\n",
            "Epoch 8303/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 45.9944 - accuracy: 0.4677 - val_loss: 20.4838 - val_accuracy: 0.1184\n",
            "Epoch 8304/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 22.4769 - accuracy: 0.5321 - val_loss: 679.2622 - val_accuracy: 0.0513\n",
            "Epoch 8305/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 49.5397 - accuracy: 0.6280 - val_loss: 684.1112 - val_accuracy: 0.2467\n",
            "Epoch 8306/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 9.3939 - accuracy: 0.8868 - val_loss: 10.5080 - val_accuracy: 0.2611\n",
            "Epoch 8307/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 8.3428 - accuracy: 0.9672 - val_loss: 63.3141 - val_accuracy: 0.1304\n",
            "Epoch 8308/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 15.0371 - accuracy: 0.1937 - val_loss: 24.6637 - val_accuracy: 0.2302\n",
            "Epoch 8309/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 180.8912 - accuracy: 0.5245 - val_loss: 21.8195 - val_accuracy: 0.2121\n",
            "Epoch 8310/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 259.3837 - accuracy: 0.8648 - val_loss: 141.8658 - val_accuracy: 0.0835\n",
            "Epoch 8311/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 147.9608 - accuracy: 0.6738 - val_loss: 571.0606 - val_accuracy: 0.0943\n",
            "Epoch 8312/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 655.9410 - accuracy: 0.5524 - val_loss: 491.2278 - val_accuracy: 0.0700\n",
            "Epoch 8313/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 150.8614 - accuracy: 0.8746 - val_loss: 372.7966 - val_accuracy: 0.1336\n",
            "Epoch 8314/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 24.0493 - accuracy: 0.9804 - val_loss: 18.8248 - val_accuracy: 0.1838\n",
            "Epoch 8315/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 20.8337 - accuracy: 0.5438 - val_loss: 452.7498 - val_accuracy: 0.4931\n",
            "Epoch 8316/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 231.2761 - accuracy: 0.7875 - val_loss: 1444.1346 - val_accuracy: 0.1895\n",
            "Epoch 8317/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 14.3449 - accuracy: 0.3375 - val_loss: 58.6111 - val_accuracy: 0.5137\n",
            "Epoch 8318/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 46.5748 - accuracy: 0.4014 - val_loss: 336.6008 - val_accuracy: 0.2949\n",
            "Epoch 8319/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 12.7560 - val_accuracy: 0.2826\n",
            "Epoch 8320/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 25.2482 - accuracy: 0.9859 - val_loss: 16692.2109 - val_accuracy: 0.8132\n",
            "Epoch 8321/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 31.2929 - accuracy: 0.9807 - val_loss: 23.5351 - val_accuracy: 0.1053\n",
            "Epoch 8322/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 14.3134 - accuracy: 0.8516 - val_loss: 431.5396 - val_accuracy: 0.0077\n",
            "Epoch 8323/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 6.0793 - accuracy: 0.9446 - val_loss: 376.7499 - val_accuracy: 0.0106\n",
            "Epoch 8324/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 26.6004 - accuracy: 0.8996 - val_loss: 35.4644 - val_accuracy: 0.0629\n",
            "Epoch 8325/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 296.0514 - accuracy: 0.9479 - val_loss: 39.5633 - val_accuracy: 0.1670\n",
            "Epoch 8326/24392\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 131.8095 - accuracy: 0.9565 - val_loss: 14.2967 - val_accuracy: 0.1949\n",
            "Epoch 8327/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 560.4557 - accuracy: 0.4689 - val_loss: 21.9963 - val_accuracy: 0.1633\n",
            "Epoch 8328/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 16.9363 - accuracy: 0.2804 - val_loss: 15.4734 - val_accuracy: 0.3206\n",
            "Epoch 8329/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 269.1173 - accuracy: 0.5641 - val_loss: 17.5561 - val_accuracy: 0.2478\n",
            "Epoch 8330/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 12.9805 - accuracy: 0.4300 - val_loss: 14.4264 - val_accuracy: 0.2022\n",
            "Epoch 8331/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 374.9678 - accuracy: 0.8035 - val_loss: 25.5162 - val_accuracy: 0.1717\n",
            "Epoch 8332/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 11.7488 - val_accuracy: 0.2436\n",
            "Epoch 8333/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 13.9176 - accuracy: 0.5060 - val_loss: 45.1333 - val_accuracy: 0.1699\n",
            "Epoch 8334/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 575.2906 - accuracy: 0.8634 - val_loss: 11.1509 - val_accuracy: 0.2884\n",
            "Epoch 8335/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 16.0966 - accuracy: 0.5368 - val_loss: 20.9309 - val_accuracy: 0.3461\n",
            "Epoch 8336/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 284.2734 - accuracy: 0.7282 - val_loss: 191.7862 - val_accuracy: 0.8669\n",
            "Epoch 8337/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 19.4054 - accuracy: 0.3395 - val_loss: 20.4631 - val_accuracy: 0.1827\n",
            "Epoch 8338/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 89.8839 - accuracy: 0.9653 - val_loss: 148.2161 - val_accuracy: 0.1269\n",
            "Epoch 8339/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 81.8104 - accuracy: 0.8963 - val_loss: 18.9727 - val_accuracy: 0.1532\n",
            "Epoch 8340/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 19.3076 - accuracy: 0.8248 - val_loss: 9.3501 - val_accuracy: 0.7097\n",
            "Epoch 8341/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 33.0231 - accuracy: 0.6414 - val_loss: 25.8443 - val_accuracy: 0.1699\n",
            "Epoch 8342/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 10.9938 - accuracy: 0.9927 - val_loss: 8.7898 - val_accuracy: 0.1949\n",
            "Epoch 8343/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 16.5262 - accuracy: 0.7701 - val_loss: 189.5271 - val_accuracy: 0.9389\n",
            "Epoch 8344/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 12.9132 - accuracy: 0.6469 - val_loss: 32.2300 - val_accuracy: 0.1551\n",
            "Epoch 8345/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 9.7165 - accuracy: 0.9397 - val_loss: 10.6463 - val_accuracy: 0.2231\n",
            "Epoch 8346/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 2408.1848 - accuracy: 0.7998 - val_loss: 21.5336 - val_accuracy: 0.3266\n",
            "Epoch 8347/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 2823.0555 - accuracy: 0.4762 - val_loss: 9.0416 - val_accuracy: 0.5683\n",
            "Epoch 8348/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 7.9983e-04 - accuracy: 1.0000 - val_loss: 33.4554 - val_accuracy: 0.2386\n",
            "Epoch 8349/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 128.9880 - accuracy: 0.9251 - val_loss: 4583.2769 - val_accuracy: 0.0252\n",
            "Epoch 8350/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 21.8031 - accuracy: 0.9669 - val_loss: 17.9434 - val_accuracy: 0.7324\n",
            "Epoch 8351/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 13.3199 - accuracy: 0.4460 - val_loss: 29.0911 - val_accuracy: 0.3829\n",
            "Epoch 8352/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 36.7443 - accuracy: 0.6570 - val_loss: 30.7736 - val_accuracy: 0.1703\n",
            "Epoch 8353/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 11.7527 - accuracy: 0.8728 - val_loss: 11.2890 - val_accuracy: 0.5682\n",
            "Epoch 8354/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 18.6240 - accuracy: 0.6656 - val_loss: 8.5068 - val_accuracy: 0.8886\n",
            "Epoch 8355/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 914.6387 - accuracy: 0.5422 - val_loss: 33.6448 - val_accuracy: 0.2028\n",
            "Epoch 8356/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 11.2249 - accuracy: 0.4035 - val_loss: 9.8366 - val_accuracy: 0.7962\n",
            "Epoch 8357/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 67.2124 - accuracy: 0.9742 - val_loss: 589.6623 - val_accuracy: 0.7535\n",
            "Epoch 8358/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 32.0980 - accuracy: 0.9772 - val_loss: 13.1035 - val_accuracy: 0.6000\n",
            "Epoch 8359/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 121.0692 - accuracy: 0.9608 - val_loss: 21.2004 - val_accuracy: 0.7548\n",
            "Epoch 8360/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 37.7463 - accuracy: 0.2688 - val_loss: 25.1368 - val_accuracy: 0.2413\n",
            "Epoch 8361/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 59.5523 - accuracy: 0.3194 - val_loss: 18.1645 - val_accuracy: 0.7781\n",
            "Epoch 8362/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 42.0383 - accuracy: 0.2980 - val_loss: 41.9089 - val_accuracy: 0.0693\n",
            "Epoch 8363/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 21.8551 - accuracy: 0.3352 - val_loss: 8.4438 - val_accuracy: 0.4982\n",
            "Epoch 8364/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 16.3670 - accuracy: 0.8466 - val_loss: 15.8017 - val_accuracy: 0.2712\n",
            "Epoch 8365/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 23.7871 - accuracy: 0.1254 - val_loss: 9.8652 - val_accuracy: 0.7686\n",
            "Epoch 8366/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 283.2567 - accuracy: 0.4379 - val_loss: 24.9417 - val_accuracy: 0.7566\n",
            "Epoch 8367/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 224.5566 - accuracy: 0.8652 - val_loss: 5.5717 - val_accuracy: 0.8491\n",
            "Epoch 8368/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 123.8384 - accuracy: 0.9054 - val_loss: 18.9989 - val_accuracy: 0.3036\n",
            "Epoch 8369/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 8.7804 - accuracy: 0.7918 - val_loss: 87.5723 - val_accuracy: 0.7914\n",
            "Epoch 8370/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 338.8205 - accuracy: 0.6579 - val_loss: 18.1383 - val_accuracy: 0.6406\n",
            "Epoch 8371/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 47.3330 - accuracy: 0.8718 - val_loss: 6.7198 - val_accuracy: 0.8175\n",
            "Epoch 8372/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 3774.9992 - accuracy: 0.4999 - val_loss: 18.0020 - val_accuracy: 0.4345\n",
            "Epoch 8373/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 14.2464 - accuracy: 0.8590 - val_loss: 114.0118 - val_accuracy: 0.4717\n",
            "Epoch 8374/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 106.2320 - accuracy: 0.7012 - val_loss: 28.7442 - val_accuracy: 0.3553\n",
            "Epoch 8375/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 16.6302 - accuracy: 0.3167 - val_loss: 8.6467 - val_accuracy: 0.6601\n",
            "Epoch 8376/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 206.6196 - accuracy: 0.8213 - val_loss: 20.3817 - val_accuracy: 0.7531\n",
            "Epoch 8377/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 8.8125 - accuracy: 0.8651 - val_loss: 8.3967 - val_accuracy: 0.9295\n",
            "Epoch 8378/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 117.9035 - accuracy: 0.7240 - val_loss: 4.9757 - val_accuracy: 0.8410\n",
            "Epoch 8379/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 31.2304 - accuracy: 0.5642 - val_loss: 281.2214 - val_accuracy: 0.8756\n",
            "Epoch 8380/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 16.0480 - accuracy: 0.8519 - val_loss: 19.3726 - val_accuracy: 0.6124\n",
            "Epoch 8381/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 70.2904 - accuracy: 0.9612 - val_loss: 16.8689 - val_accuracy: 0.3698\n",
            "Epoch 8382/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 99.6224 - accuracy: 0.8570 - val_loss: 29.4280 - val_accuracy: 0.2973\n",
            "Epoch 8383/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 292.2116 - accuracy: 0.6468 - val_loss: 16.9323 - val_accuracy: 1.0000\n",
            "Epoch 8384/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 134.3636 - accuracy: 0.8052 - val_loss: 26.4707 - val_accuracy: 0.4230\n",
            "Epoch 8385/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 14.9714 - accuracy: 0.8734 - val_loss: 19.9795 - val_accuracy: 0.3679\n",
            "Epoch 8386/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 1102.8119 - accuracy: 0.4032 - val_loss: 28.7313 - val_accuracy: 0.0968\n",
            "Epoch 8387/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 15.2158 - accuracy: 0.3302 - val_loss: 25.8366 - val_accuracy: 0.1471\n",
            "Epoch 8388/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 7.2888 - accuracy: 0.9983 - val_loss: 16.7515 - val_accuracy: 0.1088\n",
            "Epoch 8389/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 16.0969 - accuracy: 0.2726 - val_loss: 39.2152 - val_accuracy: 0.2103\n",
            "Epoch 8390/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 33.0069 - accuracy: 0.9555 - val_loss: 15.1799 - val_accuracy: 0.3763\n",
            "Epoch 8391/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 8.6865 - accuracy: 0.9725 - val_loss: 21.1452 - val_accuracy: 0.1984\n",
            "Epoch 8392/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 17.7185 - accuracy: 0.2975 - val_loss: 6.8319 - val_accuracy: 0.1725\n",
            "Epoch 8393/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 741.7871 - accuracy: 0.5606 - val_loss: 31.3123 - val_accuracy: 0.2996\n",
            "Epoch 8394/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 358.9207 - accuracy: 0.4927 - val_loss: 204.1192 - val_accuracy: 0.9727\n",
            "Epoch 8395/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 89.5883 - accuracy: 0.9283 - val_loss: 229.5145 - val_accuracy: 0.7356\n",
            "Epoch 8396/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 69.8537 - accuracy: 0.8977 - val_loss: 11.2582 - val_accuracy: 0.6138\n",
            "Epoch 8397/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 157.8369 - accuracy: 0.5478 - val_loss: 68.9302 - val_accuracy: 0.3533\n",
            "Epoch 8398/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 554.6462 - accuracy: 0.5892 - val_loss: 33.1274 - val_accuracy: 0.3345\n",
            "Epoch 8399/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 16.2353 - accuracy: 0.8571 - val_loss: 16.9623 - val_accuracy: 0.5660\n",
            "Epoch 8400/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 110.1663 - accuracy: 0.5122 - val_loss: 12.5328 - val_accuracy: 0.2945\n",
            "Epoch 8401/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 41.0110 - accuracy: 0.2930 - val_loss: 881.6578 - val_accuracy: 0.7932\n",
            "Epoch 8402/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 144.2908 - accuracy: 0.1946 - val_loss: 732.2325 - val_accuracy: 0.7638\n",
            "Epoch 8403/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 22.0698 - accuracy: 0.3952 - val_loss: 10.4909 - val_accuracy: 0.5753\n",
            "Epoch 8404/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 67.5741 - accuracy: 0.6111 - val_loss: 14.0998 - val_accuracy: 0.2264\n",
            "Epoch 8405/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 84.3126 - accuracy: 0.8151 - val_loss: 21.7062 - val_accuracy: 0.6725\n",
            "Epoch 8406/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 16.0646 - accuracy: 0.4899 - val_loss: 1464.9896 - val_accuracy: 0.4189\n",
            "Epoch 8407/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 25.5748 - accuracy: 0.2180 - val_loss: 12139.0479 - val_accuracy: 0.3967\n",
            "Epoch 8408/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 11.0506 - accuracy: 0.6842 - val_loss: 15.6877 - val_accuracy: 0.3328\n",
            "Epoch 8409/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 23.7576 - accuracy: 0.1518 - val_loss: 19.7774 - val_accuracy: 0.4771\n",
            "Epoch 8410/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 11.4099 - accuracy: 0.4689 - val_loss: 12.6596 - val_accuracy: 0.2766\n",
            "Epoch 8411/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 89.3702 - accuracy: 0.9051 - val_loss: 40.5466 - val_accuracy: 0.9716\n",
            "Epoch 8412/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 94.3039 - accuracy: 0.5603 - val_loss: 17.5194 - val_accuracy: 0.3853\n",
            "Epoch 8413/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 36.8022 - accuracy: 0.9016 - val_loss: 180.8530 - val_accuracy: 0.3328\n",
            "Epoch 8414/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 13.0609 - accuracy: 0.3594 - val_loss: 156.2821 - val_accuracy: 0.9578\n",
            "Epoch 8415/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 36.2417 - accuracy: 0.0705 - val_loss: 34.4270 - val_accuracy: 0.9841\n",
            "Epoch 8416/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 26.3080 - accuracy: 0.9549 - val_loss: 10.3188 - val_accuracy: 0.9934\n",
            "Epoch 8417/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 5.4209 - val_accuracy: 0.9420\n",
            "Epoch 8418/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 1169.1720 - accuracy: 0.8686 - val_loss: 11.4770 - val_accuracy: 0.5411\n",
            "Epoch 8419/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 18.7545 - accuracy: 0.2269 - val_loss: 12.5347 - val_accuracy: 0.8835\n",
            "Epoch 8420/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 37.9918 - accuracy: 0.3798 - val_loss: 150.0039 - val_accuracy: 0.8715\n",
            "Epoch 8421/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 13.3222 - accuracy: 0.8910 - val_loss: 0.0594 - val_accuracy: 1.0000\n",
            "Epoch 8422/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 51.9623 - accuracy: 0.3825 - val_loss: 371.0036 - val_accuracy: 0.7411\n",
            "Epoch 8423/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 29.1537 - accuracy: 0.9585 - val_loss: 13.5076 - val_accuracy: 0.5717\n",
            "Epoch 8424/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 26.7806 - accuracy: 0.9242 - val_loss: 35.2821 - val_accuracy: 0.4970\n",
            "Epoch 8425/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 60.6480 - accuracy: 0.8803 - val_loss: 12.7086 - val_accuracy: 0.3838\n",
            "Epoch 8426/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 83.6248 - accuracy: 0.8926 - val_loss: 15.5555 - val_accuracy: 0.6941\n",
            "Epoch 8427/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 21.9316 - accuracy: 0.3184 - val_loss: 80.3985 - val_accuracy: 0.2148\n",
            "Epoch 8428/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 21.5831 - accuracy: 0.2950 - val_loss: 25.9430 - val_accuracy: 0.2198\n",
            "Epoch 8429/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 458.5506 - accuracy: 0.5347 - val_loss: 83.4519 - val_accuracy: 0.1084\n",
            "Epoch 8430/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 21.4456 - accuracy: 0.3894 - val_loss: 13.0218 - val_accuracy: 0.2908\n",
            "Epoch 8431/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 10.8782 - accuracy: 0.8544 - val_loss: 9.3893 - val_accuracy: 0.8610\n",
            "Epoch 8432/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 46.7564 - accuracy: 0.8615 - val_loss: 315.1644 - val_accuracy: 0.7491\n",
            "Epoch 8433/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 242.8051 - accuracy: 0.5640 - val_loss: 11.0958 - val_accuracy: 0.5650\n",
            "Epoch 8434/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 96.1432 - accuracy: 0.8695 - val_loss: 233.2974 - val_accuracy: 0.7882\n",
            "Epoch 8435/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 21.9138 - accuracy: 0.4453 - val_loss: 48.4381 - val_accuracy: 0.9617\n",
            "Epoch 8436/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 15.6881 - accuracy: 0.5188 - val_loss: 571.3201 - val_accuracy: 0.0775\n",
            "Epoch 8437/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 10.0994 - accuracy: 0.9902 - val_loss: 3.7575 - val_accuracy: 1.0000\n",
            "Epoch 8438/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 6.9367 - accuracy: 0.9906 - val_loss: 38.2124 - val_accuracy: 0.1148\n",
            "Epoch 8439/24392\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 36.2679 - accuracy: 0.2605 - val_loss: 34.3589 - val_accuracy: 0.0786\n",
            "Epoch 8440/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 743.5251 - accuracy: 0.5756 - val_loss: 14.0192 - val_accuracy: 0.4692\n",
            "Epoch 8441/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 101.1099 - accuracy: 0.7384 - val_loss: 16.5964 - val_accuracy: 0.9816\n",
            "Epoch 8442/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 19.1071 - accuracy: 0.6692 - val_loss: 40.7671 - val_accuracy: 0.3748\n",
            "Epoch 8443/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 493.0666 - accuracy: 0.7964 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
            "Epoch 8444/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 10.4644 - accuracy: 0.9689 - val_loss: 32.1443 - val_accuracy: 0.5495\n",
            "Epoch 8445/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 879.3763 - accuracy: 0.8883 - val_loss: 15.3108 - val_accuracy: 0.3313\n",
            "Epoch 8446/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 16.3807 - accuracy: 0.6752 - val_loss: 7.7614 - val_accuracy: 0.8337\n",
            "Epoch 8447/24392\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 12.3998 - accuracy: 0.8378 - val_loss: 18.1100 - val_accuracy: 0.9461\n",
            "Epoch 8448/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 48.1226 - accuracy: 0.2925 - val_loss: 55.2579 - val_accuracy: 0.5240\n",
            "Epoch 8449/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 19.9669 - accuracy: 0.9840 - val_loss: 12.1879 - val_accuracy: 0.8013\n",
            "Epoch 8450/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 1039.6447 - accuracy: 0.7415 - val_loss: 35.7444 - val_accuracy: 0.7376\n",
            "Epoch 8451/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 16.4036 - accuracy: 0.5435 - val_loss: 10.4370 - val_accuracy: 0.9060\n",
            "Epoch 8452/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 12564.2427 - accuracy: 0.5845 - val_loss: 58.0028 - val_accuracy: 0.9813\n",
            "Epoch 8453/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 214.2360 - accuracy: 0.2139 - val_loss: 42.0893 - val_accuracy: 0.7315\n",
            "Epoch 8454/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 18.5353 - accuracy: 0.6536 - val_loss: 129.3982 - val_accuracy: 0.9163\n",
            "Epoch 8455/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 12.0805 - accuracy: 0.8539 - val_loss: 258.9519 - val_accuracy: 0.9178\n",
            "Epoch 8456/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 265.0438 - accuracy: 0.4738 - val_loss: 7.9907 - val_accuracy: 0.6284\n",
            "Epoch 8457/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 40.7355 - accuracy: 0.2262 - val_loss: 47.1324 - val_accuracy: 0.3209\n",
            "Epoch 8458/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 36.9259 - accuracy: 0.9008 - val_loss: 144.0038 - val_accuracy: 0.9163\n",
            "Epoch 8459/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 13.6075 - accuracy: 0.6407 - val_loss: 8.9862 - val_accuracy: 0.6051\n",
            "Epoch 8460/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 55.5416 - accuracy: 0.8445 - val_loss: 35.1416 - val_accuracy: 0.2160\n",
            "Epoch 8461/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 222.9138 - accuracy: 0.4649 - val_loss: 2.9537 - val_accuracy: 0.9715\n",
            "Epoch 8462/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 24.5291 - accuracy: 0.9786 - val_loss: 42.1192 - val_accuracy: 0.9445\n",
            "Epoch 8463/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 23.4490 - accuracy: 0.8172 - val_loss: 727.4821 - val_accuracy: 0.5958\n",
            "Epoch 8464/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 22.6218 - accuracy: 0.6097 - val_loss: 12.0549 - val_accuracy: 0.9103\n",
            "Epoch 8465/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 82.3772 - accuracy: 0.8323 - val_loss: 2.1513 - val_accuracy: 1.0000\n",
            "Epoch 8466/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 10.9334 - accuracy: 0.8849 - val_loss: 12.6962 - val_accuracy: 0.9382\n",
            "Epoch 8467/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 34.2193 - accuracy: 0.3722 - val_loss: 17896.3906 - val_accuracy: 0.0628\n",
            "Epoch 8468/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 158.4777 - accuracy: 0.5589 - val_loss: 10.8979 - val_accuracy: 0.9977\n",
            "Epoch 8469/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 83.0103 - accuracy: 0.8335 - val_loss: 108.6481 - val_accuracy: 0.9287\n",
            "Epoch 8470/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 756.0090 - accuracy: 0.8615 - val_loss: 19.5681 - val_accuracy: 0.6622\n",
            "Epoch 8471/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 10.9727 - accuracy: 0.9894 - val_loss: 164.1077 - val_accuracy: 0.9428\n",
            "Epoch 8472/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 584.5846 - accuracy: 0.5663 - val_loss: 32.0946 - val_accuracy: 0.1052\n",
            "Epoch 8473/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 181.4119 - accuracy: 0.8506 - val_loss: 14.7007 - val_accuracy: 0.7704\n",
            "Epoch 8474/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 3802.5431 - accuracy: 0.3746 - val_loss: 24.3506 - val_accuracy: 0.2210\n",
            "Epoch 8475/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 11.3297 - accuracy: 0.4379 - val_loss: 7.3196 - val_accuracy: 0.8882\n",
            "Epoch 8476/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 11.4251 - accuracy: 0.3818 - val_loss: 29.9963 - val_accuracy: 0.2325\n",
            "Epoch 8477/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 27.1140 - accuracy: 0.2790 - val_loss: 19.3367 - val_accuracy: 0.5203\n",
            "Epoch 8478/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 33.7010 - accuracy: 0.0858 - val_loss: 8.6725 - val_accuracy: 0.8970\n",
            "Epoch 8479/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 13.5334 - accuracy: 0.3478 - val_loss: 48.8283 - val_accuracy: 0.2130\n",
            "Epoch 8480/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 17.9473 - accuracy: 0.2526 - val_loss: 54.2762 - val_accuracy: 0.2169\n",
            "Epoch 8481/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 100.8959 - accuracy: 0.1619 - val_loss: 755.8013 - val_accuracy: 0.7817\n",
            "Epoch 8482/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 331.3055 - accuracy: 0.6595 - val_loss: 29.4200 - val_accuracy: 0.8656\n",
            "Epoch 8483/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 12.1001 - accuracy: 0.8261 - val_loss: 132.2106 - val_accuracy: 0.3748\n",
            "Epoch 8484/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 44.6567 - accuracy: 0.2281 - val_loss: 60.8347 - val_accuracy: 0.0486\n",
            "Epoch 8485/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 12.2980 - accuracy: 0.7066 - val_loss: 611.4199 - val_accuracy: 0.8858\n",
            "Epoch 8486/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 11.7136 - accuracy: 0.6839 - val_loss: 18.0227 - val_accuracy: 0.9065\n",
            "Epoch 8487/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 819.8549 - accuracy: 0.7351 - val_loss: 31.4843 - val_accuracy: 0.4210\n",
            "Epoch 8488/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 22.5842 - accuracy: 0.9398 - val_loss: 46.7663 - val_accuracy: 0.4812\n",
            "Epoch 8489/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 11.2264 - accuracy: 0.8191 - val_loss: 3605.5996 - val_accuracy: 0.6062\n",
            "Epoch 8490/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 24.0193 - accuracy: 0.8440 - val_loss: 2.3387 - val_accuracy: 0.8688\n",
            "Epoch 8491/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 46.6168 - accuracy: 0.1477 - val_loss: 16.6176 - val_accuracy: 0.6389\n",
            "Epoch 8492/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 14.3074 - accuracy: 0.3124 - val_loss: 30.7174 - val_accuracy: 0.4768\n",
            "Epoch 8493/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 40.0879 - accuracy: 0.9307 - val_loss: 9.1649 - val_accuracy: 0.7894\n",
            "Epoch 8494/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 11.7255 - accuracy: 0.8124 - val_loss: 16.2431 - val_accuracy: 0.6263\n",
            "Epoch 8495/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 57.5674 - accuracy: 0.1944 - val_loss: 19438.0996 - val_accuracy: 0.4567\n",
            "Epoch 8496/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 17.5623 - accuracy: 0.2782 - val_loss: 17.2408 - val_accuracy: 0.6103\n",
            "Epoch 8497/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 10.1105 - accuracy: 0.6513 - val_loss: 170.4694 - val_accuracy: 0.9726\n",
            "Epoch 8498/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 30.0911 - accuracy: 0.1084 - val_loss: 4.1493 - val_accuracy: 0.9458\n",
            "Epoch 8499/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 543.6450 - accuracy: 0.6807 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8500/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 15.7409 - accuracy: 0.9854 - val_loss: 7.2337 - val_accuracy: 0.7984\n",
            "Epoch 8501/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 23.3601 - accuracy: 0.5451 - val_loss: 13.1565 - val_accuracy: 0.3195\n",
            "Epoch 8502/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 6.9011 - accuracy: 0.9932 - val_loss: 769.3954 - val_accuracy: 0.6781\n",
            "Epoch 8503/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 50.0408 - accuracy: 0.8950 - val_loss: 36.0579 - val_accuracy: 0.8315\n",
            "Epoch 8504/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 31.2486 - accuracy: 0.2844 - val_loss: 10.9584 - val_accuracy: 0.6827\n",
            "Epoch 8505/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 22.5953 - accuracy: 0.2401 - val_loss: 22.8613 - val_accuracy: 0.3876\n",
            "Epoch 8506/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 9.1129 - accuracy: 0.8277 - val_loss: 25.4557 - val_accuracy: 0.2449\n",
            "Epoch 8507/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 7.6860 - accuracy: 0.9592 - val_loss: 37.4512 - val_accuracy: 0.1696\n",
            "Epoch 8508/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 39.1998 - accuracy: 0.6325 - val_loss: 12.9687 - val_accuracy: 0.7814\n",
            "Epoch 8509/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 41.7526 - accuracy: 0.3325 - val_loss: 23.9931 - val_accuracy: 0.5417\n",
            "Epoch 8510/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 23.9782 - accuracy: 0.2469 - val_loss: 6.1123 - val_accuracy: 0.8992\n",
            "Epoch 8511/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 1705.5737 - accuracy: 0.4411 - val_loss: 16.6819 - val_accuracy: 0.4590\n",
            "Epoch 8512/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 153.0088 - accuracy: 0.7000 - val_loss: 21851.7324 - val_accuracy: 0.7515\n",
            "Epoch 8513/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 153.7221 - accuracy: 0.8493 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8514/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 18.9443 - accuracy: 0.2951 - val_loss: 20.2901 - val_accuracy: 0.5746\n",
            "Epoch 8515/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 45.8024 - accuracy: 0.8333 - val_loss: 19.2518 - val_accuracy: 0.6339\n",
            "Epoch 8516/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 26.3114 - accuracy: 0.8948 - val_loss: 8.4254 - val_accuracy: 0.8879\n",
            "Epoch 8517/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 98.0858 - accuracy: 0.9384 - val_loss: 9.1215 - val_accuracy: 0.7790\n",
            "Epoch 8518/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 11.7484 - accuracy: 0.7444 - val_loss: 13.0904 - val_accuracy: 0.4445\n",
            "Epoch 8519/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 18.9179 - accuracy: 0.9543 - val_loss: 50.8425 - val_accuracy: 0.7906\n",
            "Epoch 8520/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 410.5364 - accuracy: 0.6229 - val_loss: 28.4021 - val_accuracy: 0.3147\n",
            "Epoch 8521/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 14.3562 - accuracy: 0.7839 - val_loss: 107.8836 - val_accuracy: 0.5703\n",
            "Epoch 8522/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 10.5487 - accuracy: 0.7370 - val_loss: 16.1501 - val_accuracy: 0.8952\n",
            "Epoch 8523/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 93.9607 - accuracy: 0.9715 - val_loss: 17.3680 - val_accuracy: 0.7218\n",
            "Epoch 8524/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 16.3271 - accuracy: 0.7809 - val_loss: 18.0473 - val_accuracy: 0.5200\n",
            "Epoch 8525/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 29.0127 - accuracy: 0.9526 - val_loss: 16.0976 - val_accuracy: 0.7236\n",
            "Epoch 8526/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 93.3386 - accuracy: 0.9300 - val_loss: 4.4692 - val_accuracy: 0.9051\n",
            "Epoch 8527/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 139.9442 - accuracy: 0.7297 - val_loss: 24.8702 - val_accuracy: 0.7115\n",
            "Epoch 8528/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 82.6987 - accuracy: 0.4957 - val_loss: 160.2014 - val_accuracy: 0.9501\n",
            "Epoch 8529/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 34.8962 - accuracy: 0.7647 - val_loss: 24.3973 - val_accuracy: 0.5298\n",
            "Epoch 8530/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 9.2612 - accuracy: 0.5386 - val_loss: 23.2442 - val_accuracy: 0.9010\n",
            "Epoch 8531/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 96.4438 - accuracy: 0.0137 - val_loss: 37.7948 - val_accuracy: 0.8483\n",
            "Epoch 8532/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 28.3616 - accuracy: 0.6076 - val_loss: 471.4128 - val_accuracy: 0.0832\n",
            "Epoch 8533/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 10.1696 - accuracy: 0.7249 - val_loss: 14.3958 - val_accuracy: 0.7352\n",
            "Epoch 8534/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 46.4287 - accuracy: 0.8908 - val_loss: 25.8585 - val_accuracy: 0.2366\n",
            "Epoch 8535/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 22.5177 - accuracy: 0.5400 - val_loss: 21.3326 - val_accuracy: 0.4939\n",
            "Epoch 8536/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 17.3602 - accuracy: 0.8083 - val_loss: 16.0876 - val_accuracy: 0.6350\n",
            "Epoch 8537/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 38.5920 - accuracy: 0.9095 - val_loss: 17.4432 - val_accuracy: 0.3058\n",
            "Epoch 8538/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 17.1436 - accuracy: 0.3976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8539/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 15623.3207 - accuracy: 0.5543 - val_loss: 17.8340 - val_accuracy: 0.7086\n",
            "Epoch 8540/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 295.8255 - accuracy: 0.7793 - val_loss: 488114.0625 - val_accuracy: 0.3928\n",
            "Epoch 8541/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 18.3153 - accuracy: 0.7666 - val_loss: 16.4978 - val_accuracy: 0.4675\n",
            "Epoch 8542/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 17.1957 - accuracy: 0.3109 - val_loss: 87.1921 - val_accuracy: 0.5639\n",
            "Epoch 8543/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 115.5868 - accuracy: 0.9455 - val_loss: 219.9782 - val_accuracy: 0.2466\n",
            "Epoch 8544/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 40.1145 - accuracy: 0.9514 - val_loss: 16.5073 - val_accuracy: 0.7720\n",
            "Epoch 8545/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 33.5895 - accuracy: 0.9647 - val_loss: 49.8972 - val_accuracy: 0.9877\n",
            "Epoch 8546/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 24.5824 - accuracy: 0.4509 - val_loss: 26.7964 - val_accuracy: 0.5133\n",
            "Epoch 8547/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 164.6527 - accuracy: 0.8171 - val_loss: 33.9579 - val_accuracy: 0.6931\n",
            "Epoch 8548/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 26.3477 - accuracy: 0.8552 - val_loss: 20.9700 - val_accuracy: 0.9190\n",
            "Epoch 8549/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 18.4704 - accuracy: 0.8247 - val_loss: 15.6218 - val_accuracy: 0.4661\n",
            "Epoch 8550/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 14.4499 - accuracy: 0.2271 - val_loss: 6.4009 - val_accuracy: 0.8490\n",
            "Epoch 8551/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 20.4030 - accuracy: 0.2951 - val_loss: 19.2432 - val_accuracy: 0.4678\n",
            "Epoch 8552/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 22.0793 - accuracy: 0.4402 - val_loss: 23.5858 - val_accuracy: 0.4988\n",
            "Epoch 8553/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 134.6960 - accuracy: 0.1375 - val_loss: 14.1963 - val_accuracy: 0.3212\n",
            "Epoch 8554/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 98.8850 - accuracy: 0.0767 - val_loss: 2894.7515 - val_accuracy: 0.7795\n",
            "Epoch 8555/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 160.1038 - accuracy: 0.9020 - val_loss: 64.8508 - val_accuracy: 0.3532\n",
            "Epoch 8556/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 20.6161 - accuracy: 0.6536 - val_loss: 9.4030 - val_accuracy: 0.6716\n",
            "Epoch 8557/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 13.0862 - accuracy: 0.4885 - val_loss: 9.3645 - val_accuracy: 0.9349\n",
            "Epoch 8558/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 65.9978 - accuracy: 0.9486 - val_loss: 8.5851 - val_accuracy: 0.8292\n",
            "Epoch 8559/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 188.0920 - accuracy: 0.6712 - val_loss: 830.2399 - val_accuracy: 0.6717\n",
            "Epoch 8560/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 35.9636 - accuracy: 0.8725 - val_loss: 27.3310 - val_accuracy: 0.3257\n",
            "Epoch 8561/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 36.5985 - accuracy: 0.8169 - val_loss: 25.5015 - val_accuracy: 0.8908\n",
            "Epoch 8562/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 32.8649 - accuracy: 0.7404 - val_loss: 7.3529 - val_accuracy: 0.7252\n",
            "Epoch 8563/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 154.4098 - accuracy: 0.6796 - val_loss: 14.6573 - val_accuracy: 0.8276\n",
            "Epoch 8564/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 95.7589 - accuracy: 0.8227 - val_loss: 1559.7137 - val_accuracy: 0.8309\n",
            "Epoch 8565/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 18726.8897 - accuracy: 0.5490 - val_loss: 2.4335 - val_accuracy: 0.9405\n",
            "Epoch 8566/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 13.8703 - accuracy: 0.5681 - val_loss: 52.8434 - val_accuracy: 0.7870\n",
            "Epoch 8567/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 51.9343 - accuracy: 0.4545 - val_loss: 23.9034 - val_accuracy: 0.8736\n",
            "Epoch 8568/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 16.4130 - accuracy: 0.3850 - val_loss: 22.8642 - val_accuracy: 0.2376\n",
            "Epoch 8569/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 38.7798 - accuracy: 0.9571 - val_loss: 8.6223 - val_accuracy: 0.5845\n",
            "Epoch 8570/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 205.3619 - accuracy: 0.9047 - val_loss: 41.4709 - val_accuracy: 0.4115\n",
            "Epoch 8571/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 44.0872 - accuracy: 0.9260 - val_loss: 33.5307 - val_accuracy: 0.5172\n",
            "Epoch 8572/24392\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 281.7144 - accuracy: 0.6229 - val_loss: 65.6661 - val_accuracy: 0.2189\n",
            "Epoch 8573/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 14.3188 - accuracy: 0.3559 - val_loss: 16.7568 - val_accuracy: 0.3720\n",
            "Epoch 8574/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 23.1110 - accuracy: 0.9699 - val_loss: 41.2059 - val_accuracy: 0.7015\n",
            "Epoch 8575/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 58.7643 - accuracy: 0.8737 - val_loss: 46.2359 - val_accuracy: 0.9874\n",
            "Epoch 8576/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 20.6081 - accuracy: 0.9582 - val_loss: 13.0599 - val_accuracy: 0.7728\n",
            "Epoch 8577/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 798.0180 - accuracy: 0.4139 - val_loss: 11.4915 - val_accuracy: 0.5556\n",
            "Epoch 8578/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 11.5787 - val_accuracy: 0.5905\n",
            "Epoch 8579/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 33327.3278 - accuracy: 0.6009 - val_loss: 22.0518 - val_accuracy: 0.1945\n",
            "Epoch 8580/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 20.3540 - accuracy: 0.3418 - val_loss: 29.0464 - val_accuracy: 0.1658\n",
            "Epoch 8581/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 10.3527 - accuracy: 0.9768 - val_loss: 53.1348 - val_accuracy: 0.1593\n",
            "Epoch 8582/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 16.4455 - accuracy: 0.4449 - val_loss: 3328.2051 - val_accuracy: 0.0770\n",
            "Epoch 8583/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 28.3966 - accuracy: 0.2339 - val_loss: 112.1629 - val_accuracy: 0.1446\n",
            "Epoch 8584/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 87.5421 - accuracy: 0.1828 - val_loss: 44.6018 - val_accuracy: 0.1106\n",
            "Epoch 8585/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 17.9026 - val_accuracy: 0.1387\n",
            "Epoch 8586/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 21.7139 - accuracy: 0.4938 - val_loss: 453.5710 - val_accuracy: 0.0943\n",
            "Epoch 8587/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 25.4957 - accuracy: 0.8374 - val_loss: 76.0207 - val_accuracy: 0.1147\n",
            "Epoch 8588/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 29.0675 - accuracy: 0.2212 - val_loss: 10.8620 - val_accuracy: 0.2550\n",
            "Epoch 8589/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 18.7421 - accuracy: 0.4473 - val_loss: 860.1671 - val_accuracy: 0.1444\n",
            "Epoch 8590/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 206.9770 - accuracy: 0.6191 - val_loss: 17.1476 - val_accuracy: 0.2222\n",
            "Epoch 8591/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 574.9264 - accuracy: 0.6532 - val_loss: 36.1028 - val_accuracy: 0.1370\n",
            "Epoch 8592/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 15.4139 - accuracy: 0.8043 - val_loss: 90.8970 - val_accuracy: 0.0385\n",
            "Epoch 8593/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 66.6549 - accuracy: 0.2758 - val_loss: 70.7455 - val_accuracy: 0.1238\n",
            "Epoch 8594/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 66.2537 - accuracy: 0.8448 - val_loss: 12.6906 - val_accuracy: 0.1709\n",
            "Epoch 8595/24392\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 43.6017 - accuracy: 0.9021 - val_loss: 40.8815 - val_accuracy: 0.0655\n",
            "Epoch 8596/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 26.8800 - accuracy: 0.2412 - val_loss: 28.7027 - val_accuracy: 0.1375\n",
            "Epoch 8597/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 473.8806 - accuracy: 0.3911 - val_loss: 17.8215 - val_accuracy: 0.2985\n",
            "Epoch 8598/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 22.1709 - accuracy: 0.1934 - val_loss: 15.0811 - val_accuracy: 0.2207\n",
            "Epoch 8599/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 49.3775 - val_accuracy: 0.4709\n",
            "Epoch 8600/24392\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 8.2498 - accuracy: 0.9017 - val_loss: 21.5606 - val_accuracy: 0.2254\n",
            "Epoch 8601/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 16.7097 - accuracy: 0.9099 - val_loss: 14.2181 - val_accuracy: 0.2656\n",
            "Epoch 8602/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 160.6335 - accuracy: 0.7089 - val_loss: 20.5029 - val_accuracy: 0.1573\n",
            "Epoch 8603/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 42.3249 - accuracy: 0.2028 - val_loss: 116.8553 - val_accuracy: 0.4310\n",
            "Epoch 8604/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 90.0994 - accuracy: 0.7728 - val_loss: 28.7442 - val_accuracy: 0.2316\n",
            "Epoch 8605/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 14.4618 - accuracy: 0.6440 - val_loss: 28.7732 - val_accuracy: 0.2052\n",
            "Epoch 8606/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 31.6490 - accuracy: 0.9817 - val_loss: 37.0902 - val_accuracy: 0.1371\n",
            "Epoch 8607/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 34.1430 - accuracy: 0.9532 - val_loss: 15.1348 - val_accuracy: 0.2745\n",
            "Epoch 8608/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 19.0744 - accuracy: 0.3627 - val_loss: 14.7271 - val_accuracy: 0.2385\n",
            "Epoch 8609/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 19.0144 - accuracy: 0.4442 - val_loss: 133.9953 - val_accuracy: 0.9695\n",
            "Epoch 8610/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 9.7054 - accuracy: 0.9119 - val_loss: 180.9305 - val_accuracy: 0.8454\n",
            "Epoch 8611/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 12613.6689 - accuracy: 0.4348 - val_loss: 43.1494 - val_accuracy: 0.1737\n",
            "Epoch 8612/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 40.9675 - accuracy: 0.8929 - val_loss: 734.5546 - val_accuracy: 0.2821\n",
            "Epoch 8613/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 16.8199 - accuracy: 0.2597 - val_loss: 464.4130 - val_accuracy: 0.2080\n",
            "Epoch 8614/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 66.1409 - accuracy: 0.9623 - val_loss: 17.0175 - val_accuracy: 0.1467\n",
            "Epoch 8615/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 15.8481 - accuracy: 0.8975 - val_loss: 60.8277 - val_accuracy: 0.0353\n",
            "Epoch 8616/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 63.5729 - accuracy: 0.7870 - val_loss: 22.7316 - val_accuracy: 0.2570\n",
            "Epoch 8617/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 13.1922 - accuracy: 0.7911 - val_loss: 64.6120 - val_accuracy: 0.1781\n",
            "Epoch 8618/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 33.8500 - accuracy: 0.1436 - val_loss: 14.4425 - val_accuracy: 0.1517\n",
            "Epoch 8619/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 49.0801 - accuracy: 0.9424 - val_loss: 23.2420 - val_accuracy: 0.1977\n",
            "Epoch 8620/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 9.4755 - val_accuracy: 0.3337\n",
            "Epoch 8621/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 52.7098 - accuracy: 0.8432 - val_loss: 17.0404 - val_accuracy: 0.2500\n",
            "Epoch 8622/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 17.0138 - accuracy: 0.3642 - val_loss: 15.6779 - val_accuracy: 0.4454\n",
            "Epoch 8623/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 22.7378 - accuracy: 0.3101 - val_loss: 27.2586 - val_accuracy: 0.4543\n",
            "Epoch 8624/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 20.1727 - accuracy: 0.2625 - val_loss: 8.0851 - val_accuracy: 0.2796\n",
            "Epoch 8625/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 129.6851 - accuracy: 0.7435 - val_loss: 42.1922 - val_accuracy: 0.2054\n",
            "Epoch 8626/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 851.4947 - accuracy: 0.7102 - val_loss: 17.8242 - val_accuracy: 0.2231\n",
            "Epoch 8627/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 17.9421 - accuracy: 0.8175 - val_loss: 5754.0439 - val_accuracy: 0.4900\n",
            "Epoch 8628/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 14.4609 - accuracy: 0.7378 - val_loss: 64.3797 - val_accuracy: 0.1278\n",
            "Epoch 8629/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 5630.2339 - accuracy: 0.4347 - val_loss: 23.5650 - val_accuracy: 0.5907\n",
            "Epoch 8630/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 24.1159 - accuracy: 0.3793 - val_loss: 822.5356 - val_accuracy: 0.4500\n",
            "Epoch 8631/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 17.9713 - accuracy: 0.3248 - val_loss: 36.3543 - val_accuracy: 0.3682\n",
            "Epoch 8632/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 50.0513 - accuracy: 0.7467 - val_loss: 13.1394 - val_accuracy: 0.3511\n",
            "Epoch 8633/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 24.9615 - accuracy: 0.4950 - val_loss: 479.3411 - val_accuracy: 0.4651\n",
            "Epoch 8634/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 25.2981 - accuracy: 0.3553 - val_loss: 19.5956 - val_accuracy: 0.1767\n",
            "Epoch 8635/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 63.6976 - accuracy: 0.6890 - val_loss: 60.2620 - val_accuracy: 0.1628\n",
            "Epoch 8636/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 22.2163 - accuracy: 0.9662 - val_loss: 26.9566 - val_accuracy: 0.2156\n",
            "Epoch 8637/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 38.2263 - accuracy: 0.1704 - val_loss: 40.8737 - val_accuracy: 0.2191\n",
            "Epoch 8638/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 713.1309 - accuracy: 0.5510 - val_loss: 78.8081 - val_accuracy: 0.0704\n",
            "Epoch 8639/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 35.6371 - accuracy: 0.3427 - val_loss: 21.3407 - val_accuracy: 0.1964\n",
            "Epoch 8640/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 28.6179 - accuracy: 0.2777 - val_loss: 227.3237 - val_accuracy: 0.7153\n",
            "Epoch 8641/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 10.1983 - accuracy: 0.9643 - val_loss: 106.9979 - val_accuracy: 0.2498\n",
            "Epoch 8642/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 25.8516 - accuracy: 0.8715 - val_loss: 12.2979 - val_accuracy: 0.1419\n",
            "Epoch 8643/24392\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 17.2347 - accuracy: 0.3133 - val_loss: 577.8240 - val_accuracy: 0.1328\n",
            "Epoch 8644/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 11.8361 - accuracy: 0.7151 - val_loss: 17.4218 - val_accuracy: 0.2126\n",
            "Epoch 8645/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 121.1903 - accuracy: 0.2548 - val_loss: 27.8773 - val_accuracy: 0.1912\n",
            "Epoch 8646/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 10.4125 - accuracy: 0.8479 - val_loss: 74.3072 - val_accuracy: 0.0772\n",
            "Epoch 8647/24392\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 582.6063 - accuracy: 0.0938 - val_loss: 27.2208 - val_accuracy: 0.1795\n",
            "Epoch 8648/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 14.1999 - accuracy: 0.2996 - val_loss: 912.9434 - val_accuracy: 0.0850\n",
            "Epoch 8649/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 5.8343 - accuracy: 0.9865 - val_loss: 1057.7948 - val_accuracy: 0.1189\n",
            "Epoch 8650/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 10.5793 - accuracy: 0.7825 - val_loss: 21.1394 - val_accuracy: 0.0911\n",
            "Epoch 8651/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 102.1827 - accuracy: 0.6889 - val_loss: 71.4280 - val_accuracy: 0.0809\n",
            "Epoch 8652/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 69.8614 - accuracy: 0.6800 - val_loss: 637.2750 - val_accuracy: 0.0284\n",
            "Epoch 8653/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 31.0991 - accuracy: 0.9652 - val_loss: 15.6977 - val_accuracy: 0.1630\n",
            "Epoch 8654/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 176.2215 - accuracy: 0.6871 - val_loss: 19.7701 - val_accuracy: 0.1584\n",
            "Epoch 8655/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 22.2356 - accuracy: 0.5462 - val_loss: 87.5457 - val_accuracy: 0.1247\n",
            "Epoch 8656/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 238.8260 - accuracy: 0.7710 - val_loss: 285.4883 - val_accuracy: 0.2084\n",
            "Epoch 8657/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 45.4401 - accuracy: 0.9448 - val_loss: 761.0645 - val_accuracy: 0.6684\n",
            "Epoch 8658/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.1705 - accuracy: 1.0000 - val_loss: 193.2904 - val_accuracy: 0.0188\n",
            "Epoch 8659/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 17.0600 - accuracy: 0.3728 - val_loss: 570.9546 - val_accuracy: 0.0907\n",
            "Epoch 8660/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 12.3605 - accuracy: 0.9215 - val_loss: 89.9285 - val_accuracy: 0.1635\n",
            "Epoch 8661/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 10.3774 - accuracy: 0.8962 - val_loss: 218.6439 - val_accuracy: 0.0483\n",
            "Epoch 8662/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 14.8415 - accuracy: 0.8803 - val_loss: 37.7400 - val_accuracy: 0.1991\n",
            "Epoch 8663/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 24.8840 - accuracy: 0.7343 - val_loss: 33.5599 - val_accuracy: 0.0902\n",
            "Epoch 8664/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 127.1563 - accuracy: 0.9202 - val_loss: 26.2617 - val_accuracy: 0.1434\n",
            "Epoch 8665/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 18.8238 - accuracy: 0.3678 - val_loss: 228.0733 - val_accuracy: 0.1097\n",
            "Epoch 8666/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 31.1240 - accuracy: 0.4391 - val_loss: 12.7089 - val_accuracy: 0.2152\n",
            "Epoch 8667/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 15.5757 - accuracy: 0.4850 - val_loss: 77.0151 - val_accuracy: 0.1008\n",
            "Epoch 8668/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 17.3430 - accuracy: 0.2771 - val_loss: 35.1002 - val_accuracy: 0.1284\n",
            "Epoch 8669/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 21.4142 - accuracy: 0.3766 - val_loss: 288.3135 - val_accuracy: 0.1482\n",
            "Epoch 8670/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 24.1946 - accuracy: 0.5964 - val_loss: 2183.9639 - val_accuracy: 0.0623\n",
            "Epoch 8671/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 8.5059 - accuracy: 0.7629 - val_loss: 14.9726 - val_accuracy: 0.1376\n",
            "Epoch 8672/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 163.9568 - accuracy: 0.6061 - val_loss: 15.8009 - val_accuracy: 0.2107\n",
            "Epoch 8673/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 82.5237 - accuracy: 0.9298 - val_loss: 124.4109 - val_accuracy: 0.5416\n",
            "Epoch 8674/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 23.0850 - accuracy: 0.8873 - val_loss: 18.1434 - val_accuracy: 0.3179\n",
            "Epoch 8675/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 6.9081 - accuracy: 0.8860 - val_loss: 35.4936 - val_accuracy: 0.2998\n",
            "Epoch 8676/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 101.0625 - accuracy: 0.3536 - val_loss: 323.3943 - val_accuracy: 0.2191\n",
            "Epoch 8677/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 40.5987 - accuracy: 0.9106 - val_loss: 53.5693 - val_accuracy: 0.1480\n",
            "Epoch 8678/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 11.3660 - accuracy: 0.3636 - val_loss: 24.5057 - val_accuracy: 0.1155\n",
            "Epoch 8679/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 29.1450 - accuracy: 0.2513 - val_loss: 35.4955 - val_accuracy: 0.1874\n",
            "Epoch 8680/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 255.2651 - accuracy: 0.1780 - val_loss: 96.1213 - val_accuracy: 0.0978\n",
            "Epoch 8681/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 13.4531 - accuracy: 0.5305 - val_loss: 15.2612 - val_accuracy: 0.2951\n",
            "Epoch 8682/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 109.6693 - accuracy: 0.1138 - val_loss: 34.0374 - val_accuracy: 0.1222\n",
            "Epoch 8683/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 11.5586 - accuracy: 0.7200 - val_loss: 35.2494 - val_accuracy: 0.0664\n",
            "Epoch 8684/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 31.5851 - accuracy: 0.9717 - val_loss: 987.4102 - val_accuracy: 0.1163\n",
            "Epoch 8685/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 51.1295 - accuracy: 0.4460 - val_loss: 58.4372 - val_accuracy: 0.1153\n",
            "Epoch 8686/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 1158.6619 - accuracy: 0.5618 - val_loss: 16.0347 - val_accuracy: 0.1293\n",
            "Epoch 8687/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 25.3931 - accuracy: 0.2455 - val_loss: 686.2641 - val_accuracy: 0.1090\n",
            "Epoch 8688/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 14.5914 - accuracy: 0.3172 - val_loss: 225.2234 - val_accuracy: 0.0662\n",
            "Epoch 8689/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.3765 - accuracy: 1.0000 - val_loss: 29.2164 - val_accuracy: 0.2513\n",
            "Epoch 8690/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 919.6842 - accuracy: 0.4666 - val_loss: 47.5780 - val_accuracy: 0.2576\n",
            "Epoch 8691/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 17.1053 - accuracy: 0.3049 - val_loss: 1047.4854 - val_accuracy: 0.0892\n",
            "Epoch 8692/24392\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 11.3760 - accuracy: 0.4115 - val_loss: 58.9079 - val_accuracy: 0.1016\n",
            "Epoch 8693/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 31.8740 - accuracy: 0.9652 - val_loss: 12.0736 - val_accuracy: 0.2564\n",
            "Epoch 8694/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 79.5869 - accuracy: 0.8901 - val_loss: 367.6212 - val_accuracy: 0.2481\n",
            "Epoch 8695/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 25.1504 - accuracy: 0.3387 - val_loss: 16.1826 - val_accuracy: 0.2806\n",
            "Epoch 8696/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 58.4505 - accuracy: 0.8906 - val_loss: 9.3507 - val_accuracy: 0.6910\n",
            "Epoch 8697/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 50.4590 - accuracy: 0.0864 - val_loss: 11.9217 - val_accuracy: 0.2646\n",
            "Epoch 8698/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 568.3899 - accuracy: 0.2855 - val_loss: 916.1537 - val_accuracy: 0.0588\n",
            "Epoch 8699/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 22.0175 - accuracy: 0.7977 - val_loss: 122.8992 - val_accuracy: 0.1551\n",
            "Epoch 8700/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 11.8414 - accuracy: 0.9833 - val_loss: 148.1768 - val_accuracy: 0.1714\n",
            "Epoch 8701/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 16.9312 - accuracy: 0.2931 - val_loss: 16.2371 - val_accuracy: 0.2894\n",
            "Epoch 8702/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 11.3828 - accuracy: 0.4174 - val_loss: 32.9274 - val_accuracy: 0.2267\n",
            "Epoch 8703/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 63.7873 - accuracy: 0.9722 - val_loss: 24.2181 - val_accuracy: 0.1965\n",
            "Epoch 8704/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 26.0598 - accuracy: 0.9754 - val_loss: 1072.2899 - val_accuracy: 0.1438\n",
            "Epoch 8705/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 14.2583 - accuracy: 0.8587 - val_loss: 1816.0585 - val_accuracy: 0.2618\n",
            "Epoch 8706/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 491.1831 - accuracy: 0.7141 - val_loss: 9.8843 - val_accuracy: 0.2505\n",
            "Epoch 8707/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 76.7275 - accuracy: 0.9298 - val_loss: 13.9947 - val_accuracy: 0.1498\n",
            "Epoch 8708/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 16.2505 - accuracy: 0.4467 - val_loss: 130.8456 - val_accuracy: 0.0906\n",
            "Epoch 8709/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 206.8383 - accuracy: 0.8801 - val_loss: 11.0372 - val_accuracy: 0.1819\n",
            "Epoch 8710/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 19.0931 - accuracy: 0.5617 - val_loss: 430.2319 - val_accuracy: 0.0129\n",
            "Epoch 8711/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 38.8508 - accuracy: 0.2601 - val_loss: 963.6723 - val_accuracy: 0.0820\n",
            "Epoch 8712/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 20.4328 - accuracy: 0.5176 - val_loss: 89.0443 - val_accuracy: 0.1663\n",
            "Epoch 8713/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 17.4519 - accuracy: 0.3946 - val_loss: 21.6688 - val_accuracy: 0.1473\n",
            "Epoch 8714/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 24.1615 - accuracy: 0.8845 - val_loss: 104.8248 - val_accuracy: 0.2238\n",
            "Epoch 8715/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 21.1964 - accuracy: 0.6129 - val_loss: 851.1992 - val_accuracy: 0.0411\n",
            "Epoch 8716/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 14.6262 - accuracy: 0.7158 - val_loss: 62.5508 - val_accuracy: 0.1965\n",
            "Epoch 8717/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 30.1143 - accuracy: 0.9793 - val_loss: 762.9633 - val_accuracy: 0.1432\n",
            "Epoch 8718/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 53.4137 - accuracy: 0.2095 - val_loss: 1011.9668 - val_accuracy: 0.0448\n",
            "Epoch 8719/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 52.4883 - accuracy: 0.6140 - val_loss: 22.0025 - val_accuracy: 0.1784\n",
            "Epoch 8720/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 5.0041 - accuracy: 0.9155 - val_loss: 21.3389 - val_accuracy: 0.1940\n",
            "Epoch 8721/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 18.0498 - accuracy: 0.8530 - val_loss: 695.2939 - val_accuracy: 0.0448\n",
            "Epoch 8722/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 20.3492 - accuracy: 0.9193 - val_loss: 20.6963 - val_accuracy: 0.1972\n",
            "Epoch 8723/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 22.0975 - accuracy: 0.2527 - val_loss: 46.6755 - val_accuracy: 0.1412\n",
            "Epoch 8724/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 14.2450 - accuracy: 0.3451 - val_loss: 8.8041 - val_accuracy: 0.2457\n",
            "Epoch 8725/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 44.4310 - accuracy: 0.2623 - val_loss: 19.4733 - val_accuracy: 0.2319\n",
            "Epoch 8726/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 19.4580 - accuracy: 0.2591 - val_loss: 16.7818 - val_accuracy: 0.1708\n",
            "Epoch 8727/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 23.5907 - accuracy: 0.3386 - val_loss: 117.2789 - val_accuracy: 0.0651\n",
            "Epoch 8728/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 160.2652 - accuracy: 0.7679 - val_loss: 136052.6406 - val_accuracy: 0.4143\n",
            "Epoch 8729/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 10.1586 - val_accuracy: 0.2456\n",
            "Epoch 8730/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 65.4684 - accuracy: 0.9558 - val_loss: 696.0801 - val_accuracy: 0.1993\n",
            "Epoch 8731/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 42.6209 - accuracy: 0.9791 - val_loss: 572.9678 - val_accuracy: 0.0477\n",
            "Epoch 8732/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 335.8779 - accuracy: 0.2681 - val_loss: 18.3898 - val_accuracy: 0.1957\n",
            "Epoch 8733/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 9.0823 - accuracy: 0.9047 - val_loss: 55.2290 - val_accuracy: 0.2653\n",
            "Epoch 8734/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 102.9169 - accuracy: 0.3702 - val_loss: 1196.1304 - val_accuracy: 0.0744\n",
            "Epoch 8735/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 8.9381 - accuracy: 0.9933 - val_loss: 25.8822 - val_accuracy: 0.1608\n",
            "Epoch 8736/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 11.5485 - accuracy: 0.8731 - val_loss: 178.9570 - val_accuracy: 0.0448\n",
            "Epoch 8737/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 15.5113 - accuracy: 0.2153 - val_loss: 10.6964 - val_accuracy: 0.2125\n",
            "Epoch 8738/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 35.7127 - accuracy: 0.9616 - val_loss: 188.8370 - val_accuracy: 0.0582\n",
            "Epoch 8739/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 33.4021 - accuracy: 0.5817 - val_loss: 141.7825 - val_accuracy: 0.0861\n",
            "Epoch 8740/24392\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 2567.8131 - accuracy: 0.6424 - val_loss: 54.3671 - val_accuracy: 0.0916\n",
            "Epoch 8741/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 10.9864 - accuracy: 0.5379 - val_loss: 1007.7094 - val_accuracy: 0.0728\n",
            "Epoch 8742/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 15.6739 - accuracy: 0.9088 - val_loss: 28.6520 - val_accuracy: 0.2519\n",
            "Epoch 8743/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 60.3363 - accuracy: 0.8600 - val_loss: 4633.0854 - val_accuracy: 0.1143\n",
            "Epoch 8744/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 59.5481 - accuracy: 0.9758 - val_loss: 868.7435 - val_accuracy: 0.0533\n",
            "Epoch 8745/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 69.9760 - accuracy: 0.9168 - val_loss: 52.4932 - val_accuracy: 0.1979\n",
            "Epoch 8746/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 83.7364 - accuracy: 0.1757 - val_loss: 61.0469 - val_accuracy: 0.1224\n",
            "Epoch 8747/24392\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 12.6901 - accuracy: 0.8045 - val_loss: 146.3599 - val_accuracy: 0.1020\n",
            "Epoch 8748/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 2058.6266 - accuracy: 0.4342 - val_loss: 34.1819 - val_accuracy: 0.0571\n",
            "Epoch 8749/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 31.6748 - accuracy: 0.3829 - val_loss: 349.0543 - val_accuracy: 0.1140\n",
            "Epoch 8750/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 72.5681 - accuracy: 0.9682 - val_loss: 18.6491 - val_accuracy: 0.1586\n",
            "Epoch 8751/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 17.6432 - accuracy: 0.4610 - val_loss: 756.2084 - val_accuracy: 0.0938\n",
            "Epoch 8752/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 38.0018 - accuracy: 0.3285 - val_loss: 16.4836 - val_accuracy: 0.2408\n",
            "Epoch 8753/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 996.6573 - val_accuracy: 0.0564\n",
            "Epoch 8754/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 1557.4000 - accuracy: 0.7164 - val_loss: 59.7950 - val_accuracy: 0.1334\n",
            "Epoch 8755/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 37.0587 - accuracy: 0.2846 - val_loss: 305.5965 - val_accuracy: 0.0491\n",
            "Epoch 8756/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 952.3753 - accuracy: 0.4562 - val_loss: 32.8205 - val_accuracy: 0.1176\n",
            "Epoch 8757/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 26.6092 - accuracy: 0.9757 - val_loss: 508.9091 - val_accuracy: 0.0844\n",
            "Epoch 8758/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 16.4655 - accuracy: 0.2919 - val_loss: 24.7374 - val_accuracy: 0.2136\n",
            "Epoch 8759/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 10.1815 - accuracy: 0.9309 - val_loss: 16.9746 - val_accuracy: 0.0888\n",
            "Epoch 8760/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 100.4086 - accuracy: 0.8909 - val_loss: 26.6837 - val_accuracy: 0.1953\n",
            "Epoch 8761/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 20.4659 - accuracy: 0.9719 - val_loss: 660.2770 - val_accuracy: 0.1156\n",
            "Epoch 8762/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 40.4136 - accuracy: 0.2709 - val_loss: 213.9276 - val_accuracy: 0.0483\n",
            "Epoch 8763/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 735.3912 - accuracy: 0.5561 - val_loss: 29.8622 - val_accuracy: 0.1366\n",
            "Epoch 8764/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 21.7187 - accuracy: 0.3281 - val_loss: 21.9293 - val_accuracy: 0.1372\n",
            "Epoch 8765/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 14.1117 - accuracy: 0.6039 - val_loss: 458.4854 - val_accuracy: 0.3713\n",
            "Epoch 8766/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 22.5956 - accuracy: 0.8780 - val_loss: 14.1310 - val_accuracy: 0.2474\n",
            "Epoch 8767/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 28.5677 - accuracy: 0.8664 - val_loss: 23.3746 - val_accuracy: 0.1057\n",
            "Epoch 8768/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 564.2925 - accuracy: 0.7591 - val_loss: 95.2714 - val_accuracy: 0.4428\n",
            "Epoch 8769/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 11.0712 - val_accuracy: 0.1981\n",
            "Epoch 8770/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 14.5689 - accuracy: 0.4771 - val_loss: 36.5996 - val_accuracy: 0.1966\n",
            "Epoch 8771/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 7.4727 - accuracy: 0.7425 - val_loss: 23.9966 - val_accuracy: 0.2084\n",
            "Epoch 8772/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 10.0434 - accuracy: 0.9979 - val_loss: 20.4618 - val_accuracy: 0.2830\n",
            "Epoch 8773/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 13.0916 - accuracy: 0.3693 - val_loss: 26.8422 - val_accuracy: 0.2309\n",
            "Epoch 8774/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 61.3502 - accuracy: 0.9114 - val_loss: 18.4751 - val_accuracy: 0.2182\n",
            "Epoch 8775/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 614.6033 - accuracy: 0.2778 - val_loss: 1081.4722 - val_accuracy: 0.0300\n",
            "Epoch 8776/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 6.6282 - accuracy: 0.9988 - val_loss: 83.2521 - val_accuracy: 0.0615\n",
            "Epoch 8777/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 4809.6614 - accuracy: 0.4031 - val_loss: 16.9772 - val_accuracy: 0.1072\n",
            "Epoch 8778/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 17.1640 - accuracy: 0.9734 - val_loss: 16.3159 - val_accuracy: 0.1597\n",
            "Epoch 8779/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 18.3730 - accuracy: 0.4499 - val_loss: 67.0276 - val_accuracy: 0.0895\n",
            "Epoch 8780/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 306.5951 - accuracy: 0.7270 - val_loss: 23.2136 - val_accuracy: 0.1309\n",
            "Epoch 8781/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 157.1572 - accuracy: 0.8962 - val_loss: 86.7912 - val_accuracy: 0.0234\n",
            "Epoch 8782/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 34.2240 - accuracy: 0.2976 - val_loss: 125.7837 - val_accuracy: 0.0967\n",
            "Epoch 8783/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 13.9395 - accuracy: 0.5314 - val_loss: 61.8658 - val_accuracy: 0.0969\n",
            "Epoch 8784/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 15.0323 - accuracy: 0.5677 - val_loss: 67.7090 - val_accuracy: 0.0985\n",
            "Epoch 8785/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 105.4953 - accuracy: 0.6910 - val_loss: 62.6880 - val_accuracy: 0.0205\n",
            "Epoch 8786/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 11.3235 - accuracy: 0.6138 - val_loss: 34.7306 - val_accuracy: 0.0397\n",
            "Epoch 8787/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 39.6361 - accuracy: 0.9631 - val_loss: 138.0269 - val_accuracy: 0.0366\n",
            "Epoch 8788/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 9.2750 - accuracy: 0.4906 - val_loss: 244.4143 - val_accuracy: 0.0148\n",
            "Epoch 8789/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 3797.3369 - accuracy: 0.4725 - val_loss: 60.7726 - val_accuracy: 0.1091\n",
            "Epoch 8790/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 11.8872 - accuracy: 0.5090 - val_loss: 31.2842 - val_accuracy: 0.1437\n",
            "Epoch 8791/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 117.7203 - accuracy: 0.8108 - val_loss: 18.4169 - val_accuracy: 0.0927\n",
            "Epoch 8792/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 29.8101 - accuracy: 0.9145 - val_loss: 23.2369 - val_accuracy: 0.1015\n",
            "Epoch 8793/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 22.8100 - accuracy: 0.2370 - val_loss: 13.6459 - val_accuracy: 0.1515\n",
            "Epoch 8794/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 12.5499 - accuracy: 0.9308 - val_loss: 153.8877 - val_accuracy: 0.0949\n",
            "Epoch 8795/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 70.5473 - accuracy: 0.8680 - val_loss: 157.5573 - val_accuracy: 0.1447\n",
            "Epoch 8796/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 22.2458 - accuracy: 0.2463 - val_loss: 151.8008 - val_accuracy: 0.0584\n",
            "Epoch 8797/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 73.1539 - accuracy: 0.2612 - val_loss: 12.1245 - val_accuracy: 0.1811\n",
            "Epoch 8798/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 25.5916 - accuracy: 0.9858 - val_loss: 21.4126 - val_accuracy: 0.1426\n",
            "Epoch 8799/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 45.4392 - accuracy: 0.9415 - val_loss: 90.7042 - val_accuracy: 0.0623\n",
            "Epoch 8800/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 17.9184 - accuracy: 0.2041 - val_loss: 1776.3918 - val_accuracy: 0.0142\n",
            "Epoch 8801/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 7.8343 - accuracy: 0.8263 - val_loss: 22.1340 - val_accuracy: 0.2660\n",
            "Epoch 8802/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 80.5677 - accuracy: 0.4166 - val_loss: 224.4519 - val_accuracy: 0.1151\n",
            "Epoch 8803/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 12.7578 - accuracy: 0.2857 - val_loss: 795.7480 - val_accuracy: 0.0650\n",
            "Epoch 8804/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 14.3540 - accuracy: 0.9040 - val_loss: 1403.6523 - val_accuracy: 0.0442\n",
            "Epoch 8805/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 15.6580 - accuracy: 0.8657 - val_loss: 186.3567 - val_accuracy: 0.1691\n",
            "Epoch 8806/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 14.7974 - accuracy: 0.3495 - val_loss: 18.6735 - val_accuracy: 0.3233\n",
            "Epoch 8807/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 24.1607 - accuracy: 0.9013 - val_loss: 1286.1281 - val_accuracy: 0.0533\n",
            "Epoch 8808/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 107.4011 - accuracy: 0.7146 - val_loss: 14.7206 - val_accuracy: 0.2974\n",
            "Epoch 8809/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 27.4211 - accuracy: 0.2738 - val_loss: 1416.7224 - val_accuracy: 0.0964\n",
            "Epoch 8810/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 273.4946 - accuracy: 0.5336 - val_loss: 75.2288 - val_accuracy: 0.1574\n",
            "Epoch 8811/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 4.7760 - accuracy: 0.9948 - val_loss: 29.1975 - val_accuracy: 0.2318\n",
            "Epoch 8812/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 11.6197 - accuracy: 0.4102 - val_loss: 26.9915 - val_accuracy: 0.1410\n",
            "Epoch 8813/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 12.4016 - accuracy: 0.9164 - val_loss: 29.0956 - val_accuracy: 0.2092\n",
            "Epoch 8814/24392\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 82.4686 - accuracy: 0.8246 - val_loss: 23.7962 - val_accuracy: 0.1454\n",
            "Epoch 8815/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 162.6484 - accuracy: 0.3091 - val_loss: 15.5049 - val_accuracy: 0.0323\n",
            "Epoch 8816/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 12.8006 - accuracy: 0.7915 - val_loss: 21.0647 - val_accuracy: 0.0497\n",
            "Epoch 8817/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 987.6666 - accuracy: 0.8584 - val_loss: 37.4694 - val_accuracy: 0.2278\n",
            "Epoch 8818/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 181.7514 - accuracy: 0.7260 - val_loss: 115.1019 - val_accuracy: 0.0219\n",
            "Epoch 8819/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 16.0724 - accuracy: 0.8823 - val_loss: 160.3579 - val_accuracy: 0.0911\n",
            "Epoch 8820/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 12.5671 - accuracy: 0.5958 - val_loss: 92.5850 - val_accuracy: 0.0386\n",
            "Epoch 8821/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 16.6370 - accuracy: 0.2389 - val_loss: 42.0398 - val_accuracy: 0.1746\n",
            "Epoch 8822/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 264.1659 - accuracy: 0.8563 - val_loss: 12.9625 - val_accuracy: 0.2447\n",
            "Epoch 8823/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 10.4912 - accuracy: 0.9600 - val_loss: 192.5941 - val_accuracy: 0.0611\n",
            "Epoch 8824/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 16.5404 - accuracy: 0.7318 - val_loss: 60.9993 - val_accuracy: 0.0853\n",
            "Epoch 8825/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 10.1127 - accuracy: 0.9961 - val_loss: 27.3579 - val_accuracy: 0.1640\n",
            "Epoch 8826/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 43.6050 - accuracy: 0.1999 - val_loss: 54.0810 - val_accuracy: 0.0841\n",
            "Epoch 8827/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 9.6579 - accuracy: 0.5936 - val_loss: 194.7135 - val_accuracy: 0.1974\n",
            "Epoch 8828/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1417.8414 - val_accuracy: 0.0705\n",
            "Epoch 8829/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 34.8315 - accuracy: 0.9430 - val_loss: 16.0280 - val_accuracy: 0.2743\n",
            "Epoch 8830/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 338.8875 - accuracy: 0.6194 - val_loss: 1206.3467 - val_accuracy: 0.0480\n",
            "Epoch 8831/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 1110.6461 - accuracy: 0.8233 - val_loss: 716.6609 - val_accuracy: 0.0520\n",
            "Epoch 8832/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 9.9972 - accuracy: 0.6965 - val_loss: 13.9426 - val_accuracy: 0.3479\n",
            "Epoch 8833/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 30.2282 - accuracy: 0.1746 - val_loss: 47.8153 - val_accuracy: 0.1582\n",
            "Epoch 8834/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 37.3326 - accuracy: 0.9860 - val_loss: 40.3785 - val_accuracy: 0.1864\n",
            "Epoch 8835/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 16.6409 - accuracy: 0.9868 - val_loss: 26.5250 - val_accuracy: 0.2845\n",
            "Epoch 8836/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 50.5853 - accuracy: 0.8843 - val_loss: 25.5232 - val_accuracy: 0.1355\n",
            "Epoch 8837/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 57.7976 - accuracy: 0.8468 - val_loss: 32.7730 - val_accuracy: 0.1641\n",
            "Epoch 8838/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 481.1644 - accuracy: 0.6245 - val_loss: 800.1738 - val_accuracy: 0.0376\n",
            "Epoch 8839/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 138.8179 - accuracy: 0.6953 - val_loss: 34.0133 - val_accuracy: 0.1732\n",
            "Epoch 8840/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 24.8033 - accuracy: 0.9798 - val_loss: 14.2797 - val_accuracy: 0.2287\n",
            "Epoch 8841/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 14.7504 - accuracy: 0.3847 - val_loss: 211.4901 - val_accuracy: 0.1182\n",
            "Epoch 8842/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 38.1392 - accuracy: 0.2507 - val_loss: 16.9740 - val_accuracy: 0.1728\n",
            "Epoch 8843/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 47.3329 - accuracy: 0.9533 - val_loss: 56.0838 - val_accuracy: 0.0735\n",
            "Epoch 8844/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 30.2901 - accuracy: 0.5288 - val_loss: 23.1618 - val_accuracy: 0.2725\n",
            "Epoch 8845/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 59.6722 - accuracy: 0.9525 - val_loss: 1103.3467 - val_accuracy: 0.0522\n",
            "Epoch 8846/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 99.4856 - accuracy: 0.9016 - val_loss: 41.6103 - val_accuracy: 0.1473\n",
            "Epoch 8847/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 11.0250 - accuracy: 0.9713 - val_loss: 111.0574 - val_accuracy: 0.1069\n",
            "Epoch 8848/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 12.5167 - accuracy: 0.8462 - val_loss: 901.2271 - val_accuracy: 0.0030\n",
            "Epoch 8849/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 15.5361 - accuracy: 0.8539 - val_loss: 757.2456 - val_accuracy: 0.0765\n",
            "Epoch 8850/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 64.3193 - accuracy: 0.8425 - val_loss: 780.0883 - val_accuracy: 0.0186\n",
            "Epoch 8851/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 143.4023 - accuracy: 0.1231 - val_loss: 1435.2070 - val_accuracy: 0.0580\n",
            "Epoch 8852/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 53.5877 - accuracy: 0.4524 - val_loss: 33.9703 - val_accuracy: 0.0786\n",
            "Epoch 8853/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 16.0632 - accuracy: 0.4430 - val_loss: 89.9100 - val_accuracy: 0.0686\n",
            "Epoch 8854/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 12.9370 - accuracy: 0.8306 - val_loss: 1223.0898 - val_accuracy: 0.0632\n",
            "Epoch 8855/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 30.3530 - accuracy: 0.9414 - val_loss: 48.1567 - val_accuracy: 0.2039\n",
            "Epoch 8856/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 49.8044 - accuracy: 0.9279 - val_loss: 28.4495 - val_accuracy: 0.2113\n",
            "Epoch 8857/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 10.5461 - accuracy: 0.4025 - val_loss: 181.5186 - val_accuracy: 0.1100\n",
            "Epoch 8858/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 305.3244 - accuracy: 0.7326 - val_loss: 24.6972 - val_accuracy: 0.1962\n",
            "Epoch 8859/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 16.7104 - accuracy: 0.3887 - val_loss: 97.5270 - val_accuracy: 0.1421\n",
            "Epoch 8860/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 14.6961 - accuracy: 0.5882 - val_loss: 17.5233 - val_accuracy: 0.4183\n",
            "Epoch 8861/24392\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 21.7069 - accuracy: 0.5426 - val_loss: 54.2619 - val_accuracy: 0.1234\n",
            "Epoch 8862/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 12.2869 - accuracy: 0.6494 - val_loss: 38.6766 - val_accuracy: 0.0709\n",
            "Epoch 8863/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 13.8682 - accuracy: 0.4393 - val_loss: 18.5537 - val_accuracy: 0.2836\n",
            "Epoch 8864/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 14.4931 - accuracy: 0.3343 - val_loss: 32.9875 - val_accuracy: 0.1271\n",
            "Epoch 8865/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 17.3586 - val_accuracy: 0.2766\n",
            "Epoch 8866/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 17.2966 - accuracy: 0.2365 - val_loss: 16.6362 - val_accuracy: 0.2226\n",
            "Epoch 8867/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 19.7848 - accuracy: 0.7781 - val_loss: 77.5707 - val_accuracy: 0.0634\n",
            "Epoch 8868/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 9.2974 - accuracy: 0.7238 - val_loss: 954.9088 - val_accuracy: 0.0593\n",
            "Epoch 8869/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 66.4065 - accuracy: 0.9170 - val_loss: 1158.6149 - val_accuracy: 0.0314\n",
            "Epoch 8870/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 12.8332 - accuracy: 0.7750 - val_loss: 15.0139 - val_accuracy: 0.1532\n",
            "Epoch 8871/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 10.6275 - accuracy: 0.8440 - val_loss: 27.6196 - val_accuracy: 0.0850\n",
            "Epoch 8872/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 36.1843 - accuracy: 0.9323 - val_loss: 11.6986 - val_accuracy: 0.0748\n",
            "Epoch 8873/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 21.4694 - accuracy: 0.2487 - val_loss: 380.9791 - val_accuracy: 0.0479\n",
            "Epoch 8874/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 11.2303 - accuracy: 0.4800 - val_loss: 16.0695 - val_accuracy: 0.0832\n",
            "Epoch 8875/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 15.0338 - accuracy: 0.8957 - val_loss: 32.8061 - val_accuracy: 0.2132\n",
            "Epoch 8876/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 9.2920 - accuracy: 0.8406 - val_loss: 801.2825 - val_accuracy: 0.0651\n",
            "Epoch 8877/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 13.7737 - accuracy: 0.3021 - val_loss: 463.8445 - val_accuracy: 0.0441\n",
            "Epoch 8878/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 100.5101 - accuracy: 0.8211 - val_loss: 89.8323 - val_accuracy: 0.0516\n",
            "Epoch 8879/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 17.5789 - accuracy: 0.3268 - val_loss: 17.5152 - val_accuracy: 0.2397\n",
            "Epoch 8880/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 4.9418 - accuracy: 0.9944 - val_loss: 32.8218 - val_accuracy: 0.2491\n",
            "Epoch 8881/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 17.4249 - accuracy: 0.3329 - val_loss: 34.1301 - val_accuracy: 0.1112\n",
            "Epoch 8882/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 28.9095 - accuracy: 0.9183 - val_loss: 33.3709 - val_accuracy: 0.1537\n",
            "Epoch 8883/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 31.2368 - accuracy: 0.5631 - val_loss: 36.8343 - val_accuracy: 0.1657\n",
            "Epoch 8884/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 46.8128 - accuracy: 0.1898 - val_loss: 30.1382 - val_accuracy: 0.3038\n",
            "Epoch 8885/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 25.9365 - accuracy: 0.4785 - val_loss: 41.4129 - val_accuracy: 0.2046\n",
            "Epoch 8886/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 64.7895 - accuracy: 0.4519 - val_loss: 44.6588 - val_accuracy: 0.1372\n",
            "Epoch 8887/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 17.9554 - accuracy: 0.2389 - val_loss: 29.4755 - val_accuracy: 0.1389\n",
            "Epoch 8888/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 7.9900 - accuracy: 0.9918 - val_loss: 1007.2266 - val_accuracy: 0.0447\n",
            "Epoch 8889/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 6895.2537 - accuracy: 0.5767 - val_loss: 67.1055 - val_accuracy: 0.0959\n",
            "Epoch 8890/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 251.5996 - accuracy: 0.7792 - val_loss: 36.8535 - val_accuracy: 0.0851\n",
            "Epoch 8891/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 146.6531 - accuracy: 0.8151 - val_loss: 30.3653 - val_accuracy: 0.0703\n",
            "Epoch 8892/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 161.0442 - accuracy: 0.8307 - val_loss: 62.6495 - val_accuracy: 0.0200\n",
            "Epoch 8893/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 142.6843 - accuracy: 0.9500 - val_loss: 117.7707 - val_accuracy: 0.0774\n",
            "Epoch 8894/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 27.6212 - accuracy: 0.3185 - val_loss: 18.3368 - val_accuracy: 0.1118\n",
            "Epoch 8895/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 11.0378 - accuracy: 0.7576 - val_loss: 347.9822 - val_accuracy: 0.0532\n",
            "Epoch 8896/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 35.3404 - accuracy: 0.9157 - val_loss: 108.7070 - val_accuracy: 0.1514\n",
            "Epoch 8897/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 12.1434 - accuracy: 0.4987 - val_loss: 1640.2080 - val_accuracy: 0.0717\n",
            "Epoch 8898/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 491.3955 - accuracy: 0.8753 - val_loss: 20758.6699 - val_accuracy: 0.0434\n",
            "Epoch 8899/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 18.7068 - accuracy: 0.5007 - val_loss: 176.1150 - val_accuracy: 0.0835\n",
            "Epoch 8900/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 34.6585 - accuracy: 0.3767 - val_loss: 26.0853 - val_accuracy: 0.1787\n",
            "Epoch 8901/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 75.7529 - accuracy: 0.9512 - val_loss: 56.5262 - val_accuracy: 0.1136\n",
            "Epoch 8902/24392\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 111.3532 - accuracy: 0.8552 - val_loss: 1621.7538 - val_accuracy: 0.0776\n",
            "Epoch 8903/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 1051.1453 - accuracy: 0.7977 - val_loss: 23.6517 - val_accuracy: 0.0979\n",
            "Epoch 8904/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 38.0411 - accuracy: 0.9709 - val_loss: 137.2653 - val_accuracy: 0.1156\n",
            "Epoch 8905/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 405.2777 - accuracy: 0.6850 - val_loss: 14.4325 - val_accuracy: 0.2560\n",
            "Epoch 8906/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 129.7974 - accuracy: 0.8002 - val_loss: 1185.6377 - val_accuracy: 0.0115\n",
            "Epoch 8907/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 165.1409 - accuracy: 0.9473 - val_loss: 13.3264 - val_accuracy: 0.1943\n",
            "Epoch 8908/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 2140.2558 - accuracy: 0.3621 - val_loss: 38.9972 - val_accuracy: 0.1141\n",
            "Epoch 8909/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.1536 - accuracy: 1.0000 - val_loss: 60.1795 - val_accuracy: 0.1036\n",
            "Epoch 8910/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 117.1798 - accuracy: 0.9444 - val_loss: 1148.3921 - val_accuracy: 0.0263\n",
            "Epoch 8911/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 373.7187 - accuracy: 0.5730 - val_loss: 12.9757 - val_accuracy: 0.1256\n",
            "Epoch 8912/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 195.8116 - accuracy: 0.8625 - val_loss: 45.8545 - val_accuracy: 0.2152\n",
            "Epoch 8913/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 447.7848 - accuracy: 0.7855 - val_loss: 17.6754 - val_accuracy: 0.1076\n",
            "Epoch 8914/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 52.1470 - accuracy: 0.8072 - val_loss: 91.3179 - val_accuracy: 0.1529\n",
            "Epoch 8915/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 41.0796 - accuracy: 0.4132 - val_loss: 141.6509 - val_accuracy: 0.1082\n",
            "Epoch 8916/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 20.6121 - accuracy: 0.8104 - val_loss: 495.6443 - val_accuracy: 0.0356\n",
            "Epoch 8917/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 11686.1210 - accuracy: 0.4947 - val_loss: 120.0713 - val_accuracy: 0.1334\n",
            "Epoch 8918/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 24.5320 - accuracy: 0.7388 - val_loss: 34.1638 - val_accuracy: 0.1811\n",
            "Epoch 8919/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 31.6816 - val_accuracy: 0.1442\n",
            "Epoch 8920/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 12.3135 - accuracy: 0.7119 - val_loss: 127.2797 - val_accuracy: 0.0990\n",
            "Epoch 8921/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 59.7832 - accuracy: 0.9522 - val_loss: 14.7141 - val_accuracy: 0.2066\n",
            "Epoch 8922/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 26.2506 - accuracy: 0.8799 - val_loss: 64.6704 - val_accuracy: 0.1457\n",
            "Epoch 8923/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 24.6133 - accuracy: 0.4838 - val_loss: 1876.9670 - val_accuracy: 0.1235\n",
            "Epoch 8924/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 16.0686 - accuracy: 0.3349 - val_loss: 60.3255 - val_accuracy: 0.0536\n",
            "Epoch 8925/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 714.9094 - accuracy: 0.3693 - val_loss: 147.2671 - val_accuracy: 0.0195\n",
            "Epoch 8926/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 21.6047 - accuracy: 0.9360 - val_loss: 32.3964 - val_accuracy: 0.1748\n",
            "Epoch 8927/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2019.4490 - val_accuracy: 0.1030\n",
            "Epoch 8928/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 26.8215 - accuracy: 0.2423 - val_loss: 18.9108 - val_accuracy: 0.1088\n",
            "Epoch 8929/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 236.8089 - accuracy: 0.6007 - val_loss: 25.1549 - val_accuracy: 0.1563\n",
            "Epoch 8930/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 12.5535 - accuracy: 0.3913 - val_loss: 1568.1289 - val_accuracy: 0.0918\n",
            "Epoch 8931/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 266.2881 - accuracy: 0.8403 - val_loss: 1535.3939 - val_accuracy: 0.0748\n",
            "Epoch 8932/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 20.6123 - accuracy: 0.5907 - val_loss: 29.6260 - val_accuracy: 0.1725\n",
            "Epoch 8933/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 11.4324 - accuracy: 0.9240 - val_loss: 14.0725 - val_accuracy: 0.2603\n",
            "Epoch 8934/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 12.9656 - accuracy: 0.3755 - val_loss: 134.8372 - val_accuracy: 0.1141\n",
            "Epoch 8935/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 350.7364 - accuracy: 0.4541 - val_loss: 684.0840 - val_accuracy: 0.1828\n",
            "Epoch 8936/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 356.5439 - accuracy: 0.8627 - val_loss: 118.1362 - val_accuracy: 0.2311\n",
            "Epoch 8937/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 11.7517 - accuracy: 0.4290 - val_loss: 20.3819 - val_accuracy: 0.3825\n",
            "Epoch 8938/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 17.0581 - accuracy: 0.5585 - val_loss: 129.9112 - val_accuracy: 0.1348\n",
            "Epoch 8939/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 13.6847 - accuracy: 0.8883 - val_loss: 661657.1875 - val_accuracy: 0.0198\n",
            "Epoch 8940/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 25.7246 - accuracy: 0.5042 - val_loss: 16.4820 - val_accuracy: 0.3154\n",
            "Epoch 8941/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 12.4112 - accuracy: 0.3653 - val_loss: 24.1818 - val_accuracy: 0.1968\n",
            "Epoch 8942/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 35.9126 - accuracy: 0.2047 - val_loss: 1280.8262 - val_accuracy: 0.0977\n",
            "Epoch 8943/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 13.4088 - accuracy: 0.7819 - val_loss: 18.7057 - val_accuracy: 0.2122\n",
            "Epoch 8944/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 859.5193 - accuracy: 0.8150 - val_loss: 765.7121 - val_accuracy: 0.1131\n",
            "Epoch 8945/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 45.1403 - accuracy: 0.8359 - val_loss: 18.7624 - val_accuracy: 0.2928\n",
            "Epoch 8946/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 7.6291 - accuracy: 0.9023 - val_loss: 11.8070 - val_accuracy: 0.2555\n",
            "Epoch 8947/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 14.5203 - accuracy: 0.8344 - val_loss: 26.3023 - val_accuracy: 0.1696\n",
            "Epoch 8948/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 75.0556 - accuracy: 0.7572 - val_loss: 8.9659 - val_accuracy: 0.2435\n",
            "Epoch 8949/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 12.8296 - val_accuracy: 0.3002\n",
            "Epoch 8950/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 13.1567 - accuracy: 0.8395 - val_loss: 23.5363 - val_accuracy: 0.1360\n",
            "Epoch 8951/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 536.6358 - accuracy: 0.7198 - val_loss: 724.9639 - val_accuracy: 0.0666\n",
            "Epoch 8952/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 13.0516 - accuracy: 0.5213 - val_loss: 3300.7856 - val_accuracy: 0.1693\n",
            "Epoch 8953/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 688.7661 - accuracy: 0.8452 - val_loss: 5344.7617 - val_accuracy: 0.1954\n",
            "Epoch 8954/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 34886.8716 - accuracy: 0.3073 - val_loss: 35.2998 - val_accuracy: 0.2381\n",
            "Epoch 8955/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 18.2556 - accuracy: 0.3641 - val_loss: 927.0372 - val_accuracy: 0.1112\n",
            "Epoch 8956/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 12.1768 - accuracy: 0.9795 - val_loss: 25.8165 - val_accuracy: 0.3001\n",
            "Epoch 8957/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 23.3550 - accuracy: 0.5495 - val_loss: 18.5763 - val_accuracy: 0.2434\n",
            "Epoch 8958/24392\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 395.1422 - accuracy: 0.7551 - val_loss: 150.1656 - val_accuracy: 0.0393\n",
            "Epoch 8959/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 16.8638 - accuracy: 0.6315 - val_loss: 24.4441 - val_accuracy: 0.2435\n",
            "Epoch 8960/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 72.9708 - accuracy: 0.9511 - val_loss: 648.3789 - val_accuracy: 0.0141\n",
            "Epoch 8961/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 18.7620 - accuracy: 0.8737 - val_loss: 45.3636 - val_accuracy: 0.1351\n",
            "Epoch 8962/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 42.6631 - accuracy: 0.1798 - val_loss: 201.2069 - val_accuracy: 0.0497\n",
            "Epoch 8963/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 156.9089 - accuracy: 0.6334 - val_loss: 1398.2620 - val_accuracy: 0.0367\n",
            "Epoch 8964/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 54.9223 - accuracy: 0.2437 - val_loss: 13.1978 - val_accuracy: 0.3271\n",
            "Epoch 8965/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 9.8815 - accuracy: 0.4150 - val_loss: 27.1097 - val_accuracy: 0.2133\n",
            "Epoch 8966/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 24.0057 - accuracy: 0.9682 - val_loss: 115.6678 - val_accuracy: 0.0269\n",
            "Epoch 8967/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 25.8253 - accuracy: 0.4317 - val_loss: 27.8951 - val_accuracy: 0.1231\n",
            "Epoch 8968/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 22.9655 - accuracy: 0.3068 - val_loss: 62.8388 - val_accuracy: 0.0944\n",
            "Epoch 8969/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 48.4715 - accuracy: 0.3008 - val_loss: 875.4150 - val_accuracy: 0.1025\n",
            "Epoch 8970/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 19.2717 - accuracy: 0.9463 - val_loss: 43.0162 - val_accuracy: 0.1828\n",
            "Epoch 8971/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 858.9515 - accuracy: 0.7822 - val_loss: 53.5958 - val_accuracy: 0.1288\n",
            "Epoch 8972/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 19.1232 - accuracy: 0.5585 - val_loss: 23.1336 - val_accuracy: 0.2532\n",
            "Epoch 8973/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 148.8155 - accuracy: 0.3659 - val_loss: 1565.7432 - val_accuracy: 0.1426\n",
            "Epoch 8974/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 9.5741 - accuracy: 0.8420 - val_loss: 538.3314 - val_accuracy: 0.0475\n",
            "Epoch 8975/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 16.8921 - accuracy: 0.3390 - val_loss: 620.1274 - val_accuracy: 0.0512\n",
            "Epoch 8976/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 4903.1048 - accuracy: 0.6229 - val_loss: 586.5529 - val_accuracy: 0.0940\n",
            "Epoch 8977/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 14.1081 - accuracy: 0.6721 - val_loss: 23.7040 - val_accuracy: 0.0898\n",
            "Epoch 8978/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 25.7185 - accuracy: 0.3821 - val_loss: 51.5649 - val_accuracy: 0.1474\n",
            "Epoch 8979/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 31.5410 - accuracy: 0.2793 - val_loss: 140.3868 - val_accuracy: 0.0706\n",
            "Epoch 8980/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 35.4221 - accuracy: 0.6207 - val_loss: 702.1562 - val_accuracy: 0.0841\n",
            "Epoch 8981/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 9.2091 - accuracy: 0.7848 - val_loss: 47.7282 - val_accuracy: 0.2300\n",
            "Epoch 8982/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 11.6149 - accuracy: 0.8340 - val_loss: 147.9492 - val_accuracy: 0.0236\n",
            "Epoch 8983/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 145.9651 - accuracy: 0.3933 - val_loss: 23.3125 - val_accuracy: 0.2460\n",
            "Epoch 8984/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 91.7933 - accuracy: 0.4848 - val_loss: 104.9549 - val_accuracy: 0.1694\n",
            "Epoch 8985/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 14.5333 - accuracy: 0.8058 - val_loss: 50.2821 - val_accuracy: 0.2072\n",
            "Epoch 8986/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 2439.8358 - accuracy: 0.2648 - val_loss: 16.9887 - val_accuracy: 0.2305\n",
            "Epoch 8987/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 29.2801 - accuracy: 0.9624 - val_loss: 583.8371 - val_accuracy: 0.0476\n",
            "Epoch 8988/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 394.3701 - accuracy: 0.7278 - val_loss: 502.7693 - val_accuracy: 0.0507\n",
            "Epoch 8989/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 13.8707 - accuracy: 0.4775 - val_loss: 8.7816 - val_accuracy: 0.1100\n",
            "Epoch 8990/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 12.4860 - accuracy: 0.3839 - val_loss: 536.4482 - val_accuracy: 0.0598\n",
            "Epoch 8991/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 8.7883 - accuracy: 0.8983 - val_loss: 33.0184 - val_accuracy: 0.1189\n",
            "Epoch 8992/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 19.4971 - accuracy: 0.5091 - val_loss: 13.3227 - val_accuracy: 0.2126\n",
            "Epoch 8993/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 1062.7923 - accuracy: 0.6473 - val_loss: 265.1569 - val_accuracy: 0.0885\n",
            "Epoch 8994/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 342.0924 - accuracy: 0.7586 - val_loss: 19.5789 - val_accuracy: 0.1944\n",
            "Epoch 8995/24392\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 18.3061 - accuracy: 0.9092 - val_loss: 18.0707 - val_accuracy: 0.1216\n",
            "Epoch 8996/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 54.8959 - accuracy: 0.8734 - val_loss: 10.4678 - val_accuracy: 0.2347\n",
            "Epoch 8997/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 18.2679 - accuracy: 0.3554 - val_loss: 408.1611 - val_accuracy: 0.2008\n",
            "Epoch 8998/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 249.7629 - accuracy: 0.6702 - val_loss: 1633.4979 - val_accuracy: 0.0946\n",
            "Epoch 8999/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 39.3668 - accuracy: 0.9663 - val_loss: 575.1591 - val_accuracy: 0.0774\n",
            "Epoch 9000/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 17.1607 - accuracy: 0.2307 - val_loss: 17.0405 - val_accuracy: 0.4709\n",
            "Epoch 9001/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 10.8799 - accuracy: 0.4802 - val_loss: 51.6946 - val_accuracy: 0.1109\n",
            "Epoch 9002/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 18.5487 - accuracy: 0.6170 - val_loss: 1155.0587 - val_accuracy: 0.1120\n",
            "Epoch 9003/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 26.3681 - accuracy: 0.3334 - val_loss: 10.7924 - val_accuracy: 0.2390\n",
            "Epoch 9004/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 65.7571 - accuracy: 0.8383 - val_loss: 434.7197 - val_accuracy: 0.0803\n",
            "Epoch 9005/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 138.0950 - accuracy: 0.4038 - val_loss: 91.9057 - val_accuracy: 0.1312\n",
            "Epoch 9006/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 15.3161 - accuracy: 0.3380 - val_loss: 7.7835 - val_accuracy: 0.1737\n",
            "Epoch 9007/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 44.9305 - accuracy: 0.9458 - val_loss: 15.2137 - val_accuracy: 0.2811\n",
            "Epoch 9008/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 51.5171 - accuracy: 0.8908 - val_loss: 7.9091 - val_accuracy: 0.1407\n",
            "Epoch 9009/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 49.4088 - accuracy: 0.3866 - val_loss: 42.6070 - val_accuracy: 0.2020\n",
            "Epoch 9010/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 53.0954 - accuracy: 0.9569 - val_loss: 201.3097 - val_accuracy: 0.0636\n",
            "Epoch 9011/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 33.5516 - accuracy: 0.2107 - val_loss: 8.3973 - val_accuracy: 0.0759\n",
            "Epoch 9012/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 20.6444 - accuracy: 0.1551 - val_loss: 39.2563 - val_accuracy: 0.2583\n",
            "Epoch 9013/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 33.5382 - accuracy: 0.9616 - val_loss: 31.3538 - val_accuracy: 0.1850\n",
            "Epoch 9014/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 24.4343 - accuracy: 0.2154 - val_loss: 72.3503 - val_accuracy: 0.1000\n",
            "Epoch 9015/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 6604.4839 - accuracy: 0.5950 - val_loss: 1058.2538 - val_accuracy: 0.0285\n",
            "Epoch 9016/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 7.9194 - accuracy: 0.7049 - val_loss: 19.2501 - val_accuracy: 0.2245\n",
            "Epoch 9017/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 15.3792 - accuracy: 0.8104 - val_loss: 58.1701 - val_accuracy: 0.0971\n",
            "Epoch 9018/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 99.1183 - accuracy: 0.6888 - val_loss: 873.8658 - val_accuracy: 0.1322\n",
            "Epoch 9019/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 104.0029 - accuracy: 0.2705 - val_loss: 68.1578 - val_accuracy: 0.0938\n",
            "Epoch 9020/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 39.9251 - accuracy: 0.6500 - val_loss: 20.8390 - val_accuracy: 0.1925\n",
            "Epoch 9021/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 24.1472 - accuracy: 0.8891 - val_loss: 1228.8204 - val_accuracy: 0.1014\n",
            "Epoch 9022/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 11.5750 - accuracy: 0.4711 - val_loss: 10.0857 - val_accuracy: 0.2340\n",
            "Epoch 9023/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 7.0824 - accuracy: 0.7284 - val_loss: 837.8945 - val_accuracy: 0.0379\n",
            "Epoch 9024/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 75.9424 - accuracy: 0.2846 - val_loss: 62.4664 - val_accuracy: 0.1571\n",
            "Epoch 9025/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 48.4416 - accuracy: 0.3458 - val_loss: 1419.8132 - val_accuracy: 0.0513\n",
            "Epoch 9026/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 18.0698 - accuracy: 0.4568 - val_loss: 12.0060 - val_accuracy: 0.1998\n",
            "Epoch 9027/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 17.6725 - accuracy: 0.2472 - val_loss: 104.6505 - val_accuracy: 0.1006\n",
            "Epoch 9028/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 71.3947 - accuracy: 0.9339 - val_loss: 1129.9240 - val_accuracy: 0.0295\n",
            "Epoch 9029/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 72.1363 - accuracy: 0.9351 - val_loss: 31.8985 - val_accuracy: 0.1529\n",
            "Epoch 9030/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 63.9876 - accuracy: 0.9004 - val_loss: 1180.0459 - val_accuracy: 0.0626\n",
            "Epoch 9031/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 29.2407 - accuracy: 0.3194 - val_loss: 191.4881 - val_accuracy: 0.1171\n",
            "Epoch 9032/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 39.9046 - accuracy: 0.6648 - val_loss: 954.0278 - val_accuracy: 0.0201\n",
            "Epoch 9033/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 15.0958 - accuracy: 0.3501 - val_loss: 893.1190 - val_accuracy: 0.1081\n",
            "Epoch 9034/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 18.6079 - accuracy: 0.3648 - val_loss: 19.9061 - val_accuracy: 0.1269\n",
            "Epoch 9035/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 432.7226 - accuracy: 0.8965 - val_loss: 14.4346 - val_accuracy: 0.1360\n",
            "Epoch 9036/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 772.5336 - accuracy: 0.3271 - val_loss: 26.8573 - val_accuracy: 0.1513\n",
            "Epoch 9037/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 14.8571 - accuracy: 0.3315 - val_loss: 18.0817 - val_accuracy: 0.2166\n",
            "Epoch 9038/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 76.0940 - accuracy: 0.8339 - val_loss: 13.2012 - val_accuracy: 0.1712\n",
            "Epoch 9039/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 58.7875 - accuracy: 0.9150 - val_loss: 774.8964 - val_accuracy: 0.0626\n",
            "Epoch 9040/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 11.7179 - accuracy: 0.8546 - val_loss: 115.2098 - val_accuracy: 0.1015\n",
            "Epoch 9041/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 9.9735 - accuracy: 0.5651 - val_loss: 28.1025 - val_accuracy: 0.1607\n",
            "Epoch 9042/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 12.9299 - accuracy: 0.8813 - val_loss: 33.9585 - val_accuracy: 0.0914\n",
            "Epoch 9043/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 12.7578 - accuracy: 0.8225 - val_loss: 13.4677 - val_accuracy: 0.3227\n",
            "Epoch 9044/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 89.9202 - accuracy: 0.8921 - val_loss: 596.4698 - val_accuracy: 0.0411\n",
            "Epoch 9045/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 111.1573 - accuracy: 0.8572 - val_loss: 126.2372 - val_accuracy: 0.0881\n",
            "Epoch 9046/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 37.1735 - accuracy: 0.3621 - val_loss: 507.1331 - val_accuracy: 0.0617\n",
            "Epoch 9047/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 9.1723 - accuracy: 0.5503 - val_loss: 39.8381 - val_accuracy: 0.1131\n",
            "Epoch 9048/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 16.5381 - accuracy: 0.6149 - val_loss: 4991.4019 - val_accuracy: 0.0955\n",
            "Epoch 9049/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 1636.0045 - accuracy: 0.6119 - val_loss: 19.4146 - val_accuracy: 0.2022\n",
            "Epoch 9050/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 324.3580 - accuracy: 0.6785 - val_loss: 464.7608 - val_accuracy: 0.1095\n",
            "Epoch 9051/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 29.0139 - accuracy: 0.2006 - val_loss: 11.5138 - val_accuracy: 0.1451\n",
            "Epoch 9052/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 8.9229 - accuracy: 0.7497 - val_loss: 804.3940 - val_accuracy: 0.0508\n",
            "Epoch 9053/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 32.7773 - accuracy: 0.9699 - val_loss: 13.3465 - val_accuracy: 0.2346\n",
            "Epoch 9054/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 21.9532 - accuracy: 0.5794 - val_loss: 10.8847 - val_accuracy: 0.1356\n",
            "Epoch 9055/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 11.6534 - accuracy: 0.9281 - val_loss: 8.7968 - val_accuracy: 0.2255\n",
            "Epoch 9056/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 28.8946 - accuracy: 0.4466 - val_loss: 25.8606 - val_accuracy: 0.1172\n",
            "Epoch 9057/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 218.2522 - accuracy: 0.7756 - val_loss: 11.3420 - val_accuracy: 0.2582\n",
            "Epoch 9058/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 33.3726 - accuracy: 0.4338 - val_loss: 13.2914 - val_accuracy: 0.2973\n",
            "Epoch 9059/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 39.1203 - accuracy: 0.9122 - val_loss: 443.6967 - val_accuracy: 0.0600\n",
            "Epoch 9060/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 44.7508 - accuracy: 0.8739 - val_loss: 15.2443 - val_accuracy: 0.2664\n",
            "Epoch 9061/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 45.9113 - accuracy: 0.2367 - val_loss: 651.0571 - val_accuracy: 0.0772\n",
            "Epoch 9062/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 29.2740 - accuracy: 0.9663 - val_loss: 1038.1333 - val_accuracy: 0.0895\n",
            "Epoch 9063/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 17.3927 - accuracy: 0.9496 - val_loss: 13.3395 - val_accuracy: 0.2876\n",
            "Epoch 9064/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 92.3894 - accuracy: 0.0101 - val_loss: 24.7082 - val_accuracy: 0.3066\n",
            "Epoch 9065/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 730.4521 - accuracy: 0.4259 - val_loss: 588.2817 - val_accuracy: 0.8458\n",
            "Epoch 9066/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 11.9967 - accuracy: 0.6663 - val_loss: 10.2339 - val_accuracy: 0.4739\n",
            "Epoch 9067/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 166.6618 - accuracy: 0.0884 - val_loss: 20.6067 - val_accuracy: 0.1773\n",
            "Epoch 9068/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 1899.9546 - accuracy: 0.5869 - val_loss: 450.2077 - val_accuracy: 0.7927\n",
            "Epoch 9069/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 17.7711 - accuracy: 0.8337 - val_loss: 381.4426 - val_accuracy: 0.2995\n",
            "Epoch 9070/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 27.5899 - accuracy: 0.4250 - val_loss: 26.8447 - val_accuracy: 0.2016\n",
            "Epoch 9071/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 17.9558 - accuracy: 0.4446 - val_loss: 32.1327 - val_accuracy: 0.2309\n",
            "Epoch 9072/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 21.0488 - accuracy: 0.2700 - val_loss: 785.1031 - val_accuracy: 0.3971\n",
            "Epoch 9073/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 15.2569 - accuracy: 0.6589 - val_loss: 12.1888 - val_accuracy: 0.4417\n",
            "Epoch 9074/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 0.2440 - accuracy: 1.0000 - val_loss: 722.9146 - val_accuracy: 0.2511\n",
            "Epoch 9075/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 1031.9965 - accuracy: 0.5742 - val_loss: 1010.8751 - val_accuracy: 0.1536\n",
            "Epoch 9076/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 265.9348 - accuracy: 0.4921 - val_loss: 114.1284 - val_accuracy: 0.1614\n",
            "Epoch 9077/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 95.2023 - accuracy: 0.3739 - val_loss: 199.3388 - val_accuracy: 0.1751\n",
            "Epoch 9078/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 34.5649 - accuracy: 0.5022 - val_loss: 16.0026 - val_accuracy: 0.1326\n",
            "Epoch 9079/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 108.4610 - val_accuracy: 0.1341\n",
            "Epoch 9080/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 12.0570 - accuracy: 0.7049 - val_loss: 46.2597 - val_accuracy: 0.1975\n",
            "Epoch 9081/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 237.2344 - accuracy: 0.9679 - val_loss: 1121.5293 - val_accuracy: 0.1157\n",
            "Epoch 9082/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 7177.3356 - accuracy: 0.5345 - val_loss: 66.3926 - val_accuracy: 0.0546\n",
            "Epoch 9083/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 79.9535 - accuracy: 0.1459 - val_loss: 1560.9547 - val_accuracy: 0.0871\n",
            "Epoch 9084/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 14.6046 - accuracy: 0.8532 - val_loss: 61.3996 - val_accuracy: 0.0851\n",
            "Epoch 9085/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 333.3453 - accuracy: 0.6258 - val_loss: 13.1316 - val_accuracy: 0.2366\n",
            "Epoch 9086/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 34.0604 - accuracy: 0.9831 - val_loss: 38.7364 - val_accuracy: 0.1309\n",
            "Epoch 9087/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 11.1560 - accuracy: 0.9031 - val_loss: 2429.1877 - val_accuracy: 0.0586\n",
            "Epoch 9088/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 12.5608 - accuracy: 0.4131 - val_loss: 62.9345 - val_accuracy: 0.1717\n",
            "Epoch 9089/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 119.4571 - accuracy: 0.8407 - val_loss: 25.4317 - val_accuracy: 0.1440\n",
            "Epoch 9090/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 56.7263 - accuracy: 0.9686 - val_loss: 23.8806 - val_accuracy: 0.2247\n",
            "Epoch 9091/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 25413.5913 - accuracy: 0.2031 - val_loss: 1557.2916 - val_accuracy: 0.1526\n",
            "Epoch 9092/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 783.4100 - accuracy: 0.6204 - val_loss: 478.9030 - val_accuracy: 0.0814\n",
            "Epoch 9093/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 23.6694 - accuracy: 0.6972 - val_loss: 12.2574 - val_accuracy: 0.2125\n",
            "Epoch 9094/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 53.8380 - accuracy: 0.8820 - val_loss: 1852.6992 - val_accuracy: 0.0598\n",
            "Epoch 9095/24392\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 19.8917 - accuracy: 0.7300 - val_loss: 103.1092 - val_accuracy: 0.0881\n",
            "Epoch 9096/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 103.4363 - val_accuracy: 0.0486\n",
            "Epoch 9097/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 15.9030 - accuracy: 0.4382 - val_loss: 29.8382 - val_accuracy: 0.1070\n",
            "Epoch 9098/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 5.0170 - accuracy: 0.9604 - val_loss: 31.1496 - val_accuracy: 0.1738\n",
            "Epoch 9099/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 22.5271 - accuracy: 0.2915 - val_loss: 61.9458 - val_accuracy: 0.0506\n",
            "Epoch 9100/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 136.0895 - accuracy: 0.8006 - val_loss: 1917.5928 - val_accuracy: 0.0597\n",
            "Epoch 9101/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 12.3716 - accuracy: 0.7984 - val_loss: 1299.8331 - val_accuracy: 0.0407\n",
            "Epoch 9102/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 11.0371 - accuracy: 0.3796 - val_loss: 76.2819 - val_accuracy: 0.1241\n",
            "Epoch 9103/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 9.3731 - accuracy: 0.9300 - val_loss: 2110.9707 - val_accuracy: 0.0434\n",
            "Epoch 9104/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 70.0180 - accuracy: 0.9359 - val_loss: 36.1627 - val_accuracy: 0.1089\n",
            "Epoch 9105/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 10.6642 - accuracy: 0.7406 - val_loss: 43.6017 - val_accuracy: 0.0542\n",
            "Epoch 9106/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 1.7811 - accuracy: 0.9989 - val_loss: 31.5334 - val_accuracy: 0.1139\n",
            "Epoch 9107/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 105.2894 - accuracy: 0.9052 - val_loss: 99.2791 - val_accuracy: 0.0629\n",
            "Epoch 9108/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 19.1441 - accuracy: 0.7893 - val_loss: 27.0580 - val_accuracy: 0.1056\n",
            "Epoch 9109/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 1900.7066 - accuracy: 0.4106 - val_loss: 39.3852 - val_accuracy: 0.1181\n",
            "Epoch 9110/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 11.8604 - accuracy: 0.4872 - val_loss: 2152.3672 - val_accuracy: 0.0772\n",
            "Epoch 9111/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 214.0553 - accuracy: 0.3195 - val_loss: 27.3825 - val_accuracy: 0.1279\n",
            "Epoch 9112/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 20.7006 - accuracy: 0.9673 - val_loss: 44.7261 - val_accuracy: 0.1434\n",
            "Epoch 9113/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 9.8550 - accuracy: 0.5287 - val_loss: 49.9122 - val_accuracy: 0.0955\n",
            "Epoch 9114/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 14.1793 - accuracy: 0.7015 - val_loss: 197.7909 - val_accuracy: 0.0244\n",
            "Epoch 9115/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 251.7755 - accuracy: 0.8490 - val_loss: 646.4133 - val_accuracy: 0.0492\n",
            "Epoch 9116/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 31.2814 - accuracy: 0.3033 - val_loss: 20.6096 - val_accuracy: 0.1083\n",
            "Epoch 9117/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 12.8701 - accuracy: 0.4414 - val_loss: 15.8859 - val_accuracy: 0.1590\n",
            "Epoch 9118/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 9.6769 - accuracy: 0.9353 - val_loss: 148.2476 - val_accuracy: 0.0267\n",
            "Epoch 9119/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 9.3155 - accuracy: 0.8500 - val_loss: 438.9817 - val_accuracy: 0.0595\n",
            "Epoch 9120/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 16.4945 - accuracy: 0.3259 - val_loss: 84.9175 - val_accuracy: 0.0501\n",
            "Epoch 9121/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 566.1993 - accuracy: 0.9423 - val_loss: 2362.8171 - val_accuracy: 0.0797\n",
            "Epoch 9122/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 7.2310 - accuracy: 0.7560 - val_loss: 1399.0791 - val_accuracy: 0.0842\n",
            "Epoch 9123/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 10.0072 - accuracy: 0.9936 - val_loss: 1865.9861 - val_accuracy: 0.1349\n",
            "Epoch 9124/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 111.3989 - accuracy: 0.8172 - val_loss: 50.6054 - val_accuracy: 0.0651\n",
            "Epoch 9125/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 2047.6524 - accuracy: 0.4066 - val_loss: 40.1699 - val_accuracy: 0.1079\n",
            "Epoch 9126/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 8.3886 - accuracy: 0.8623 - val_loss: 23.2056 - val_accuracy: 0.1524\n",
            "Epoch 9127/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 52.9804 - accuracy: 0.9520 - val_loss: 78.8058 - val_accuracy: 0.0390\n",
            "Epoch 9128/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 11.4472 - accuracy: 0.9361 - val_loss: 30.1455 - val_accuracy: 0.0886\n",
            "Epoch 9129/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 44.6857 - accuracy: 0.9628 - val_loss: 38.1528 - val_accuracy: 0.1577\n",
            "Epoch 9130/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 85.1337 - accuracy: 0.1618 - val_loss: 4052.7302 - val_accuracy: 0.0830\n",
            "Epoch 9131/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 270.0722 - accuracy: 0.4769 - val_loss: 54.1863 - val_accuracy: 0.1410\n",
            "Epoch 9132/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 14.3996 - accuracy: 0.5644 - val_loss: 76.5242 - val_accuracy: 0.1599\n",
            "Epoch 9133/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 714.8042 - accuracy: 0.6317 - val_loss: 1561.8806 - val_accuracy: 0.1059\n",
            "Epoch 9134/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 97.0704 - accuracy: 0.8377 - val_loss: 379.8836 - val_accuracy: 0.0825\n",
            "Epoch 9135/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 13.1865 - accuracy: 0.9946 - val_loss: 14.6822 - val_accuracy: 0.2166\n",
            "Epoch 9136/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 33.8786 - val_accuracy: 0.1994\n",
            "Epoch 9137/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 170.9227 - accuracy: 0.8536 - val_loss: 89.8088 - val_accuracy: 0.1123\n",
            "Epoch 9138/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 21.0723 - accuracy: 0.7560 - val_loss: 11.9875 - val_accuracy: 0.3160\n",
            "Epoch 9139/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 33.8236 - accuracy: 0.6799 - val_loss: 27.0484 - val_accuracy: 0.1386\n",
            "Epoch 9140/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 48.4783 - accuracy: 0.9698 - val_loss: 896.6088 - val_accuracy: 0.0663\n",
            "Epoch 9141/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 13.8464 - accuracy: 0.8929 - val_loss: 17.7998 - val_accuracy: 0.2259\n",
            "Epoch 9142/24392\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 439.9432 - accuracy: 0.4659 - val_loss: 81.3637 - val_accuracy: 0.1174\n",
            "Epoch 9143/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 93.7132 - accuracy: 0.3506 - val_loss: 26.1922 - val_accuracy: 0.3889\n",
            "Epoch 9144/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 512.1227 - accuracy: 0.2441 - val_loss: 2031.0479 - val_accuracy: 0.0551\n",
            "Epoch 9145/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 228.1362 - accuracy: 0.6516 - val_loss: 54.1380 - val_accuracy: 0.1782\n",
            "Epoch 9146/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 13.2270 - accuracy: 0.7874 - val_loss: 1555.3359 - val_accuracy: 0.1138\n",
            "Epoch 9147/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 30.5730 - accuracy: 0.2945 - val_loss: 1587.6246 - val_accuracy: 0.1060\n",
            "Epoch 9148/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 26.3560 - accuracy: 0.4499 - val_loss: 20.9300 - val_accuracy: 0.1648\n",
            "Epoch 9149/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 204.5347 - accuracy: 0.1166 - val_loss: 106.9814 - val_accuracy: 0.0466\n",
            "Epoch 9150/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 9.3361 - accuracy: 0.7395 - val_loss: 25.8763 - val_accuracy: 0.1332\n",
            "Epoch 9151/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 2529.6346 - accuracy: 0.2959 - val_loss: 20.3703 - val_accuracy: 0.1240\n",
            "Epoch 9152/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1834.2273 - val_accuracy: 0.1340\n",
            "Epoch 9153/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 14.2302 - accuracy: 0.2802 - val_loss: 790.8652 - val_accuracy: 7.0944e-04\n",
            "Epoch 9154/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 471.0688 - accuracy: 0.6604 - val_loss: 171.3870 - val_accuracy: 0.0615\n",
            "Epoch 9155/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 11.4718 - accuracy: 0.6831 - val_loss: 108.6029 - val_accuracy: 0.1010\n",
            "Epoch 9156/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 24.3941 - accuracy: 0.9484 - val_loss: 2067.5527 - val_accuracy: 0.1353\n",
            "Epoch 9157/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 8.0753 - accuracy: 0.8317 - val_loss: 1841.9221 - val_accuracy: 0.1357\n",
            "Epoch 9158/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 47.0276 - accuracy: 0.8935 - val_loss: 1465.5470 - val_accuracy: 0.2257\n",
            "Epoch 9159/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 30.7628 - accuracy: 0.2060 - val_loss: 51.7555 - val_accuracy: 0.1489\n",
            "Epoch 9160/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 19.8136 - accuracy: 0.9961 - val_loss: 1957.9376 - val_accuracy: 0.0465\n",
            "Epoch 9161/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 165.2518 - accuracy: 0.1461 - val_loss: 25.3005 - val_accuracy: 0.1645\n",
            "Epoch 9162/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 22.9148 - accuracy: 0.9572 - val_loss: 17.2829 - val_accuracy: 0.1729\n",
            "Epoch 9163/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 36.0095 - accuracy: 0.9670 - val_loss: 125.7707 - val_accuracy: 0.0721\n",
            "Epoch 9164/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 81.9250 - accuracy: 0.9513 - val_loss: 2222.2913 - val_accuracy: 0.1387\n",
            "Epoch 9165/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 14.1003 - accuracy: 0.8470 - val_loss: 34.7151 - val_accuracy: 0.1386\n",
            "Epoch 9166/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 408.7039 - val_accuracy: 0.0323\n",
            "Epoch 9167/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 12.6175 - accuracy: 0.9929 - val_loss: 27.2924 - val_accuracy: 0.1161\n",
            "Epoch 9168/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 10.5631 - accuracy: 0.6620 - val_loss: 80.2022 - val_accuracy: 0.0422\n",
            "Epoch 9169/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 73.7825 - accuracy: 0.9834 - val_loss: 1883.0908 - val_accuracy: 0.0488\n",
            "Epoch 9170/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 6.9809 - accuracy: 0.9959 - val_loss: 35.1006 - val_accuracy: 0.1312\n",
            "Epoch 9171/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 20.7871 - accuracy: 0.3446 - val_loss: 1910.7501 - val_accuracy: 0.0434\n",
            "Epoch 9172/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 34.3778 - accuracy: 0.9851 - val_loss: 29.9438 - val_accuracy: 0.1057\n",
            "Epoch 9173/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1556.1484 - val_accuracy: 0.0125\n",
            "Epoch 9174/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 15.8264 - accuracy: 0.3923 - val_loss: 24.5389 - val_accuracy: 0.1837\n",
            "Epoch 9175/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 20.7508 - accuracy: 0.4957 - val_loss: 90.8415 - val_accuracy: 0.0405\n",
            "Epoch 9176/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 195.8798 - accuracy: 0.8783 - val_loss: 1030.3311 - val_accuracy: 0.1357\n",
            "Epoch 9177/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 35.9852 - val_accuracy: 0.2006\n",
            "Epoch 9178/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 10.8048 - accuracy: 0.5013 - val_loss: 1020.5796 - val_accuracy: 0.1390\n",
            "Epoch 9179/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 304.8231 - accuracy: 0.7298 - val_loss: 27.5724 - val_accuracy: 0.1587\n",
            "Epoch 9180/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 14.3314 - accuracy: 0.7257 - val_loss: 21.6537 - val_accuracy: 0.1879\n",
            "Epoch 9181/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 222.3958 - accuracy: 0.8543 - val_loss: 564.6548 - val_accuracy: 0.0195\n",
            "Epoch 9182/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 105.1830 - accuracy: 0.7454 - val_loss: 22.1688 - val_accuracy: 0.1790\n",
            "Epoch 9183/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 190.3177 - accuracy: 0.7001 - val_loss: 32.1064 - val_accuracy: 0.2451\n",
            "Epoch 9184/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 19.7278 - accuracy: 0.3738 - val_loss: 42.0178 - val_accuracy: 0.1416\n",
            "Epoch 9185/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 15.0451 - accuracy: 0.3939 - val_loss: 104.5995 - val_accuracy: 0.0838\n",
            "Epoch 9186/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 14.4762 - accuracy: 0.4157 - val_loss: 33.1725 - val_accuracy: 0.1478\n",
            "Epoch 9187/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 18.4834 - accuracy: 0.2338 - val_loss: 694.5035 - val_accuracy: 0.1102\n",
            "Epoch 9188/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 960.5453 - accuracy: 0.6126 - val_loss: 105.7096 - val_accuracy: 0.1423\n",
            "Epoch 9189/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 13.7966 - accuracy: 0.8271 - val_loss: 10.0861 - val_accuracy: 0.2557\n",
            "Epoch 9190/24392\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 127.8227 - accuracy: 0.8271 - val_loss: 16.7592 - val_accuracy: 0.1851\n",
            "Epoch 9191/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 11.7582 - accuracy: 0.6879 - val_loss: 16.7185 - val_accuracy: 0.2008\n",
            "Epoch 9192/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 893.1923 - val_accuracy: 0.1146\n",
            "Epoch 9193/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 36.3800 - accuracy: 0.1813 - val_loss: 68.9831 - val_accuracy: 0.0660\n",
            "Epoch 9194/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 24.8289 - accuracy: 0.9487 - val_loss: 19.6269 - val_accuracy: 0.1370\n",
            "Epoch 9195/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 295.7550 - accuracy: 0.0674 - val_loss: 154.1262 - val_accuracy: 0.1007\n",
            "Epoch 9196/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 8.3679 - accuracy: 0.7517 - val_loss: 1825.0841 - val_accuracy: 0.0904\n",
            "Epoch 9197/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 139.7078 - accuracy: 0.8854 - val_loss: 22.5595 - val_accuracy: 0.1180\n",
            "Epoch 9198/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 13.0570 - accuracy: 0.4578 - val_loss: 11.7756 - val_accuracy: 0.2505\n",
            "Epoch 9199/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 819.5084 - accuracy: 0.7914 - val_loss: 17.1036 - val_accuracy: 0.2017\n",
            "Epoch 9200/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 54.4365 - accuracy: 0.9732 - val_loss: 31.4595 - val_accuracy: 0.1286\n",
            "Epoch 9201/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 209.6510 - accuracy: 0.7262 - val_loss: 30.2199 - val_accuracy: 0.2129\n",
            "Epoch 9202/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 37.5613 - accuracy: 0.3661 - val_loss: 134.4332 - val_accuracy: 0.0860\n",
            "Epoch 9203/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 796.1062 - accuracy: 0.7608 - val_loss: 26.3232 - val_accuracy: 0.1647\n",
            "Epoch 9204/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 51.2786 - accuracy: 0.9481 - val_loss: 20.8599 - val_accuracy: 0.2164\n",
            "Epoch 9205/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 53.9045 - accuracy: 0.9374 - val_loss: 1746.8475 - val_accuracy: 0.1316\n",
            "Epoch 9206/24392\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 13.9198 - accuracy: 0.3852 - val_loss: 48.7742 - val_accuracy: 0.1010\n",
            "Epoch 9207/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 13.8710 - accuracy: 0.4134 - val_loss: 28.8240 - val_accuracy: 0.1361\n",
            "Epoch 9208/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 20.6251 - accuracy: 0.8988 - val_loss: 113.1983 - val_accuracy: 0.0895\n",
            "Epoch 9209/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 128.6998 - accuracy: 0.9526 - val_loss: 13.4910 - val_accuracy: 0.2058\n",
            "Epoch 9210/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 19.8840 - accuracy: 0.3732 - val_loss: 8.9017 - val_accuracy: 0.2534\n",
            "Epoch 9211/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 226.0021 - accuracy: 0.3878 - val_loss: 22.3405 - val_accuracy: 0.2595\n",
            "Epoch 9212/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 46.5019 - accuracy: 0.9433 - val_loss: 44.9481 - val_accuracy: 0.1581\n",
            "Epoch 9213/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 160.3808 - accuracy: 0.6530 - val_loss: 606.7834 - val_accuracy: 0.1212\n",
            "Epoch 9214/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 25.1753 - accuracy: 0.8738 - val_loss: 508.8310 - val_accuracy: 0.1272\n",
            "Epoch 9215/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 637.2412 - accuracy: 0.5488 - val_loss: 51.9840 - val_accuracy: 0.3230\n",
            "Epoch 9216/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 41.8084 - val_accuracy: 0.1289\n",
            "Epoch 9217/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 17.9672 - accuracy: 0.2228 - val_loss: 8.6347 - val_accuracy: 0.2301\n",
            "Epoch 9218/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 11.9795 - accuracy: 0.2910 - val_loss: 25.7487 - val_accuracy: 0.1897\n",
            "Epoch 9219/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 12.0515 - accuracy: 0.8372 - val_loss: 9.4466 - val_accuracy: 0.5960\n",
            "Epoch 9220/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 40.0679 - accuracy: 0.3482 - val_loss: 43.0088 - val_accuracy: 0.2074\n",
            "Epoch 9221/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 10.1038 - accuracy: 0.7802 - val_loss: 224.0330 - val_accuracy: 0.4281\n",
            "Epoch 9222/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 11.3574 - accuracy: 0.6047 - val_loss: 22.0380 - val_accuracy: 0.2953\n",
            "Epoch 9223/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 0.6303 - accuracy: 0.9993 - val_loss: 41.4717 - val_accuracy: 0.3250\n",
            "Epoch 9224/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 1688.7507 - accuracy: 0.6595 - val_loss: 7.3910 - val_accuracy: 0.5269\n",
            "Epoch 9225/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 3877.5971 - accuracy: 0.2166 - val_loss: 22.1266 - val_accuracy: 0.1337\n",
            "Epoch 9226/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 34.0118 - accuracy: 0.8517 - val_loss: 110.4822 - val_accuracy: 0.1750\n",
            "Epoch 9227/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 4815.9744 - accuracy: 0.5459 - val_loss: 96.8035 - val_accuracy: 0.0828\n",
            "Epoch 9228/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 10.7213 - accuracy: 0.3697 - val_loss: 1653.4413 - val_accuracy: 0.0947\n",
            "Epoch 9229/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 28.2914 - accuracy: 0.1780 - val_loss: 52.5403 - val_accuracy: 0.1489\n",
            "Epoch 9230/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 42.3977 - accuracy: 0.6248 - val_loss: 612.8704 - val_accuracy: 0.0947\n",
            "Epoch 9231/24392\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 29.3236 - accuracy: 0.9609 - val_loss: 25.8465 - val_accuracy: 0.2367\n",
            "Epoch 9232/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 11.2054 - accuracy: 0.7785 - val_loss: 11.7463 - val_accuracy: 0.3019\n",
            "Epoch 9233/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 355.5040 - accuracy: 0.6723 - val_loss: 52.4697 - val_accuracy: 0.1824\n",
            "Epoch 9234/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 15.3090 - accuracy: 0.2513 - val_loss: 287.3123 - val_accuracy: 0.7525\n",
            "Epoch 9235/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 76.1074 - accuracy: 0.9558 - val_loss: 67.4370 - val_accuracy: 0.0942\n",
            "Epoch 9236/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 20.8340 - accuracy: 0.3447 - val_loss: 7.0825 - val_accuracy: 0.1655\n",
            "Epoch 9237/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 30.0441 - accuracy: 0.9795 - val_loss: 22.6378 - val_accuracy: 0.1522\n",
            "Epoch 9238/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 17.3068 - accuracy: 0.2502 - val_loss: 35.8727 - val_accuracy: 0.1763\n",
            "Epoch 9239/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 26.9671 - accuracy: 0.2068 - val_loss: 770.9812 - val_accuracy: 0.1010\n",
            "Epoch 9240/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 7.9199 - accuracy: 0.9013 - val_loss: 44.9846 - val_accuracy: 0.1331\n",
            "Epoch 9241/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 14.4075 - accuracy: 0.9544 - val_loss: 11.3020 - val_accuracy: 0.2565\n",
            "Epoch 9242/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 21.8625 - accuracy: 0.9215 - val_loss: 73.5625 - val_accuracy: 0.1735\n",
            "Epoch 9243/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 19.7950 - accuracy: 0.7332 - val_loss: 17.0056 - val_accuracy: 0.2560\n",
            "Epoch 9244/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 20.0072 - accuracy: 0.8967 - val_loss: 2862.8364 - val_accuracy: 0.2597\n",
            "Epoch 9245/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 14.8634 - accuracy: 0.6039 - val_loss: 16.3937 - val_accuracy: 0.2084\n",
            "Epoch 9246/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 133.0548 - accuracy: 0.7087 - val_loss: 881.7407 - val_accuracy: 0.1153\n",
            "Epoch 9247/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 11.5625 - accuracy: 0.3362 - val_loss: 394.5091 - val_accuracy: 0.2624\n",
            "Epoch 9248/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 117.9933 - accuracy: 0.9688 - val_loss: 196.0879 - val_accuracy: 0.7216\n",
            "Epoch 9249/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 181.9147 - accuracy: 0.5863 - val_loss: 38.9829 - val_accuracy: 0.1460\n",
            "Epoch 9250/24392\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 59.3953 - accuracy: 0.9657 - val_loss: 16.2816 - val_accuracy: 0.3659\n",
            "Epoch 9251/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 16.4530 - accuracy: 0.2725 - val_loss: 18.9040 - val_accuracy: 0.2576\n",
            "Epoch 9252/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 15.3996 - accuracy: 0.7542 - val_loss: 54.3427 - val_accuracy: 0.1486\n",
            "Epoch 9253/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 99.9055 - accuracy: 0.4296 - val_loss: 13.1574 - val_accuracy: 0.2500\n",
            "Epoch 9254/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 9.2545 - accuracy: 0.9600 - val_loss: 99.9325 - val_accuracy: 0.2259\n",
            "Epoch 9255/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 10.8536 - accuracy: 0.8269 - val_loss: 44.8664 - val_accuracy: 0.1493\n",
            "Epoch 9256/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 9.7702 - accuracy: 0.4680 - val_loss: 52.7007 - val_accuracy: 0.1001\n",
            "Epoch 9257/24392\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 54.5615 - accuracy: 0.8276 - val_loss: 48.2790 - val_accuracy: 0.4785\n",
            "Epoch 9258/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 14.1847 - val_accuracy: 0.2267\n",
            "Epoch 9259/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 103.7601 - accuracy: 0.1456 - val_loss: 244.0992 - val_accuracy: 0.1735\n",
            "Epoch 9260/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 7.0451 - accuracy: 0.9965 - val_loss: 532.7407 - val_accuracy: 0.2042\n",
            "Epoch 9261/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 150.2864 - accuracy: 0.8674 - val_loss: 5057.9448 - val_accuracy: 0.2463\n",
            "Epoch 9262/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 5033.4608 - accuracy: 0.5761 - val_loss: 1618.9198 - val_accuracy: 0.2851\n",
            "Epoch 9263/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 30.6554 - accuracy: 0.2791 - val_loss: 19.4447 - val_accuracy: 0.2058\n",
            "Epoch 9264/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 94.7537 - accuracy: 0.3692 - val_loss: 335.3960 - val_accuracy: 0.4914\n",
            "Epoch 9265/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 297.0678 - accuracy: 0.7229 - val_loss: 278.2546 - val_accuracy: 0.6675\n",
            "Epoch 9266/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 14.0180 - accuracy: 0.9060 - val_loss: 1149.4515 - val_accuracy: 0.7689\n",
            "Epoch 9267/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 11.0681 - accuracy: 0.5871 - val_loss: 40.2300 - val_accuracy: 0.2524\n",
            "Epoch 9268/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 13.7315 - accuracy: 0.6446 - val_loss: 81.9343 - val_accuracy: 0.3547\n",
            "Epoch 9269/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 51.8237 - accuracy: 0.9648 - val_loss: 164.3229 - val_accuracy: 0.2169\n",
            "Epoch 9270/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 10.5961 - accuracy: 0.7858 - val_loss: 12160.0703 - val_accuracy: 0.1832\n",
            "Epoch 9271/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 930.0033 - accuracy: 0.3077 - val_loss: 701.3524 - val_accuracy: 0.2793\n",
            "Epoch 9272/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 282.3519 - accuracy: 0.7561 - val_loss: 71.1860 - val_accuracy: 0.2082\n",
            "Epoch 9273/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 1045.0842 - accuracy: 0.8114 - val_loss: 72.9071 - val_accuracy: 0.1087\n",
            "Epoch 9274/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 23.0414 - accuracy: 0.3639 - val_loss: 60.8688 - val_accuracy: 0.0928\n",
            "Epoch 9275/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 10.7624 - accuracy: 0.4110 - val_loss: 18.4313 - val_accuracy: 0.2329\n",
            "Epoch 9276/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 12.2664 - accuracy: 0.7399 - val_loss: 21.0989 - val_accuracy: 0.2371\n",
            "Epoch 9277/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 15.0158 - accuracy: 0.8563 - val_loss: 10.8598 - val_accuracy: 0.4489\n",
            "Epoch 9278/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 16.6323 - accuracy: 0.2713 - val_loss: 68.7574 - val_accuracy: 0.0933\n",
            "Epoch 9279/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 14.8413 - accuracy: 0.5463 - val_loss: 27.0504 - val_accuracy: 0.1924\n",
            "Epoch 9280/24392\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 234.5018 - accuracy: 0.6459 - val_loss: 12.9717 - val_accuracy: 0.1438\n",
            "Epoch 9281/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 23.4268 - accuracy: 0.9048 - val_loss: 518.4539 - val_accuracy: 0.1264\n",
            "Epoch 9282/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 131.7327 - accuracy: 0.3396 - val_loss: 13.5667 - val_accuracy: 0.1954\n",
            "Epoch 9283/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 15.9618 - accuracy: 0.9690 - val_loss: 53.6363 - val_accuracy: 0.2027\n",
            "Epoch 9284/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 25.2842 - val_accuracy: 0.1555\n",
            "Epoch 9285/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 13.5282 - accuracy: 0.3119 - val_loss: 355.8795 - val_accuracy: 0.1435\n",
            "Epoch 9286/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 20.0257 - accuracy: 0.3507 - val_loss: 13.5202 - val_accuracy: 0.4230\n",
            "Epoch 9287/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 34.1224 - accuracy: 0.6900 - val_loss: 127.6948 - val_accuracy: 0.1018\n",
            "Epoch 9288/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 17.6620 - accuracy: 0.5594 - val_loss: 25.5911 - val_accuracy: 0.2793\n",
            "Epoch 9289/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 828.2572 - accuracy: 0.8350 - val_loss: 124.6547 - val_accuracy: 0.2901\n",
            "Epoch 9290/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 17.9908 - accuracy: 0.3527 - val_loss: 36.9707 - val_accuracy: 0.1938\n",
            "Epoch 9291/24392\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 27.6999 - accuracy: 0.9722 - val_loss: 93.2018 - val_accuracy: 0.1969\n",
            "Epoch 9292/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 43.2632 - accuracy: 0.8974 - val_loss: 5.2595 - val_accuracy: 0.5426\n",
            "Epoch 9293/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 18.7664 - accuracy: 0.4220 - val_loss: 105.4361 - val_accuracy: 0.9569\n",
            "Epoch 9294/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 11.6753 - accuracy: 0.4471 - val_loss: 198.2847 - val_accuracy: 0.9309\n",
            "Epoch 9295/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 23.9385 - accuracy: 0.9412 - val_loss: 15.2060 - val_accuracy: 0.6997\n",
            "Epoch 9296/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 29.3646 - accuracy: 0.1968 - val_loss: 18.4895 - val_accuracy: 0.2074\n",
            "Epoch 9297/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 15.9432 - accuracy: 0.5744 - val_loss: 39.4727 - val_accuracy: 0.3530\n",
            "Epoch 9298/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 24.8943 - accuracy: 0.9749 - val_loss: 15.0923 - val_accuracy: 0.2182\n",
            "Epoch 9299/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 52.6355 - accuracy: 0.4458 - val_loss: 436.8034 - val_accuracy: 0.4221\n",
            "Epoch 9300/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 23.7159 - accuracy: 0.3117 - val_loss: 112.0002 - val_accuracy: 0.9170\n",
            "Epoch 9301/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 24.7311 - accuracy: 0.2349 - val_loss: 16.6489 - val_accuracy: 0.5863\n",
            "Epoch 9302/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 10.4621 - accuracy: 0.3734 - val_loss: 822.2758 - val_accuracy: 0.7088\n",
            "Epoch 9303/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 145.7503 - accuracy: 0.0577 - val_loss: 111.4431 - val_accuracy: 0.2930\n",
            "Epoch 9304/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 12.9883 - accuracy: 0.6548 - val_loss: 66.3147 - val_accuracy: 0.1320\n",
            "Epoch 9305/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 15.8219 - accuracy: 0.5177 - val_loss: 64.0125 - val_accuracy: 0.9839\n",
            "Epoch 9306/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 12.3499 - accuracy: 0.6201 - val_loss: 57.6860 - val_accuracy: 0.9363\n",
            "Epoch 9307/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 1251.1521 - accuracy: 0.3473 - val_loss: 14.2187 - val_accuracy: 0.2981\n",
            "Epoch 9308/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 79.9337 - accuracy: 0.4377 - val_loss: 18.8916 - val_accuracy: 0.4528\n",
            "Epoch 9309/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 65.2846 - accuracy: 0.9349 - val_loss: 27.9312 - val_accuracy: 0.4486\n",
            "Epoch 9310/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 12.0924 - accuracy: 0.9954 - val_loss: 82.3650 - val_accuracy: 0.2260\n",
            "Epoch 9311/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 21.4773 - accuracy: 0.2123 - val_loss: 16.1055 - val_accuracy: 0.2866\n",
            "Epoch 9312/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 14.2099 - accuracy: 0.3194 - val_loss: 417.7828 - val_accuracy: 0.6670\n",
            "Epoch 9313/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 40.3419 - accuracy: 0.4366 - val_loss: 102.5499 - val_accuracy: 0.8889\n",
            "Epoch 9314/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 15.4300 - accuracy: 0.7272 - val_loss: 258.7772 - val_accuracy: 0.8297\n",
            "Epoch 9315/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 36.7377 - accuracy: 0.2684 - val_loss: 22.7143 - val_accuracy: 0.3893\n",
            "Epoch 9316/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 252.2510 - accuracy: 0.4648 - val_loss: 654.1441 - val_accuracy: 0.9140\n",
            "Epoch 9317/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 23.1458 - accuracy: 0.8466 - val_loss: 14.4574 - val_accuracy: 0.3071\n",
            "Epoch 9318/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 167.7424 - accuracy: 0.8884 - val_loss: 124.7913 - val_accuracy: 0.9068\n",
            "Epoch 9319/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 40.7969 - accuracy: 0.2895 - val_loss: 50.5374 - val_accuracy: 0.2163\n",
            "Epoch 9320/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 18.0894 - accuracy: 0.6637 - val_loss: 167.0719 - val_accuracy: 0.7034\n",
            "Epoch 9321/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 13.4323 - accuracy: 0.3829 - val_loss: 15.4034 - val_accuracy: 0.3168\n",
            "Epoch 9322/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 71.2513 - accuracy: 0.7967 - val_loss: 21.5653 - val_accuracy: 0.1711\n",
            "Epoch 9323/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 43.1278 - accuracy: 0.3514 - val_loss: 725.6843 - val_accuracy: 0.0576\n",
            "Epoch 9324/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 2218.9230 - accuracy: 0.5699 - val_loss: 116.4428 - val_accuracy: 0.8547\n",
            "Epoch 9325/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 91.9733 - accuracy: 0.8539 - val_loss: 7.6967 - val_accuracy: 0.3157\n",
            "Epoch 9326/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 120.0255 - accuracy: 0.8117 - val_loss: 17.3341 - val_accuracy: 0.3120\n",
            "Epoch 9327/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 21.5579 - accuracy: 0.7901 - val_loss: 18.1450 - val_accuracy: 0.2212\n",
            "Epoch 9328/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 108.9079 - accuracy: 0.8865 - val_loss: 6.3840 - val_accuracy: 0.4029\n",
            "Epoch 9329/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 22.5764 - accuracy: 0.4063 - val_loss: 10.6821 - val_accuracy: 0.6069\n",
            "Epoch 9330/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 356.9022 - accuracy: 0.9535 - val_loss: 9.3976 - val_accuracy: 0.4510\n",
            "Epoch 9331/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 217.1645 - accuracy: 0.8902 - val_loss: 260.3782 - val_accuracy: 0.7468\n",
            "Epoch 9332/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 14.3565 - accuracy: 0.3405 - val_loss: 11.3372 - val_accuracy: 0.6745\n",
            "Epoch 9333/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 681.6813 - accuracy: 0.7837 - val_loss: 47.1972 - val_accuracy: 0.5241\n",
            "Epoch 9334/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 42.9371 - accuracy: 0.2985 - val_loss: 25.7348 - val_accuracy: 0.1591\n",
            "Epoch 9335/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 14.7235 - accuracy: 0.4473 - val_loss: 359.7358 - val_accuracy: 0.4228\n",
            "Epoch 9336/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 13.3162 - accuracy: 0.5615 - val_loss: 11.9732 - val_accuracy: 0.2878\n",
            "Epoch 9337/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 62.4896 - accuracy: 0.3453 - val_loss: 132.4368 - val_accuracy: 0.8507\n",
            "Epoch 9338/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 15.2138 - accuracy: 0.6342 - val_loss: 15.2071 - val_accuracy: 0.5599\n",
            "Epoch 9339/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 21.8524 - accuracy: 0.9850 - val_loss: 14.3182 - val_accuracy: 0.4565\n",
            "Epoch 9340/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 304.6374 - accuracy: 0.7073 - val_loss: 29.0032 - val_accuracy: 0.5074\n",
            "Epoch 9341/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 415.7144 - val_accuracy: 0.8044\n",
            "Epoch 9342/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 65.3367 - accuracy: 0.8476 - val_loss: 20.3363 - val_accuracy: 0.7336\n",
            "Epoch 9343/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 28.5914 - accuracy: 0.2853 - val_loss: 7.6794 - val_accuracy: 0.7120\n",
            "Epoch 9344/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 13.6576 - accuracy: 0.8862 - val_loss: 6.2612 - val_accuracy: 0.8789\n",
            "Epoch 9345/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 137.4630 - accuracy: 0.7132 - val_loss: 59.8687 - val_accuracy: 0.9404\n",
            "Epoch 9346/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 18.1084 - accuracy: 0.6158 - val_loss: 297.1089 - val_accuracy: 0.3959\n",
            "Epoch 9347/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 14.4886 - accuracy: 0.3476 - val_loss: 41.6968 - val_accuracy: 0.6338\n",
            "Epoch 9348/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 110.1629 - val_accuracy: 0.6394\n",
            "Epoch 9349/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 12.3471 - accuracy: 0.9310 - val_loss: 22.5560 - val_accuracy: 0.4115\n",
            "Epoch 9350/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 54.6048 - accuracy: 0.7885 - val_loss: 10.2069 - val_accuracy: 0.2765\n",
            "Epoch 9351/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 30.3479 - accuracy: 0.2946 - val_loss: 388.4249 - val_accuracy: 0.7939\n",
            "Epoch 9352/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 27.3312 - accuracy: 0.3637 - val_loss: 38.1870 - val_accuracy: 0.6661\n",
            "Epoch 9353/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 36.8997 - accuracy: 0.4026 - val_loss: 9.3058 - val_accuracy: 0.6660\n",
            "Epoch 9354/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 19.2471 - accuracy: 0.9805 - val_loss: 185.0702 - val_accuracy: 0.8460\n",
            "Epoch 9355/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 10.4710 - accuracy: 0.5576 - val_loss: 12.7398 - val_accuracy: 0.2993\n",
            "Epoch 9356/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 18.4349 - accuracy: 0.9086 - val_loss: 295.9133 - val_accuracy: 0.1221\n",
            "Epoch 9357/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 11.5947 - accuracy: 0.8291 - val_loss: 1346.6971 - val_accuracy: 0.0897\n",
            "Epoch 9358/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 106.0000 - accuracy: 0.9412 - val_loss: 97.6334 - val_accuracy: 0.1800\n",
            "Epoch 9359/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 20.7764 - accuracy: 0.3373 - val_loss: 229.8209 - val_accuracy: 0.4206\n",
            "Epoch 9360/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 27.1433 - accuracy: 0.3108 - val_loss: 14.7287 - val_accuracy: 0.1844\n",
            "Epoch 9361/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 41.4741 - accuracy: 0.3047 - val_loss: 54.5351 - val_accuracy: 0.2026\n",
            "Epoch 9362/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 24.9180 - accuracy: 0.1915 - val_loss: 19.8393 - val_accuracy: 0.2580\n",
            "Epoch 9363/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 14.9416 - accuracy: 0.2529 - val_loss: 9.8115 - val_accuracy: 0.2082\n",
            "Epoch 9364/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 233.5144 - accuracy: 0.8466 - val_loss: 20.5272 - val_accuracy: 0.2012\n",
            "Epoch 9365/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 8.4654 - accuracy: 0.5727 - val_loss: 549.3004 - val_accuracy: 0.3616\n",
            "Epoch 9366/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 22.5750 - accuracy: 0.4856 - val_loss: 103.4680 - val_accuracy: 0.2923\n",
            "Epoch 9367/24392\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 36.4100 - accuracy: 0.1999 - val_loss: 13.8708 - val_accuracy: 0.3476\n",
            "Epoch 9368/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 13.1242 - accuracy: 0.7162 - val_loss: 20.3192 - val_accuracy: 0.2050\n",
            "Epoch 9369/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 38.2758 - accuracy: 0.9660 - val_loss: 13828.0625 - val_accuracy: 0.4888\n",
            "Epoch 9370/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 1.2251 - accuracy: 1.0000 - val_loss: 38.4159 - val_accuracy: 0.5366\n",
            "Epoch 9371/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 17.4387 - accuracy: 0.2075 - val_loss: 57.6126 - val_accuracy: 0.1917\n",
            "Epoch 9372/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 19.3371 - accuracy: 0.4906 - val_loss: 16.7444 - val_accuracy: 0.8346\n",
            "Epoch 9373/24392\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 65.3322 - accuracy: 0.9345 - val_loss: 254.6924 - val_accuracy: 0.8059\n",
            "Epoch 9374/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 31.8780 - accuracy: 0.1808 - val_loss: 25.3651 - val_accuracy: 0.4342\n",
            "Epoch 9375/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 592.0521 - accuracy: 0.6490 - val_loss: 8.9336 - val_accuracy: 0.3015\n",
            "Epoch 9376/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 176.2085 - accuracy: 0.5856 - val_loss: 7.5207 - val_accuracy: 0.3706\n",
            "Epoch 9377/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 14.1453 - accuracy: 0.3696 - val_loss: 186.6754 - val_accuracy: 0.6541\n",
            "Epoch 9378/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 61.0329 - accuracy: 0.2322 - val_loss: 2694.7000 - val_accuracy: 0.7834\n",
            "Epoch 9379/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 75.9244 - accuracy: 0.7719 - val_loss: 104.0657 - val_accuracy: 0.3937\n",
            "Epoch 9380/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 111.1400 - accuracy: 0.8106 - val_loss: 32.3700 - val_accuracy: 0.1236\n",
            "Epoch 9381/24392\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 41.8395 - accuracy: 0.9592 - val_loss: 11.3755 - val_accuracy: 0.5169\n",
            "Epoch 9382/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 312.7649 - accuracy: 0.7830 - val_loss: 7.3373 - val_accuracy: 0.5000\n",
            "Epoch 9383/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 2697.9142 - accuracy: 0.7848 - val_loss: 105.3652 - val_accuracy: 0.9559\n",
            "Epoch 9384/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 18.3066 - accuracy: 0.4143 - val_loss: 24.4552 - val_accuracy: 0.5804\n",
            "Epoch 9385/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 13269.9461 - accuracy: 0.3102 - val_loss: 118.5732 - val_accuracy: 0.1319\n",
            "Epoch 9386/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 11.2306 - accuracy: 0.9469 - val_loss: 431.3237 - val_accuracy: 0.2048\n",
            "Epoch 9387/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 18.5354 - accuracy: 0.2857 - val_loss: 15.9152 - val_accuracy: 0.2975\n",
            "Epoch 9388/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 9.6515 - accuracy: 0.5487 - val_loss: 21.4739 - val_accuracy: 0.2101\n",
            "Epoch 9389/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 13.5956 - accuracy: 0.7520 - val_loss: 263.9442 - val_accuracy: 0.1134\n",
            "Epoch 9390/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 19.9502 - accuracy: 0.6798 - val_loss: 297.1378 - val_accuracy: 0.3484\n",
            "Epoch 9391/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 62.4475 - accuracy: 0.9371 - val_loss: 16.3530 - val_accuracy: 0.2275\n",
            "Epoch 9392/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 12.9521 - accuracy: 0.3183 - val_loss: 19.0910 - val_accuracy: 0.2806\n",
            "Epoch 9393/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 16.8144 - accuracy: 0.5883 - val_loss: 8.2578 - val_accuracy: 0.2570\n",
            "Epoch 9394/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 13.9385 - accuracy: 0.7860 - val_loss: 12.9789 - val_accuracy: 0.1842\n",
            "Epoch 9395/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 91.2487 - val_accuracy: 0.1877\n",
            "Epoch 9396/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 457.0007 - accuracy: 0.4614 - val_loss: 13.9465 - val_accuracy: 0.1575\n",
            "Epoch 9397/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 103.3781 - accuracy: 0.7061 - val_loss: 15.0932 - val_accuracy: 0.2800\n",
            "Epoch 9398/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 70.5437 - accuracy: 0.4154 - val_loss: 1120.4507 - val_accuracy: 0.2078\n",
            "Epoch 9399/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 33.6266 - accuracy: 0.9669 - val_loss: 19.0413 - val_accuracy: 0.9237\n",
            "Epoch 9400/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 14.4837 - accuracy: 0.3539 - val_loss: 378.4231 - val_accuracy: 0.1263\n",
            "Epoch 9401/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 10.4823 - accuracy: 0.3897 - val_loss: 451.7324 - val_accuracy: 0.1641\n",
            "Epoch 9402/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 7.8038 - accuracy: 0.7355 - val_loss: 9.4414 - val_accuracy: 0.2327\n",
            "Epoch 9403/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 14488.7279 - accuracy: 0.4392 - val_loss: 30.5648 - val_accuracy: 0.2498\n",
            "Epoch 9404/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 24.3224 - accuracy: 0.4751 - val_loss: 1628.6493 - val_accuracy: 0.0617\n",
            "Epoch 9405/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 38.0813 - accuracy: 0.4135 - val_loss: 25.6179 - val_accuracy: 0.2471\n",
            "Epoch 9406/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 30.2677 - accuracy: 0.5250 - val_loss: 32248.4844 - val_accuracy: 0.0730\n",
            "Epoch 9407/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 6.5474 - accuracy: 0.9992 - val_loss: 17.0342 - val_accuracy: 0.0910\n",
            "Epoch 9408/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 210.2427 - accuracy: 0.8474 - val_loss: 823.5867 - val_accuracy: 0.1566\n",
            "Epoch 9409/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 46.9151 - accuracy: 0.4131 - val_loss: 10.6601 - val_accuracy: 0.1568\n",
            "Epoch 9410/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 19.5347 - accuracy: 0.7333 - val_loss: 31.0668 - val_accuracy: 0.2014\n",
            "Epoch 9411/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 105.4367 - accuracy: 0.7746 - val_loss: 1669.6854 - val_accuracy: 0.1302\n",
            "Epoch 9412/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 30.8250 - accuracy: 0.8960 - val_loss: 80.5123 - val_accuracy: 0.0300\n",
            "Epoch 9413/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 15.6352 - accuracy: 0.8881 - val_loss: 39.0494 - val_accuracy: 0.1043\n",
            "Epoch 9414/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 479.9947 - accuracy: 0.5078 - val_loss: 475.2598 - val_accuracy: 0.0846\n",
            "Epoch 9415/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 2103.1826 - accuracy: 0.5754 - val_loss: 1035.6085 - val_accuracy: 0.1145\n",
            "Epoch 9416/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 14.6696 - accuracy: 0.7130 - val_loss: 18.4014 - val_accuracy: 0.2490\n",
            "Epoch 9417/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 18.7587 - accuracy: 0.4804 - val_loss: 831.3584 - val_accuracy: 0.1018\n",
            "Epoch 9418/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 38.7421 - accuracy: 0.9565 - val_loss: 47.0484 - val_accuracy: 0.1791\n",
            "Epoch 9419/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 11.2112 - accuracy: 0.4551 - val_loss: 509.8423 - val_accuracy: 0.1338\n",
            "Epoch 9420/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 20.0305 - accuracy: 0.2703 - val_loss: 23.9698 - val_accuracy: 0.2857\n",
            "Epoch 9421/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 224.8779 - accuracy: 0.6652 - val_loss: 363.9392 - val_accuracy: 0.2072\n",
            "Epoch 9422/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 19.9098 - accuracy: 0.9520 - val_loss: 22.6370 - val_accuracy: 0.2440\n",
            "Epoch 9423/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 146.6172 - val_accuracy: 0.1061\n",
            "Epoch 9424/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 14.0731 - accuracy: 0.8572 - val_loss: 432.8381 - val_accuracy: 0.0761\n",
            "Epoch 9425/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 20.4011 - accuracy: 0.7689 - val_loss: 24.6111 - val_accuracy: 0.1908\n",
            "Epoch 9426/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 32.4500 - accuracy: 0.9524 - val_loss: 67.9859 - val_accuracy: 0.1977\n",
            "Epoch 9427/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 17.4783 - accuracy: 0.6010 - val_loss: 272.0961 - val_accuracy: 0.2709\n",
            "Epoch 9428/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 19.3687 - val_accuracy: 0.1696\n",
            "Epoch 9429/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 11.6915 - accuracy: 0.4062 - val_loss: 332.4898 - val_accuracy: 0.1253\n",
            "Epoch 9430/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 108.7102 - accuracy: 0.9487 - val_loss: 35.0746 - val_accuracy: 0.2428\n",
            "Epoch 9431/24392\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 46.9479 - accuracy: 0.9306 - val_loss: 348.8419 - val_accuracy: 0.1868\n",
            "Epoch 9432/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 22.0483 - accuracy: 0.4493 - val_loss: 10.3220 - val_accuracy: 0.2929\n",
            "Epoch 9433/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 20.3811 - accuracy: 0.6002 - val_loss: 16.8001 - val_accuracy: 0.4634\n",
            "Epoch 9434/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 27.9112 - accuracy: 0.6512 - val_loss: 282.8138 - val_accuracy: 0.6912\n",
            "Epoch 9435/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 11.7146 - accuracy: 0.3992 - val_loss: 16.1873 - val_accuracy: 0.2445\n",
            "Epoch 9436/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 87.3864 - accuracy: 0.9723 - val_loss: 14.0571 - val_accuracy: 0.8438\n",
            "Epoch 9437/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 10.6256 - accuracy: 0.8267 - val_loss: 319.3646 - val_accuracy: 0.3259\n",
            "Epoch 9438/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 49.4262 - val_accuracy: 0.2174\n",
            "Epoch 9439/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 33.1213 - accuracy: 0.1085 - val_loss: 2668.0549 - val_accuracy: 0.6349\n",
            "Epoch 9440/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 11.9742 - accuracy: 0.8562 - val_loss: 11.3424 - val_accuracy: 0.1866\n",
            "Epoch 9441/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 31.4872 - accuracy: 0.2449 - val_loss: 21.6963 - val_accuracy: 0.2028\n",
            "Epoch 9442/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 10.3858 - accuracy: 0.4796 - val_loss: 10.2674 - val_accuracy: 0.2290\n",
            "Epoch 9443/24392\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1163.8233 - accuracy: 0.5531 - val_loss: 17.4540 - val_accuracy: 0.2329\n",
            "Epoch 9444/24392\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 1771.9502 - accuracy: 0.9485 - val_loss: 13.8174 - val_accuracy: 0.2545\n",
            "Epoch 9445/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 14.9735 - accuracy: 0.7460 - val_loss: 174.1715 - val_accuracy: 0.9042\n",
            "Epoch 9446/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 13.3354 - accuracy: 0.8969 - val_loss: 89.0715 - val_accuracy: 0.1551\n",
            "Epoch 9447/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 16.4360 - accuracy: 0.7431 - val_loss: 8.0230 - val_accuracy: 0.6488\n",
            "Epoch 9448/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 14.5058 - accuracy: 0.5763 - val_loss: 9.3614 - val_accuracy: 0.8248\n",
            "Epoch 9449/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 258.2106 - accuracy: 0.7250 - val_loss: 22.1992 - val_accuracy: 0.2140\n",
            "Epoch 9450/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 442.3193 - accuracy: 0.8652 - val_loss: 492.6640 - val_accuracy: 0.6744\n",
            "Epoch 9451/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 94.2769 - accuracy: 0.2952 - val_loss: 55.5631 - val_accuracy: 0.1734\n",
            "Epoch 9452/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 30.7362 - accuracy: 0.2647 - val_loss: 12.7204 - val_accuracy: 0.2504\n",
            "Epoch 9453/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 9.6711 - accuracy: 0.9228 - val_loss: 9.5516 - val_accuracy: 0.1418\n",
            "Epoch 9454/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 23.5762 - accuracy: 0.8490 - val_loss: 47.5838 - val_accuracy: 0.1870\n",
            "Epoch 9455/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 11.3841 - accuracy: 0.6419 - val_loss: 5401.6465 - val_accuracy: 0.1053\n",
            "Epoch 9456/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 11.1918 - accuracy: 0.4018 - val_loss: 13.3630 - val_accuracy: 0.1758\n",
            "Epoch 9457/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 22.2817 - accuracy: 0.6256 - val_loss: 546.8581 - val_accuracy: 0.1180\n",
            "Epoch 9458/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 30.9283 - accuracy: 0.3056 - val_loss: 28.5569 - val_accuracy: 0.1071\n",
            "Epoch 9459/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 13.6592 - accuracy: 0.3387 - val_loss: 39.4894 - val_accuracy: 0.1437\n",
            "Epoch 9460/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 18.4105 - accuracy: 0.3805 - val_loss: 38.0269 - val_accuracy: 0.1287\n",
            "Epoch 9461/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 14.0003 - accuracy: 0.9697 - val_loss: 31.6674 - val_accuracy: 0.1542\n",
            "Epoch 9462/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 131.5837 - accuracy: 0.9362 - val_loss: 30.2607 - val_accuracy: 0.1378\n",
            "Epoch 9463/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 56.9041 - accuracy: 0.8518 - val_loss: 654.0309 - val_accuracy: 0.0608\n",
            "Epoch 9464/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 13.4498 - accuracy: 0.4477 - val_loss: 1034.6787 - val_accuracy: 0.2487\n",
            "Epoch 9465/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 75.1827 - accuracy: 0.8366 - val_loss: 16.5615 - val_accuracy: 0.1352\n",
            "Epoch 9466/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 48.7580 - accuracy: 0.0700 - val_loss: 106.9737 - val_accuracy: 0.1048\n",
            "Epoch 9467/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 11.2201 - accuracy: 0.4605 - val_loss: 227.4443 - val_accuracy: 0.1349\n",
            "Epoch 9468/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 12.9718 - accuracy: 0.9413 - val_loss: 521.5547 - val_accuracy: 0.1317\n",
            "Epoch 9469/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 19.8897 - accuracy: 0.4259 - val_loss: 54.4223 - val_accuracy: 0.2126\n",
            "Epoch 9470/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 18.1630 - accuracy: 0.4731 - val_loss: 20.4836 - val_accuracy: 0.2980\n",
            "Epoch 9471/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 369.0618 - accuracy: 0.6681 - val_loss: 51.1625 - val_accuracy: 0.1224\n",
            "Epoch 9472/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 340.1132 - accuracy: 0.0025 - val_loss: 11.6105 - val_accuracy: 0.9305\n",
            "Epoch 9473/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 207.2723 - accuracy: 0.8819 - val_loss: 12.6099 - val_accuracy: 0.5596\n",
            "Epoch 9474/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 74.2668 - accuracy: 0.0954 - val_loss: 9.7673 - val_accuracy: 0.8172\n",
            "Epoch 9475/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 134.2538 - accuracy: 0.8886 - val_loss: 5.2638 - val_accuracy: 0.8903\n",
            "Epoch 9476/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 363.7255 - accuracy: 0.1264 - val_loss: 21.2495 - val_accuracy: 0.4444\n",
            "Epoch 9477/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 17.5047 - accuracy: 0.3877 - val_loss: 20.9072 - val_accuracy: 0.7552\n",
            "Epoch 9478/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 16.3580 - accuracy: 0.3531 - val_loss: 187.9987 - val_accuracy: 0.8851\n",
            "Epoch 9479/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 21.5566 - accuracy: 0.2395 - val_loss: 577.6150 - val_accuracy: 0.7260\n",
            "Epoch 9480/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 225.6203 - accuracy: 0.8019 - val_loss: 45.4398 - val_accuracy: 0.6796\n",
            "Epoch 9481/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 16.9063 - accuracy: 0.7846 - val_loss: 22.2515 - val_accuracy: 0.8596\n",
            "Epoch 9482/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 14.7640 - accuracy: 0.6397 - val_loss: 24.2582 - val_accuracy: 0.3774\n",
            "Epoch 9483/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 32.0323 - accuracy: 0.1569 - val_loss: 9.9220 - val_accuracy: 0.2870\n",
            "Epoch 9484/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 95.1277 - accuracy: 0.8540 - val_loss: 50.1322 - val_accuracy: 0.6472\n",
            "Epoch 9485/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 12.9567 - accuracy: 0.6358 - val_loss: 13.1054 - val_accuracy: 0.7771\n",
            "Epoch 9486/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 18.0960 - accuracy: 0.8292 - val_loss: 24.5739 - val_accuracy: 0.3775\n",
            "Epoch 9487/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 93.3272 - accuracy: 0.8257 - val_loss: 646.7592 - val_accuracy: 0.7038\n",
            "Epoch 9488/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 28.5419 - accuracy: 0.8222 - val_loss: 66.0345 - val_accuracy: 0.2861\n",
            "Epoch 9489/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 14.0117 - accuracy: 0.5086 - val_loss: 22.4010 - val_accuracy: 0.1824\n",
            "Epoch 9490/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 525.1862 - accuracy: 0.4646 - val_loss: 5.1838 - val_accuracy: 0.9469\n",
            "Epoch 9491/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 33.9141 - accuracy: 0.4143 - val_loss: 21.5783 - val_accuracy: 0.2288\n",
            "Epoch 9492/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 367.4758 - accuracy: 0.4605 - val_loss: 23.0862 - val_accuracy: 0.4055\n",
            "Epoch 9493/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 100.2502 - accuracy: 0.9173 - val_loss: 164.9818 - val_accuracy: 0.9430\n",
            "Epoch 9494/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 113.3151 - accuracy: 0.6946 - val_loss: 200.4993 - val_accuracy: 0.1654\n",
            "Epoch 9495/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 14.1771 - accuracy: 0.5950 - val_loss: 15.0239 - val_accuracy: 0.3801\n",
            "Epoch 9496/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 47.2787 - accuracy: 0.9800 - val_loss: 47.2471 - val_accuracy: 0.3226\n",
            "Epoch 9497/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 26.5980 - accuracy: 0.2154 - val_loss: 27.3031 - val_accuracy: 0.2747\n",
            "Epoch 9498/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 45.7993 - accuracy: 0.9578 - val_loss: 15.8333 - val_accuracy: 0.2868\n",
            "Epoch 9499/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 36.2323 - accuracy: 0.9187 - val_loss: 15.4136 - val_accuracy: 0.2536\n",
            "Epoch 9500/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 21.7862 - accuracy: 0.7099 - val_loss: 195.6987 - val_accuracy: 0.1014\n",
            "Epoch 9501/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 17.4035 - accuracy: 0.8062 - val_loss: 31.3173 - val_accuracy: 0.1582\n",
            "Epoch 9502/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 14.9980 - accuracy: 0.9734 - val_loss: 808.8679 - val_accuracy: 0.1141\n",
            "Epoch 9503/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 401.5600 - accuracy: 0.6790 - val_loss: 585.4026 - val_accuracy: 0.1483\n",
            "Epoch 9504/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 8.1299 - accuracy: 0.9916 - val_loss: 19.5064 - val_accuracy: 0.1811\n",
            "Epoch 9505/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 10.6073 - accuracy: 0.5391 - val_loss: 834.6089 - val_accuracy: 0.0591\n",
            "Epoch 9506/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 12.1563 - accuracy: 0.6830 - val_loss: 39.5837 - val_accuracy: 0.4106\n",
            "Epoch 9507/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 77.5701 - accuracy: 0.8885 - val_loss: 109.1473 - val_accuracy: 0.1599\n",
            "Epoch 9508/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 8.3394 - accuracy: 0.9426 - val_loss: 58.4507 - val_accuracy: 0.0526\n",
            "Epoch 9509/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 13.1356 - accuracy: 0.7955 - val_loss: 72.1089 - val_accuracy: 0.2020\n",
            "Epoch 9510/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 35.4886 - accuracy: 0.9686 - val_loss: 16.7004 - val_accuracy: 0.3044\n",
            "Epoch 9511/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 10.3742 - accuracy: 0.9994 - val_loss: 20.7761 - val_accuracy: 0.0788\n",
            "Epoch 9512/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 81.8246 - accuracy: 0.8099 - val_loss: 7.9384 - val_accuracy: 0.1406\n",
            "Epoch 9513/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 79.7083 - accuracy: 0.0715 - val_loss: 57.7948 - val_accuracy: 0.1595\n",
            "Epoch 9514/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 71.8964 - accuracy: 0.9603 - val_loss: 320.1176 - val_accuracy: 0.2592\n",
            "Epoch 9515/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 105.2205 - accuracy: 0.8093 - val_loss: 12.6897 - val_accuracy: 0.4729\n",
            "Epoch 9516/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 193.9739 - accuracy: 0.7522 - val_loss: 33.7231 - val_accuracy: 0.1327\n",
            "Epoch 9517/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 33.5889 - accuracy: 0.2141 - val_loss: 38.8221 - val_accuracy: 0.0832\n",
            "Epoch 9518/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 22.6611 - accuracy: 0.6292 - val_loss: 20.3055 - val_accuracy: 0.2844\n",
            "Epoch 9519/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 398.5101 - accuracy: 0.5665 - val_loss: 38.4299 - val_accuracy: 0.2544\n",
            "Epoch 9520/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 8.8489 - accuracy: 0.7125 - val_loss: 8.1883 - val_accuracy: 0.3561\n",
            "Epoch 9521/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 31.7634 - accuracy: 0.2515 - val_loss: 38.1582 - val_accuracy: 0.1313\n",
            "Epoch 9522/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 16.6026 - accuracy: 0.5202 - val_loss: 1575.2769 - val_accuracy: 0.1998\n",
            "Epoch 9523/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 43.3784 - accuracy: 0.9764 - val_loss: 448.4351 - val_accuracy: 0.0953\n",
            "Epoch 9524/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 9.3810 - accuracy: 0.8907 - val_loss: 19.8133 - val_accuracy: 0.1633\n",
            "Epoch 9525/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 11.2826 - accuracy: 0.8002 - val_loss: 38.2647 - val_accuracy: 0.2832\n",
            "Epoch 9526/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 38.9105 - accuracy: 0.2580 - val_loss: 10.1582 - val_accuracy: 0.3096\n",
            "Epoch 9527/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 19.2518 - accuracy: 0.3135 - val_loss: 29.7466 - val_accuracy: 0.2052\n",
            "Epoch 9528/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 11.3206 - accuracy: 0.8434 - val_loss: 398.7981 - val_accuracy: 0.0698\n",
            "Epoch 9529/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 10080.3545 - val_accuracy: 0.0477\n",
            "Epoch 9530/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 58.5856 - accuracy: 0.9384 - val_loss: 41.8269 - val_accuracy: 0.1574\n",
            "Epoch 9531/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 21.8304 - accuracy: 0.9733 - val_loss: 443.3818 - val_accuracy: 0.2006\n",
            "Epoch 9532/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 61.8469 - accuracy: 0.5315 - val_loss: 11.1455 - val_accuracy: 0.2786\n",
            "Epoch 9533/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 346.4434 - accuracy: 0.8353 - val_loss: 16.1028 - val_accuracy: 0.2320\n",
            "Epoch 9534/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 85.2523 - accuracy: 0.7307 - val_loss: 42.7907 - val_accuracy: 0.0546\n",
            "Epoch 9535/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 13.8313 - accuracy: 0.3351 - val_loss: 103.7078 - val_accuracy: 0.0105\n",
            "Epoch 9536/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 133.2810 - accuracy: 0.7627 - val_loss: 13.7578 - val_accuracy: 0.2715\n",
            "Epoch 9537/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 9.0158 - accuracy: 0.5747 - val_loss: 14.9483 - val_accuracy: 0.2721\n",
            "Epoch 9538/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 13.6250 - accuracy: 0.7749 - val_loss: 120.4429 - val_accuracy: 0.2295\n",
            "Epoch 9539/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 27.6859 - accuracy: 0.4686 - val_loss: 71.8761 - val_accuracy: 0.1929\n",
            "Epoch 9540/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 408.8825 - accuracy: 0.5677 - val_loss: 456.2016 - val_accuracy: 0.5417\n",
            "Epoch 9541/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 61.3357 - accuracy: 0.8623 - val_loss: 8.0128 - val_accuracy: 0.2460\n",
            "Epoch 9542/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 52.4328 - accuracy: 0.8972 - val_loss: 557.2447 - val_accuracy: 0.3182\n",
            "Epoch 9543/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 43.7562 - accuracy: 0.9063 - val_loss: 31.3594 - val_accuracy: 0.1040\n",
            "Epoch 9544/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 54.5007 - accuracy: 0.8521 - val_loss: 41.2129 - val_accuracy: 0.6198\n",
            "Epoch 9545/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 594.3199 - accuracy: 0.6574 - val_loss: 59.2994 - val_accuracy: 0.3969\n",
            "Epoch 9546/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 10.2758 - accuracy: 0.8808 - val_loss: 44.0228 - val_accuracy: 0.6135\n",
            "Epoch 9547/24392\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 1190.7478 - accuracy: 0.5133 - val_loss: 11.9884 - val_accuracy: 0.3097\n",
            "Epoch 9548/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 23.9964 - accuracy: 0.4513 - val_loss: 4.4970 - val_accuracy: 0.9588\n",
            "Epoch 9549/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 37.1117 - accuracy: 0.9608 - val_loss: 7.1194 - val_accuracy: 0.3272\n",
            "Epoch 9550/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 826.1897 - accuracy: 0.9582 - val_loss: 27.0264 - val_accuracy: 0.2349\n",
            "Epoch 9551/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 30.5927 - accuracy: 0.9396 - val_loss: 60.6813 - val_accuracy: 0.0564\n",
            "Epoch 9552/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 56.9190 - accuracy: 0.9796 - val_loss: 19.8896 - val_accuracy: 0.5253\n",
            "Epoch 9553/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 32.8095 - accuracy: 0.9210 - val_loss: 144.3395 - val_accuracy: 0.9712\n",
            "Epoch 9554/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 9.8065 - accuracy: 0.4592 - val_loss: 13.0895 - val_accuracy: 0.4464\n",
            "Epoch 9555/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 37.8599 - accuracy: 0.3440 - val_loss: 19.5423 - val_accuracy: 0.4048\n",
            "Epoch 9556/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 11.1959 - accuracy: 0.7764 - val_loss: 41.3963 - val_accuracy: 0.4563\n",
            "Epoch 9557/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 46.3692 - accuracy: 0.9702 - val_loss: 10.8483 - val_accuracy: 0.7580\n",
            "Epoch 9558/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 26.6621 - accuracy: 0.5925 - val_loss: 158.8707 - val_accuracy: 0.9702\n",
            "Epoch 9559/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 16.3918 - accuracy: 0.7887 - val_loss: 10.7424 - val_accuracy: 0.6588\n",
            "Epoch 9560/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 1571.3698 - accuracy: 0.3332 - val_loss: 27.0745 - val_accuracy: 0.4949\n",
            "Epoch 9561/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 12.1088 - accuracy: 0.8135 - val_loss: 203.8371 - val_accuracy: 0.8721\n",
            "Epoch 9562/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 58.0027 - val_accuracy: 0.1678\n",
            "Epoch 9563/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 3.4475e-04 - accuracy: 1.0000 - val_loss: 47.2172 - val_accuracy: 0.2466\n",
            "Epoch 9564/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 16.1554 - accuracy: 0.7928 - val_loss: 463.7813 - val_accuracy: 0.9217\n",
            "Epoch 9565/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 212.9360 - accuracy: 0.8150 - val_loss: 5.3981 - val_accuracy: 0.8427\n",
            "Epoch 9566/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 39.0892 - accuracy: 0.4523 - val_loss: 44.9394 - val_accuracy: 0.1098\n",
            "Epoch 9567/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 16.8620 - accuracy: 0.8049 - val_loss: 294.6985 - val_accuracy: 0.4731\n",
            "Epoch 9568/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 55.8514 - accuracy: 0.8307 - val_loss: 353.5916 - val_accuracy: 0.5790\n",
            "Epoch 9569/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 41.6405 - accuracy: 0.8790 - val_loss: 38.0741 - val_accuracy: 0.2579\n",
            "Epoch 9570/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 11.1108 - accuracy: 0.5744 - val_loss: 60.5688 - val_accuracy: 0.1937\n",
            "Epoch 9571/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 13.3961 - accuracy: 0.9630 - val_loss: 19.7657 - val_accuracy: 0.1124\n",
            "Epoch 9572/24392\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 16.2400 - accuracy: 0.5127 - val_loss: 1095.5972 - val_accuracy: 0.4967\n",
            "Epoch 9573/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 27.0203 - accuracy: 0.6629 - val_loss: 41.6884 - val_accuracy: 0.4720\n",
            "Epoch 9574/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 50.1245 - accuracy: 0.2395 - val_loss: 316.1461 - val_accuracy: 0.0924\n",
            "Epoch 9575/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 23.9342 - accuracy: 0.1865 - val_loss: 822.7505 - val_accuracy: 0.1373\n",
            "Epoch 9576/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 18.6291 - accuracy: 0.8109 - val_loss: 15.3745 - val_accuracy: 0.1367\n",
            "Epoch 9577/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 18.9682 - accuracy: 0.7980 - val_loss: 13.6726 - val_accuracy: 0.2728\n",
            "Epoch 9578/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 18.9950 - accuracy: 0.3288 - val_loss: 9.4157 - val_accuracy: 0.2194\n",
            "Epoch 9579/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 66.8350 - accuracy: 0.9964 - val_loss: 8.5167 - val_accuracy: 0.2737\n",
            "Epoch 9580/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 27.2719 - accuracy: 0.9806 - val_loss: 22.8372 - val_accuracy: 0.1284\n",
            "Epoch 9581/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 277.3452 - accuracy: 0.6086 - val_loss: 3194.1113 - val_accuracy: 0.4190\n",
            "Epoch 9582/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 13.4871 - accuracy: 0.5178 - val_loss: 16.7753 - val_accuracy: 0.4052\n",
            "Epoch 9583/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 320.7472 - accuracy: 0.7795 - val_loss: 13.8793 - val_accuracy: 0.1214\n",
            "Epoch 9584/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 623.8494 - accuracy: 0.7614 - val_loss: 20.5352 - val_accuracy: 0.1535\n",
            "Epoch 9585/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 7.3356 - val_accuracy: 0.5352\n",
            "Epoch 9586/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 517.6899 - accuracy: 0.9002 - val_loss: 24.2542 - val_accuracy: 0.2841\n",
            "Epoch 9587/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 9.4078 - accuracy: 0.7998 - val_loss: 55.3651 - val_accuracy: 0.2128\n",
            "Epoch 9588/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 845.0964 - accuracy: 0.7486 - val_loss: 28.0579 - val_accuracy: 0.1843\n",
            "Epoch 9589/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 1709.4093 - accuracy: 0.3261 - val_loss: 18.4115 - val_accuracy: 0.4854\n",
            "Epoch 9590/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 95.9221 - accuracy: 0.2731 - val_loss: 32.3437 - val_accuracy: 0.3319\n",
            "Epoch 9591/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 20.1461 - accuracy: 0.8652 - val_loss: 21.7724 - val_accuracy: 0.1462\n",
            "Epoch 9592/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 183.3069 - accuracy: 0.9510 - val_loss: 37.8709 - val_accuracy: 0.1274\n",
            "Epoch 9593/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 19.5965 - accuracy: 0.2793 - val_loss: 52.8668 - val_accuracy: 0.1427\n",
            "Epoch 9594/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 15.0468 - val_accuracy: 0.2421\n",
            "Epoch 9595/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 13.0665 - accuracy: 0.3602 - val_loss: 14.8689 - val_accuracy: 0.2178\n",
            "Epoch 9596/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 15.3484 - accuracy: 0.3313 - val_loss: 39.2281 - val_accuracy: 0.1796\n",
            "Epoch 9597/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 125.1103 - accuracy: 0.8348 - val_loss: 44.9315 - val_accuracy: 0.1418\n",
            "Epoch 9598/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 161.5120 - accuracy: 0.3567 - val_loss: 17391.7949 - val_accuracy: 0.6666\n",
            "Epoch 9599/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 48.5611 - accuracy: 0.2549 - val_loss: 21.0612 - val_accuracy: 0.2014\n",
            "Epoch 9600/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 433.5797 - accuracy: 0.8257 - val_loss: 20.4016 - val_accuracy: 0.2680\n",
            "Epoch 9601/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 18.8171 - accuracy: 0.5671 - val_loss: 14.1579 - val_accuracy: 0.3034\n",
            "Epoch 9602/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 19.7571 - accuracy: 0.9251 - val_loss: 263.9658 - val_accuracy: 0.9374\n",
            "Epoch 9603/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 28.7995 - accuracy: 0.8712 - val_loss: 10.5096 - val_accuracy: 0.5402\n",
            "Epoch 9604/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 103.2179 - accuracy: 0.2123 - val_loss: 26.7144 - val_accuracy: 0.1006\n",
            "Epoch 9605/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 1619.1531 - accuracy: 0.8333 - val_loss: 379.5327 - val_accuracy: 0.3859\n",
            "Epoch 9606/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 144.4023 - accuracy: 0.6906 - val_loss: 1023.3871 - val_accuracy: 0.4012\n",
            "Epoch 9607/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 1405.4128 - accuracy: 0.7353 - val_loss: 19.4681 - val_accuracy: 0.2247\n",
            "Epoch 9608/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 29.9521 - accuracy: 0.3232 - val_loss: 82.0209 - val_accuracy: 0.1929\n",
            "Epoch 9609/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 48.9766 - accuracy: 0.4079 - val_loss: 55.8524 - val_accuracy: 0.0773\n",
            "Epoch 9610/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 26.7382 - val_accuracy: 0.1827\n",
            "Epoch 9611/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 22.7465 - accuracy: 0.3209 - val_loss: 35.5527 - val_accuracy: 0.1246\n",
            "Epoch 9612/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 27.2148 - accuracy: 0.9755 - val_loss: 340.5977 - val_accuracy: 0.0336\n",
            "Epoch 9613/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 202.9167 - accuracy: 0.8963 - val_loss: 43.7857 - val_accuracy: 0.1974\n",
            "Epoch 9614/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 105.8765 - accuracy: 0.9520 - val_loss: 434.7705 - val_accuracy: 0.1272\n",
            "Epoch 9615/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 2101.9046 - accuracy: 0.7721 - val_loss: 15.8165 - val_accuracy: 0.2481\n",
            "Epoch 9616/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 32.6843 - accuracy: 0.4101 - val_loss: 10.4214 - val_accuracy: 0.3371\n",
            "Epoch 9617/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 95.7805 - accuracy: 0.8794 - val_loss: 33.5138 - val_accuracy: 0.2227\n",
            "Epoch 9618/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 15.4559 - accuracy: 0.7502 - val_loss: 15.3867 - val_accuracy: 0.1563\n",
            "Epoch 9619/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 102.9170 - accuracy: 0.7946 - val_loss: 29.4029 - val_accuracy: 0.2291\n",
            "Epoch 9620/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 33.5025 - accuracy: 0.4342 - val_loss: 35.2178 - val_accuracy: 0.2151\n",
            "Epoch 9621/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 27.9493 - accuracy: 0.3387 - val_loss: 224.0773 - val_accuracy: 0.8053\n",
            "Epoch 9622/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 17.6104 - accuracy: 0.4746 - val_loss: 9.7545 - val_accuracy: 0.6077\n",
            "Epoch 9623/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 329.5354 - accuracy: 0.8320 - val_loss: 75.3630 - val_accuracy: 0.2240\n",
            "Epoch 9624/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 38.3223 - accuracy: 0.8933 - val_loss: 254.8387 - val_accuracy: 0.4475\n",
            "Epoch 9625/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 51.3491 - accuracy: 0.9636 - val_loss: 41.9050 - val_accuracy: 0.3209\n",
            "Epoch 9626/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 34.6644 - accuracy: 0.3586 - val_loss: 49.5014 - val_accuracy: 0.3189\n",
            "Epoch 9627/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 205.2918 - accuracy: 0.8448 - val_loss: 14.7207 - val_accuracy: 0.1726\n",
            "Epoch 9628/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 203.0741 - accuracy: 0.5703 - val_loss: 11.3850 - val_accuracy: 0.3310\n",
            "Epoch 9629/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 168.4776 - accuracy: 0.6864 - val_loss: 391.1956 - val_accuracy: 0.4364\n",
            "Epoch 9630/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 13.6696 - accuracy: 0.2391 - val_loss: 35.2242 - val_accuracy: 0.5451\n",
            "Epoch 9631/24392\n",
            "4/4 [==============================] - 1s 196ms/step - loss: 13.3942 - accuracy: 0.6550 - val_loss: 8.4297 - val_accuracy: 0.5198\n",
            "Epoch 9632/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 8.8339 - accuracy: 0.9725 - val_loss: 61.7274 - val_accuracy: 0.0353\n",
            "Epoch 9633/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 33.5318 - accuracy: 0.7531 - val_loss: 42.2397 - val_accuracy: 0.4904\n",
            "Epoch 9634/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 607.8002 - accuracy: 0.6610 - val_loss: 16.9414 - val_accuracy: 0.2353\n",
            "Epoch 9635/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 8.6466 - val_accuracy: 0.5559\n",
            "Epoch 9636/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 33.9937 - accuracy: 0.9810 - val_loss: 8.9295 - val_accuracy: 0.5744\n",
            "Epoch 9637/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 37.1693 - accuracy: 0.9603 - val_loss: 16.3214 - val_accuracy: 0.8163\n",
            "Epoch 9638/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 31.6750 - accuracy: 0.2058 - val_loss: 21.5271 - val_accuracy: 0.1283\n",
            "Epoch 9639/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 11.7776 - accuracy: 0.9280 - val_loss: 295.4815 - val_accuracy: 0.2906\n",
            "Epoch 9640/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 44.5113 - accuracy: 0.1811 - val_loss: 23.9234 - val_accuracy: 0.2475\n",
            "Epoch 9641/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 117.4458 - accuracy: 0.9486 - val_loss: 399.2242 - val_accuracy: 0.1416\n",
            "Epoch 9642/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 29.5329 - accuracy: 0.9213 - val_loss: 3797.2185 - val_accuracy: 0.3447\n",
            "Epoch 9643/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 35.9346 - val_accuracy: 0.1953\n",
            "Epoch 9644/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 33.3756 - accuracy: 0.2063 - val_loss: 13.1529 - val_accuracy: 0.1923\n",
            "Epoch 9645/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 79.2301 - accuracy: 0.8328 - val_loss: 12.4598 - val_accuracy: 0.2556\n",
            "Epoch 9646/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 13.3349 - accuracy: 0.8401 - val_loss: 32.2508 - val_accuracy: 0.2074\n",
            "Epoch 9647/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 95.9704 - accuracy: 0.2102 - val_loss: 4.4867 - val_accuracy: 0.2847\n",
            "Epoch 9648/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 14.0003 - accuracy: 0.4197 - val_loss: 30.0828 - val_accuracy: 0.2787\n",
            "Epoch 9649/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 20352.9242 - accuracy: 0.3704 - val_loss: 503.0180 - val_accuracy: 0.2478\n",
            "Epoch 9650/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 14.1836 - accuracy: 0.3957 - val_loss: 11.7446 - val_accuracy: 0.2345\n",
            "Epoch 9651/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 13.3910 - accuracy: 0.7229 - val_loss: 310.5130 - val_accuracy: 0.1878\n",
            "Epoch 9652/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 22.2907 - accuracy: 0.2706 - val_loss: 18.4893 - val_accuracy: 0.2831\n",
            "Epoch 9653/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 14.3134 - accuracy: 0.6931 - val_loss: 14.8821 - val_accuracy: 0.2139\n",
            "Epoch 9654/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 14.8195 - accuracy: 0.8997 - val_loss: 45.6414 - val_accuracy: 0.2423\n",
            "Epoch 9655/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 177.6921 - accuracy: 0.6848 - val_loss: 403.3419 - val_accuracy: 0.2056\n",
            "Epoch 9656/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 308.9856 - accuracy: 0.6844 - val_loss: 10.0672 - val_accuracy: 0.2459\n",
            "Epoch 9657/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 12.7626 - accuracy: 0.9821 - val_loss: 16.8663 - val_accuracy: 0.2868\n",
            "Epoch 9658/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 12.8717 - accuracy: 0.6257 - val_loss: 35.3698 - val_accuracy: 0.2151\n",
            "Epoch 9659/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 12.7898 - accuracy: 0.3460 - val_loss: 35.9722 - val_accuracy: 0.1647\n",
            "Epoch 9660/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 761.3577 - accuracy: 0.8325 - val_loss: 395.6062 - val_accuracy: 0.2231\n",
            "Epoch 9661/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 8.6144 - accuracy: 0.6794 - val_loss: 16.2242 - val_accuracy: 0.4217\n",
            "Epoch 9662/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 36.0733 - accuracy: 0.9183 - val_loss: 1836.3711 - val_accuracy: 0.2901\n",
            "Epoch 9663/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 682.6004 - accuracy: 0.4243 - val_loss: 13.3998 - val_accuracy: 0.3476\n",
            "Epoch 9664/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 135.1648 - accuracy: 0.9124 - val_loss: 261.9576 - val_accuracy: 0.3091\n",
            "Epoch 9665/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 19.9851 - accuracy: 0.8793 - val_loss: 9.5746 - val_accuracy: 0.2987\n",
            "Epoch 9666/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 24.5060 - accuracy: 0.1437 - val_loss: 23.1923 - val_accuracy: 0.1443\n",
            "Epoch 9667/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 25.8434 - accuracy: 0.5694 - val_loss: 36.1555 - val_accuracy: 0.3594\n",
            "Epoch 9668/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 108.8618 - accuracy: 0.1967 - val_loss: 37.0639 - val_accuracy: 0.2541\n",
            "Epoch 9669/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 61.9455 - accuracy: 0.0355 - val_loss: 21.5456 - val_accuracy: 0.5087\n",
            "Epoch 9670/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 156.5870 - accuracy: 0.8227 - val_loss: 24.3424 - val_accuracy: 0.2530\n",
            "Epoch 9671/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 10.1089 - accuracy: 0.8777 - val_loss: 11.1111 - val_accuracy: 0.9714\n",
            "Epoch 9672/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 87.4132 - accuracy: 0.3488 - val_loss: 282.1841 - val_accuracy: 0.5679\n",
            "Epoch 9673/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 23.0137 - accuracy: 0.9525 - val_loss: 16.6357 - val_accuracy: 0.4378\n",
            "Epoch 9674/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 127.9780 - accuracy: 0.3269 - val_loss: 20.0287 - val_accuracy: 0.2241\n",
            "Epoch 9675/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 15.1662 - val_accuracy: 0.4393\n",
            "Epoch 9676/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 386.2569 - accuracy: 0.4602 - val_loss: 52.4293 - val_accuracy: 0.2829\n",
            "Epoch 9677/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 10.2723 - accuracy: 0.4960 - val_loss: 11.7553 - val_accuracy: 0.4113\n",
            "Epoch 9678/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 150.6901 - accuracy: 0.7657 - val_loss: 19.7719 - val_accuracy: 0.2748\n",
            "Epoch 9679/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 319.0513 - accuracy: 0.8345 - val_loss: 122.8408 - val_accuracy: 0.8525\n",
            "Epoch 9680/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 18.9544 - accuracy: 0.9100 - val_loss: 24.4972 - val_accuracy: 0.3481\n",
            "Epoch 9681/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 3306.8064 - accuracy: 0.3048 - val_loss: 57.8629 - val_accuracy: 0.6122\n",
            "Epoch 9682/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 8.0490 - accuracy: 0.5533 - val_loss: 18.0656 - val_accuracy: 0.4818\n",
            "Epoch 9683/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 577.6317 - accuracy: 0.5493 - val_loss: 557.2834 - val_accuracy: 0.6854\n",
            "Epoch 9684/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 439.7954 - accuracy: 0.6090 - val_loss: 20.3589 - val_accuracy: 0.4474\n",
            "Epoch 9685/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 11.3152 - accuracy: 0.6747 - val_loss: 8.1005 - val_accuracy: 0.6214\n",
            "Epoch 9686/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 10.8185 - accuracy: 0.7877 - val_loss: 10.3475 - val_accuracy: 0.7655\n",
            "Epoch 9687/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 22.0474 - accuracy: 0.7870 - val_loss: 30.3792 - val_accuracy: 0.5679\n",
            "Epoch 9688/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 161.3945 - accuracy: 0.9411 - val_loss: 12.7040 - val_accuracy: 0.2934\n",
            "Epoch 9689/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 23.5021 - accuracy: 0.2457 - val_loss: 29.3588 - val_accuracy: 0.2507\n",
            "Epoch 9690/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 236.3691 - accuracy: 0.4408 - val_loss: 12.5130 - val_accuracy: 0.2920\n",
            "Epoch 9691/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 17.7823 - accuracy: 0.4980 - val_loss: 13.2796 - val_accuracy: 0.2478\n",
            "Epoch 9692/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 37.8802 - accuracy: 0.9124 - val_loss: 27.5275 - val_accuracy: 0.1918\n",
            "Epoch 9693/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 122.3834 - accuracy: 0.9542 - val_loss: 18.5993 - val_accuracy: 0.1738\n",
            "Epoch 9694/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 27.4077 - accuracy: 0.3529 - val_loss: 18722.0254 - val_accuracy: 0.0892\n",
            "Epoch 9695/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 14.2682 - accuracy: 0.8557 - val_loss: 531.1577 - val_accuracy: 0.2754\n",
            "Epoch 9696/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 18.5575 - accuracy: 0.6792 - val_loss: 16.4599 - val_accuracy: 0.1313\n",
            "Epoch 9697/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 74.0528 - accuracy: 0.8284 - val_loss: 268.4727 - val_accuracy: 0.0413\n",
            "Epoch 9698/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 386.8335 - accuracy: 0.5968 - val_loss: 10.6556 - val_accuracy: 0.2519\n",
            "Epoch 9699/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 1164.9690 - accuracy: 0.6670 - val_loss: 837.4947 - val_accuracy: 0.2770\n",
            "Epoch 9700/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 14.0807 - accuracy: 0.4438 - val_loss: 4263.7544 - val_accuracy: 0.1302\n",
            "Epoch 9701/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 131.5519 - accuracy: 0.9595 - val_loss: 413.1150 - val_accuracy: 0.2240\n",
            "Epoch 9702/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 13.1904 - accuracy: 0.3594 - val_loss: 215.8905 - val_accuracy: 0.1127\n",
            "Epoch 9703/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 15.2458 - accuracy: 0.6421 - val_loss: 14.8499 - val_accuracy: 0.2539\n",
            "Epoch 9704/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 52.8073 - accuracy: 0.9066 - val_loss: 532.0818 - val_accuracy: 0.1429\n",
            "Epoch 9705/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 9.0207 - accuracy: 0.9858 - val_loss: 14.7283 - val_accuracy: 0.1707\n",
            "Epoch 9706/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 18.3767 - accuracy: 0.1849 - val_loss: 446.0339 - val_accuracy: 0.2359\n",
            "Epoch 9707/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 21.7502 - accuracy: 0.5800 - val_loss: 96.5687 - val_accuracy: 0.2033\n",
            "Epoch 9708/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 8.4143 - accuracy: 0.8371 - val_loss: 7.4524 - val_accuracy: 0.2547\n",
            "Epoch 9709/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 34.9091 - accuracy: 0.6101 - val_loss: 30.4233 - val_accuracy: 0.1499\n",
            "Epoch 9710/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 14.4653 - accuracy: 0.5203 - val_loss: 25.5921 - val_accuracy: 0.1684\n",
            "Epoch 9711/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 6384.8613 - accuracy: 0.5348 - val_loss: 40.2923 - val_accuracy: 0.1416\n",
            "Epoch 9712/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 30.8172 - accuracy: 0.4637 - val_loss: 69.7715 - val_accuracy: 0.0660\n",
            "Epoch 9713/24392\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 24.5443 - val_accuracy: 0.1505\n",
            "Epoch 9714/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 14.2914 - accuracy: 0.5523 - val_loss: 38.0046 - val_accuracy: 0.2165\n",
            "Epoch 9715/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 6.2491 - accuracy: 0.6625 - val_loss: 52.3765 - val_accuracy: 0.1208\n",
            "Epoch 9716/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 51.9641 - accuracy: 0.1505 - val_loss: 263.3503 - val_accuracy: 0.4181\n",
            "Epoch 9717/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 14.2865 - accuracy: 0.3212 - val_loss: 22.4437 - val_accuracy: 0.2189\n",
            "Epoch 9718/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 12.9621 - accuracy: 0.3642 - val_loss: 320.9089 - val_accuracy: 0.2510\n",
            "Epoch 9719/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 22.4450 - accuracy: 0.2149 - val_loss: 8.8330 - val_accuracy: 0.4105\n",
            "Epoch 9720/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 46.9947 - accuracy: 0.7255 - val_loss: 65.9561 - val_accuracy: 0.2482\n",
            "Epoch 9721/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 757.2057 - accuracy: 0.6959 - val_loss: 328.3357 - val_accuracy: 0.5151\n",
            "Epoch 9722/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 25.1900 - accuracy: 0.9367 - val_loss: 116.6469 - val_accuracy: 0.5343\n",
            "Epoch 9723/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 587.3928 - accuracy: 0.4451 - val_loss: 8.2095 - val_accuracy: 0.7291\n",
            "Epoch 9724/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 48.1365 - accuracy: 0.2534 - val_loss: 53.3837 - val_accuracy: 0.2626\n",
            "Epoch 9725/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 432.6525 - accuracy: 0.8712 - val_loss: 16.5364 - val_accuracy: 0.2896\n",
            "Epoch 9726/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 39.1180 - accuracy: 0.3944 - val_loss: 10.6380 - val_accuracy: 0.3256\n",
            "Epoch 9727/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 69.5519 - accuracy: 0.9267 - val_loss: 9.7850 - val_accuracy: 0.8974\n",
            "Epoch 9728/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 466.3579 - accuracy: 0.7179 - val_loss: 19.4096 - val_accuracy: 0.2213\n",
            "Epoch 9729/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 13.6231 - accuracy: 0.9927 - val_loss: 11.5766 - val_accuracy: 0.1992\n",
            "Epoch 9730/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 56.7102 - accuracy: 0.0905 - val_loss: 28.0470 - val_accuracy: 0.5819\n",
            "Epoch 9731/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 252.2053 - accuracy: 0.7374 - val_loss: 59.4803 - val_accuracy: 0.4911\n",
            "Epoch 9732/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 15.9195 - accuracy: 0.4848 - val_loss: 110.4186 - val_accuracy: 0.8943\n",
            "Epoch 9733/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 34.8723 - accuracy: 0.2416 - val_loss: 7.9040 - val_accuracy: 0.5942\n",
            "Epoch 9734/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 312.5572 - accuracy: 0.7404 - val_loss: 21.6262 - val_accuracy: 0.2645\n",
            "Epoch 9735/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 37.6674 - accuracy: 0.9406 - val_loss: 29.9013 - val_accuracy: 0.2649\n",
            "Epoch 9736/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 15.0066 - accuracy: 0.3255 - val_loss: 488.1103 - val_accuracy: 0.3709\n",
            "Epoch 9737/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 5.3066 - accuracy: 0.9935 - val_loss: 42.4342 - val_accuracy: 0.1901\n",
            "Epoch 9738/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 23.2887 - accuracy: 0.5760 - val_loss: 218.4473 - val_accuracy: 0.6411\n",
            "Epoch 9739/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 13.8643 - accuracy: 0.6102 - val_loss: 496.9320 - val_accuracy: 0.2821\n",
            "Epoch 9740/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 47.7301 - accuracy: 0.9694 - val_loss: 36.0216 - val_accuracy: 0.4888\n",
            "Epoch 9741/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 204.5000 - accuracy: 0.8067 - val_loss: 35.8576 - val_accuracy: 0.1815\n",
            "Epoch 9742/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 98.1170 - accuracy: 0.6836 - val_loss: 82.0457 - val_accuracy: 0.5222\n",
            "Epoch 9743/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 10.0862 - accuracy: 0.9371 - val_loss: 31.3801 - val_accuracy: 0.2155\n",
            "Epoch 9744/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 25.0456 - accuracy: 0.1714 - val_loss: 286.0322 - val_accuracy: 0.3365\n",
            "Epoch 9745/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 19.1281 - accuracy: 0.3783 - val_loss: 21.3281 - val_accuracy: 0.5129\n",
            "Epoch 9746/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 72.2186 - accuracy: 0.9590 - val_loss: 17.6595 - val_accuracy: 0.1900\n",
            "Epoch 9747/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 8.3131 - accuracy: 0.6176 - val_loss: 11.8707 - val_accuracy: 0.5581\n",
            "Epoch 9748/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 17.8780 - accuracy: 0.3735 - val_loss: 351.5534 - val_accuracy: 0.4063\n",
            "Epoch 9749/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 12.1736 - accuracy: 0.3624 - val_loss: 10.9252 - val_accuracy: 0.4453\n",
            "Epoch 9750/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 36.6650 - accuracy: 0.3454 - val_loss: 140.1730 - val_accuracy: 0.6145\n",
            "Epoch 9751/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 79.5393 - accuracy: 0.7528 - val_loss: 9.9772 - val_accuracy: 0.2994\n",
            "Epoch 9752/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 13.7256 - accuracy: 0.3102 - val_loss: 7.1708 - val_accuracy: 0.8317\n",
            "Epoch 9753/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 2682.5998 - accuracy: 0.5015 - val_loss: 44.1280 - val_accuracy: 0.3060\n",
            "Epoch 9754/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 197.9257 - accuracy: 0.6063 - val_loss: 428.4688 - val_accuracy: 0.8424\n",
            "Epoch 9755/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 13.4229 - accuracy: 0.5009 - val_loss: 24.2666 - val_accuracy: 0.6214\n",
            "Epoch 9756/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 692.2728 - accuracy: 0.8750 - val_loss: 294.8545 - val_accuracy: 0.2286\n",
            "Epoch 9757/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 214.6841 - accuracy: 0.8598 - val_loss: 26.2545 - val_accuracy: 0.3459\n",
            "Epoch 9758/24392\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 433.7017 - accuracy: 0.7492 - val_loss: 10.6892 - val_accuracy: 0.2053\n",
            "Epoch 9759/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 18.6926 - accuracy: 0.9605 - val_loss: 55.9245 - val_accuracy: 0.1952\n",
            "Epoch 9760/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 136.1727 - accuracy: 0.8653 - val_loss: 10.2854 - val_accuracy: 0.3962\n",
            "Epoch 9761/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 1575.6229 - accuracy: 0.4323 - val_loss: 48.7371 - val_accuracy: 0.1211\n",
            "Epoch 9762/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 54.2521 - accuracy: 0.3426 - val_loss: 49.7097 - val_accuracy: 0.3630\n",
            "Epoch 9763/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 14.3299 - accuracy: 0.3014 - val_loss: 233.6334 - val_accuracy: 0.6718\n",
            "Epoch 9764/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 24.5758 - accuracy: 0.9272 - val_loss: 101.2512 - val_accuracy: 0.2287\n",
            "Epoch 9765/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 29.9232 - accuracy: 0.7364 - val_loss: 17.7555 - val_accuracy: 0.1699\n",
            "Epoch 9766/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 52.3259 - accuracy: 0.8913 - val_loss: 75.4898 - val_accuracy: 0.0921\n",
            "Epoch 9767/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 1684.1767 - accuracy: 0.1422 - val_loss: 1161.9795 - val_accuracy: 0.1207\n",
            "Epoch 9768/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 411.0880 - accuracy: 0.8721 - val_loss: 16.5699 - val_accuracy: 0.1422\n",
            "Epoch 9769/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 13.6101 - accuracy: 0.8177 - val_loss: 23.4133 - val_accuracy: 0.1664\n",
            "Epoch 9770/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 15.0720 - accuracy: 0.3440 - val_loss: 12.5689 - val_accuracy: 0.2810\n",
            "Epoch 9771/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 10.2861 - accuracy: 0.6368 - val_loss: 16.9874 - val_accuracy: 0.2548\n",
            "Epoch 9772/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 11.8907 - accuracy: 0.5999 - val_loss: 240.2567 - val_accuracy: 0.4048\n",
            "Epoch 9773/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 26.1265 - accuracy: 0.3894 - val_loss: 3425.3162 - val_accuracy: 0.0196\n",
            "Epoch 9774/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 9.8741 - accuracy: 0.3451 - val_loss: 62.0733 - val_accuracy: 0.2173\n",
            "Epoch 9775/24392\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 20.8243 - accuracy: 0.8521 - val_loss: 263.4614 - val_accuracy: 0.2999\n",
            "Epoch 9776/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 45.4674 - accuracy: 0.9591 - val_loss: 435.4991 - val_accuracy: 0.1673\n",
            "Epoch 9777/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 74.7060 - accuracy: 0.9151 - val_loss: 25.9840 - val_accuracy: 0.2106\n",
            "Epoch 9778/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 11.7666 - accuracy: 0.5484 - val_loss: 64.5746 - val_accuracy: 0.1837\n",
            "Epoch 9779/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 150.1689 - accuracy: 0.7959 - val_loss: 25.6198 - val_accuracy: 0.1088\n",
            "Epoch 9780/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 9.2145 - accuracy: 0.6695 - val_loss: 17.0317 - val_accuracy: 0.2641\n",
            "Epoch 9781/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 76.5642 - accuracy: 0.7497 - val_loss: 38.5026 - val_accuracy: 0.1012\n",
            "Epoch 9782/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 22.4256 - accuracy: 0.3270 - val_loss: 38.2512 - val_accuracy: 0.2941\n",
            "Epoch 9783/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 15.8297 - accuracy: 0.3033 - val_loss: 21.5920 - val_accuracy: 0.3104\n",
            "Epoch 9784/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 11.5821 - accuracy: 0.8382 - val_loss: 7.0926 - val_accuracy: 0.5720\n",
            "Epoch 9785/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 417.8393 - accuracy: 0.3901 - val_loss: 310.4747 - val_accuracy: 0.6282\n",
            "Epoch 9786/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 14.7838 - accuracy: 0.3744 - val_loss: 33.8655 - val_accuracy: 0.1892\n",
            "Epoch 9787/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 12.3078 - accuracy: 0.9103 - val_loss: 36.8436 - val_accuracy: 0.1618\n",
            "Epoch 9788/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 15.0328 - accuracy: 0.5200 - val_loss: 18.5195 - val_accuracy: 0.4381\n",
            "Epoch 9789/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 28.3579 - accuracy: 0.7898 - val_loss: 52.1640 - val_accuracy: 0.1285\n",
            "Epoch 9790/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 14.5716 - accuracy: 0.7760 - val_loss: 3789.2812 - val_accuracy: 0.1014\n",
            "Epoch 9791/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 45.6187 - accuracy: 0.9381 - val_loss: 51.8049 - val_accuracy: 0.1332\n",
            "Epoch 9792/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 11.2895 - accuracy: 0.7818 - val_loss: 13.2330 - val_accuracy: 0.2016\n",
            "Epoch 9793/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 378.7005 - val_accuracy: 0.1205\n",
            "Epoch 9794/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 222.1040 - accuracy: 0.1858 - val_loss: 501.9631 - val_accuracy: 0.0584\n",
            "Epoch 9795/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 525.8077 - accuracy: 0.6148 - val_loss: 9.0738 - val_accuracy: 0.1424\n",
            "Epoch 9796/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 24.4173 - accuracy: 0.7712 - val_loss: 8.7491 - val_accuracy: 0.3100\n",
            "Epoch 9797/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 49.5196 - accuracy: 0.7980 - val_loss: 8.1504 - val_accuracy: 0.1387\n",
            "Epoch 9798/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 50.4729 - accuracy: 0.9072 - val_loss: 25.0909 - val_accuracy: 0.1960\n",
            "Epoch 9799/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 21.4194 - accuracy: 0.2704 - val_loss: 16.8067 - val_accuracy: 0.1345\n",
            "Epoch 9800/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 14.0469 - accuracy: 0.3372 - val_loss: 231.2260 - val_accuracy: 0.2394\n",
            "Epoch 9801/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 53.1000 - accuracy: 0.8302 - val_loss: 12.2635 - val_accuracy: 0.1722\n",
            "Epoch 9802/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 210.3693 - accuracy: 0.8956 - val_loss: 649.0287 - val_accuracy: 0.1833\n",
            "Epoch 9803/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 214.5371 - accuracy: 0.7840 - val_loss: 25.0056 - val_accuracy: 0.2654\n",
            "Epoch 9804/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 12.9819 - val_accuracy: 0.3276\n",
            "Epoch 9805/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 1054.8128 - accuracy: 0.5937 - val_loss: 22.9143 - val_accuracy: 0.1093\n",
            "Epoch 9806/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 11.2332 - accuracy: 0.5046 - val_loss: 46.5416 - val_accuracy: 0.2671\n",
            "Epoch 9807/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 17.7776 - accuracy: 0.9856 - val_loss: 56.4761 - val_accuracy: 0.0990\n",
            "Epoch 9808/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 15.5141 - accuracy: 0.4895 - val_loss: 1289.4652 - val_accuracy: 0.1756\n",
            "Epoch 9809/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 23.4662 - accuracy: 0.2231 - val_loss: 31.0327 - val_accuracy: 0.2206\n",
            "Epoch 9810/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 20.0379 - accuracy: 0.3659 - val_loss: 38.8098 - val_accuracy: 0.1099\n",
            "Epoch 9811/24392\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 13.5548 - accuracy: 0.6146 - val_loss: 404.0494 - val_accuracy: 0.1725\n",
            "Epoch 9812/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 256.8844 - accuracy: 0.7691 - val_loss: 84.4437 - val_accuracy: 0.1024\n",
            "Epoch 9813/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 20.3951 - accuracy: 0.5954 - val_loss: 19.1494 - val_accuracy: 0.2249\n",
            "Epoch 9814/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 56.0981 - accuracy: 0.9799 - val_loss: 121.6028 - val_accuracy: 0.0663\n",
            "Epoch 9815/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 34.0446 - accuracy: 0.9333 - val_loss: 18.4868 - val_accuracy: 0.2317\n",
            "Epoch 9816/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 20.4973 - accuracy: 0.9360 - val_loss: 15.0630 - val_accuracy: 0.2359\n",
            "Epoch 9817/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 226.2263 - accuracy: 0.6483 - val_loss: 37.2485 - val_accuracy: 0.0916\n",
            "Epoch 9818/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 175.3743 - accuracy: 0.8737 - val_loss: 5274.3867 - val_accuracy: 0.2465\n",
            "Epoch 9819/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 38.1805 - accuracy: 0.9052 - val_loss: 20.3399 - val_accuracy: 0.2421\n",
            "Epoch 9820/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 19.6995 - accuracy: 0.6717 - val_loss: 16.8608 - val_accuracy: 0.1969\n",
            "Epoch 9821/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 26.2612 - accuracy: 0.9375 - val_loss: 238.3399 - val_accuracy: 0.5008\n",
            "Epoch 9822/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 25.5055 - accuracy: 0.7857 - val_loss: 163.3926 - val_accuracy: 0.1649\n",
            "Epoch 9823/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 14.4913 - accuracy: 0.8400 - val_loss: 37.0476 - val_accuracy: 0.6383\n",
            "Epoch 9824/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 19.3598 - accuracy: 0.4027 - val_loss: 18.3226 - val_accuracy: 0.2725\n",
            "Epoch 9825/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 46.6995 - accuracy: 0.8800 - val_loss: 209.7430 - val_accuracy: 0.9862\n",
            "Epoch 9826/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 51.6817 - accuracy: 0.5398 - val_loss: 15.4674 - val_accuracy: 0.5737\n",
            "Epoch 9827/24392\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 11.4539 - val_accuracy: 0.4151\n",
            "Epoch 9828/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 22.4082 - accuracy: 0.8907 - val_loss: 22.1871 - val_accuracy: 0.1334\n",
            "Epoch 9829/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 56.0927 - accuracy: 0.8787 - val_loss: 11.4854 - val_accuracy: 0.5647\n",
            "Epoch 9830/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 248.3886 - accuracy: 0.8956 - val_loss: 267.8895 - val_accuracy: 0.8074\n",
            "Epoch 9831/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 15.1138 - accuracy: 0.9404 - val_loss: 422.4039 - val_accuracy: 0.5031\n",
            "Epoch 9832/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 45.1882 - accuracy: 0.9334 - val_loss: 14.6250 - val_accuracy: 0.6197\n",
            "Epoch 9833/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 33.0416 - accuracy: 0.7396 - val_loss: 84.7495 - val_accuracy: 0.2454\n",
            "Epoch 9834/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 13.7829 - accuracy: 0.3719 - val_loss: 6.3475 - val_accuracy: 0.5984\n",
            "Epoch 9835/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 24.1531 - accuracy: 0.9456 - val_loss: 128.1041 - val_accuracy: 0.9770\n",
            "Epoch 9836/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 16.5015 - accuracy: 0.3580 - val_loss: 9.3857 - val_accuracy: 0.7877\n",
            "Epoch 9837/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 31.3583 - accuracy: 0.4715 - val_loss: 120.0679 - val_accuracy: 0.1393\n",
            "Epoch 9838/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 15.7877 - accuracy: 0.9152 - val_loss: 23062.8789 - val_accuracy: 0.4620\n",
            "Epoch 9839/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 538.2750 - accuracy: 0.6848 - val_loss: 46.4120 - val_accuracy: 0.6917\n",
            "Epoch 9840/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 12.4967 - accuracy: 0.3519 - val_loss: 20.1901 - val_accuracy: 0.1721\n",
            "Epoch 9841/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 40.9317 - accuracy: 0.1206 - val_loss: 4.8870 - val_accuracy: 0.7386\n",
            "Epoch 9842/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 455.2512 - accuracy: 0.8537 - val_loss: 16.6622 - val_accuracy: 0.5023\n",
            "Epoch 9843/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 31.4075 - accuracy: 0.9782 - val_loss: 423.2043 - val_accuracy: 0.2117\n",
            "Epoch 9844/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 17.4292 - accuracy: 0.3613 - val_loss: 26.7992 - val_accuracy: 0.3977\n",
            "Epoch 9845/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 40.7703 - accuracy: 0.9580 - val_loss: 117.8128 - val_accuracy: 0.8712\n",
            "Epoch 9846/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 17.2002 - accuracy: 0.4389 - val_loss: 179.3292 - val_accuracy: 0.9006\n",
            "Epoch 9847/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 16.9933 - accuracy: 0.3160 - val_loss: 358.8398 - val_accuracy: 0.8433\n",
            "Epoch 9848/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 51.2067 - accuracy: 0.8465 - val_loss: 22.7764 - val_accuracy: 0.7413\n",
            "Epoch 9849/24392\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 9.1376 - accuracy: 0.6927 - val_loss: 12.6605 - val_accuracy: 0.3406\n",
            "Epoch 9850/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 19.7940 - accuracy: 0.4803 - val_loss: 15.3207 - val_accuracy: 0.3841\n",
            "Epoch 9851/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 15.2394 - accuracy: 0.3926 - val_loss: 5.3251 - val_accuracy: 0.9245\n",
            "Epoch 9852/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 1111.5218 - accuracy: 0.1806 - val_loss: 25.3881 - val_accuracy: 0.2704\n",
            "Epoch 9853/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 48.6569 - accuracy: 0.9133 - val_loss: 80.3094 - val_accuracy: 0.2307\n",
            "Epoch 9854/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 125.9163 - accuracy: 0.9784 - val_loss: 8.8276 - val_accuracy: 0.7245\n",
            "Epoch 9855/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 4.5695 - accuracy: 0.8847 - val_loss: 8712.7783 - val_accuracy: 0.5680\n",
            "Epoch 9856/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 16.6154 - accuracy: 0.8498 - val_loss: 244.4064 - val_accuracy: 0.9583\n",
            "Epoch 9857/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 103.1557 - accuracy: 0.0377 - val_loss: 20.2589 - val_accuracy: 0.0905\n",
            "Epoch 9858/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 42.7821 - accuracy: 0.8409 - val_loss: 136.4672 - val_accuracy: 0.0530\n",
            "Epoch 9859/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 133.0114 - accuracy: 0.8351 - val_loss: 68.2372 - val_accuracy: 0.2429\n",
            "Epoch 9860/24392\n",
            "4/4 [==============================] - 1s 196ms/step - loss: 53.5925 - accuracy: 0.8735 - val_loss: 15.3796 - val_accuracy: 0.2398\n",
            "Epoch 9861/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 37.0656 - accuracy: 0.9676 - val_loss: 1795.3790 - val_accuracy: 0.1363\n",
            "Epoch 9862/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 39.9089 - accuracy: 0.9204 - val_loss: 45.8353 - val_accuracy: 0.0640\n",
            "Epoch 9863/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 37.1717 - accuracy: 0.9608 - val_loss: 36.4875 - val_accuracy: 0.1273\n",
            "Epoch 9864/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 38.2610 - accuracy: 0.1930 - val_loss: 10.2009 - val_accuracy: 0.1468\n",
            "Epoch 9865/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 11.1132 - accuracy: 0.9959 - val_loss: 12.1282 - val_accuracy: 0.0793\n",
            "Epoch 9866/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 17.9080 - accuracy: 0.5911 - val_loss: 23.9739 - val_accuracy: 0.0997\n",
            "Epoch 9867/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 28.4610 - accuracy: 0.2337 - val_loss: 27.2678 - val_accuracy: 0.1515\n",
            "Epoch 9868/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 59.0545 - accuracy: 0.9298 - val_loss: 59.7877 - val_accuracy: 0.0524\n",
            "Epoch 9869/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.1529 - accuracy: 1.0000 - val_loss: 10.9010 - val_accuracy: 0.2759\n",
            "Epoch 9870/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 374.2410 - accuracy: 0.8404 - val_loss: 11.6732 - val_accuracy: 0.1585\n",
            "Epoch 9871/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 12.6524 - accuracy: 0.6855 - val_loss: 51.5610 - val_accuracy: 0.1490\n",
            "Epoch 9872/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 78.1870 - accuracy: 0.9716 - val_loss: 69.5461 - val_accuracy: 0.1283\n",
            "Epoch 9873/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 87.3980 - accuracy: 0.9493 - val_loss: 23.3655 - val_accuracy: 0.0819\n",
            "Epoch 9874/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 22.0271 - accuracy: 0.6306 - val_loss: 36.3318 - val_accuracy: 0.1327\n",
            "Epoch 9875/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 12.4506 - accuracy: 0.4599 - val_loss: 34.5272 - val_accuracy: 0.1088\n",
            "Epoch 9876/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 42.3333 - accuracy: 0.8325 - val_loss: 41.5284 - val_accuracy: 0.1911\n",
            "Epoch 9877/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 83.6932 - accuracy: 0.7942 - val_loss: 341.5187 - val_accuracy: 0.1404\n",
            "Epoch 9878/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 566.9585 - accuracy: 0.8515 - val_loss: 20.0666 - val_accuracy: 0.1833\n",
            "Epoch 9879/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 47.8494 - accuracy: 0.3484 - val_loss: 18.0782 - val_accuracy: 0.2525\n",
            "Epoch 9880/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 9.8690 - accuracy: 0.8220 - val_loss: 28.2622 - val_accuracy: 0.2265\n",
            "Epoch 9881/24392\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 93.6100 - accuracy: 0.9378 - val_loss: 42.6241 - val_accuracy: 0.1042\n",
            "Epoch 9882/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 144.4840 - accuracy: 0.6538 - val_loss: 55.5032 - val_accuracy: 0.1089\n",
            "Epoch 9883/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 26.9884 - accuracy: 0.3051 - val_loss: 35.6820 - val_accuracy: 0.0738\n",
            "Epoch 9884/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 477.5751 - accuracy: 0.8291 - val_loss: 16.1541 - val_accuracy: 0.2601\n",
            "Epoch 9885/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 23.8789 - accuracy: 0.1602 - val_loss: 15.6611 - val_accuracy: 0.2921\n",
            "Epoch 9886/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 15.0829 - accuracy: 0.4408 - val_loss: 2831.7656 - val_accuracy: 0.0409\n",
            "Epoch 9887/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 12.3283 - accuracy: 0.7097 - val_loss: 98.1885 - val_accuracy: 0.0200\n",
            "Epoch 9888/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 20.2493 - accuracy: 0.9196 - val_loss: 95.9660 - val_accuracy: 0.0428\n",
            "Epoch 9889/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 15.6729 - accuracy: 0.3165 - val_loss: 42.9390 - val_accuracy: 0.1049\n",
            "Epoch 9890/24392\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 18.0351 - accuracy: 0.3141 - val_loss: 37.9582 - val_accuracy: 0.0891\n",
            "Epoch 9891/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 572.3316 - accuracy: 0.3221 - val_loss: 20.7752 - val_accuracy: 0.1187\n",
            "Epoch 9892/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 166.3274 - accuracy: 0.7960 - val_loss: 22396.6152 - val_accuracy: 0.0875\n",
            "Epoch 9893/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 152.5384 - accuracy: 0.8862 - val_loss: 106.8214 - val_accuracy: 0.0168\n",
            "Epoch 9894/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 359.8432 - accuracy: 0.8818 - val_loss: 409.0120 - val_accuracy: 0.0106\n",
            "Epoch 9895/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 681.0396 - accuracy: 0.4307 - val_loss: 48.4867 - val_accuracy: 0.0612\n",
            "Epoch 9896/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 13.8564 - accuracy: 0.5097 - val_loss: 54.2966 - val_accuracy: 0.1158\n",
            "Epoch 9897/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 81.8311 - accuracy: 0.1036 - val_loss: 259.7840 - val_accuracy: 0.0211\n",
            "Epoch 9898/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 806.1590 - accuracy: 0.8922 - val_loss: 2365.0916 - val_accuracy: 0.0145\n",
            "Epoch 9899/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 17.8503 - accuracy: 0.3258 - val_loss: 43.8008 - val_accuracy: 0.0925\n",
            "Epoch 9900/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 15.0533 - accuracy: 0.3110 - val_loss: 2381.2410 - val_accuracy: 0.0014\n",
            "Epoch 9901/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 493.3634 - accuracy: 0.8690 - val_loss: 22.3403 - val_accuracy: 0.1556\n",
            "Epoch 9902/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 19.6608 - accuracy: 0.4684 - val_loss: 93.7510 - val_accuracy: 0.0341\n",
            "Epoch 9903/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 14.1700 - accuracy: 0.9612 - val_loss: 108.0641 - val_accuracy: 0.1221\n",
            "Epoch 9904/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 38.4714 - accuracy: 0.9263 - val_loss: 98.3522 - val_accuracy: 0.1632\n",
            "Epoch 9905/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 15.6141 - accuracy: 0.8792 - val_loss: 1810.3280 - val_accuracy: 0.1215\n",
            "Epoch 9906/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 23.3745 - accuracy: 0.2972 - val_loss: 1827.0314 - val_accuracy: 0.0972\n",
            "Epoch 9907/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 1341.0283 - accuracy: 0.6963 - val_loss: 18.3469 - val_accuracy: 0.0856\n",
            "Epoch 9908/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 90.2736 - accuracy: 0.9437 - val_loss: 27.3600 - val_accuracy: 0.1284\n",
            "Epoch 9909/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 11.8768 - accuracy: 0.9619 - val_loss: 20.7181 - val_accuracy: 0.2347\n",
            "Epoch 9910/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 85.4021 - accuracy: 0.8125 - val_loss: 46.5713 - val_accuracy: 0.1635\n",
            "Epoch 9911/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 15.9544 - accuracy: 0.6735 - val_loss: 67.1433 - val_accuracy: 0.1209\n",
            "Epoch 9912/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 35.0332 - accuracy: 0.4470 - val_loss: 1515.9702 - val_accuracy: 0.0202\n",
            "Epoch 9913/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 16.8795 - accuracy: 0.8961 - val_loss: 20.4140 - val_accuracy: 0.1679\n",
            "Epoch 9914/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 19.1862 - accuracy: 0.4167 - val_loss: 388.1760 - val_accuracy: 0.0400\n",
            "Epoch 9915/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 9.8913 - accuracy: 0.7678 - val_loss: 34.5669 - val_accuracy: 0.0913\n",
            "Epoch 9916/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 8.8297 - accuracy: 0.7232 - val_loss: 40.3726 - val_accuracy: 0.1273\n",
            "Epoch 9917/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 15.1480 - accuracy: 0.8652 - val_loss: 36.5743 - val_accuracy: 0.1917\n",
            "Epoch 9918/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 87.3340 - accuracy: 0.9155 - val_loss: 37.3879 - val_accuracy: 0.1563\n",
            "Epoch 9919/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 45.6022 - accuracy: 0.0863 - val_loss: 276.4024 - val_accuracy: 0.0721\n",
            "Epoch 9920/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 28.5697 - accuracy: 0.8222 - val_loss: 14.9045 - val_accuracy: 0.2918\n",
            "Epoch 9921/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 58.0391 - val_accuracy: 0.1210\n",
            "Epoch 9922/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 12.0903 - accuracy: 0.6803 - val_loss: 42.1942 - val_accuracy: 0.2727\n",
            "Epoch 9923/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 24.5589 - accuracy: 0.6477 - val_loss: 24.4714 - val_accuracy: 0.1889\n",
            "Epoch 9924/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 12.0122 - accuracy: 0.7784 - val_loss: 42.3124 - val_accuracy: 0.1467\n",
            "Epoch 9925/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 9.8096 - accuracy: 0.9483 - val_loss: 20.5429 - val_accuracy: 0.1806\n",
            "Epoch 9926/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 4282.8513 - accuracy: 0.5882 - val_loss: 18.2140 - val_accuracy: 0.2395\n",
            "Epoch 9927/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 38.8568 - accuracy: 0.3571 - val_loss: 16.0599 - val_accuracy: 0.2193\n",
            "Epoch 9928/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 253.0982 - accuracy: 0.6069 - val_loss: 21.1208 - val_accuracy: 0.2781\n",
            "Epoch 9929/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 119.4956 - accuracy: 0.1860 - val_loss: 59.1371 - val_accuracy: 0.1617\n",
            "Epoch 9930/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 76.9396 - accuracy: 0.5667 - val_loss: 56.3544 - val_accuracy: 0.0239\n",
            "Epoch 9931/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 26.8140 - accuracy: 0.2318 - val_loss: 69.5144 - val_accuracy: 0.1952\n",
            "Epoch 9932/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 170.7592 - accuracy: 0.7110 - val_loss: 104.8875 - val_accuracy: 0.0760\n",
            "Epoch 9933/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 16.7891 - accuracy: 0.5886 - val_loss: 49.6931 - val_accuracy: 0.0831\n",
            "Epoch 9934/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 14.2280 - accuracy: 0.9842 - val_loss: 42.3887 - val_accuracy: 0.1584\n",
            "Epoch 9935/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 75.1662 - accuracy: 0.0971 - val_loss: 21.6621 - val_accuracy: 0.0971\n",
            "Epoch 9936/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 599.5418 - accuracy: 0.8371 - val_loss: 227.2473 - val_accuracy: 0.0427\n",
            "Epoch 9937/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 15.8392 - accuracy: 0.4518 - val_loss: 689.0879 - val_accuracy: 0.0516\n",
            "Epoch 9938/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 18.9415 - accuracy: 0.8488 - val_loss: 1644.1875 - val_accuracy: 0.0273\n",
            "Epoch 9939/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 20.4186 - accuracy: 0.8030 - val_loss: 1199.3436 - val_accuracy: 0.0401\n",
            "Epoch 9940/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 134.5331 - accuracy: 0.3531 - val_loss: 33.7763 - val_accuracy: 0.1562\n",
            "Epoch 9941/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 19.8573 - accuracy: 0.3392 - val_loss: 18.3924 - val_accuracy: 0.2632\n",
            "Epoch 9942/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 31.9751 - accuracy: 0.3326 - val_loss: 28.2691 - val_accuracy: 0.1465\n",
            "Epoch 9943/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 122.7064 - accuracy: 0.9910 - val_loss: 10.5080 - val_accuracy: 0.2663\n",
            "Epoch 9944/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 58.5177 - accuracy: 0.2132 - val_loss: 2942.3318 - val_accuracy: 0.0098\n",
            "Epoch 9945/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 13.3029 - accuracy: 0.6015 - val_loss: 18.9067 - val_accuracy: 0.1793\n",
            "Epoch 9946/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 33.7898 - val_accuracy: 0.2652\n",
            "Epoch 9947/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 11.9579 - accuracy: 0.9845 - val_loss: 55.5119 - val_accuracy: 0.1741\n",
            "Epoch 9948/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 17.1019 - accuracy: 0.8277 - val_loss: 1632.1941 - val_accuracy: 0.0710\n",
            "Epoch 9949/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 32.5254 - accuracy: 0.1516 - val_loss: 151.3705 - val_accuracy: 0.0460\n",
            "Epoch 9950/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 253.6983 - accuracy: 0.5942 - val_loss: 69.3171 - val_accuracy: 0.1465\n",
            "Epoch 9951/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 25.4737 - accuracy: 0.9019 - val_loss: 27.1311 - val_accuracy: 0.2104\n",
            "Epoch 9952/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 101.3752 - accuracy: 0.9244 - val_loss: 54.0048 - val_accuracy: 0.1579\n",
            "Epoch 9953/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 17.9606 - accuracy: 0.9704 - val_loss: 1529.4406 - val_accuracy: 0.0936\n",
            "Epoch 9954/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 21.3085 - accuracy: 0.5718 - val_loss: 35.4200 - val_accuracy: 0.1993\n",
            "Epoch 9955/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 14.9097 - accuracy: 0.4256 - val_loss: 14.4727 - val_accuracy: 0.2912\n",
            "Epoch 9956/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 192.0331 - accuracy: 0.8084 - val_loss: 31.5601 - val_accuracy: 0.0503\n",
            "Epoch 9957/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 106.1750 - val_accuracy: 0.0876\n",
            "Epoch 9958/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 73.2090 - accuracy: 0.9483 - val_loss: 23.9320 - val_accuracy: 0.0907\n",
            "Epoch 9959/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 23.5528 - accuracy: 0.3821 - val_loss: 51.3655 - val_accuracy: 0.1817\n",
            "Epoch 9960/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 236.8200 - accuracy: 0.8609 - val_loss: 26.3575 - val_accuracy: 0.1460\n",
            "Epoch 9961/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 25.0948 - accuracy: 0.9385 - val_loss: 1178.5635 - val_accuracy: 0.0183\n",
            "Epoch 9962/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 20.5690 - accuracy: 0.5218 - val_loss: 284.7137 - val_accuracy: 0.0718\n",
            "Epoch 9963/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 17.8490 - accuracy: 0.4417 - val_loss: 95.0195 - val_accuracy: 0.0814\n",
            "Epoch 9964/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 17.9114 - accuracy: 0.7847 - val_loss: 1060.1627 - val_accuracy: 0.0020\n",
            "Epoch 9965/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 1344.0500 - accuracy: 0.8225 - val_loss: 48.1350 - val_accuracy: 0.2133\n",
            "Epoch 9966/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 32.8601 - val_accuracy: 0.1097\n",
            "Epoch 9967/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 145.4603 - accuracy: 0.0019 - val_loss: 129.1923 - val_accuracy: 0.0550\n",
            "Epoch 9968/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 2259.6152 - accuracy: 0.6998 - val_loss: 12.9695 - val_accuracy: 0.3706\n",
            "Epoch 9969/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 10.9224 - accuracy: 0.8381 - val_loss: 42.6957 - val_accuracy: 0.1002\n",
            "Epoch 9970/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 17.5372 - accuracy: 0.9401 - val_loss: 32.7415 - val_accuracy: 0.0825\n",
            "Epoch 9971/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 587.5998 - accuracy: 0.7393 - val_loss: 931.4834 - val_accuracy: 0.2347\n",
            "Epoch 9972/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 35.8967 - accuracy: 0.3122 - val_loss: 13.5576 - val_accuracy: 0.2726\n",
            "Epoch 9973/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 24.4270 - accuracy: 0.9363 - val_loss: 47.0280 - val_accuracy: 0.0773\n",
            "Epoch 9974/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 66.8303 - accuracy: 0.9069 - val_loss: 28.4509 - val_accuracy: 0.1603\n",
            "Epoch 9975/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 235.7708 - accuracy: 0.6424 - val_loss: 16.9580 - val_accuracy: 0.2134\n",
            "Epoch 9976/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 4117.8343 - accuracy: 0.4259 - val_loss: 40.1137 - val_accuracy: 0.1887\n",
            "Epoch 9977/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 57.6952 - accuracy: 0.2904 - val_loss: 183.7094 - val_accuracy: 0.1099\n",
            "Epoch 9978/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 22.9510 - val_accuracy: 0.1902\n",
            "Epoch 9979/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 302.0248 - accuracy: 0.7465 - val_loss: 1137.2062 - val_accuracy: 0.1279\n",
            "Epoch 9980/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 25.5263 - accuracy: 0.3702 - val_loss: 16.6313 - val_accuracy: 0.1622\n",
            "Epoch 9981/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 134.8610 - accuracy: 0.8948 - val_loss: 24.6898 - val_accuracy: 0.2095\n",
            "Epoch 9982/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 18.9604 - accuracy: 0.5863 - val_loss: 689.6815 - val_accuracy: 0.0499\n",
            "Epoch 9983/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 19.4453 - accuracy: 0.4172 - val_loss: 42.1322 - val_accuracy: 0.0848\n",
            "Epoch 9984/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 66.3788 - accuracy: 0.1452 - val_loss: 48.7792 - val_accuracy: 0.1073\n",
            "Epoch 9985/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 17.1858 - accuracy: 0.9702 - val_loss: 61.0125 - val_accuracy: 0.1061\n",
            "Epoch 9986/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 18.8048 - accuracy: 0.6900 - val_loss: 201.6816 - val_accuracy: 0.0281\n",
            "Epoch 9987/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 16.6497 - accuracy: 0.3779 - val_loss: 1271.0371 - val_accuracy: 0.0247\n",
            "Epoch 9988/24392\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 8.6004 - accuracy: 0.7295 - val_loss: 1113.8912 - val_accuracy: 0.1244\n",
            "Epoch 9989/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 8.1378 - accuracy: 0.9929 - val_loss: 36.2852 - val_accuracy: 0.1494\n",
            "Epoch 9990/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 507.8315 - accuracy: 0.5256 - val_loss: 1067.2568 - val_accuracy: 0.0343\n",
            "Epoch 9991/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 17.1838 - accuracy: 0.8632 - val_loss: 991.7701 - val_accuracy: 0.1733\n",
            "Epoch 9992/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 28.4601 - accuracy: 0.9430 - val_loss: 30.5390 - val_accuracy: 0.1994\n",
            "Epoch 9993/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 39.1851 - accuracy: 0.9612 - val_loss: 13.2125 - val_accuracy: 0.2591\n",
            "Epoch 9994/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 16.4851 - accuracy: 0.8363 - val_loss: 44.4295 - val_accuracy: 0.0725\n",
            "Epoch 9995/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 15.8062 - accuracy: 0.9576 - val_loss: 894.4302 - val_accuracy: 0.0603\n",
            "Epoch 9996/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 33.9126 - accuracy: 0.4045 - val_loss: 150.4742 - val_accuracy: 0.0570\n",
            "Epoch 9997/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 144.4111 - accuracy: 0.7732 - val_loss: 377.2019 - val_accuracy: 5.3641e-04\n",
            "Epoch 9998/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 14.9697 - accuracy: 0.6987 - val_loss: 64.5850 - val_accuracy: 0.0979\n",
            "Epoch 9999/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 33.0707 - accuracy: 0.6475 - val_loss: 74.5249 - val_accuracy: 0.0837\n",
            "Epoch 10000/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 18.3409 - accuracy: 0.3592 - val_loss: 26.9078 - val_accuracy: 0.1262\n",
            "Epoch 10001/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 1657.9298 - accuracy: 0.5701 - val_loss: 1511.0674 - val_accuracy: 0.0505\n",
            "Epoch 10002/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 38.4401 - accuracy: 0.2376 - val_loss: 265.8768 - val_accuracy: 0.0712\n",
            "Epoch 10003/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 308.7416 - accuracy: 0.4698 - val_loss: 34.1504 - val_accuracy: 0.0552\n",
            "Epoch 10004/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 11.7187 - accuracy: 0.4063 - val_loss: 121.6470 - val_accuracy: 0.1298\n",
            "Epoch 10005/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 499.7698 - accuracy: 0.5955 - val_loss: 85.3315 - val_accuracy: 0.1532\n",
            "Epoch 10006/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 33.5481 - accuracy: 0.3419 - val_loss: 57.5334 - val_accuracy: 0.1331\n",
            "Epoch 10007/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 51.2554 - accuracy: 0.3230 - val_loss: 15.6234 - val_accuracy: 0.1961\n",
            "Epoch 10008/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 148.1755 - accuracy: 0.1344 - val_loss: 147.7030 - val_accuracy: 0.1088\n",
            "Epoch 10009/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 263.0101 - accuracy: 0.7694 - val_loss: 55.9797 - val_accuracy: 0.1260\n",
            "Epoch 10010/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 12.3345 - accuracy: 0.6196 - val_loss: 18.0016 - val_accuracy: 0.1986\n",
            "Epoch 10011/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 72.8093 - accuracy: 0.0714 - val_loss: 68.1375 - val_accuracy: 0.1003\n",
            "Epoch 10012/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 35.8901 - accuracy: 0.9512 - val_loss: 100.9199 - val_accuracy: 0.1185\n",
            "Epoch 10013/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 8.5235 - accuracy: 0.7775 - val_loss: 19.5476 - val_accuracy: 0.2095\n",
            "Epoch 10014/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 23.7002 - accuracy: 0.3295 - val_loss: 39.1034 - val_accuracy: 0.1630\n",
            "Epoch 10015/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 12.2549 - accuracy: 0.7770 - val_loss: 20.2822 - val_accuracy: 0.1416\n",
            "Epoch 10016/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 86.1949 - accuracy: 0.1114 - val_loss: 26.8385 - val_accuracy: 0.1453\n",
            "Epoch 10017/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 0.8137 - accuracy: 0.9997 - val_loss: 10.0858 - val_accuracy: 0.2682\n",
            "Epoch 10018/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 71.4896 - accuracy: 0.8982 - val_loss: 1382.8207 - val_accuracy: 0.0985\n",
            "Epoch 10019/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 89.0016 - accuracy: 0.2053 - val_loss: 240.3719 - val_accuracy: 0.0720\n",
            "Epoch 10020/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 8.5883 - accuracy: 0.8196 - val_loss: 20.5345 - val_accuracy: 0.1750\n",
            "Epoch 10021/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 375.6694 - accuracy: 0.7239 - val_loss: 70.3440 - val_accuracy: 0.1407\n",
            "Epoch 10022/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 21.7949 - accuracy: 0.9361 - val_loss: 64.2426 - val_accuracy: 0.0909\n",
            "Epoch 10023/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 23.1470 - accuracy: 0.8928 - val_loss: 40.3642 - val_accuracy: 0.0951\n",
            "Epoch 10024/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 17.4257 - accuracy: 0.9261 - val_loss: 22.4948 - val_accuracy: 0.1980\n",
            "Epoch 10025/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 7.7374 - accuracy: 0.9224 - val_loss: 102.7041 - val_accuracy: 0.0369\n",
            "Epoch 10026/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 58.1970 - accuracy: 0.9021 - val_loss: 58.2106 - val_accuracy: 0.1974\n",
            "Epoch 10027/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 25.2761 - accuracy: 0.2277 - val_loss: 59.2605 - val_accuracy: 0.2375\n",
            "Epoch 10028/24392\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 209.3875 - accuracy: 0.8545 - val_loss: 86.6169 - val_accuracy: 0.1186\n",
            "Epoch 10029/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 137.6394 - accuracy: 0.8624 - val_loss: 277.4914 - val_accuracy: 0.1416\n",
            "Epoch 10030/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 1409.2944 - accuracy: 0.8984 - val_loss: 2810.0793 - val_accuracy: 0.1805\n",
            "Epoch 10031/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 11.6443 - accuracy: 0.3481 - val_loss: 1814.8317 - val_accuracy: 0.0236\n",
            "Epoch 10032/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 46.9132 - accuracy: 0.3504 - val_loss: 1011.0483 - val_accuracy: 0.0628\n",
            "Epoch 10033/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 20.1488 - accuracy: 0.6217 - val_loss: 524.1893 - val_accuracy: 0.0754\n",
            "Epoch 10034/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 53.6159 - accuracy: 0.9028 - val_loss: 16.6020 - val_accuracy: 0.2447\n",
            "Epoch 10035/24392\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 29.0463 - accuracy: 0.5786 - val_loss: 1578.2372 - val_accuracy: 0.0953\n",
            "Epoch 10036/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 15.6606 - accuracy: 0.2425 - val_loss: 1216.3658 - val_accuracy: 0.1347\n",
            "Epoch 10037/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 8.9672 - accuracy: 0.7923 - val_loss: 30.6163 - val_accuracy: 0.1589\n",
            "Epoch 10038/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 57.0907 - accuracy: 0.8820 - val_loss: 1640.4373 - val_accuracy: 0.1511\n",
            "Epoch 10039/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 32.2415 - val_accuracy: 0.3030\n",
            "Epoch 10040/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 18.0201 - accuracy: 0.2696 - val_loss: 30.3757 - val_accuracy: 0.1171\n",
            "Epoch 10041/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 15.7804 - accuracy: 0.9791 - val_loss: 26.6041 - val_accuracy: 0.1519\n",
            "Epoch 10042/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 19.2681 - accuracy: 0.8140 - val_loss: 33.0999 - val_accuracy: 0.1078\n",
            "Epoch 10043/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 17.3510 - accuracy: 0.8104 - val_loss: 671.2963 - val_accuracy: 0.0465\n",
            "Epoch 10044/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 89.6447 - accuracy: 0.9475 - val_loss: 103.3953 - val_accuracy: 0.0394\n",
            "Epoch 10045/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 122.8833 - accuracy: 0.2159 - val_loss: 1241.9512 - val_accuracy: 0.1093\n",
            "Epoch 10046/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 5320.0237 - accuracy: 0.6136 - val_loss: 52.7973 - val_accuracy: 0.1913\n",
            "Epoch 10047/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 24.5791 - accuracy: 0.3621 - val_loss: 203.7598 - val_accuracy: 0.1553\n",
            "Epoch 10048/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 53.7434 - accuracy: 0.9638 - val_loss: 31.2196 - val_accuracy: 0.2330\n",
            "Epoch 10049/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 38.8945 - accuracy: 0.9310 - val_loss: 16.7352 - val_accuracy: 0.1283\n",
            "Epoch 10050/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 16.3382 - accuracy: 0.3422 - val_loss: 747.7724 - val_accuracy: 0.1170\n",
            "Epoch 10051/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 7.4240 - accuracy: 0.7225 - val_loss: 12.8554 - val_accuracy: 0.2083\n",
            "Epoch 10052/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 14.8347 - accuracy: 0.9057 - val_loss: 15.6523 - val_accuracy: 0.0955\n",
            "Epoch 10053/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 21.9403 - accuracy: 0.3909 - val_loss: 803.2031 - val_accuracy: 0.1517\n",
            "Epoch 10054/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 111.0276 - accuracy: 0.1145 - val_loss: 43.8771 - val_accuracy: 0.1614\n",
            "Epoch 10055/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 53.8978 - accuracy: 0.9764 - val_loss: 16.1259 - val_accuracy: 0.1813\n",
            "Epoch 10056/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 29.6546 - accuracy: 0.9641 - val_loss: 1140.7178 - val_accuracy: 0.0749\n",
            "Epoch 10057/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 28.9233 - accuracy: 0.9747 - val_loss: 20.3974 - val_accuracy: 0.2208\n",
            "Epoch 10058/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 18.2321 - accuracy: 0.4707 - val_loss: 1195.2355 - val_accuracy: 0.2529\n",
            "Epoch 10059/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 165.6333 - accuracy: 0.3652 - val_loss: 115.4953 - val_accuracy: 0.0477\n",
            "Epoch 10060/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 19.4329 - accuracy: 0.6872 - val_loss: 416.5776 - val_accuracy: 0.0498\n",
            "Epoch 10061/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 23.7483 - accuracy: 0.9322 - val_loss: 246035.3594 - val_accuracy: 0.0318\n",
            "Epoch 10062/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 106.6615 - accuracy: 0.8376 - val_loss: 16.4518 - val_accuracy: 0.1769\n",
            "Epoch 10063/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 442.2054 - accuracy: 0.6266 - val_loss: 89.4583 - val_accuracy: 0.0667\n",
            "Epoch 10064/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 417.5931 - accuracy: 0.5980 - val_loss: 62.7250 - val_accuracy: 0.0328\n",
            "Epoch 10065/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 34.5185 - accuracy: 0.9537 - val_loss: 19.6121 - val_accuracy: 0.1351\n",
            "Epoch 10066/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 14.6474 - accuracy: 0.2788 - val_loss: 1714.6886 - val_accuracy: 0.0553\n",
            "Epoch 10067/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 14.4180 - accuracy: 0.5386 - val_loss: 1575.9570 - val_accuracy: 0.0937\n",
            "Epoch 10068/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 1097.5069 - accuracy: 0.5131 - val_loss: 23.2390 - val_accuracy: 0.1820\n",
            "Epoch 10069/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 64.1491 - accuracy: 0.8804 - val_loss: 1350.2607 - val_accuracy: 0.1210\n",
            "Epoch 10070/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 58.1776 - accuracy: 0.1335 - val_loss: 1562.3413 - val_accuracy: 0.1228\n",
            "Epoch 10071/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 60.9868 - accuracy: 0.9371 - val_loss: 22.7058 - val_accuracy: 0.1825\n",
            "Epoch 10072/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 2196.5165 - accuracy: 0.9574 - val_loss: 80.6810 - val_accuracy: 0.0558\n",
            "Epoch 10073/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 0.5260 - accuracy: 1.0000 - val_loss: 1264.3516 - val_accuracy: 0.0859\n",
            "Epoch 10074/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 63.2614 - accuracy: 0.9630 - val_loss: 50.0385 - val_accuracy: 0.0696\n",
            "Epoch 10075/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 25.7919 - accuracy: 0.1850 - val_loss: 25.9954 - val_accuracy: 0.0749\n",
            "Epoch 10076/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 20.4941 - accuracy: 0.2364 - val_loss: 19.7964 - val_accuracy: 0.1165\n",
            "Epoch 10077/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 13.8630 - accuracy: 0.6070 - val_loss: 24.0459 - val_accuracy: 0.2090\n",
            "Epoch 10078/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 49.4759 - accuracy: 0.9668 - val_loss: 417.6812 - val_accuracy: 0.0717\n",
            "Epoch 10079/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 17.9742 - accuracy: 0.2536 - val_loss: 22.1572 - val_accuracy: 0.1020\n",
            "Epoch 10080/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 14.1015 - accuracy: 0.7640 - val_loss: 16.1228 - val_accuracy: 0.2409\n",
            "Epoch 10081/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 15.6235 - accuracy: 0.4095 - val_loss: 10983.7275 - val_accuracy: 0.0207\n",
            "Epoch 10082/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 18.0970 - accuracy: 0.2771 - val_loss: 107.4499 - val_accuracy: 0.1221\n",
            "Epoch 10083/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 47.5631 - accuracy: 0.1243 - val_loss: 32.8418 - val_accuracy: 0.2154\n",
            "Epoch 10084/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 167.1820 - accuracy: 0.6114 - val_loss: 52.6676 - val_accuracy: 0.1283\n",
            "Epoch 10085/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 241.8558 - accuracy: 0.5717 - val_loss: 938.9023 - val_accuracy: 0.2348\n",
            "Epoch 10086/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 75.0490 - accuracy: 0.9623 - val_loss: 27.5797 - val_accuracy: 0.2293\n",
            "Epoch 10087/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 103.6186 - accuracy: 0.7837 - val_loss: 670.9191 - val_accuracy: 0.3317\n",
            "Epoch 10088/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 917.3290 - accuracy: 0.7162 - val_loss: 1407.8672 - val_accuracy: 0.1318\n",
            "Epoch 10089/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 6.5704 - accuracy: 0.8259 - val_loss: 56.9019 - val_accuracy: 0.1226\n",
            "Epoch 10090/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 10.5147 - accuracy: 0.8346 - val_loss: 115.2896 - val_accuracy: 0.0839\n",
            "Epoch 10091/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 58.4705 - accuracy: 0.9888 - val_loss: 1123.9713 - val_accuracy: 0.1026\n",
            "Epoch 10092/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 13.0553 - accuracy: 0.8808 - val_loss: 1101.0986 - val_accuracy: 0.0979\n",
            "Epoch 10093/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 23.8467 - accuracy: 0.5932 - val_loss: 153.9942 - val_accuracy: 0.0930\n",
            "Epoch 10094/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 14.3666 - accuracy: 0.7849 - val_loss: 23.3001 - val_accuracy: 0.1946\n",
            "Epoch 10095/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 27.6468 - accuracy: 0.3314 - val_loss: 740.8398 - val_accuracy: 0.0997\n",
            "Epoch 10096/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 20.1414 - accuracy: 0.3029 - val_loss: 13.8235 - val_accuracy: 0.2615\n",
            "Epoch 10097/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 879.3588 - accuracy: 0.4019 - val_loss: 26.3165 - val_accuracy: 0.1321\n",
            "Epoch 10098/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 412.3838 - accuracy: 0.4341 - val_loss: 18.4883 - val_accuracy: 0.2361\n",
            "Epoch 10099/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 10.0508 - accuracy: 0.7640 - val_loss: 18.1495 - val_accuracy: 0.2081\n",
            "Epoch 10100/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 282.6653 - accuracy: 0.8784 - val_loss: 240.2055 - val_accuracy: 0.0617\n",
            "Epoch 10101/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 478.1392 - accuracy: 0.5987 - val_loss: 60.2250 - val_accuracy: 0.0900\n",
            "Epoch 10102/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 12.0839 - accuracy: 0.9258 - val_loss: 29.0358 - val_accuracy: 0.1973\n",
            "Epoch 10103/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 31.9938 - accuracy: 0.3954 - val_loss: 10.1643 - val_accuracy: 0.1859\n",
            "Epoch 10104/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 16.8811 - accuracy: 0.5005 - val_loss: 27.6789 - val_accuracy: 0.2226\n",
            "Epoch 10105/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 15.5632 - accuracy: 0.8523 - val_loss: 63.4264 - val_accuracy: 0.1222\n",
            "Epoch 10106/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 13.1184 - accuracy: 0.5878 - val_loss: 66.0614 - val_accuracy: 0.0488\n",
            "Epoch 10107/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 13.8859 - accuracy: 0.3504 - val_loss: 40.1813 - val_accuracy: 0.1537\n",
            "Epoch 10108/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 21.4308 - accuracy: 0.9294 - val_loss: 409.1749 - val_accuracy: 0.4530\n",
            "Epoch 10109/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 22.6733 - accuracy: 0.9916 - val_loss: 23.3249 - val_accuracy: 0.1667\n",
            "Epoch 10110/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 11.5393 - accuracy: 0.7906 - val_loss: 20.6242 - val_accuracy: 0.1399\n",
            "Epoch 10111/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 60.9245 - accuracy: 0.9216 - val_loss: 25.6912 - val_accuracy: 0.1998\n",
            "Epoch 10112/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 125.8680 - accuracy: 0.7331 - val_loss: 111.5482 - val_accuracy: 0.1894\n",
            "Epoch 10113/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 126.5634 - accuracy: 0.9031 - val_loss: 55.1028 - val_accuracy: 0.2041\n",
            "Epoch 10114/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 157.2357 - accuracy: 0.8313 - val_loss: 507.6179 - val_accuracy: 0.1343\n",
            "Epoch 10115/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 32.3837 - accuracy: 0.9636 - val_loss: 34.3791 - val_accuracy: 0.1533\n",
            "Epoch 10116/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 61.6565 - accuracy: 0.8492 - val_loss: 154.2244 - val_accuracy: 0.1399\n",
            "Epoch 10117/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 23.1102 - accuracy: 0.4628 - val_loss: 18.4078 - val_accuracy: 0.2301\n",
            "Epoch 10118/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 18.3948 - accuracy: 0.3039 - val_loss: 16.8304 - val_accuracy: 0.1680\n",
            "Epoch 10119/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 1471.7333 - accuracy: 0.3564 - val_loss: 13.2680 - val_accuracy: 0.2494\n",
            "Epoch 10120/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 13.8733 - accuracy: 0.9113 - val_loss: 93.5978 - val_accuracy: 0.1915\n",
            "Epoch 10121/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 26.8669 - accuracy: 0.7742 - val_loss: 969.7972 - val_accuracy: 0.1722\n",
            "Epoch 10122/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 10.7222 - accuracy: 0.3830 - val_loss: 41.8430 - val_accuracy: 0.1447\n",
            "Epoch 10123/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 141.2879 - accuracy: 0.9907 - val_loss: 34.6559 - val_accuracy: 0.2240\n",
            "Epoch 10124/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 189.0053 - accuracy: 0.9278 - val_loss: 435.1387 - val_accuracy: 0.1328\n",
            "Epoch 10125/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 40.6709 - accuracy: 0.1155 - val_loss: 387.0211 - val_accuracy: 0.1917\n",
            "Epoch 10126/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 14.6350 - accuracy: 0.8113 - val_loss: 34.6519 - val_accuracy: 0.3680\n",
            "Epoch 10127/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 298.5205 - accuracy: 0.6240 - val_loss: 439.1428 - val_accuracy: 0.1446\n",
            "Epoch 10128/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 159.2628 - accuracy: 0.2145 - val_loss: 871.6588 - val_accuracy: 0.1196\n",
            "Epoch 10129/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 118.1366 - accuracy: 0.9457 - val_loss: 26.5684 - val_accuracy: 0.2803\n",
            "Epoch 10130/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 98.3925 - accuracy: 0.4399 - val_loss: 10.6655 - val_accuracy: 0.3001\n",
            "Epoch 10131/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 31.3285 - accuracy: 0.3559 - val_loss: 18.8759 - val_accuracy: 0.2865\n",
            "Epoch 10132/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 24.3801 - accuracy: 0.6833 - val_loss: 18.3802 - val_accuracy: 0.2700\n",
            "Epoch 10133/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 66.1616 - accuracy: 0.9666 - val_loss: 16.7212 - val_accuracy: 0.1777\n",
            "Epoch 10134/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 44.8612 - accuracy: 0.2076 - val_loss: 36.6945 - val_accuracy: 0.2011\n",
            "Epoch 10135/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 15.6713 - accuracy: 0.3916 - val_loss: 35.6155 - val_accuracy: 0.1976\n",
            "Epoch 10136/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 141.5927 - accuracy: 0.9199 - val_loss: 89.1796 - val_accuracy: 0.0839\n",
            "Epoch 10137/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 49.8842 - accuracy: 0.4162 - val_loss: 353.3517 - val_accuracy: 0.1081\n",
            "Epoch 10138/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 266.4534 - accuracy: 0.8529 - val_loss: 286.0451 - val_accuracy: 0.3006\n",
            "Epoch 10139/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 754.3664 - accuracy: 0.3222 - val_loss: 22.8223 - val_accuracy: 0.5277\n",
            "Epoch 10140/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 43.4175 - accuracy: 0.8879 - val_loss: 15.6092 - val_accuracy: 0.2579\n",
            "Epoch 10141/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 94.9576 - accuracy: 0.6519 - val_loss: 316.4009 - val_accuracy: 0.3518\n",
            "Epoch 10142/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 232.8320 - accuracy: 0.8114 - val_loss: 19.9708 - val_accuracy: 0.1645\n",
            "Epoch 10143/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 39.0227 - accuracy: 0.9890 - val_loss: 266.0063 - val_accuracy: 0.0629\n",
            "Epoch 10144/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 22.3824 - accuracy: 0.2935 - val_loss: 28.6586 - val_accuracy: 0.1395\n",
            "Epoch 10145/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 65.1149 - accuracy: 0.4236 - val_loss: 52.7197 - val_accuracy: 0.2095\n",
            "Epoch 10146/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 24.4879 - accuracy: 0.4042 - val_loss: 1448.5438 - val_accuracy: 0.1085\n",
            "Epoch 10147/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 971.4004 - accuracy: 0.6479 - val_loss: 186.7728 - val_accuracy: 0.0712\n",
            "Epoch 10148/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 18.0130 - accuracy: 0.3263 - val_loss: 7677.7070 - val_accuracy: 0.1172\n",
            "Epoch 10149/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 62.1481 - accuracy: 0.2366 - val_loss: 14.7920 - val_accuracy: 0.2773\n",
            "Epoch 10150/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 12.9981 - accuracy: 0.8403 - val_loss: 43.1861 - val_accuracy: 0.1935\n",
            "Epoch 10151/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 29.5492 - accuracy: 0.8937 - val_loss: 143.0768 - val_accuracy: 0.0971\n",
            "Epoch 10152/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 828.9983 - accuracy: 0.5128 - val_loss: 407.4748 - val_accuracy: 0.1085\n",
            "Epoch 10153/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 100.8800 - accuracy: 0.1875 - val_loss: 537.2300 - val_accuracy: 0.1911\n",
            "Epoch 10154/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 6.7328 - accuracy: 0.7565 - val_loss: 29.6133 - val_accuracy: 0.2132\n",
            "Epoch 10155/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 313.1083 - accuracy: 0.9289 - val_loss: 78.0206 - val_accuracy: 0.3214\n",
            "Epoch 10156/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 121.9818 - accuracy: 0.9101 - val_loss: 26.0810 - val_accuracy: 0.2284\n",
            "Epoch 10157/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 13.3987 - accuracy: 0.9238 - val_loss: 49.9367 - val_accuracy: 0.2574\n",
            "Epoch 10158/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 12.5532 - accuracy: 0.8177 - val_loss: 27.5667 - val_accuracy: 0.2303\n",
            "Epoch 10159/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 94.7761 - accuracy: 0.4304 - val_loss: 815.4328 - val_accuracy: 0.1561\n",
            "Epoch 10160/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 185.1079 - accuracy: 0.8502 - val_loss: 10.6736 - val_accuracy: 0.3227\n",
            "Epoch 10161/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 21.4925 - accuracy: 0.2864 - val_loss: 233.0248 - val_accuracy: 0.0544\n",
            "Epoch 10162/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 12.8419 - accuracy: 0.3435 - val_loss: 789.3926 - val_accuracy: 0.1011\n",
            "Epoch 10163/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 13.3533 - accuracy: 0.6726 - val_loss: 17.1127 - val_accuracy: 0.2272\n",
            "Epoch 10164/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 9.8238 - accuracy: 0.6426 - val_loss: 14.9251 - val_accuracy: 0.2951\n",
            "Epoch 10165/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 1813.8545 - accuracy: 0.5088 - val_loss: 18.6821 - val_accuracy: 0.2375\n",
            "Epoch 10166/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 51.4511 - accuracy: 0.8402 - val_loss: 11.5677 - val_accuracy: 0.1755\n",
            "Epoch 10167/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 32.7399 - accuracy: 0.7446 - val_loss: 171.5582 - val_accuracy: 0.0985\n",
            "Epoch 10168/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 11.6122 - accuracy: 0.8935 - val_loss: 109.6691 - val_accuracy: 0.0930\n",
            "Epoch 10169/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 12.8644 - accuracy: 0.4225 - val_loss: 28.5061 - val_accuracy: 0.1452\n",
            "Epoch 10170/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 49.2467 - accuracy: 0.5393 - val_loss: 982.0614 - val_accuracy: 0.1027\n",
            "Epoch 10171/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 12.5981 - accuracy: 0.7795 - val_loss: 79.0321 - val_accuracy: 0.0922\n",
            "Epoch 10172/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 27.0644 - accuracy: 0.4996 - val_loss: 2897.4124 - val_accuracy: 0.1633\n",
            "Epoch 10173/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 31.4990 - accuracy: 0.3457 - val_loss: 10.1261 - val_accuracy: 0.2432\n",
            "Epoch 10174/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 1794.9168 - accuracy: 0.6344 - val_loss: 785.3793 - val_accuracy: 0.0865\n",
            "Epoch 10175/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 17.0020 - accuracy: 0.3616 - val_loss: 24.1724 - val_accuracy: 0.1975\n",
            "Epoch 10176/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 21.9491 - accuracy: 0.2759 - val_loss: 95.8160 - val_accuracy: 0.1780\n",
            "Epoch 10177/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 53.5051 - accuracy: 0.9149 - val_loss: 12.0326 - val_accuracy: 0.2064\n",
            "Epoch 10178/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 1403.8968 - accuracy: 0.2767 - val_loss: 24.6694 - val_accuracy: 0.1517\n",
            "Epoch 10179/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 54.9462 - accuracy: 0.9914 - val_loss: 10.5240 - val_accuracy: 0.2761\n",
            "Epoch 10180/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 22.5388 - accuracy: 0.6415 - val_loss: 105.5958 - val_accuracy: 0.2693\n",
            "Epoch 10181/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 40.9600 - accuracy: 0.8775 - val_loss: 31.4086 - val_accuracy: 0.2465\n",
            "Epoch 10182/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 358.9434 - accuracy: 0.8280 - val_loss: 7.8317 - val_accuracy: 0.2600\n",
            "Epoch 10183/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 18.9554 - accuracy: 0.3318 - val_loss: 871.1704 - val_accuracy: 0.1474\n",
            "Epoch 10184/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 14.6332 - accuracy: 0.8496 - val_loss: 149.3007 - val_accuracy: 0.1674\n",
            "Epoch 10185/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 42.3192 - accuracy: 0.1113 - val_loss: 909.1201 - val_accuracy: 0.1429\n",
            "Epoch 10186/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 29.4752 - accuracy: 0.8119 - val_loss: 24.0368 - val_accuracy: 0.2117\n",
            "Epoch 10187/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 36.8461 - accuracy: 0.9669 - val_loss: 109.9547 - val_accuracy: 0.0742\n",
            "Epoch 10188/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 408.1560 - accuracy: 0.5780 - val_loss: 22.8806 - val_accuracy: 0.2226\n",
            "Epoch 10189/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 130.3348 - accuracy: 0.7408 - val_loss: 87.6517 - val_accuracy: 0.2271\n",
            "Epoch 10190/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 192.3309 - accuracy: 0.9825 - val_loss: 75.6983 - val_accuracy: 0.1154\n",
            "Epoch 10191/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 10.3274 - accuracy: 0.9644 - val_loss: 9.3739 - val_accuracy: 0.1655\n",
            "Epoch 10192/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 538.5773 - accuracy: 0.6573 - val_loss: 196.4863 - val_accuracy: 0.1060\n",
            "Epoch 10193/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 264.4393 - accuracy: 0.5482 - val_loss: 515.0811 - val_accuracy: 0.1718\n",
            "Epoch 10194/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 37.1892 - accuracy: 0.8684 - val_loss: 45.5334 - val_accuracy: 0.2363\n",
            "Epoch 10195/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 114.5564 - accuracy: 0.5060 - val_loss: 562.7349 - val_accuracy: 0.1328\n",
            "Epoch 10196/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 7712.5396 - accuracy: 0.3838 - val_loss: 72.0305 - val_accuracy: 0.0616\n",
            "Epoch 10197/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 45.2749 - accuracy: 0.2786 - val_loss: 55.6726 - val_accuracy: 0.1502\n",
            "Epoch 10198/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 447.8959 - accuracy: 0.4946 - val_loss: 16.4873 - val_accuracy: 0.1934\n",
            "Epoch 10199/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 17.5529 - accuracy: 0.2479 - val_loss: 22.1689 - val_accuracy: 0.2461\n",
            "Epoch 10200/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 13.2218 - accuracy: 0.3380 - val_loss: 1105.7823 - val_accuracy: 0.1110\n",
            "Epoch 10201/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 16.7928 - accuracy: 0.6188 - val_loss: 58.0284 - val_accuracy: 0.1439\n",
            "Epoch 10202/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 360.0919 - accuracy: 0.5977 - val_loss: 196.6101 - val_accuracy: 0.1172\n",
            "Epoch 10203/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 16.1739 - accuracy: 0.4163 - val_loss: 49.7966 - val_accuracy: 0.1261\n",
            "Epoch 10204/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 15.7235 - accuracy: 0.4097 - val_loss: 248.9241 - val_accuracy: 0.1237\n",
            "Epoch 10205/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 9.1125 - accuracy: 0.8525 - val_loss: 25.9288 - val_accuracy: 0.1457\n",
            "Epoch 10206/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 24.8004 - accuracy: 0.2626 - val_loss: 66.1824 - val_accuracy: 0.1986\n",
            "Epoch 10207/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 10.2586 - accuracy: 0.7464 - val_loss: 970.5941 - val_accuracy: 0.1270\n",
            "Epoch 10208/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 8.4971 - accuracy: 0.8954 - val_loss: 9.5527 - val_accuracy: 0.2847\n",
            "Epoch 10209/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 188.8833 - accuracy: 0.9954 - val_loss: 17.6371 - val_accuracy: 0.3287\n",
            "Epoch 10210/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 12.2783 - accuracy: 0.3828 - val_loss: 18.6430 - val_accuracy: 0.1803\n",
            "Epoch 10211/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 100.0368 - accuracy: 0.8943 - val_loss: 28.1787 - val_accuracy: 0.1189\n",
            "Epoch 10212/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 54.0096 - accuracy: 0.9452 - val_loss: 1165.7328 - val_accuracy: 0.0890\n",
            "Epoch 10213/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 27.8997 - accuracy: 0.8740 - val_loss: 1219.0582 - val_accuracy: 0.0838\n",
            "Epoch 10214/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 12.3011 - accuracy: 0.7118 - val_loss: 14.4922 - val_accuracy: 0.2569\n",
            "Epoch 10215/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 10.5250 - accuracy: 0.5666 - val_loss: 15.6997 - val_accuracy: 0.2312\n",
            "Epoch 10216/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 36.1720 - accuracy: 0.9578 - val_loss: 94.9423 - val_accuracy: 0.1402\n",
            "Epoch 10217/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 12.5275 - accuracy: 0.8274 - val_loss: 23.7163 - val_accuracy: 0.2425\n",
            "Epoch 10218/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 26.8704 - accuracy: 0.5916 - val_loss: 13.5411 - val_accuracy: 0.2625\n",
            "Epoch 10219/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 133.9113 - accuracy: 0.7503 - val_loss: 9.5649 - val_accuracy: 0.1198\n",
            "Epoch 10220/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 572.2634 - accuracy: 0.4912 - val_loss: 107.9582 - val_accuracy: 0.0552\n",
            "Epoch 10221/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 0.1184 - accuracy: 1.0000 - val_loss: 32.9585 - val_accuracy: 0.2661\n",
            "Epoch 10222/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 9.7444 - accuracy: 0.4770 - val_loss: 45.1280 - val_accuracy: 0.1444\n",
            "Epoch 10223/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 476.0243 - accuracy: 0.9260 - val_loss: 498136.8125 - val_accuracy: 0.0475\n",
            "Epoch 10224/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 39.8247 - accuracy: 0.9392 - val_loss: 11903.1328 - val_accuracy: 0.1081\n",
            "Epoch 10225/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 64.4674 - accuracy: 0.9232 - val_loss: 28.5241 - val_accuracy: 0.1238\n",
            "Epoch 10226/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 16.3553 - accuracy: 0.8466 - val_loss: 13.1712 - val_accuracy: 0.2356\n",
            "Epoch 10227/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 41.1876 - accuracy: 0.9466 - val_loss: 17.3369 - val_accuracy: 0.0755\n",
            "Epoch 10228/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 19.3551 - accuracy: 0.3196 - val_loss: 19.9806 - val_accuracy: 0.2282\n",
            "Epoch 10229/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 19.0959 - accuracy: 0.3236 - val_loss: 13.4515 - val_accuracy: 0.3123\n",
            "Epoch 10230/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 23246.7803 - accuracy: 0.5013 - val_loss: 14.6285 - val_accuracy: 0.1578\n",
            "Epoch 10231/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 142.7818 - accuracy: 0.8051 - val_loss: 49.4229 - val_accuracy: 0.0684\n",
            "Epoch 10232/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 23.6022 - accuracy: 0.3006 - val_loss: 15.0243 - val_accuracy: 0.2134\n",
            "Epoch 10233/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 6.9519 - accuracy: 0.8401 - val_loss: 181.8127 - val_accuracy: 0.0833\n",
            "Epoch 10234/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 24.9300 - accuracy: 0.2242 - val_loss: 24.9553 - val_accuracy: 0.1743\n",
            "Epoch 10235/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 13.3436 - accuracy: 0.7514 - val_loss: 18.9753 - val_accuracy: 0.1210\n",
            "Epoch 10236/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 116.5068 - accuracy: 0.8551 - val_loss: 33.3564 - val_accuracy: 0.1132\n",
            "Epoch 10237/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 10.4504 - accuracy: 0.9118 - val_loss: 1151.0922 - val_accuracy: 0.1421\n",
            "Epoch 10238/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 11.5034 - accuracy: 0.9824 - val_loss: 14.2011 - val_accuracy: 0.1735\n",
            "Epoch 10239/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 24.1786 - accuracy: 0.1804 - val_loss: 38.8699 - val_accuracy: 0.0270\n",
            "Epoch 10240/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 12.5014 - accuracy: 0.6760 - val_loss: 1019.3710 - val_accuracy: 0.1387\n",
            "Epoch 10241/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 396.0540 - accuracy: 0.8260 - val_loss: 28.0987 - val_accuracy: 0.1345\n",
            "Epoch 10242/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 17.4184 - accuracy: 0.9460 - val_loss: 10.1799 - val_accuracy: 0.1144\n",
            "Epoch 10243/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 537.5399 - accuracy: 0.6114 - val_loss: 14.9902 - val_accuracy: 0.1540\n",
            "Epoch 10244/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 20789.8656 - accuracy: 0.6518 - val_loss: 554.1643 - val_accuracy: 0.0380\n",
            "Epoch 10245/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 12.1738 - accuracy: 0.5317 - val_loss: 27.3263 - val_accuracy: 0.2014\n",
            "Epoch 10246/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 14.2960 - accuracy: 0.5358 - val_loss: 19.1867 - val_accuracy: 0.1083\n",
            "Epoch 10247/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 61.0667 - accuracy: 0.9302 - val_loss: 80.4583 - val_accuracy: 0.0892\n",
            "Epoch 10248/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 8.4124 - accuracy: 0.6053 - val_loss: 50.0044 - val_accuracy: 0.0789\n",
            "Epoch 10249/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 49.1120 - accuracy: 0.9713 - val_loss: 393.2331 - val_accuracy: 0.0362\n",
            "Epoch 10250/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 10.7688 - accuracy: 0.9962 - val_loss: 17.1719 - val_accuracy: 0.2585\n",
            "Epoch 10251/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 12.2049 - accuracy: 0.3987 - val_loss: 1839.5706 - val_accuracy: 0.0554\n",
            "Epoch 10252/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 1490.2139 - accuracy: 0.8555 - val_loss: 8.9805 - val_accuracy: 0.2390\n",
            "Epoch 10253/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 146.1092 - accuracy: 0.9456 - val_loss: 528.3735 - val_accuracy: 0.0493\n",
            "Epoch 10254/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 9.9717 - accuracy: 0.5658 - val_loss: 423.8154 - val_accuracy: 0.0294\n",
            "Epoch 10255/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 161.1288 - accuracy: 0.6754 - val_loss: 364.6039 - val_accuracy: 0.0250\n",
            "Epoch 10256/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 55.6475 - accuracy: 0.9333 - val_loss: 382.1388 - val_accuracy: 0.0494\n",
            "Epoch 10257/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 12.2911 - accuracy: 0.3619 - val_loss: 27.0006 - val_accuracy: 0.1990\n",
            "Epoch 10258/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 3.7243 - accuracy: 0.9960 - val_loss: 49.0164 - val_accuracy: 0.0463\n",
            "Epoch 10259/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 219.5706 - val_accuracy: 0.0927\n",
            "Epoch 10260/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 17.3280 - accuracy: 0.2757 - val_loss: 38.0849 - val_accuracy: 0.1826\n",
            "Epoch 10261/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 36.9658 - accuracy: 0.9757 - val_loss: 184.2075 - val_accuracy: 0.0587\n",
            "Epoch 10262/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 1163.4768 - accuracy: 0.6917 - val_loss: 10.2472 - val_accuracy: 0.2051\n",
            "Epoch 10263/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 18.2643 - accuracy: 0.8434 - val_loss: 21.8043 - val_accuracy: 0.0667\n",
            "Epoch 10264/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 541.9797 - accuracy: 0.2670 - val_loss: 604.9787 - val_accuracy: 0.0398\n",
            "Epoch 10265/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 41.8840 - accuracy: 0.2910 - val_loss: 355.4800 - val_accuracy: 0.0547\n",
            "Epoch 10266/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 12.3578 - accuracy: 0.8615 - val_loss: 21.9747 - val_accuracy: 0.0844\n",
            "Epoch 10267/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 122.1284 - accuracy: 0.1972 - val_loss: 26.0166 - val_accuracy: 0.2059\n",
            "Epoch 10268/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 29.9749 - accuracy: 0.2438 - val_loss: 1183.0397 - val_accuracy: 0.1002\n",
            "Epoch 10269/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 251.6814 - accuracy: 0.8707 - val_loss: 17.7542 - val_accuracy: 0.2381\n",
            "Epoch 10270/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 8.0353 - accuracy: 0.4349 - val_loss: 1456.5372 - val_accuracy: 0.0940\n",
            "Epoch 10271/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 38.3540 - accuracy: 0.2287 - val_loss: 124.2532 - val_accuracy: 0.1111\n",
            "Epoch 10272/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 31.6334 - accuracy: 0.6178 - val_loss: 113.7659 - val_accuracy: 0.1855\n",
            "Epoch 10273/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 12.6601 - accuracy: 0.8553 - val_loss: 29.5374 - val_accuracy: 0.1725\n",
            "Epoch 10274/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 22.2137 - accuracy: 0.7836 - val_loss: 34921.7070 - val_accuracy: 0.0454\n",
            "Epoch 10275/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 22.4288 - accuracy: 0.6696 - val_loss: 19.1509 - val_accuracy: 0.1616\n",
            "Epoch 10276/24392\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 19.7220 - accuracy: 0.3495 - val_loss: 32.8347 - val_accuracy: 0.1441\n",
            "Epoch 10277/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 8.8373 - accuracy: 0.9379 - val_loss: 772.1146 - val_accuracy: 0.0977\n",
            "Epoch 10278/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 22.8017 - accuracy: 0.9702 - val_loss: 41.0141 - val_accuracy: 0.1129\n",
            "Epoch 10279/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 308.6989 - accuracy: 0.6631 - val_loss: 69.9335 - val_accuracy: 0.1415\n",
            "Epoch 10280/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 7.4889 - accuracy: 0.8529 - val_loss: 178.2456 - val_accuracy: 0.0321\n",
            "Epoch 10281/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 7.5875 - accuracy: 0.8595 - val_loss: 579.5032 - val_accuracy: 0.0731\n",
            "Epoch 10282/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 46.2300 - accuracy: 0.8337 - val_loss: 32.7199 - val_accuracy: 0.1270\n",
            "Epoch 10283/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 12.5108 - accuracy: 0.6622 - val_loss: 36.3198 - val_accuracy: 0.1949\n",
            "Epoch 10284/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 63.2428 - accuracy: 0.1806 - val_loss: 29.8996 - val_accuracy: 0.2286\n",
            "Epoch 10285/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 792.7442 - val_accuracy: 0.0750\n",
            "Epoch 10286/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 30.0546 - accuracy: 0.2834 - val_loss: 15.6562 - val_accuracy: 0.1440\n",
            "Epoch 10287/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 53.2990 - accuracy: 0.9264 - val_loss: 794.0430 - val_accuracy: 0.0409\n",
            "Epoch 10288/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 145.4332 - accuracy: 0.3491 - val_loss: 11.3309 - val_accuracy: 0.3057\n",
            "Epoch 10289/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 25.5818 - accuracy: 0.3135 - val_loss: 42.1469 - val_accuracy: 0.1998\n",
            "Epoch 10290/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 1155.1659 - accuracy: 0.6547 - val_loss: 12.6984 - val_accuracy: 0.3160\n",
            "Epoch 10291/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 149.7433 - accuracy: 0.8080 - val_loss: 2312.0603 - val_accuracy: 0.1909\n",
            "Epoch 10292/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 37.4268 - accuracy: 0.9625 - val_loss: 14.4271 - val_accuracy: 0.1287\n",
            "Epoch 10293/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 9.9258 - accuracy: 0.3897 - val_loss: 967.7637 - val_accuracy: 0.0740\n",
            "Epoch 10294/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 11.2317 - accuracy: 0.7854 - val_loss: 857.5361 - val_accuracy: 0.0821\n",
            "Epoch 10295/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 10.2131 - accuracy: 0.8172 - val_loss: 528.2028 - val_accuracy: 0.2173\n",
            "Epoch 10296/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 26.9959 - accuracy: 0.3037 - val_loss: 13.7009 - val_accuracy: 0.2909\n",
            "Epoch 10297/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 26.6298 - accuracy: 0.9362 - val_loss: 5219.2896 - val_accuracy: 0.0106\n",
            "Epoch 10298/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 520.4718 - accuracy: 0.5734 - val_loss: 122.0977 - val_accuracy: 0.1111\n",
            "Epoch 10299/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 16.2980 - accuracy: 0.8381 - val_loss: 10.6034 - val_accuracy: 0.2620\n",
            "Epoch 10300/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 85.9757 - accuracy: 0.6208 - val_loss: 1028.1456 - val_accuracy: 0.1015\n",
            "Epoch 10301/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 18.8584 - accuracy: 0.7999 - val_loss: 49.0897 - val_accuracy: 0.1827\n",
            "Epoch 10302/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 10.4496 - accuracy: 0.9043 - val_loss: 423.2527 - val_accuracy: 0.2176\n",
            "Epoch 10303/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 11.1618 - accuracy: 0.3186 - val_loss: 15.2668 - val_accuracy: 0.2647\n",
            "Epoch 10304/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 14.3717 - accuracy: 0.7582 - val_loss: 21.2655 - val_accuracy: 0.1497\n",
            "Epoch 10305/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 13.7815 - accuracy: 0.8810 - val_loss: 39.5109 - val_accuracy: 0.2529\n",
            "Epoch 10306/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 87.1704 - accuracy: 0.8594 - val_loss: 897.7974 - val_accuracy: 0.1736\n",
            "Epoch 10307/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 21.0629 - accuracy: 0.7742 - val_loss: 58.3666 - val_accuracy: 0.0918\n",
            "Epoch 10308/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 11.9175 - accuracy: 0.8777 - val_loss: 421.9297 - val_accuracy: 0.1287\n",
            "Epoch 10309/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 40.1140 - accuracy: 0.9517 - val_loss: 379.9419 - val_accuracy: 0.1249\n",
            "Epoch 10310/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 154.7270 - accuracy: 0.6472 - val_loss: 12.9419 - val_accuracy: 0.1353\n",
            "Epoch 10311/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 13.3569 - accuracy: 0.8979 - val_loss: 14.1228 - val_accuracy: 0.1215\n",
            "Epoch 10312/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 21.2809 - accuracy: 0.2984 - val_loss: 1108.1740 - val_accuracy: 0.1628\n",
            "Epoch 10313/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 51.6043 - accuracy: 0.9661 - val_loss: 19.6808 - val_accuracy: 0.1244\n",
            "Epoch 10314/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 33.8013 - accuracy: 0.9716 - val_loss: 13.2150 - val_accuracy: 0.1561\n",
            "Epoch 10315/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 0.4218 - accuracy: 0.9999 - val_loss: 21.8351 - val_accuracy: 0.2111\n",
            "Epoch 10316/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 10.2534 - accuracy: 0.9023 - val_loss: 12.5562 - val_accuracy: 0.3015\n",
            "Epoch 10317/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 468.3395 - accuracy: 0.5053 - val_loss: 195.1662 - val_accuracy: 0.4508\n",
            "Epoch 10318/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 39.0553 - accuracy: 0.5525 - val_loss: 8.4314 - val_accuracy: 0.1481\n",
            "Epoch 10319/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 18.4672 - accuracy: 0.3003 - val_loss: 46.2086 - val_accuracy: 0.2185\n",
            "Epoch 10320/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 69.6069 - accuracy: 0.8656 - val_loss: 13.1298 - val_accuracy: 0.3210\n",
            "Epoch 10321/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 10.9092 - accuracy: 0.9385 - val_loss: 1071.8710 - val_accuracy: 0.2551\n",
            "Epoch 10322/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 10.7784 - accuracy: 0.9409 - val_loss: 12.8045 - val_accuracy: 0.1120\n",
            "Epoch 10323/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 9.1766 - accuracy: 0.8274 - val_loss: 672.3774 - val_accuracy: 0.1729\n",
            "Epoch 10324/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 22.3223 - accuracy: 0.3241 - val_loss: 214.9417 - val_accuracy: 0.1326\n",
            "Epoch 10325/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 840.1672 - accuracy: 0.8031 - val_loss: 8.6602 - val_accuracy: 0.1149\n",
            "Epoch 10326/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 26.1177 - accuracy: 0.1272 - val_loss: 64.1996 - val_accuracy: 0.1501\n",
            "Epoch 10327/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 90.6564 - accuracy: 0.3467 - val_loss: 42.9006 - val_accuracy: 0.1314\n",
            "Epoch 10328/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 16.8338 - accuracy: 0.9459 - val_loss: 25.9155 - val_accuracy: 0.2266\n",
            "Epoch 10329/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 26.0808 - accuracy: 0.9455 - val_loss: 40.3559 - val_accuracy: 0.1481\n",
            "Epoch 10330/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 199.6083 - accuracy: 0.9004 - val_loss: 17.5552 - val_accuracy: 0.2022\n",
            "Epoch 10331/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 49250.2185 - accuracy: 0.3723 - val_loss: 11.0972 - val_accuracy: 0.0886\n",
            "Epoch 10332/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 11.2600 - accuracy: 0.8675 - val_loss: 27.4249 - val_accuracy: 0.2372\n",
            "Epoch 10333/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 20.6726 - accuracy: 0.2532 - val_loss: 46.4131 - val_accuracy: 0.1558\n",
            "Epoch 10334/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 536.7985 - accuracy: 0.5166 - val_loss: 31.1925 - val_accuracy: 0.0876\n",
            "Epoch 10335/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 112.2219 - accuracy: 0.8177 - val_loss: 149.2516 - val_accuracy: 0.0223\n",
            "Epoch 10336/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 40.2962 - accuracy: 0.3220 - val_loss: 13.3530 - val_accuracy: 0.2304\n",
            "Epoch 10337/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 16.0675 - accuracy: 0.6080 - val_loss: 14.4193 - val_accuracy: 0.2394\n",
            "Epoch 10338/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 30.6952 - accuracy: 0.2580 - val_loss: 852.2553 - val_accuracy: 0.0125\n",
            "Epoch 10339/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 906.5487 - accuracy: 0.3775 - val_loss: 822.2914 - val_accuracy: 0.0712\n",
            "Epoch 10340/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 144.4726 - accuracy: 0.6398 - val_loss: 439.6626 - val_accuracy: 0.0294\n",
            "Epoch 10341/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 14.2384 - accuracy: 0.9968 - val_loss: 728.8413 - val_accuracy: 0.0476\n",
            "Epoch 10342/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 31.3721 - accuracy: 0.9647 - val_loss: 27.6519 - val_accuracy: 0.2678\n",
            "Epoch 10343/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 32.3126 - accuracy: 0.2209 - val_loss: 28.3781 - val_accuracy: 0.1662\n",
            "Epoch 10344/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 36.3398 - accuracy: 0.9585 - val_loss: 44.8091 - val_accuracy: 0.1538\n",
            "Epoch 10345/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 253.0264 - accuracy: 0.8714 - val_loss: 115.9516 - val_accuracy: 0.0162\n",
            "Epoch 10346/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 63.0421 - accuracy: 0.9384 - val_loss: 21.6565 - val_accuracy: 0.1171\n",
            "Epoch 10347/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 12.1738 - accuracy: 0.6358 - val_loss: 14.8829 - val_accuracy: 0.0337\n",
            "Epoch 10348/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 94.9144 - accuracy: 0.4416 - val_loss: 105.2961 - val_accuracy: 0.0373\n",
            "Epoch 10349/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 11.6829 - accuracy: 0.8390 - val_loss: 7382.6997 - val_accuracy: 0.0953\n",
            "Epoch 10350/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 22.3860 - accuracy: 0.9059 - val_loss: 44.5431 - val_accuracy: 0.0943\n",
            "Epoch 10351/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 13.1408 - accuracy: 0.5779 - val_loss: 66.5722 - val_accuracy: 0.1332\n",
            "Epoch 10352/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 105.7064 - accuracy: 0.3369 - val_loss: 126.4685 - val_accuracy: 0.0572\n",
            "Epoch 10353/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 35.9561 - accuracy: 0.9660 - val_loss: 38.0289 - val_accuracy: 0.2146\n",
            "Epoch 10354/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 68.9174 - accuracy: 0.8482 - val_loss: 13.6186 - val_accuracy: 0.1940\n",
            "Epoch 10355/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 19.8779 - accuracy: 0.8082 - val_loss: 466.8142 - val_accuracy: 0.0051\n",
            "Epoch 10356/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 32.1936 - accuracy: 0.5041 - val_loss: 20.7512 - val_accuracy: 0.1345\n",
            "Epoch 10357/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 26.8471 - accuracy: 0.3669 - val_loss: 18.9136 - val_accuracy: 0.2194\n",
            "Epoch 10358/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 16.2950 - accuracy: 0.8791 - val_loss: 27.8326 - val_accuracy: 0.1397\n",
            "Epoch 10359/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 254.9355 - accuracy: 0.7055 - val_loss: 570.4734 - val_accuracy: 0.0624\n",
            "Epoch 10360/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 71.2889 - accuracy: 0.3178 - val_loss: 220.2742 - val_accuracy: 0.0166\n",
            "Epoch 10361/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 13.4506 - accuracy: 0.9841 - val_loss: 28.3650 - val_accuracy: 0.2323\n",
            "Epoch 10362/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 41.6734 - accuracy: 0.9806 - val_loss: 214.9282 - val_accuracy: 0.0396\n",
            "Epoch 10363/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 14.5048 - accuracy: 0.8446 - val_loss: 31.7065 - val_accuracy: 0.1104\n",
            "Epoch 10364/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 19.5013 - accuracy: 0.2894 - val_loss: 115.8558 - val_accuracy: 0.1327\n",
            "Epoch 10365/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 34.0386 - accuracy: 0.9454 - val_loss: 440.2311 - val_accuracy: 0.0493\n",
            "Epoch 10366/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 304.7508 - accuracy: 0.8432 - val_loss: 281.8724 - val_accuracy: 0.3253\n",
            "Epoch 10367/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 124.9484 - accuracy: 0.8807 - val_loss: 1683.1945 - val_accuracy: 0.1434\n",
            "Epoch 10368/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 14.2939 - accuracy: 0.7330 - val_loss: 31.1557 - val_accuracy: 0.1795\n",
            "Epoch 10369/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 5748.5337 - accuracy: 0.5526 - val_loss: 52.1285 - val_accuracy: 0.0478\n",
            "Epoch 10370/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 129.1295 - accuracy: 0.7497 - val_loss: 17.9194 - val_accuracy: 0.0515\n",
            "Epoch 10371/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 81.1432 - accuracy: 0.9029 - val_loss: 18.7957 - val_accuracy: 0.2487\n",
            "Epoch 10372/24392\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 174.5180 - accuracy: 0.2372 - val_loss: 35.5121 - val_accuracy: 0.2190\n",
            "Epoch 10373/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 13.6829 - accuracy: 0.9888 - val_loss: 33.5234 - val_accuracy: 0.1503\n",
            "Epoch 10374/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 12.9245 - accuracy: 0.5950 - val_loss: 135.1710 - val_accuracy: 0.0742\n",
            "Epoch 10375/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 40.1210 - accuracy: 0.9693 - val_loss: 605.0843 - val_accuracy: 0.1262\n",
            "Epoch 10376/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 246.5981 - accuracy: 0.1167 - val_loss: 25.4035 - val_accuracy: 0.2142\n",
            "Epoch 10377/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 49.0226 - accuracy: 0.9630 - val_loss: 288.2217 - val_accuracy: 0.9525\n",
            "Epoch 10378/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 20.0576 - accuracy: 0.9603 - val_loss: 50.4508 - val_accuracy: 0.9225\n",
            "Epoch 10379/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 19.1383 - accuracy: 0.5569 - val_loss: 18.5033 - val_accuracy: 0.8049\n",
            "Epoch 10380/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 18.5569 - accuracy: 0.2141 - val_loss: 15.5399 - val_accuracy: 0.1887\n",
            "Epoch 10381/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 30.3223 - accuracy: 0.3285 - val_loss: 371.5020 - val_accuracy: 0.0390\n",
            "Epoch 10382/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 16.5381 - accuracy: 0.3446 - val_loss: 1494.3322 - val_accuracy: 0.1361\n",
            "Epoch 10383/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 17.6877 - accuracy: 0.4909 - val_loss: 512.8382 - val_accuracy: 0.0791\n",
            "Epoch 10384/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 12.8988 - accuracy: 0.3726 - val_loss: 74.8911 - val_accuracy: 0.0683\n",
            "Epoch 10385/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 29.9212 - val_accuracy: 0.0861\n",
            "Epoch 10386/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 92.6009 - accuracy: 0.5680 - val_loss: 113.6406 - val_accuracy: 0.1019\n",
            "Epoch 10387/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 195.1011 - accuracy: 0.9454 - val_loss: 59.1533 - val_accuracy: 0.0602\n",
            "Epoch 10388/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 39.9201 - accuracy: 0.8654 - val_loss: 1681.8828 - val_accuracy: 0.0837\n",
            "Epoch 10389/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 41.6616 - accuracy: 0.8363 - val_loss: 26.7813 - val_accuracy: 0.1831\n",
            "Epoch 10390/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 86.1634 - accuracy: 0.9154 - val_loss: 17.4620 - val_accuracy: 0.2577\n",
            "Epoch 10391/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 114.4537 - accuracy: 0.0861 - val_loss: 8.8402 - val_accuracy: 0.1935\n",
            "Epoch 10392/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 1950.4442 - accuracy: 0.4768 - val_loss: 44.6165 - val_accuracy: 0.1045\n",
            "Epoch 10393/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 15.2747 - accuracy: 0.3061 - val_loss: 13.5927 - val_accuracy: 0.1138\n",
            "Epoch 10394/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 19.1773 - accuracy: 0.7603 - val_loss: 368.3914 - val_accuracy: 0.0376\n",
            "Epoch 10395/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 62.4225 - val_accuracy: 0.1411\n",
            "Epoch 10396/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 30.8674 - accuracy: 0.9832 - val_loss: 97.9515 - val_accuracy: 0.0407\n",
            "Epoch 10397/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 26.2335 - accuracy: 0.5918 - val_loss: 11.5374 - val_accuracy: 0.1636\n",
            "Epoch 10398/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.6792 - accuracy: 0.9993 - val_loss: 14.9710 - val_accuracy: 0.1956\n",
            "Epoch 10399/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 17.1591 - accuracy: 0.8554 - val_loss: 1668.0350 - val_accuracy: 0.1817\n",
            "Epoch 10400/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 228.0602 - val_accuracy: 0.0281\n",
            "Epoch 10401/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 15.1478 - accuracy: 0.6042 - val_loss: 18.1482 - val_accuracy: 0.2390\n",
            "Epoch 10402/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 3.8769e-04 - accuracy: 1.0000 - val_loss: 273.6497 - val_accuracy: 0.2214\n",
            "Epoch 10403/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 91.2619 - accuracy: 0.2690 - val_loss: 17.4737 - val_accuracy: 0.5128\n",
            "Epoch 10404/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 15.7427 - accuracy: 0.9864 - val_loss: 123.0328 - val_accuracy: 0.3378\n",
            "Epoch 10405/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 15.6764 - accuracy: 0.3593 - val_loss: 357.6524 - val_accuracy: 0.2426\n",
            "Epoch 10406/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 11.2873 - accuracy: 0.9655 - val_loss: 21.1860 - val_accuracy: 0.2228\n",
            "Epoch 10407/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 17.5804 - accuracy: 0.2527 - val_loss: 20.1081 - val_accuracy: 0.1573\n",
            "Epoch 10408/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 41.3070 - accuracy: 0.4157 - val_loss: 383.1117 - val_accuracy: 0.0668\n",
            "Epoch 10409/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 13.6336 - accuracy: 0.8769 - val_loss: 300.5604 - val_accuracy: 0.0647\n",
            "Epoch 10410/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 7.4298 - val_accuracy: 0.2261\n",
            "Epoch 10411/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 2340.9451 - accuracy: 0.5473 - val_loss: 12.8755 - val_accuracy: 0.0921\n",
            "Epoch 10412/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 20.7100 - accuracy: 0.9888 - val_loss: 2141.2207 - val_accuracy: 0.0461\n",
            "Epoch 10413/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 17.1978 - accuracy: 0.8196 - val_loss: 18.9616 - val_accuracy: 0.2859\n",
            "Epoch 10414/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 250.4154 - accuracy: 0.7714 - val_loss: 273.2304 - val_accuracy: 0.0282\n",
            "Epoch 10415/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 23.3163 - accuracy: 0.9424 - val_loss: 38.1282 - val_accuracy: 0.1336\n",
            "Epoch 10416/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 11.3682 - accuracy: 0.8171 - val_loss: 6.6421 - val_accuracy: 0.2291\n",
            "Epoch 10417/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 17.3316 - accuracy: 0.2497 - val_loss: 10.8789 - val_accuracy: 0.2200\n",
            "Epoch 10418/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 74.8817 - accuracy: 0.9378 - val_loss: 88.6816 - val_accuracy: 0.0690\n",
            "Epoch 10419/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 20.3616 - accuracy: 0.9074 - val_loss: 15.2081 - val_accuracy: 0.1981\n",
            "Epoch 10420/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 13.2301 - accuracy: 0.6226 - val_loss: 35.5937 - val_accuracy: 0.1599\n",
            "Epoch 10421/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 273.7421 - accuracy: 0.8594 - val_loss: 487.4356 - val_accuracy: 0.7073\n",
            "Epoch 10422/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 22.0960 - accuracy: 0.9836 - val_loss: 23.2664 - val_accuracy: 0.2503\n",
            "Epoch 10423/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 14.3389 - accuracy: 0.3237 - val_loss: 122.8190 - val_accuracy: 0.0967\n",
            "Epoch 10424/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 10.3243 - accuracy: 0.3612 - val_loss: 16.0580 - val_accuracy: 0.0830\n",
            "Epoch 10425/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 12.1001 - accuracy: 0.7445 - val_loss: 13.8262 - val_accuracy: 0.0894\n",
            "Epoch 10426/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 837.0552 - accuracy: 0.2888 - val_loss: 21.5322 - val_accuracy: 0.2105\n",
            "Epoch 10427/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 18.9806 - accuracy: 0.1845 - val_loss: 58.4286 - val_accuracy: 0.0969\n",
            "Epoch 10428/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 20.7838 - accuracy: 0.7579 - val_loss: 13.0646 - val_accuracy: 0.0999\n",
            "Epoch 10429/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 90.7201 - accuracy: 0.1227 - val_loss: 11.8614 - val_accuracy: 0.2009\n",
            "Epoch 10430/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 15.8370 - accuracy: 0.5034 - val_loss: 14.6544 - val_accuracy: 0.0329\n",
            "Epoch 10431/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 18.8731 - accuracy: 0.3451 - val_loss: 432.3005 - val_accuracy: 0.0295\n",
            "Epoch 10432/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 39.3077 - accuracy: 0.9654 - val_loss: 13.2576 - val_accuracy: 0.2000\n",
            "Epoch 10433/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 11.7376 - accuracy: 0.9322 - val_loss: 590.5897 - val_accuracy: 0.0763\n",
            "Epoch 10434/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 151.0136 - accuracy: 0.6816 - val_loss: 29.9842 - val_accuracy: 0.1770\n",
            "Epoch 10435/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 14.9572 - accuracy: 0.3333 - val_loss: 11.1948 - val_accuracy: 0.1732\n",
            "Epoch 10436/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 12.4693 - accuracy: 0.4254 - val_loss: 396.7509 - val_accuracy: 0.0145\n",
            "Epoch 10437/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 11.6486 - accuracy: 0.3010 - val_loss: 444.4824 - val_accuracy: 0.0655\n",
            "Epoch 10438/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 238.9090 - accuracy: 0.4853 - val_loss: 16.2704 - val_accuracy: 0.1664\n",
            "Epoch 10439/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 64.3732 - accuracy: 0.8978 - val_loss: 18.8090 - val_accuracy: 0.1979\n",
            "Epoch 10440/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 16.4591 - accuracy: 0.3154 - val_loss: 2260.2393 - val_accuracy: 0.0790\n",
            "Epoch 10441/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 316.5876 - accuracy: 0.7188 - val_loss: 116.8412 - val_accuracy: 0.0485\n",
            "Epoch 10442/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 80.5873 - accuracy: 0.8212 - val_loss: 53.2015 - val_accuracy: 0.0903\n",
            "Epoch 10443/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 23.9774 - accuracy: 0.2744 - val_loss: 15.1481 - val_accuracy: 0.1551\n",
            "Epoch 10444/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 47.9732 - accuracy: 0.9369 - val_loss: 21.2611 - val_accuracy: 0.1459\n",
            "Epoch 10445/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 27.9676 - accuracy: 0.9685 - val_loss: 11.3210 - val_accuracy: 0.3121\n",
            "Epoch 10446/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 305.2773 - accuracy: 0.5165 - val_loss: 16.1201 - val_accuracy: 0.0586\n",
            "Epoch 10447/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 13.7852 - accuracy: 0.9867 - val_loss: 19.3262 - val_accuracy: 0.2632\n",
            "Epoch 10448/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 26.3445 - accuracy: 0.5821 - val_loss: 386.6798 - val_accuracy: 0.0208\n",
            "Epoch 10449/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 15.9444 - accuracy: 0.4556 - val_loss: 72.8475 - val_accuracy: 0.1603\n",
            "Epoch 10450/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 13.4605 - accuracy: 0.3877 - val_loss: 8.4145 - val_accuracy: 0.0711\n",
            "Epoch 10451/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 20.4317 - accuracy: 0.5662 - val_loss: 434.8039 - val_accuracy: 0.0158\n",
            "Epoch 10452/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 8.0045 - accuracy: 0.9451 - val_loss: 111.1608 - val_accuracy: 0.0751\n",
            "Epoch 10453/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 80.7595 - accuracy: 0.8770 - val_loss: 384.7908 - val_accuracy: 0.0402\n",
            "Epoch 10454/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 2898.8886 - accuracy: 0.2263 - val_loss: 14.7426 - val_accuracy: 0.2559\n",
            "Epoch 10455/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 35.4655 - accuracy: 0.9571 - val_loss: 13.4514 - val_accuracy: 0.1530\n",
            "Epoch 10456/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 345.6281 - accuracy: 0.8459 - val_loss: 10.4206 - val_accuracy: 0.2938\n",
            "Epoch 10457/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 281.6992 - accuracy: 0.7751 - val_loss: 6422.8633 - val_accuracy: 0.0703\n",
            "Epoch 10458/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 420.0719 - accuracy: 0.6560 - val_loss: 33.4864 - val_accuracy: 0.0869\n",
            "Epoch 10459/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 1845148.8750 - val_accuracy: 0.0519\n",
            "Epoch 10460/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 120.7402 - accuracy: 0.0567 - val_loss: 48.1920 - val_accuracy: 0.0858\n",
            "Epoch 10461/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 77.8335 - accuracy: 0.1531 - val_loss: 1053.2853 - val_accuracy: 0.0302\n",
            "Epoch 10462/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 24.5394 - accuracy: 0.9357 - val_loss: 18.4260 - val_accuracy: 0.0455\n",
            "Epoch 10463/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 14.7434 - accuracy: 0.3634 - val_loss: 813.8986 - val_accuracy: 0.0193\n",
            "Epoch 10464/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 10.1983 - accuracy: 0.8229 - val_loss: 30.8097 - val_accuracy: 0.2485\n",
            "Epoch 10465/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 363.8237 - accuracy: 0.3425 - val_loss: 531.0318 - val_accuracy: 0.0530\n",
            "Epoch 10466/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 28.0807 - accuracy: 0.7321 - val_loss: 513.0048 - val_accuracy: 6.9214e-04\n",
            "Epoch 10467/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 40.5951 - accuracy: 0.9561 - val_loss: 10.0397 - val_accuracy: 0.2945\n",
            "Epoch 10468/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 36.4126 - accuracy: 0.7008 - val_loss: 15.7985 - val_accuracy: 0.2233\n",
            "Epoch 10469/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 26.5357 - val_accuracy: 0.1243\n",
            "Epoch 10470/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 230.6940 - accuracy: 0.6566 - val_loss: 19.0165 - val_accuracy: 0.1526\n",
            "Epoch 10471/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 372.3664 - accuracy: 0.4207 - val_loss: 329.2142 - val_accuracy: 0.0233\n",
            "Epoch 10472/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 16.1771 - accuracy: 0.8724 - val_loss: 9.9086 - val_accuracy: 0.3286\n",
            "Epoch 10473/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 23.1574 - accuracy: 0.2386 - val_loss: 40.6283 - val_accuracy: 0.0386\n",
            "Epoch 10474/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 17.9999 - accuracy: 0.5419 - val_loss: 10.1986 - val_accuracy: 0.2229\n",
            "Epoch 10475/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 69.3377 - accuracy: 0.0569 - val_loss: 593.9473 - val_accuracy: 0.0277\n",
            "Epoch 10476/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 11.8399 - accuracy: 0.6628 - val_loss: 40.6353 - val_accuracy: 0.0089\n",
            "Epoch 10477/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 41.7113 - accuracy: 0.9621 - val_loss: 493.6661 - val_accuracy: 0.0155\n",
            "Epoch 10478/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 15.1576 - accuracy: 0.7892 - val_loss: 588.3464 - val_accuracy: 0.1041\n",
            "Epoch 10479/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 26.8510 - accuracy: 0.9839 - val_loss: 16.9245 - val_accuracy: 0.0399\n",
            "Epoch 10480/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 19.3339 - accuracy: 0.9493 - val_loss: 137.7222 - val_accuracy: 0.0270\n",
            "Epoch 10481/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 26.6040 - accuracy: 0.2837 - val_loss: 207.3037 - val_accuracy: 0.1003\n",
            "Epoch 10482/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 372.3651 - accuracy: 0.7907 - val_loss: 105.7872 - val_accuracy: 0.1038\n",
            "Epoch 10483/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 10.7622 - accuracy: 0.8825 - val_loss: 473.2529 - val_accuracy: 0.0407\n",
            "Epoch 10484/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 11.4952 - accuracy: 0.4541 - val_loss: 14.0924 - val_accuracy: 0.2304\n",
            "Epoch 10485/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 10.0224 - accuracy: 0.4094 - val_loss: 56.1533 - val_accuracy: 0.0653\n",
            "Epoch 10486/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 85.9000 - accuracy: 0.9470 - val_loss: 134.8014 - val_accuracy: 0.0226\n",
            "Epoch 10487/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 11.1926 - accuracy: 0.3235 - val_loss: 127.1454 - val_accuracy: 0.0659\n",
            "Epoch 10488/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 9.6058 - accuracy: 0.4282 - val_loss: 40.1872 - val_accuracy: 0.1754\n",
            "Epoch 10489/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 14.8324 - accuracy: 0.5294 - val_loss: 239.3193 - val_accuracy: 0.0357\n",
            "Epoch 10490/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 14.1390 - accuracy: 0.6261 - val_loss: 61.3068 - val_accuracy: 0.0555\n",
            "Epoch 10491/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 5.5055 - accuracy: 0.9973 - val_loss: 34.9211 - val_accuracy: 0.0881\n",
            "Epoch 10492/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 71.5779 - accuracy: 0.7313 - val_loss: 10.5348 - val_accuracy: 0.2557\n",
            "Epoch 10493/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 169.5963 - accuracy: 0.6189 - val_loss: 14.4742 - val_accuracy: 0.1355\n",
            "Epoch 10494/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 16.0904 - accuracy: 0.3345 - val_loss: 638.6752 - val_accuracy: 0.1103\n",
            "Epoch 10495/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 12.3191 - accuracy: 0.8484 - val_loss: 1760.9376 - val_accuracy: 0.0366\n",
            "Epoch 10496/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 81.8008 - accuracy: 0.7733 - val_loss: 287.7254 - val_accuracy: 0.0976\n",
            "Epoch 10497/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 98.5788 - accuracy: 0.9101 - val_loss: 7756.1846 - val_accuracy: 0.0801\n",
            "Epoch 10498/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 26.7192 - accuracy: 0.4803 - val_loss: 13.0495 - val_accuracy: 0.0871\n",
            "Epoch 10499/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 14.2999 - accuracy: 0.5746 - val_loss: 17.6402 - val_accuracy: 0.1046\n",
            "Epoch 10500/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 463.8282 - accuracy: 0.5123 - val_loss: 24.4385 - val_accuracy: 0.1033\n",
            "Epoch 10501/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 103.4500 - accuracy: 0.8588 - val_loss: 11.3726 - val_accuracy: 0.2365\n",
            "Epoch 10502/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 15.9129 - accuracy: 0.4150 - val_loss: 24.2011 - val_accuracy: 0.2101\n",
            "Epoch 10503/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 49.6213 - accuracy: 0.8894 - val_loss: 28.7320 - val_accuracy: 0.2208\n",
            "Epoch 10504/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 21.1015 - accuracy: 0.9500 - val_loss: 11.5804 - val_accuracy: 0.1595\n",
            "Epoch 10505/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 162.5221 - accuracy: 0.7814 - val_loss: 637.7921 - val_accuracy: 0.0697\n",
            "Epoch 10506/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 36.1997 - accuracy: 0.4521 - val_loss: 3.3621 - val_accuracy: 0.1138\n",
            "Epoch 10507/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 15.0478 - accuracy: 0.5371 - val_loss: 15.0554 - val_accuracy: 0.2314\n",
            "Epoch 10508/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 19147.2871 - val_accuracy: 0.0298\n",
            "Epoch 10509/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 14.4196 - accuracy: 0.7142 - val_loss: 59.3882 - val_accuracy: 0.3031\n",
            "Epoch 10510/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 259.8944 - accuracy: 0.0362 - val_loss: 205.4389 - val_accuracy: 1.0000\n",
            "Epoch 10511/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 82.1817 - accuracy: 0.9452 - val_loss: 51.6339 - val_accuracy: 0.5770\n",
            "Epoch 10512/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 528.3668 - accuracy: 0.6983 - val_loss: 182.9737 - val_accuracy: 1.0000\n",
            "Epoch 10513/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 62.8261 - accuracy: 0.1016 - val_loss: 9.9769 - val_accuracy: 0.3201\n",
            "Epoch 10514/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 9.2892 - accuracy: 0.8576 - val_loss: 9.8083 - val_accuracy: 0.3814\n",
            "Epoch 10515/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 15.3504 - accuracy: 0.8371 - val_loss: 21.1881 - val_accuracy: 0.4352\n",
            "Epoch 10516/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 161.5386 - accuracy: 0.7802 - val_loss: 22.3524 - val_accuracy: 0.2680\n",
            "Epoch 10517/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 27.5123 - accuracy: 0.6128 - val_loss: 18.4570 - val_accuracy: 0.2498\n",
            "Epoch 10518/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 42.8122 - accuracy: 0.3951 - val_loss: 72.6788 - val_accuracy: 0.1932\n",
            "Epoch 10519/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 42.0443 - accuracy: 0.9149 - val_loss: 420.0542 - val_accuracy: 0.7878\n",
            "Epoch 10520/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 13.2929 - accuracy: 0.4233 - val_loss: 14.8759 - val_accuracy: 0.6830\n",
            "Epoch 10521/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 27.7265 - accuracy: 0.4049 - val_loss: 10.8582 - val_accuracy: 0.5307\n",
            "Epoch 10522/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 11.6141 - accuracy: 0.5803 - val_loss: 28.2801 - val_accuracy: 0.6647\n",
            "Epoch 10523/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 13.9153 - accuracy: 0.3887 - val_loss: 433.5586 - val_accuracy: 0.8317\n",
            "Epoch 10524/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 297.9113 - accuracy: 0.5404 - val_loss: 362.9465 - val_accuracy: 0.5297\n",
            "Epoch 10525/24392\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 753.3063 - accuracy: 0.5718 - val_loss: 42515.6211 - val_accuracy: 0.3874\n",
            "Epoch 10526/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 40.7914 - accuracy: 0.4370 - val_loss: 316.6846 - val_accuracy: 0.6037\n",
            "Epoch 10527/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 320.0373 - accuracy: 0.6407 - val_loss: 10.5094 - val_accuracy: 0.1230\n",
            "Epoch 10528/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 32.5613 - accuracy: 0.9606 - val_loss: 28.4546 - val_accuracy: 0.2716\n",
            "Epoch 10529/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 18.8852 - accuracy: 0.3321 - val_loss: 16.2316 - val_accuracy: 0.1172\n",
            "Epoch 10530/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 528.7926 - accuracy: 0.7928 - val_loss: 6.1540 - val_accuracy: 0.2183\n",
            "Epoch 10531/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 13.8335 - accuracy: 0.7675 - val_loss: 8.8197 - val_accuracy: 0.1873\n",
            "Epoch 10532/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 23.9398 - accuracy: 0.3736 - val_loss: 101.6731 - val_accuracy: 0.0842\n",
            "Epoch 10533/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 20.0698 - accuracy: 0.7301 - val_loss: 310.1308 - val_accuracy: 0.0297\n",
            "Epoch 10534/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 16.4666 - accuracy: 0.4994 - val_loss: 245.9433 - val_accuracy: 0.2893\n",
            "Epoch 10535/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 7.3741 - accuracy: 0.7897 - val_loss: 25.2907 - val_accuracy: 0.2875\n",
            "Epoch 10536/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 15.9492 - accuracy: 0.4053 - val_loss: 24.9014 - val_accuracy: 0.1420\n",
            "Epoch 10537/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 70.4079 - accuracy: 0.9487 - val_loss: 320.2825 - val_accuracy: 0.2409\n",
            "Epoch 10538/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 22.6254 - accuracy: 0.8585 - val_loss: 27.7410 - val_accuracy: 0.1481\n",
            "Epoch 10539/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 420.3392 - accuracy: 0.6629 - val_loss: 16.4112 - val_accuracy: 0.1878\n",
            "Epoch 10540/24392\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 64.6079 - accuracy: 0.6078 - val_loss: 66.9973 - val_accuracy: 0.1543\n",
            "Epoch 10541/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 396.1693 - accuracy: 0.6785 - val_loss: 260.0239 - val_accuracy: 0.5524\n",
            "Epoch 10542/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 10.0575 - accuracy: 0.4420 - val_loss: 18.3467 - val_accuracy: 0.1929\n",
            "Epoch 10543/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 11.2041 - accuracy: 0.9873 - val_loss: 620.8828 - val_accuracy: 0.1592\n",
            "Epoch 10544/24392\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 25.9666 - accuracy: 0.5651 - val_loss: 13.3311 - val_accuracy: 0.2946\n",
            "Epoch 10545/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 25.0287 - accuracy: 0.8750 - val_loss: 102.6754 - val_accuracy: 0.5315\n",
            "Epoch 10546/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 1758.0844 - accuracy: 0.1622 - val_loss: 321.7019 - val_accuracy: 0.0947\n",
            "Epoch 10547/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 21.8201 - val_accuracy: 0.2675\n",
            "Epoch 10548/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 28.7838 - accuracy: 0.9698 - val_loss: 12.5657 - val_accuracy: 0.8048\n",
            "Epoch 10549/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 85.5121 - accuracy: 0.9800 - val_loss: 273.4461 - val_accuracy: 0.9020\n",
            "Epoch 10550/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 21.9638 - accuracy: 0.4447 - val_loss: 92.6208 - val_accuracy: 0.2256\n",
            "Epoch 10551/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 280.2100 - accuracy: 0.7225 - val_loss: 42.8867 - val_accuracy: 0.9460\n",
            "Epoch 10552/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 14.7586 - accuracy: 0.8337 - val_loss: 20.7906 - val_accuracy: 0.2466\n",
            "Epoch 10553/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 475.1044 - accuracy: 0.6681 - val_loss: 14.7994 - val_accuracy: 0.7634\n",
            "Epoch 10554/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 7.0181 - accuracy: 0.9356 - val_loss: 12.1317 - val_accuracy: 0.7803\n",
            "Epoch 10555/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 290.7509 - accuracy: 0.8675 - val_loss: 758.6558 - val_accuracy: 0.9667\n",
            "Epoch 10556/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 15.8102 - accuracy: 0.7683 - val_loss: 22.6653 - val_accuracy: 0.5373\n",
            "Epoch 10557/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 21.9754 - accuracy: 0.3541 - val_loss: 76.5455 - val_accuracy: 0.4641\n",
            "Epoch 10558/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 27.7572 - accuracy: 0.3406 - val_loss: 14.9722 - val_accuracy: 0.7508\n",
            "Epoch 10559/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 13.7701 - accuracy: 0.8633 - val_loss: 50.0164 - val_accuracy: 0.9656\n",
            "Epoch 10560/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 59.4066 - accuracy: 0.3141 - val_loss: 2635.8247 - val_accuracy: 0.7159\n",
            "Epoch 10561/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 28.1137 - accuracy: 0.6178 - val_loss: 251.6769 - val_accuracy: 0.9317\n",
            "Epoch 10562/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 16.0170 - accuracy: 0.7956 - val_loss: 21.6453 - val_accuracy: 0.1933\n",
            "Epoch 10563/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 20.9472 - accuracy: 0.5356 - val_loss: 12.6702 - val_accuracy: 0.7948\n",
            "Epoch 10564/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 14.9705 - accuracy: 0.9152 - val_loss: 31.5647 - val_accuracy: 0.2375\n",
            "Epoch 10565/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 141.6936 - accuracy: 0.9024 - val_loss: 190.9821 - val_accuracy: 0.9880\n",
            "Epoch 10566/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 14.4418 - accuracy: 0.3058 - val_loss: 79.8147 - val_accuracy: 0.0146\n",
            "Epoch 10567/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 414.0217 - accuracy: 0.5702 - val_loss: 18.9584 - val_accuracy: 0.8756\n",
            "Epoch 10568/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 17.3648 - accuracy: 0.6012 - val_loss: 228.0019 - val_accuracy: 0.9602\n",
            "Epoch 10569/24392\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 73.6449 - accuracy: 0.2024 - val_loss: 620.0237 - val_accuracy: 0.0400\n",
            "Epoch 10570/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 12.3342 - accuracy: 0.8069 - val_loss: 31.2113 - val_accuracy: 0.1389\n",
            "Epoch 10571/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 179.7332 - accuracy: 0.6555 - val_loss: 28.0567 - val_accuracy: 0.0254\n",
            "Epoch 10572/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 26.5405 - accuracy: 0.1464 - val_loss: 1013.7226 - val_accuracy: 0.0357\n",
            "Epoch 10573/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 7129.7087 - accuracy: 0.2883 - val_loss: 1236.4863 - val_accuracy: 0.0256\n",
            "Epoch 10574/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 19.2858 - accuracy: 0.3038 - val_loss: 217.9855 - val_accuracy: 0.0235\n",
            "Epoch 10575/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 153.7988 - accuracy: 0.8992 - val_loss: 1179.6730 - val_accuracy: 0.0369\n",
            "Epoch 10576/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 431.5184 - accuracy: 0.6572 - val_loss: 1541.1469 - val_accuracy: 0.0905\n",
            "Epoch 10577/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 16.5785 - accuracy: 0.3912 - val_loss: 1077.7563 - val_accuracy: 0.0129\n",
            "Epoch 10578/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 27.5484 - accuracy: 0.6195 - val_loss: 932.0807 - val_accuracy: 0.1230\n",
            "Epoch 10579/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 275.0697 - accuracy: 0.8227 - val_loss: 14.4139 - val_accuracy: 0.1787\n",
            "Epoch 10580/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 22.5529 - accuracy: 0.6161 - val_loss: 118.6731 - val_accuracy: 0.0951\n",
            "Epoch 10581/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 11.4298 - accuracy: 0.2834 - val_loss: 1248.1606 - val_accuracy: 0.1525\n",
            "Epoch 10582/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 524.3525 - accuracy: 0.6020 - val_loss: 45.8666 - val_accuracy: 0.1370\n",
            "Epoch 10583/24392\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 20.7807 - accuracy: 0.5846 - val_loss: 62.2552 - val_accuracy: 0.0600\n",
            "Epoch 10584/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 8.4531 - accuracy: 0.7561 - val_loss: 13.6684 - val_accuracy: 0.2751\n",
            "Epoch 10585/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 14.3058 - accuracy: 0.9855 - val_loss: 828.7573 - val_accuracy: 0.1022\n",
            "Epoch 10586/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 7.6601 - accuracy: 0.9985 - val_loss: 107.0067 - val_accuracy: 0.0665\n",
            "Epoch 10587/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 15.4997 - accuracy: 0.8647 - val_loss: 20.2852 - val_accuracy: 0.1632\n",
            "Epoch 10588/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 14.7120 - accuracy: 0.3506 - val_loss: 804.9745 - val_accuracy: 0.0011\n",
            "Epoch 10589/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 511.5524 - accuracy: 0.7643 - val_loss: 8.5153 - val_accuracy: 0.2220\n",
            "Epoch 10590/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 217.8162 - accuracy: 0.4832 - val_loss: 765.5347 - val_accuracy: 0.2073\n",
            "Epoch 10591/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 11.3858 - accuracy: 0.7530 - val_loss: 19.4892 - val_accuracy: 0.1118\n",
            "Epoch 10592/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 13.9569 - accuracy: 0.9815 - val_loss: 59.9973 - val_accuracy: 0.0583\n",
            "Epoch 10593/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 8.7354 - accuracy: 0.7641 - val_loss: 713.5722 - val_accuracy: 0.0492\n",
            "Epoch 10594/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 495.3531 - accuracy: 0.7051 - val_loss: 18.0405 - val_accuracy: 0.2018\n",
            "Epoch 10595/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 14.6394 - accuracy: 0.6042 - val_loss: 37.3889 - val_accuracy: 0.1472\n",
            "Epoch 10596/24392\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 13.1205 - accuracy: 0.7983 - val_loss: 57.5030 - val_accuracy: 0.1288\n",
            "Epoch 10597/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 111.6591 - accuracy: 0.7909 - val_loss: 38.3641 - val_accuracy: 0.1329\n",
            "Epoch 10598/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 13.1546 - accuracy: 0.9942 - val_loss: 16.3674 - val_accuracy: 0.2624\n",
            "Epoch 10599/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 13.5368 - accuracy: 0.8547 - val_loss: 9.1268 - val_accuracy: 0.3162\n",
            "Epoch 10600/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 315.9580 - accuracy: 0.8947 - val_loss: 425.4851 - val_accuracy: 0.0027\n",
            "Epoch 10601/24392\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 22.9615 - accuracy: 0.2265 - val_loss: 278.3014 - val_accuracy: 0.0204\n",
            "Epoch 10602/24392\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 16.6452 - accuracy: 0.7212 - val_loss: 10.5225 - val_accuracy: 0.1609\n",
            "Epoch 10603/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 14.6629 - accuracy: 0.4221 - val_loss: 99.9800 - val_accuracy: 0.0843\n",
            "Epoch 10604/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 49.7776 - accuracy: 0.9497 - val_loss: 10.1354 - val_accuracy: 0.2199\n",
            "Epoch 10605/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 14.3810 - accuracy: 0.8844 - val_loss: 799.0900 - val_accuracy: 0.0162\n",
            "Epoch 10606/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 36.2025 - accuracy: 0.6247 - val_loss: 63.8936 - val_accuracy: 0.1175\n",
            "Epoch 10607/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 7.9191 - accuracy: 0.8129 - val_loss: 13.7785 - val_accuracy: 0.2444\n",
            "Epoch 10608/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 77.4840 - accuracy: 0.3899 - val_loss: 42.1517 - val_accuracy: 0.0725\n",
            "Epoch 10609/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 893.3831 - accuracy: 0.5876 - val_loss: 382.8462 - val_accuracy: 0.0028\n",
            "Epoch 10610/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 23.2216 - accuracy: 0.2086 - val_loss: 714.2695 - val_accuracy: 0.0108\n",
            "Epoch 10611/24392\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 49.2896 - accuracy: 0.9526 - val_loss: 11.6288 - val_accuracy: 0.1348\n",
            "Epoch 10612/24392\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 9.9422 - accuracy: 0.4794 - val_loss: 17.8914 - val_accuracy: 0.0852\n",
            "Epoch 10613/24392\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 16.7397 - accuracy: 0.3405 - val_loss: 473.8994 - val_accuracy: 0.0121\n",
            "Epoch 10614/24392\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 25.1284 - accuracy: 0.9992 - val_loss: 38.6390 - val_accuracy: 0.1624\n",
            "Epoch 10615/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 70.6552 - accuracy: 0.8279 - val_loss: 36.4761 - val_accuracy: 0.0800\n",
            "Epoch 10616/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 20.1480 - accuracy: 0.9712 - val_loss: 397.9535 - val_accuracy: 0.1030\n",
            "Epoch 10617/24392\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 40.5042 - accuracy: 0.8364 - val_loss: 8.7391 - val_accuracy: 0.0554\n",
            "Epoch 10618/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 173.9641 - accuracy: 0.7997 - val_loss: 321.7406 - val_accuracy: 0.0094\n",
            "Epoch 10619/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 275.3313 - accuracy: 0.5309 - val_loss: 12.9467 - val_accuracy: 0.1496\n",
            "Epoch 10620/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 250.5185 - accuracy: 0.6540 - val_loss: 17.1316 - val_accuracy: 0.1130\n",
            "Epoch 10621/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 24.9688 - accuracy: 0.8949 - val_loss: 11.5329 - val_accuracy: 0.1441\n",
            "Epoch 10622/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 23.1061 - accuracy: 0.9030 - val_loss: 49.5053 - val_accuracy: 0.1030\n",
            "Epoch 10623/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 12.1109 - accuracy: 0.7756 - val_loss: 23.4274 - val_accuracy: 0.5051\n",
            "Epoch 10624/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 10617.8351 - accuracy: 0.4476 - val_loss: 226.6918 - val_accuracy: 0.0228\n",
            "Epoch 10625/24392\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 13.9904 - accuracy: 0.3269 - val_loss: 21.0114 - val_accuracy: 0.1831\n",
            "Epoch 10626/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 16.4326 - accuracy: 0.9358 - val_loss: 11.0306 - val_accuracy: 0.2360\n",
            "Epoch 10627/24392\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 14.9665 - accuracy: 0.9793 - val_loss: 29.7164 - val_accuracy: 0.2107\n",
            "Epoch 10628/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 81.8330 - accuracy: 0.8820 - val_loss: 15.2417 - val_accuracy: 0.1311\n",
            "Epoch 10629/24392\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 13613.9052 - accuracy: 0.5801 - val_loss: 10.1775 - val_accuracy: 0.2139\n",
            "Epoch 10630/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 23.0484 - accuracy: 0.2021 - val_loss: 31.5417 - val_accuracy: 0.1280\n",
            "Epoch 10631/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 15.3222 - accuracy: 0.3049 - val_loss: 615.1467 - val_accuracy: 0.1038\n",
            "Epoch 10632/24392\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 63.5795 - accuracy: 0.8869 - val_loss: 1738.9583 - val_accuracy: 0.1272\n",
            "Epoch 10633/24392\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 13.2418 - accuracy: 0.7975 - val_loss: 397.0940 - val_accuracy: 0.0014\n",
            "Epoch 10634/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 26.2918 - accuracy: 0.2707 - val_loss: 253.1450 - val_accuracy: 0.0887\n",
            "Epoch 10635/24392\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 69.5998 - accuracy: 0.9400 - val_loss: 24.1688 - val_accuracy: 0.1377\n",
            "Epoch 10636/24392\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 49.8728 - accuracy: 0.8381 - val_loss: 362.4836 - val_accuracy: 0.0550\n",
            "Epoch 10637/24392\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 11.0080 - accuracy: 0.7879 - val_loss: 134.7761 - val_accuracy: 0.1222\n",
            "Epoch 10638/24392\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 20.1329 - accuracy: 0.3015 - val_loss: 40.4619 - val_accuracy: 0.1494\n",
            "Epoch 10639/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 23.4757 - accuracy: 0.3551 - val_loss: 63.0945 - val_accuracy: 0.1158\n",
            "Epoch 10640/24392\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 2.1931 - accuracy: 0.9992 - val_loss: 15.6203 - val_accuracy: 0.1004\n",
            "Epoch 10641/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 3.3747 - accuracy: 0.9966 - val_loss: 7.7755 - val_accuracy: 0.2765\n",
            "Epoch 10642/24392\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 27.0302 - accuracy: 0.1414 - val_loss: 26.9278 - val_accuracy: 0.1075\n",
            "Epoch 10643/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 6.1305 - accuracy: 0.8809 - val_loss: 43.7057 - val_accuracy: 0.1337\n",
            "Epoch 10644/24392\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 8140.8549 - accuracy: 0.4717 - val_loss: 1667.5087 - val_accuracy: 0.2042\n",
            "Epoch 10645/24392\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 74.3394 - accuracy: 0.3916 - val_loss: 1542.6016 - val_accuracy: 0.0692\n",
            "Epoch 10646/24392\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 579.8251 - accuracy: 0.3376 - val_loss: 23.5017 - val_accuracy: 0.2025\n",
            "Epoch 10647/24392\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 47.3038 - accuracy: 0.2119 - val_loss: 69.1087 - val_accuracy: 0.0059\n",
            "Epoch 10648/24392\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 51.3368 - accuracy: 0.3740 - val_loss: 50.9407 - val_accuracy: 0.0647\n",
            "Epoch 10649/24392\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 43.6552 - accuracy: 0.2580 - val_loss: 2458.8750 - val_accuracy: 0.0336\n",
            "Epoch 10650/24392\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 71.2556 - accuracy: 0.8887 - val_loss: 53.1149 - val_accuracy: 0.0310\n",
            "Epoch 10651/24392\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 18.0039 - accuracy: 0.3384 - val_loss: 67.7598 - val_accuracy: 0.0188\n",
            "Epoch 10652/24392\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 16.0497 - accuracy: 0.8942"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbaUHJWBZGzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d2d71fc-ad47-4c15-8f61-9624646f7eb1"
      },
      "source": [
        "listdir = os.listdir(DATA_PATH)\n",
        "\n",
        "with zipfile.ZipFile(DATA_PATH + \"/\" + listdir[0]) as tmpzip:\n",
        "    filelist = tmpzip.namelist()\n",
        "\n",
        "    tmp_df = pickle.loads(tmpzip.read(filelist[0]))\n",
        "    \n",
        "tmp_df[-28:].shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-K1_UOuZ6F_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "d6f250bf-9f24-4009-f652-c766436e11d6"
      },
      "source": [
        "model.predict(tmp_df[-28:].fillna(0).values.reshape(1,28,70))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1.5491114],\n",
              "        [1.5525239],\n",
              "        [1.550781 ],\n",
              "        [1.550313 ],\n",
              "        [1.5511258],\n",
              "        [1.5506256],\n",
              "        [1.5506971],\n",
              "        [1.550659 ],\n",
              "        [1.5506213],\n",
              "        [1.5506275],\n",
              "        [1.5506353],\n",
              "        [1.5506573],\n",
              "        [1.5506909],\n",
              "        [1.5507317],\n",
              "        [1.5507798],\n",
              "        [1.5508325],\n",
              "        [1.5508895],\n",
              "        [1.5509486],\n",
              "        [1.5510106],\n",
              "        [1.5510731],\n",
              "        [1.551137 ],\n",
              "        [1.5512018],\n",
              "        [1.5512667],\n",
              "        [1.5513306],\n",
              "        [1.5513947],\n",
              "        [1.5514572],\n",
              "        [1.5515199],\n",
              "        [1.5515816]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17mFjb0G1yCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "743c5f33-73b8-4344-90fe-558fbac26223"
      },
      "source": [
        "RTG.__getitem__(1)[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 28, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfjvx8Wtk-6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f2324dd-408a-4ed4-8c74-c86b2543aae9"
      },
      "source": [
        "RTG.now_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1969, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INLwaZW5lMdD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8abcf98-8a20-4be5-9db4-8b43b8859e69"
      },
      "source": [
        "RTG.on_epoch_end()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['./training_datas/train_data2314.zip']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvqSKPSViPUq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21f5eb17-dfdc-4d07-c3bd-3b2e95b5c576"
      },
      "source": [
        "RTG.num_epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psMJFyEei8Kw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "497a09df-f2a9-4302-908a-ba3f6d429e5a"
      },
      "source": [
        "RTG.data_idx[RTG.num_epoch]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "928"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWY2YUFlho_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "8442a9eb-8c5f-46a1-c2e5-0d69f5e1e579"
      },
      "source": [
        "RTG.now_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ..., 59.93333333,\n",
              "         3.97070312,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ..., 60.4       ,\n",
              "         3.97070312,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ..., 59.63333333,\n",
              "         3.97070312,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDX3roHFk17n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "6d682116-a2bd-41d5-c828-0ac6ec6cb25b"
      },
      "source": [
        "RTG.tmp_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_name_1_Chanukah End</th>\n",
              "      <th>event_name_1_Christmas</th>\n",
              "      <th>event_name_1_Cinco De Mayo</th>\n",
              "      <th>event_name_1_ColumbusDay</th>\n",
              "      <th>event_name_1_Easter</th>\n",
              "      <th>event_name_1_Eid al-Fitr</th>\n",
              "      <th>event_name_1_EidAlAdha</th>\n",
              "      <th>event_name_1_Father's day</th>\n",
              "      <th>event_name_1_Halloween</th>\n",
              "      <th>event_name_1_IndependenceDay</th>\n",
              "      <th>event_name_1_LaborDay</th>\n",
              "      <th>event_name_1_LentStart</th>\n",
              "      <th>event_name_1_LentWeek2</th>\n",
              "      <th>event_name_1_MartinLutherKingDay</th>\n",
              "      <th>event_name_1_MemorialDay</th>\n",
              "      <th>event_name_1_Mother's day</th>\n",
              "      <th>event_name_1_NBAFinalsEnd</th>\n",
              "      <th>event_name_1_NBAFinalsStart</th>\n",
              "      <th>event_name_1_NewYear</th>\n",
              "      <th>event_name_1_OrthodoxChristmas</th>\n",
              "      <th>event_name_1_OrthodoxEaster</th>\n",
              "      <th>event_name_1_Pesach End</th>\n",
              "      <th>event_name_1_PresidentsDay</th>\n",
              "      <th>event_name_1_Purim End</th>\n",
              "      <th>event_name_1_Ramadan starts</th>\n",
              "      <th>event_name_1_StPatricksDay</th>\n",
              "      <th>event_name_1_SuperBowl</th>\n",
              "      <th>event_name_1_Thanksgiving</th>\n",
              "      <th>event_name_1_ValentinesDay</th>\n",
              "      <th>event_name_1_VeteransDay</th>\n",
              "      <th>event_type_1_Cultural</th>\n",
              "      <th>event_type_1_National</th>\n",
              "      <th>event_type_1_Religious</th>\n",
              "      <th>event_type_1_Sporting</th>\n",
              "      <th>event_name_2_Cinco De Mayo</th>\n",
              "      <th>event_name_2_Easter</th>\n",
              "      <th>event_name_2_Father's day</th>\n",
              "      <th>event_name_2_OrthodoxEaster</th>\n",
              "      <th>event_type_2_Cultural</th>\n",
              "      <th>event_type_2_Religious</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>2314</th>\n",
              "      <th>2314</th>\n",
              "      <th>price</th>\n",
              "      <th>sale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1936</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50.285714</td>\n",
              "      <td>58.400000</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1937</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52.571429</td>\n",
              "      <td>58.600000</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1938</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.428571</td>\n",
              "      <td>59.933333</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1939</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54.285714</td>\n",
              "      <td>60.400000</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1940</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52.857143</td>\n",
              "      <td>59.633333</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1941 rows × 70 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      snap_CA  snap_TX  snap_WI  ...       2314     price  sale\n",
              "0           0        0        0  ...   0.000000  0.000000   0.0\n",
              "1           0        0        0  ...   0.000000  0.000000   0.0\n",
              "2           0        0        0  ...   0.000000  0.000000   0.0\n",
              "3           1        1        0  ...   0.000000  0.000000   0.0\n",
              "4           1        0        1  ...   0.000000  0.000000   0.0\n",
              "...       ...      ...      ...  ...        ...       ...   ...\n",
              "1936        0        0        0  ...  58.400000  3.970703   0.0\n",
              "1937        0        0        0  ...  58.600000  3.970703   0.0\n",
              "1938        0        0        0  ...  59.933333  3.970703   0.0\n",
              "1939        0        0        0  ...  60.400000  3.970703   0.0\n",
              "1940        0        0        0  ...  59.633333  3.970703   0.0\n",
              "\n",
              "[1941 rows x 70 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JritQ5N3NLSD",
        "colab_type": "text"
      },
      "source": [
        "# クロスバリデーションのテスト\n",
        "■ accuracyについて<br />\n",
        "分類の正解・不正解から算出。今回は回帰なので意味がない？<br />\n",
        "validation lossが暴れないことを確認したら十分そう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nsWsJzpNNcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=5)\n",
        "CV_gen = kfold.split(np.arange(0,1000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ipw_35qNUJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2c79e40-2ec2-4bd4-cc3d-758dd8022208"
      },
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        "\n",
        "History = []\n",
        "\n",
        "# 1000サンプルでクロスバリデーションテスト(kfold.splitの引数に、0～999が順に入った配列を代入)\n",
        "for train_cv_idx, valid_cv_idx in kfold.split(np.arange(0,30490)):\n",
        "    X_CV_train_gen = ReccurentTrainGenerator(DataPath=DATA_PATH, batch_size=128, InputSteps=28, sample_indices=train_cv_idx)\n",
        "    X_CV_valid_gen = ReccurentTrainGenerator(DataPath=DATA_PATH, batch_size=128, InputSteps=28, sample_indices=valid_cv_idx)\n",
        "\n",
        "    model = build_model() #カテゴリごとのモデルを作る時も、同様にfor文内で再度モデルをビルドすればよいかもしれない。\n",
        " \n",
        "    # Early-stopping: patienceはもう少し大きくとる？\n",
        "    early_stopping = EarlyStopping(patience=100, verbose=1) \n",
        "\n",
        "    history = model.fit_generator(X_CV_train_gen, epochs=500, verbose=1, validation_data=X_CV_valid_gen, callbacks=[early_stopping])\n",
        "    History.append(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 244ms/step - loss: 17.2825 - accuracy: 0.2291 - val_loss: 1.3013 - val_accuracy: 0.8715\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 13.6302 - accuracy: 0.2324 - val_loss: 1.4011 - val_accuracy: 0.8711\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 12.0956 - accuracy: 0.2365 - val_loss: 1.1496 - val_accuracy: 0.8713\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 11.4883 - accuracy: 0.2367 - val_loss: 1.1198 - val_accuracy: 0.8724\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 4s 245ms/step - loss: 10.9414 - accuracy: 0.2408 - val_loss: 1.0533 - val_accuracy: 0.8606\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 10.4521 - accuracy: 0.2435 - val_loss: 0.9319 - val_accuracy: 0.8591\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 10.0977 - accuracy: 0.2452 - val_loss: 1.1564 - val_accuracy: 0.8585\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 10.0879 - accuracy: 0.2375 - val_loss: 1.1472 - val_accuracy: 0.8504\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 9.5648 - accuracy: 0.2406 - val_loss: 1.1506 - val_accuracy: 0.8594\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 9.1539 - accuracy: 0.2380 - val_loss: 1.1574 - val_accuracy: 0.8571\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 9.0564 - accuracy: 0.2403 - val_loss: 1.0387 - val_accuracy: 0.8499\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 8.8615 - accuracy: 0.2392 - val_loss: 1.2565 - val_accuracy: 0.6139\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 8.5265 - accuracy: 0.2397 - val_loss: 1.3856 - val_accuracy: 0.5691\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 8.2772 - accuracy: 0.2426 - val_loss: 1.4379 - val_accuracy: 0.5848\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 8.3341 - accuracy: 0.2398 - val_loss: 1.5436 - val_accuracy: 0.5172\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 8.2143 - accuracy: 0.2449 - val_loss: 1.3965 - val_accuracy: 0.5629\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 8.2624 - accuracy: 0.2355 - val_loss: 1.5067 - val_accuracy: 0.5440\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 7.8717 - accuracy: 0.2427 - val_loss: 1.8043 - val_accuracy: 0.5289\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 7.6556 - accuracy: 0.2421 - val_loss: 1.7611 - val_accuracy: 0.4716\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 7.4762 - accuracy: 0.2444 - val_loss: 2.2863 - val_accuracy: 0.4632\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 7.5649 - accuracy: 0.2439 - val_loss: 1.9211 - val_accuracy: 0.5182\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 7.6276 - accuracy: 0.2415 - val_loss: 1.7552 - val_accuracy: 0.5155\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 7.4885 - accuracy: 0.2429 - val_loss: 1.9105 - val_accuracy: 0.3854\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 7.2383 - accuracy: 0.2380 - val_loss: 2.1839 - val_accuracy: 0.3487\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 7.1730 - accuracy: 0.2416 - val_loss: 2.4589 - val_accuracy: 0.2915\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 7.3612 - accuracy: 0.2406 - val_loss: 2.4505 - val_accuracy: 0.2016\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 7.4461 - accuracy: 0.2391 - val_loss: 2.7253 - val_accuracy: 0.2075\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 7.1556 - accuracy: 0.2383 - val_loss: 2.3077 - val_accuracy: 0.3802\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 7.2469 - accuracy: 0.2325 - val_loss: 2.6132 - val_accuracy: 0.1385\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 7.0173 - accuracy: 0.2369 - val_loss: 2.6501 - val_accuracy: 0.1628\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 7.0684 - accuracy: 0.2317 - val_loss: 2.5855 - val_accuracy: 0.2885\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 7.2058 - accuracy: 0.2361 - val_loss: 4.0024 - val_accuracy: 0.0303\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.7723 - accuracy: 0.2411 - val_loss: 4.9827 - val_accuracy: 0.0334\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 6.7494 - accuracy: 0.2365 - val_loss: 6.4905 - val_accuracy: 0.0286\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.5130 - accuracy: 0.2384 - val_loss: 5.8744 - val_accuracy: 0.0319\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 6.9803 - accuracy: 0.2407 - val_loss: 4.9324 - val_accuracy: 0.0269\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 7.0294 - accuracy: 0.2302 - val_loss: 4.8612 - val_accuracy: 0.0301\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 6.9358 - accuracy: 0.2348 - val_loss: 5.6175 - val_accuracy: 0.0240\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.6857 - accuracy: 0.2397 - val_loss: 5.1656 - val_accuracy: 0.0269\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 6.6425 - accuracy: 0.2330 - val_loss: 5.7248 - val_accuracy: 0.0215\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 6.8426 - accuracy: 0.2395 - val_loss: 9.4778 - val_accuracy: 0.0164\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.5871 - accuracy: 0.2324 - val_loss: 10.7517 - val_accuracy: 0.0141\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.5650 - accuracy: 0.2369 - val_loss: 11.6749 - val_accuracy: 0.0152\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 6.4563 - accuracy: 0.2346 - val_loss: 11.7512 - val_accuracy: 0.0171\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.3935 - accuracy: 0.2333 - val_loss: 11.5627 - val_accuracy: 0.0172\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.5028 - accuracy: 0.2372 - val_loss: 12.8066 - val_accuracy: 0.0150\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.3842 - accuracy: 0.2358 - val_loss: 13.3381 - val_accuracy: 0.0150\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 6.4125 - accuracy: 0.2363 - val_loss: 12.9154 - val_accuracy: 0.0163\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.3912 - accuracy: 0.2320 - val_loss: 13.7246 - val_accuracy: 0.0164\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.2946 - accuracy: 0.2423 - val_loss: 14.0844 - val_accuracy: 0.0144\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 6.2605 - accuracy: 0.2323 - val_loss: 13.6607 - val_accuracy: 0.0150\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.1326 - accuracy: 0.2380 - val_loss: 12.0295 - val_accuracy: 0.0164\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.1442 - accuracy: 0.2336 - val_loss: 12.2782 - val_accuracy: 0.0168\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 6.1985 - accuracy: 0.2316 - val_loss: 12.1573 - val_accuracy: 0.0176\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.9964 - accuracy: 0.2397 - val_loss: 13.2219 - val_accuracy: 0.0151\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 5.9760 - accuracy: 0.2346 - val_loss: 14.7929 - val_accuracy: 0.0137\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 6.1019 - accuracy: 0.2407 - val_loss: 10.4486 - val_accuracy: 0.0171\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.0800 - accuracy: 0.2371 - val_loss: 12.6034 - val_accuracy: 0.0163\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.0348 - accuracy: 0.2327 - val_loss: 9.6338 - val_accuracy: 0.0170\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.9434 - accuracy: 0.2354 - val_loss: 11.4239 - val_accuracy: 0.0134\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 5.8592 - accuracy: 0.2390 - val_loss: 13.0565 - val_accuracy: 0.0133\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.8542 - accuracy: 0.2390 - val_loss: 12.4094 - val_accuracy: 0.0138\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.9203 - accuracy: 0.2383 - val_loss: 10.6643 - val_accuracy: 0.0160\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.2547 - accuracy: 0.2318 - val_loss: 17.4921 - val_accuracy: 0.0084\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 8.4550 - accuracy: 0.2337 - val_loss: 6.6778 - val_accuracy: 0.0956\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 7.1189 - accuracy: 0.2355 - val_loss: 5.8219 - val_accuracy: 0.0451\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.6458 - accuracy: 0.2361 - val_loss: 6.5984 - val_accuracy: 0.0259\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.4193 - accuracy: 0.2375 - val_loss: 7.0059 - val_accuracy: 0.0290\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 6.2054 - accuracy: 0.2360 - val_loss: 7.2807 - val_accuracy: 0.0469\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 6.1373 - accuracy: 0.2360 - val_loss: 6.5990 - val_accuracy: 0.1454\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.2648 - accuracy: 0.2346 - val_loss: 5.2129 - val_accuracy: 0.2070\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 6.0853 - accuracy: 0.2377 - val_loss: 5.6345 - val_accuracy: 0.1742\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.0539 - accuracy: 0.2390 - val_loss: 5.0124 - val_accuracy: 0.1903\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 6.0337 - accuracy: 0.2384 - val_loss: 6.2739 - val_accuracy: 0.1749\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.9218 - accuracy: 0.2425 - val_loss: 4.8881 - val_accuracy: 0.2388\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 5.9757 - accuracy: 0.2407 - val_loss: 3.9600 - val_accuracy: 0.3267\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 5.8934 - accuracy: 0.2426 - val_loss: 5.2834 - val_accuracy: 0.2836\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 5.9470 - accuracy: 0.2451 - val_loss: 5.0557 - val_accuracy: 0.2173\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.0689 - accuracy: 0.2429 - val_loss: 5.8633 - val_accuracy: 0.1723\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.9117 - accuracy: 0.2405 - val_loss: 6.1238 - val_accuracy: 0.1628\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 5.8194 - accuracy: 0.2459 - val_loss: 5.8895 - val_accuracy: 0.2253\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 5.8431 - accuracy: 0.2457 - val_loss: 6.8770 - val_accuracy: 0.1743\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 5.8399 - accuracy: 0.2488 - val_loss: 5.7034 - val_accuracy: 0.1579\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 5.7489 - accuracy: 0.2428 - val_loss: 5.6250 - val_accuracy: 0.1541\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 5.7429 - accuracy: 0.2456 - val_loss: 4.4958 - val_accuracy: 0.1981\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 5.7261 - accuracy: 0.2517 - val_loss: 4.5921 - val_accuracy: 0.1845\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.6549 - accuracy: 0.2466 - val_loss: 6.0801 - val_accuracy: 0.1608\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 5.7216 - accuracy: 0.2487 - val_loss: 5.7437 - val_accuracy: 0.1546\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.8121 - accuracy: 0.2424 - val_loss: 5.2092 - val_accuracy: 0.1659\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.7304 - accuracy: 0.2437 - val_loss: 6.7228 - val_accuracy: 0.1589\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.5323 - accuracy: 0.2463 - val_loss: 5.0470 - val_accuracy: 0.2129\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.6300 - accuracy: 0.2445 - val_loss: 5.9910 - val_accuracy: 0.1727\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 5.6470 - accuracy: 0.2482 - val_loss: 6.6666 - val_accuracy: 0.1770\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 5.5380 - accuracy: 0.2454 - val_loss: 5.0938 - val_accuracy: 0.2148\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.6621 - accuracy: 0.2436 - val_loss: 6.2067 - val_accuracy: 0.2017\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 5.6287 - accuracy: 0.2471 - val_loss: 5.3311 - val_accuracy: 0.2489\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.5019 - accuracy: 0.2446 - val_loss: 5.9195 - val_accuracy: 0.1844\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 5.4526 - accuracy: 0.2467 - val_loss: 5.2629 - val_accuracy: 0.2275\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.4178 - accuracy: 0.2449 - val_loss: 5.5054 - val_accuracy: 0.2100\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 5.5342 - accuracy: 0.2483 - val_loss: 4.9100 - val_accuracy: 0.2705\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 5.5181 - accuracy: 0.2454 - val_loss: 4.5761 - val_accuracy: 0.2613\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.2947 - accuracy: 0.2468 - val_loss: 4.5897 - val_accuracy: 0.2698\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 5.3545 - accuracy: 0.2495 - val_loss: 5.0596 - val_accuracy: 0.2612\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.3298 - accuracy: 0.2504 - val_loss: 4.9783 - val_accuracy: 0.2562\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.3440 - accuracy: 0.2506 - val_loss: 5.8229 - val_accuracy: 0.2571\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.3789 - accuracy: 0.2489 - val_loss: 5.9361 - val_accuracy: 0.2031\n",
            "Epoch 00106: early stopping\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 261ms/step - loss: 1.1514 - accuracy: 0.6799 - val_loss: 31.1057 - val_accuracy: 0.2098\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0954 - accuracy: 0.6995 - val_loss: 26.1283 - val_accuracy: 0.2101\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0904 - accuracy: 0.7138 - val_loss: 23.5067 - val_accuracy: 0.2067\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0738 - accuracy: 0.7237 - val_loss: 30.4362 - val_accuracy: 0.2052\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0409 - accuracy: 0.7306 - val_loss: 31.7386 - val_accuracy: 0.2081\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0653 - accuracy: 0.7160 - val_loss: 29.1680 - val_accuracy: 0.2065\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0426 - accuracy: 0.7234 - val_loss: 28.4264 - val_accuracy: 0.2086\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0384 - accuracy: 0.7360 - val_loss: 27.8821 - val_accuracy: 0.2084\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0347 - accuracy: 0.7398 - val_loss: 26.5325 - val_accuracy: 0.2078\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0284 - accuracy: 0.7362 - val_loss: 27.7200 - val_accuracy: 0.2094\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0310 - accuracy: 0.7341 - val_loss: 26.6544 - val_accuracy: 0.2054\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0333 - accuracy: 0.7118 - val_loss: 26.5346 - val_accuracy: 0.2085\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0211 - accuracy: 0.7315 - val_loss: 31.6141 - val_accuracy: 0.2069\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0445 - accuracy: 0.7406 - val_loss: 27.3236 - val_accuracy: 0.2090\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0528 - accuracy: 0.7480 - val_loss: 25.9802 - val_accuracy: 0.2073\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0142 - accuracy: 0.7625 - val_loss: 26.0284 - val_accuracy: 0.2071\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 1.0539 - accuracy: 0.7256 - val_loss: 25.3547 - val_accuracy: 0.2111\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 1.0324 - accuracy: 0.7456 - val_loss: 28.3029 - val_accuracy: 0.2130\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0385 - accuracy: 0.7150 - val_loss: 35.5219 - val_accuracy: 0.2075\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0498 - accuracy: 0.7190 - val_loss: 25.7927 - val_accuracy: 0.2081\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0329 - accuracy: 0.7445 - val_loss: 25.1134 - val_accuracy: 0.2070\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0418 - accuracy: 0.7135 - val_loss: 25.1381 - val_accuracy: 0.2060\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0271 - accuracy: 0.7251 - val_loss: 29.0632 - val_accuracy: 0.2092\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0324 - accuracy: 0.7331 - val_loss: 30.6880 - val_accuracy: 0.2093\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0239 - accuracy: 0.7328 - val_loss: 24.9943 - val_accuracy: 0.2107\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0296 - accuracy: 0.7132 - val_loss: 31.4004 - val_accuracy: 0.2099\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0317 - accuracy: 0.7432 - val_loss: 33.1539 - val_accuracy: 0.2045\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0211 - accuracy: 0.7217 - val_loss: 28.0415 - val_accuracy: 0.2061\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0146 - accuracy: 0.7221 - val_loss: 23.2830 - val_accuracy: 0.2067\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0284 - accuracy: 0.7205 - val_loss: 26.9443 - val_accuracy: 0.2085\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0265 - accuracy: 0.7427 - val_loss: 41.4850 - val_accuracy: 0.2092\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0294 - accuracy: 0.7012 - val_loss: 25.7281 - val_accuracy: 0.2093\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0174 - accuracy: 0.7368 - val_loss: 28.5942 - val_accuracy: 0.2115\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0129 - accuracy: 0.7276 - val_loss: 40.2359 - val_accuracy: 0.2032\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0323 - accuracy: 0.7331 - val_loss: 28.3301 - val_accuracy: 0.2051\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0118 - accuracy: 0.7422 - val_loss: 29.7781 - val_accuracy: 0.2030\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0138 - accuracy: 0.7178 - val_loss: 35.3238 - val_accuracy: 0.2046\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0263 - accuracy: 0.7091 - val_loss: 36.8526 - val_accuracy: 0.1980\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0215 - accuracy: 0.7239 - val_loss: 134.7704 - val_accuracy: 0.2034\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0041 - accuracy: 0.7291 - val_loss: 31.2256 - val_accuracy: 0.2129\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0010 - accuracy: 0.7129 - val_loss: 24.9568 - val_accuracy: 0.2107\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0274 - accuracy: 0.7019 - val_loss: 87.0241 - val_accuracy: 0.2098\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0261 - accuracy: 0.7428 - val_loss: 344.0115 - val_accuracy: 0.2091\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0251 - accuracy: 0.7167 - val_loss: 46.7169 - val_accuracy: 0.2098\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0200 - accuracy: 0.6788 - val_loss: 63.3610 - val_accuracy: 0.2086\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0179 - accuracy: 0.7363 - val_loss: 63.6499 - val_accuracy: 0.2059\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0301 - accuracy: 0.7029 - val_loss: 34.1072 - val_accuracy: 0.2106\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0059 - accuracy: 0.7065 - val_loss: 30.2047 - val_accuracy: 0.2073\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0131 - accuracy: 0.7289 - val_loss: 42.8233 - val_accuracy: 0.2100\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0215 - accuracy: 0.7142 - val_loss: 39.8443 - val_accuracy: 0.2045\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0097 - accuracy: 0.7041 - val_loss: 64.2735 - val_accuracy: 0.2070\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0052 - accuracy: 0.6843 - val_loss: 30.7099 - val_accuracy: 0.2049\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0330 - accuracy: 0.7242 - val_loss: 30.8481 - val_accuracy: 0.2044\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0201 - accuracy: 0.6810 - val_loss: 41.2340 - val_accuracy: 0.2077\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0049 - accuracy: 0.7463 - val_loss: 467.3768 - val_accuracy: 0.2056\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0046 - accuracy: 0.7003 - val_loss: 51.7079 - val_accuracy: 0.2075\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0080 - accuracy: 0.7167 - val_loss: 3998.4531 - val_accuracy: 0.2055\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0284 - accuracy: 0.6996 - val_loss: 849.5452 - val_accuracy: 0.2046\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0070 - accuracy: 0.6998 - val_loss: 16867.2441 - val_accuracy: 0.2005\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0250 - accuracy: 0.7037 - val_loss: 4078.6340 - val_accuracy: 0.2002\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0123 - accuracy: 0.6966 - val_loss: 713.3966 - val_accuracy: 0.2048\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0138 - accuracy: 0.6978 - val_loss: 1652.9319 - val_accuracy: 0.2034\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0168 - accuracy: 0.7195 - val_loss: 22184.1602 - val_accuracy: 0.2007\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9836 - accuracy: 0.6747 - val_loss: 328.0176 - val_accuracy: 0.2039\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0081 - accuracy: 0.7218 - val_loss: 248.3865 - val_accuracy: 0.2023\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9966 - accuracy: 0.6969 - val_loss: 6917.5972 - val_accuracy: 0.2050\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9968 - accuracy: 0.7069 - val_loss: 10907.5674 - val_accuracy: 0.2040\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0074 - accuracy: 0.6843 - val_loss: 5254.0312 - val_accuracy: 0.2058\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0180 - accuracy: 0.7041 - val_loss: 507.9926 - val_accuracy: 0.2020\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9989 - accuracy: 0.6863 - val_loss: 1626.9248 - val_accuracy: 0.2041\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9887 - accuracy: 0.7066 - val_loss: 2435.9500 - val_accuracy: 0.2048\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9857 - accuracy: 0.7048 - val_loss: 89.1305 - val_accuracy: 0.2057\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9942 - accuracy: 0.7101 - val_loss: 3031.8196 - val_accuracy: 0.2048\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 0.9848 - accuracy: 0.6970 - val_loss: 413.6667 - val_accuracy: 0.2068\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0041 - accuracy: 0.6933 - val_loss: 42.6145 - val_accuracy: 0.2048\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9771 - accuracy: 0.7156 - val_loss: 241.4746 - val_accuracy: 0.2099\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9880 - accuracy: 0.6969 - val_loss: 67.3423 - val_accuracy: 0.2122\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9872 - accuracy: 0.7034 - val_loss: 47.4189 - val_accuracy: 0.2158\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0029 - accuracy: 0.6845 - val_loss: 384.2636 - val_accuracy: 0.2157\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9958 - accuracy: 0.6859 - val_loss: 2344.0989 - val_accuracy: 0.2135\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9975 - accuracy: 0.6850 - val_loss: 95.0949 - val_accuracy: 0.2193\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9899 - accuracy: 0.6906 - val_loss: 115.1968 - val_accuracy: 0.2188\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9937 - accuracy: 0.6897 - val_loss: 256.3484 - val_accuracy: 0.2172\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9899 - accuracy: 0.7010 - val_loss: 1031.4191 - val_accuracy: 0.2090\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9793 - accuracy: 0.7096 - val_loss: 230.8210 - val_accuracy: 0.2020\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0020 - accuracy: 0.6817 - val_loss: 497.7546 - val_accuracy: 0.2115\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9991 - accuracy: 0.6950 - val_loss: 453.5020 - val_accuracy: 0.2084\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9790 - accuracy: 0.6957 - val_loss: 217.1539 - val_accuracy: 0.2089\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9822 - accuracy: 0.6883 - val_loss: 121.2488 - val_accuracy: 0.2006\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9901 - accuracy: 0.6986 - val_loss: 520.4290 - val_accuracy: 0.2000\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9871 - accuracy: 0.6982 - val_loss: 343.1030 - val_accuracy: 0.2022\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0102 - accuracy: 0.6948 - val_loss: 6875.7788 - val_accuracy: 0.1899\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9853 - accuracy: 0.6936 - val_loss: 277.6364 - val_accuracy: 0.1840\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9890 - accuracy: 0.7062 - val_loss: 6409.5269 - val_accuracy: 0.1717\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9976 - accuracy: 0.7077 - val_loss: 31.1488 - val_accuracy: 0.1960\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9937 - accuracy: 0.7023 - val_loss: 33.6174 - val_accuracy: 0.1946\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9857 - accuracy: 0.6972 - val_loss: 71.5943 - val_accuracy: 0.1994\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9844 - accuracy: 0.6950 - val_loss: 39.1853 - val_accuracy: 0.1908\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9749 - accuracy: 0.7066 - val_loss: 38.2036 - val_accuracy: 0.1903\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9673 - accuracy: 0.6935 - val_loss: 34.0146 - val_accuracy: 0.1973\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9852 - accuracy: 0.7089 - val_loss: 38.3233 - val_accuracy: 0.1989\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9771 - accuracy: 0.7094 - val_loss: 39.8872 - val_accuracy: 0.1935\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9742 - accuracy: 0.7067 - val_loss: 67.1959 - val_accuracy: 0.1940\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9764 - accuracy: 0.6945 - val_loss: 91.8585 - val_accuracy: 0.2004\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9923 - accuracy: 0.7003 - val_loss: 341.8253 - val_accuracy: 0.1961\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9799 - accuracy: 0.6977 - val_loss: 330.5425 - val_accuracy: 0.1937\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9850 - accuracy: 0.7064 - val_loss: 524.5082 - val_accuracy: 0.1806\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9804 - accuracy: 0.6915 - val_loss: 463.5335 - val_accuracy: 0.1898\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9958 - accuracy: 0.6893 - val_loss: 1461.5697 - val_accuracy: 0.1951\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9791 - accuracy: 0.6964 - val_loss: 443.1496 - val_accuracy: 0.1951\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9855 - accuracy: 0.6872 - val_loss: 63.5593 - val_accuracy: 0.1919\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0132 - accuracy: 0.7051 - val_loss: 67.8121 - val_accuracy: 0.2021\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9859 - accuracy: 0.7125 - val_loss: 51.3608 - val_accuracy: 0.2075\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9953 - accuracy: 0.6695 - val_loss: 47.6018 - val_accuracy: 0.2037\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9921 - accuracy: 0.6978 - val_loss: 2724.2344 - val_accuracy: 0.1962\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9695 - accuracy: 0.6986 - val_loss: 3278.9819 - val_accuracy: 0.2013\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9743 - accuracy: 0.7016 - val_loss: 2725.6653 - val_accuracy: 0.2024\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9767 - accuracy: 0.7066 - val_loss: 2712.2266 - val_accuracy: 0.2056\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9791 - accuracy: 0.7103 - val_loss: 1438.4084 - val_accuracy: 0.2061\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9660 - accuracy: 0.6993 - val_loss: 2115.9026 - val_accuracy: 0.2106\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9912 - accuracy: 0.7025 - val_loss: 741.7953 - val_accuracy: 0.2056\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9982 - accuracy: 0.7096 - val_loss: 242.1306 - val_accuracy: 0.2057\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9922 - accuracy: 0.6851 - val_loss: 326.6280 - val_accuracy: 0.2036\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9757 - accuracy: 0.7151 - val_loss: 80.1530 - val_accuracy: 0.2072\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9800 - accuracy: 0.6832 - val_loss: 56.8564 - val_accuracy: 0.2052\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9785 - accuracy: 0.6974 - val_loss: 65.5540 - val_accuracy: 0.2061\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9718 - accuracy: 0.7063 - val_loss: 24.6979 - val_accuracy: 0.2123\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9730 - accuracy: 0.7010 - val_loss: 1817.0040 - val_accuracy: 0.2144\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9702 - accuracy: 0.7016 - val_loss: 57.7719 - val_accuracy: 0.2080\n",
            "Epoch 00129: early stopping\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 267ms/step - loss: 1.1985 - accuracy: 0.6713 - val_loss: 1.5039 - val_accuracy: 0.7707\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0752 - accuracy: 0.7124 - val_loss: 1.5670 - val_accuracy: 0.7718\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0689 - accuracy: 0.7180 - val_loss: 1.7425 - val_accuracy: 0.7674\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0626 - accuracy: 0.7066 - val_loss: 1.6136 - val_accuracy: 0.7706\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0512 - accuracy: 0.7153 - val_loss: 1.9794 - val_accuracy: 0.7676\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0490 - accuracy: 0.7097 - val_loss: 1.7762 - val_accuracy: 0.7683\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.0270 - accuracy: 0.7249 - val_loss: 1.6671 - val_accuracy: 0.7702\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0341 - accuracy: 0.7174 - val_loss: 1.9353 - val_accuracy: 0.7675\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0227 - accuracy: 0.7148 - val_loss: 2.1315 - val_accuracy: 0.7667\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0288 - accuracy: 0.7058 - val_loss: 1.7105 - val_accuracy: 0.7723\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0433 - accuracy: 0.7214 - val_loss: 1.4801 - val_accuracy: 0.7714\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0226 - accuracy: 0.7138 - val_loss: 1.8341 - val_accuracy: 0.7683\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0141 - accuracy: 0.7082 - val_loss: 2.0885 - val_accuracy: 0.7673\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0244 - accuracy: 0.7060 - val_loss: 2.2756 - val_accuracy: 0.7680\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.0273 - accuracy: 0.7093 - val_loss: 1.8611 - val_accuracy: 0.7674\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0178 - accuracy: 0.7088 - val_loss: 1.4261 - val_accuracy: 0.7723\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9942 - accuracy: 0.6970 - val_loss: 1.7844 - val_accuracy: 0.7683\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9988 - accuracy: 0.7017 - val_loss: 1.7938 - val_accuracy: 0.7697\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0211 - accuracy: 0.6973 - val_loss: 1.1621 - val_accuracy: 0.7686\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9932 - accuracy: 0.6970 - val_loss: 1.5486 - val_accuracy: 0.7675\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9983 - accuracy: 0.6992 - val_loss: 1.5088 - val_accuracy: 0.7706\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9989 - accuracy: 0.7031 - val_loss: 1.8258 - val_accuracy: 0.7663\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0067 - accuracy: 0.7002 - val_loss: 1.6107 - val_accuracy: 0.7598\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9829 - accuracy: 0.6981 - val_loss: 1.3811 - val_accuracy: 0.7582\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9802 - accuracy: 0.6994 - val_loss: 1.7529 - val_accuracy: 0.7390\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9847 - accuracy: 0.6995 - val_loss: 1.7471 - val_accuracy: 0.7508\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9885 - accuracy: 0.7026 - val_loss: 1.1498 - val_accuracy: 0.7325\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9873 - accuracy: 0.7081 - val_loss: 1.2842 - val_accuracy: 0.7354\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 4s 263ms/step - loss: 0.9810 - accuracy: 0.6963 - val_loss: 1.7325 - val_accuracy: 0.7314\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.9821 - accuracy: 0.7122 - val_loss: 2.0729 - val_accuracy: 0.7280\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.9833 - accuracy: 0.7051 - val_loss: 3.3914 - val_accuracy: 0.7310\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9936 - accuracy: 0.6947 - val_loss: 2.0756 - val_accuracy: 0.7365\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9925 - accuracy: 0.7025 - val_loss: 4.8450 - val_accuracy: 0.7302\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9705 - accuracy: 0.7080 - val_loss: 3.7148 - val_accuracy: 0.7301\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9646 - accuracy: 0.7173 - val_loss: 3.0339 - val_accuracy: 0.7268\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9847 - accuracy: 0.7039 - val_loss: 17.5410 - val_accuracy: 0.7220\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9778 - accuracy: 0.6943 - val_loss: 4.5116 - val_accuracy: 0.7251\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9670 - accuracy: 0.7127 - val_loss: 9.7210 - val_accuracy: 0.7294\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9788 - accuracy: 0.7036 - val_loss: 3.1646 - val_accuracy: 0.7268\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9670 - accuracy: 0.7167 - val_loss: 5.9544 - val_accuracy: 0.7325\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9696 - accuracy: 0.7114 - val_loss: 1310.8828 - val_accuracy: 0.7315\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9511 - accuracy: 0.7090 - val_loss: 36833.9922 - val_accuracy: 0.6991\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9599 - accuracy: 0.7228 - val_loss: 23819.9844 - val_accuracy: 0.6838\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9611 - accuracy: 0.7134 - val_loss: 16668.3594 - val_accuracy: 0.6720\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9596 - accuracy: 0.7236 - val_loss: 46774.6680 - val_accuracy: 0.6546\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9576 - accuracy: 0.7181 - val_loss: 3700.2852 - val_accuracy: 0.4768\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9392 - accuracy: 0.7209 - val_loss: 7808.8271 - val_accuracy: 0.4968\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9435 - accuracy: 0.7186 - val_loss: 399051.7188 - val_accuracy: 0.4496\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9935 - accuracy: 0.7396 - val_loss: 9960.1729 - val_accuracy: 0.4564\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.1053 - accuracy: 0.7312 - val_loss: 37.1209 - val_accuracy: 0.4688\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0712 - accuracy: 0.7146 - val_loss: 1.9497 - val_accuracy: 0.6953\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0765 - accuracy: 0.7546 - val_loss: 1.8736 - val_accuracy: 0.7461\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0692 - accuracy: 0.7303 - val_loss: 1.5995 - val_accuracy: 0.7633\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0640 - accuracy: 0.7915 - val_loss: 2.0434 - val_accuracy: 0.7650\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0523 - accuracy: 0.7350 - val_loss: 1.7304 - val_accuracy: 0.7664\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0485 - accuracy: 0.7439 - val_loss: 1.8405 - val_accuracy: 0.7615\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0448 - accuracy: 0.8051 - val_loss: 1.6780 - val_accuracy: 0.7633\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0329 - accuracy: 0.7751 - val_loss: 1.2516 - val_accuracy: 0.7678\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0275 - accuracy: 0.7967 - val_loss: 1.2537 - val_accuracy: 0.7671\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0552 - accuracy: 0.7421 - val_loss: 1.8428 - val_accuracy: 0.7685\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0431 - accuracy: 0.7062 - val_loss: 2.1802 - val_accuracy: 0.7638\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0260 - accuracy: 0.7611 - val_loss: 1.7897 - val_accuracy: 0.7636\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0358 - accuracy: 0.7502 - val_loss: 1.8388 - val_accuracy: 0.7664\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0360 - accuracy: 0.7683 - val_loss: 1.5915 - val_accuracy: 0.7668\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0185 - accuracy: 0.7750 - val_loss: 2.4274 - val_accuracy: 0.7610\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.0248 - accuracy: 0.7783 - val_loss: 1.3236 - val_accuracy: 0.7715\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0181 - accuracy: 0.7769 - val_loss: 2.2137 - val_accuracy: 0.7632\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0368 - accuracy: 0.7648 - val_loss: 2.6581 - val_accuracy: 0.7614\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0364 - accuracy: 0.7592 - val_loss: 2.7776 - val_accuracy: 0.7651\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0215 - accuracy: 0.7587 - val_loss: 2.6134 - val_accuracy: 0.7623\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0174 - accuracy: 0.7776 - val_loss: 3.5207 - val_accuracy: 0.7608\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0288 - accuracy: 0.7688 - val_loss: 4.8756 - val_accuracy: 0.7637\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0287 - accuracy: 0.7749 - val_loss: 3.5238 - val_accuracy: 0.7624\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0377 - accuracy: 0.7693 - val_loss: 4.9335 - val_accuracy: 0.7634\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0200 - accuracy: 0.7768 - val_loss: 5.5399 - val_accuracy: 0.7643\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0283 - accuracy: 0.7682 - val_loss: 14.3344 - val_accuracy: 0.7621\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0147 - accuracy: 0.7820 - val_loss: 4.1709 - val_accuracy: 0.7636\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0145 - accuracy: 0.7897 - val_loss: 11.5421 - val_accuracy: 0.7673\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0093 - accuracy: 0.7585 - val_loss: 17.3112 - val_accuracy: 0.7606\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0208 - accuracy: 0.7808 - val_loss: 15.8948 - val_accuracy: 0.7596\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0302 - accuracy: 0.7589 - val_loss: 9.9653 - val_accuracy: 0.7503\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0185 - accuracy: 0.7760 - val_loss: 27.4460 - val_accuracy: 0.7604\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.0016 - accuracy: 0.7780 - val_loss: 19.5051 - val_accuracy: 0.7573\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0290 - accuracy: 0.7665 - val_loss: 18.6337 - val_accuracy: 0.7493\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0238 - accuracy: 0.7872 - val_loss: 5.8206 - val_accuracy: 0.7553\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0232 - accuracy: 0.7750 - val_loss: 14.7694 - val_accuracy: 0.7419\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0063 - accuracy: 0.7717 - val_loss: 53.1560 - val_accuracy: 0.7443\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0144 - accuracy: 0.7724 - val_loss: 35.0498 - val_accuracy: 0.7278\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0203 - accuracy: 0.7573 - val_loss: 99.1008 - val_accuracy: 0.7404\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0126 - accuracy: 0.7691 - val_loss: 55.5639 - val_accuracy: 0.7307\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0292 - accuracy: 0.7760 - val_loss: 14.5944 - val_accuracy: 0.6783\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0140 - accuracy: 0.7621 - val_loss: 85.2162 - val_accuracy: 0.6819\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0069 - accuracy: 0.7672 - val_loss: 46.9187 - val_accuracy: 0.6863\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0231 - accuracy: 0.7787 - val_loss: 61.7739 - val_accuracy: 0.6364\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0066 - accuracy: 0.7475 - val_loss: 172.9866 - val_accuracy: 0.6798\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0126 - accuracy: 0.7570 - val_loss: 194.5864 - val_accuracy: 0.4944\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0161 - accuracy: 0.7600 - val_loss: 432.3449 - val_accuracy: 0.4242\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0396 - accuracy: 0.7655 - val_loss: 612.4710 - val_accuracy: 0.6282\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0292 - accuracy: 0.7681 - val_loss: 434.1555 - val_accuracy: 0.5139\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0146 - accuracy: 0.7559 - val_loss: 1182.1732 - val_accuracy: 0.6567\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0093 - accuracy: 0.7632 - val_loss: 1229.7117 - val_accuracy: 0.5985\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0230 - accuracy: 0.7745 - val_loss: 893.9402 - val_accuracy: 0.3003\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0092 - accuracy: 0.7600 - val_loss: 1448.3928 - val_accuracy: 0.6168\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0129 - accuracy: 0.7714 - val_loss: 2135.9805 - val_accuracy: 0.4290\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0001 - accuracy: 0.7737 - val_loss: 3458.2358 - val_accuracy: 0.4125\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0088 - accuracy: 0.7599 - val_loss: 2884.9746 - val_accuracy: 0.5408\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0108 - accuracy: 0.7568 - val_loss: 11725.2188 - val_accuracy: 0.6113\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0117 - accuracy: 0.7535 - val_loss: 9680.0801 - val_accuracy: 0.5654\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0056 - accuracy: 0.7517 - val_loss: 8375.1074 - val_accuracy: 0.5450\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0157 - accuracy: 0.7488 - val_loss: 10283.1787 - val_accuracy: 0.4833\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0070 - accuracy: 0.7657 - val_loss: 10057.9668 - val_accuracy: 0.5016\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0254 - accuracy: 0.7492 - val_loss: 1363.0100 - val_accuracy: 0.5306\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9941 - accuracy: 0.7755 - val_loss: 3099.1858 - val_accuracy: 0.5562\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0061 - accuracy: 0.7348 - val_loss: 1479.5970 - val_accuracy: 0.5803\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0090 - accuracy: 0.7506 - val_loss: 7299.5469 - val_accuracy: 0.5931\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0053 - accuracy: 0.7494 - val_loss: 9473.5957 - val_accuracy: 0.5665\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0047 - accuracy: 0.7546 - val_loss: 19639.8223 - val_accuracy: 0.5396\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0095 - accuracy: 0.7408 - val_loss: 21440.3945 - val_accuracy: 0.5546\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0039 - accuracy: 0.7514 - val_loss: 27629.0977 - val_accuracy: 0.6113\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9983 - accuracy: 0.7619 - val_loss: 15052.4912 - val_accuracy: 0.4925\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0142 - accuracy: 0.7337 - val_loss: 22017.4961 - val_accuracy: 0.5484\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0077 - accuracy: 0.7622 - val_loss: 10177.2236 - val_accuracy: 0.5099\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0018 - accuracy: 0.7407 - val_loss: 8052.1885 - val_accuracy: 0.5405\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9837 - accuracy: 0.7585 - val_loss: 5489.5693 - val_accuracy: 0.5841\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0050 - accuracy: 0.7545 - val_loss: 7547.4834 - val_accuracy: 0.5543\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9955 - accuracy: 0.7323 - val_loss: 5074.2031 - val_accuracy: 0.5767\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9904 - accuracy: 0.7576 - val_loss: 6374.5161 - val_accuracy: 0.5443\n",
            "Epoch 00127: early stopping\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 257ms/step - loss: 1.2750 - accuracy: 0.6786 - val_loss: 2.5572 - val_accuracy: 0.5678\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.1089 - accuracy: 0.7279 - val_loss: 2.4457 - val_accuracy: 0.5675\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0839 - accuracy: 0.7368 - val_loss: 2.5366 - val_accuracy: 0.5707\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0784 - accuracy: 0.7265 - val_loss: 2.4499 - val_accuracy: 0.5714\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.0681 - accuracy: 0.7352 - val_loss: 2.8092 - val_accuracy: 0.5634\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.0570 - accuracy: 0.7168 - val_loss: 2.1110 - val_accuracy: 0.5684\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0368 - accuracy: 0.7325 - val_loss: 2.2660 - val_accuracy: 0.5708\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0614 - accuracy: 0.7284 - val_loss: 2.4930 - val_accuracy: 0.5668\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0614 - accuracy: 0.7263 - val_loss: 2.7575 - val_accuracy: 0.5634\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0472 - accuracy: 0.7186 - val_loss: 2.3267 - val_accuracy: 0.5665\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0258 - accuracy: 0.7183 - val_loss: 2.5417 - val_accuracy: 0.5680\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0421 - accuracy: 0.7177 - val_loss: 2.5467 - val_accuracy: 0.5670\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0347 - accuracy: 0.7138 - val_loss: 2.2885 - val_accuracy: 0.5661\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0239 - accuracy: 0.7167 - val_loss: 1.9347 - val_accuracy: 0.5679\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0250 - accuracy: 0.7207 - val_loss: 2.1875 - val_accuracy: 0.5494\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0084 - accuracy: 0.7231 - val_loss: 2.0070 - val_accuracy: 0.5368\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0061 - accuracy: 0.7164 - val_loss: 2.1160 - val_accuracy: 0.5143\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0537 - accuracy: 0.7226 - val_loss: 2.2447 - val_accuracy: 0.5616\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0486 - accuracy: 0.7126 - val_loss: 2.5372 - val_accuracy: 0.5619\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0205 - accuracy: 0.7316 - val_loss: 2.3588 - val_accuracy: 0.5716\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0405 - accuracy: 0.6996 - val_loss: 2.3433 - val_accuracy: 0.5336\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0197 - accuracy: 0.7131 - val_loss: 1.6955 - val_accuracy: 0.5351\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0082 - accuracy: 0.7139 - val_loss: 2.2108 - val_accuracy: 0.5612\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0004 - accuracy: 0.6859 - val_loss: 2.5260 - val_accuracy: 0.4881\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0229 - accuracy: 0.7263 - val_loss: 1.8954 - val_accuracy: 0.4956\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0044 - accuracy: 0.7039 - val_loss: 1.9667 - val_accuracy: 0.5555\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0072 - accuracy: 0.7120 - val_loss: 2.2994 - val_accuracy: 0.5573\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0061 - accuracy: 0.7064 - val_loss: 2.4688 - val_accuracy: 0.5178\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0121 - accuracy: 0.7044 - val_loss: 2.8717 - val_accuracy: 0.4722\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9975 - accuracy: 0.6970 - val_loss: 2.5008 - val_accuracy: 0.4540\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0076 - accuracy: 0.6941 - val_loss: 2.9927 - val_accuracy: 0.4462\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0001 - accuracy: 0.7055 - val_loss: 3.4444 - val_accuracy: 0.4403\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9766 - accuracy: 0.6997 - val_loss: 4.3943 - val_accuracy: 0.4274\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9751 - accuracy: 0.7106 - val_loss: 4.9221 - val_accuracy: 0.4211\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9948 - accuracy: 0.7005 - val_loss: 8.2798 - val_accuracy: 0.4163\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9829 - accuracy: 0.6989 - val_loss: 14.5967 - val_accuracy: 0.4092\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 0.9847 - accuracy: 0.7000 - val_loss: 19.2618 - val_accuracy: 0.4109\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9966 - accuracy: 0.7051 - val_loss: 19.9567 - val_accuracy: 0.4058\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9841 - accuracy: 0.7111 - val_loss: 30.0900 - val_accuracy: 0.4108\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9988 - accuracy: 0.6977 - val_loss: 7.3317 - val_accuracy: 0.4581\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9876 - accuracy: 0.6971 - val_loss: 5.4987 - val_accuracy: 0.4685\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9834 - accuracy: 0.7072 - val_loss: 6.5442 - val_accuracy: 0.4760\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9877 - accuracy: 0.7021 - val_loss: 7.1327 - val_accuracy: 0.4836\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9736 - accuracy: 0.6991 - val_loss: 7.2505 - val_accuracy: 0.4863\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9697 - accuracy: 0.7130 - val_loss: 7.9630 - val_accuracy: 0.4870\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 0.9774 - accuracy: 0.7077 - val_loss: 5.9049 - val_accuracy: 0.4885\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 0.9771 - accuracy: 0.7119 - val_loss: 6.1118 - val_accuracy: 0.4938\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9898 - accuracy: 0.7017 - val_loss: 8.0635 - val_accuracy: 0.4917\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9652 - accuracy: 0.7203 - val_loss: 26.2539 - val_accuracy: 0.4836\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9859 - accuracy: 0.7077 - val_loss: 16.6499 - val_accuracy: 0.4740\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9680 - accuracy: 0.7148 - val_loss: 19.2550 - val_accuracy: 0.4592\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9771 - accuracy: 0.7156 - val_loss: 54.5577 - val_accuracy: 0.4606\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9680 - accuracy: 0.7109 - val_loss: 55.5210 - val_accuracy: 0.4636\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9548 - accuracy: 0.7156 - val_loss: 28.6357 - val_accuracy: 0.4512\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9422 - accuracy: 0.7097 - val_loss: 38.7311 - val_accuracy: 0.4599\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9623 - accuracy: 0.7352 - val_loss: 71.9605 - val_accuracy: 0.4430\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9648 - accuracy: 0.7119 - val_loss: 82.8917 - val_accuracy: 0.4392\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9570 - accuracy: 0.7176 - val_loss: 71.4578 - val_accuracy: 0.4400\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9509 - accuracy: 0.7297 - val_loss: 61.9073 - val_accuracy: 0.4523\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9551 - accuracy: 0.7186 - val_loss: 47.5048 - val_accuracy: 0.4446\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9625 - accuracy: 0.7138 - val_loss: 33.1979 - val_accuracy: 0.4425\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9556 - accuracy: 0.7251 - val_loss: 79.7059 - val_accuracy: 0.4477\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9508 - accuracy: 0.7246 - val_loss: 57.5278 - val_accuracy: 0.4455\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9546 - accuracy: 0.7307 - val_loss: 40.9597 - val_accuracy: 0.4583\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9541 - accuracy: 0.7144 - val_loss: 50.3314 - val_accuracy: 0.4429\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9507 - accuracy: 0.7269 - val_loss: 48.3432 - val_accuracy: 0.4661\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9512 - accuracy: 0.7221 - val_loss: 341.3463 - val_accuracy: 0.4442\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9436 - accuracy: 0.7376 - val_loss: 62.3334 - val_accuracy: 0.4484\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9293 - accuracy: 0.7253 - val_loss: 35.5321 - val_accuracy: 0.4340\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9436 - accuracy: 0.7351 - val_loss: 12.7042 - val_accuracy: 0.4409\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9405 - accuracy: 0.7252 - val_loss: 13.9782 - val_accuracy: 0.4463\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9348 - accuracy: 0.7344 - val_loss: 39.6997 - val_accuracy: 0.4354\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9240 - accuracy: 0.7496 - val_loss: 4.2984 - val_accuracy: 0.4513\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9491 - accuracy: 0.7401 - val_loss: 11.2691 - val_accuracy: 0.4774\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 0.9315 - accuracy: 0.7369 - val_loss: 8.1451 - val_accuracy: 0.3811\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9325 - accuracy: 0.7293 - val_loss: 16.5970 - val_accuracy: 0.4000\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 179ms/step - loss: 0.9198 - accuracy: 0.7507 - val_loss: 5.0887 - val_accuracy: 0.3917\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9155 - accuracy: 0.7459 - val_loss: 7.5361 - val_accuracy: 0.4021\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9161 - accuracy: 0.7452 - val_loss: 12.1305 - val_accuracy: 0.3974\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9110 - accuracy: 0.7481 - val_loss: 23.4293 - val_accuracy: 0.3824\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9209 - accuracy: 0.7419 - val_loss: 14.7888 - val_accuracy: 0.3774\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9131 - accuracy: 0.7615 - val_loss: 5.9854 - val_accuracy: 0.3808\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9033 - accuracy: 0.7447 - val_loss: 9.3158 - val_accuracy: 0.3973\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9222 - accuracy: 0.7493 - val_loss: 14.1220 - val_accuracy: 0.3661\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9187 - accuracy: 0.7531 - val_loss: 11.6002 - val_accuracy: 0.3678\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9046 - accuracy: 0.7520 - val_loss: 14.1861 - val_accuracy: 0.3733\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9169 - accuracy: 0.7545 - val_loss: 10.5299 - val_accuracy: 0.3361\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9062 - accuracy: 0.7569 - val_loss: 8.9079 - val_accuracy: 0.3035\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8952 - accuracy: 0.7614 - val_loss: 10.4786 - val_accuracy: 0.3798\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9112 - accuracy: 0.7466 - val_loss: 6.1515 - val_accuracy: 0.3856\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9141 - accuracy: 0.7597 - val_loss: 10.8150 - val_accuracy: 0.2934\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9180 - accuracy: 0.7566 - val_loss: 11.0012 - val_accuracy: 0.3297\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9170 - accuracy: 0.7471 - val_loss: 21.3644 - val_accuracy: 0.2137\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9093 - accuracy: 0.7612 - val_loss: 11.3596 - val_accuracy: 0.2790\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.8817 - accuracy: 0.7643 - val_loss: 28.1802 - val_accuracy: 0.2241\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.8820 - accuracy: 0.7638 - val_loss: 26.8969 - val_accuracy: 0.2314\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8972 - accuracy: 0.7632 - val_loss: 15.6538 - val_accuracy: 0.2815\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.8787 - accuracy: 0.7632 - val_loss: 28.7071 - val_accuracy: 0.2237\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.8928 - accuracy: 0.7626 - val_loss: 12.1071 - val_accuracy: 0.3212\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8746 - accuracy: 0.7628 - val_loss: 6.1597 - val_accuracy: 0.3975\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8888 - accuracy: 0.7736 - val_loss: 7.8589 - val_accuracy: 0.3700\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.8867 - accuracy: 0.7670 - val_loss: 19.9636 - val_accuracy: 0.3093\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.8999 - accuracy: 0.7595 - val_loss: 13.4833 - val_accuracy: 0.3521\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.8788 - accuracy: 0.7662 - val_loss: 18.2757 - val_accuracy: 0.3579\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.8519 - accuracy: 0.7685 - val_loss: 12.0800 - val_accuracy: 0.3449\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8666 - accuracy: 0.7731 - val_loss: 20.8373 - val_accuracy: 0.3373\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.8487 - accuracy: 0.7727 - val_loss: 12.6401 - val_accuracy: 0.3435\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8536 - accuracy: 0.7739 - val_loss: 7.6087 - val_accuracy: 0.3896\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.8617 - accuracy: 0.7689 - val_loss: 12.1487 - val_accuracy: 0.3433\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.8465 - accuracy: 0.7737 - val_loss: 7.2018 - val_accuracy: 0.3966\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.8452 - accuracy: 0.7748 - val_loss: 4.9416 - val_accuracy: 0.4501\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.8744 - accuracy: 0.7640 - val_loss: 9.5560 - val_accuracy: 0.3796\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.8386 - accuracy: 0.7720 - val_loss: 6.9974 - val_accuracy: 0.3717\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.8531 - accuracy: 0.7731 - val_loss: 7.1247 - val_accuracy: 0.4309\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8398 - accuracy: 0.7751 - val_loss: 4.3775 - val_accuracy: 0.4472\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 181ms/step - loss: 0.8180 - accuracy: 0.7793 - val_loss: 4.3445 - val_accuracy: 0.4881\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8340 - accuracy: 0.7712 - val_loss: 4.9898 - val_accuracy: 0.4657\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8489 - accuracy: 0.7780 - val_loss: 4.8663 - val_accuracy: 0.4648\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.8828 - accuracy: 0.7681 - val_loss: 6.2922 - val_accuracy: 0.4166\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8344 - accuracy: 0.7687 - val_loss: 5.7474 - val_accuracy: 0.4531\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8280 - accuracy: 0.7795 - val_loss: 5.6766 - val_accuracy: 0.4355\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.8584 - accuracy: 0.7715 - val_loss: 6.3510 - val_accuracy: 0.4354\n",
            "Epoch 00122: early stopping\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 247ms/step - loss: 1.1392 - accuracy: 0.6980 - val_loss: 20.0120 - val_accuracy: 0.3839\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0950 - accuracy: 0.7103 - val_loss: 20.8318 - val_accuracy: 0.3864\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0576 - accuracy: 0.7346 - val_loss: 21.3401 - val_accuracy: 0.3825\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0634 - accuracy: 0.7067 - val_loss: 19.5851 - val_accuracy: 0.3825\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0363 - accuracy: 0.7245 - val_loss: 19.9369 - val_accuracy: 0.3871\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0320 - accuracy: 0.7027 - val_loss: 22.4807 - val_accuracy: 0.3857\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0202 - accuracy: 0.7231 - val_loss: 20.6791 - val_accuracy: 0.3874\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0155 - accuracy: 0.7146 - val_loss: 21.2943 - val_accuracy: 0.3857\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0276 - accuracy: 0.7103 - val_loss: 19.8338 - val_accuracy: 0.3894\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0150 - accuracy: 0.7128 - val_loss: 19.8915 - val_accuracy: 0.3837\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0300 - accuracy: 0.7095 - val_loss: 20.8208 - val_accuracy: 0.3833\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0598 - accuracy: 0.7300 - val_loss: 22.4705 - val_accuracy: 0.3851\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1181 - accuracy: 0.7383 - val_loss: 20.2412 - val_accuracy: 0.3826\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0747 - accuracy: 0.7084 - val_loss: 19.0562 - val_accuracy: 0.3833\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0689 - accuracy: 0.7483 - val_loss: 23.2263 - val_accuracy: 0.3832\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0594 - accuracy: 0.6944 - val_loss: 20.9110 - val_accuracy: 0.3832\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0237 - accuracy: 0.7371 - val_loss: 22.0082 - val_accuracy: 0.3804\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0392 - accuracy: 0.7263 - val_loss: 20.0857 - val_accuracy: 0.3846\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0213 - accuracy: 0.7201 - val_loss: 19.9819 - val_accuracy: 0.3837\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0203 - accuracy: 0.7006 - val_loss: 20.2721 - val_accuracy: 0.3835\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0165 - accuracy: 0.7324 - val_loss: 23.9657 - val_accuracy: 0.3853\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0263 - accuracy: 0.6858 - val_loss: 20.6258 - val_accuracy: 0.3842\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0084 - accuracy: 0.7632 - val_loss: 19.6275 - val_accuracy: 0.3834\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0221 - accuracy: 0.7224 - val_loss: 20.1249 - val_accuracy: 0.3833\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0319 - accuracy: 0.7072 - val_loss: 19.9428 - val_accuracy: 0.3830\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0177 - accuracy: 0.7155 - val_loss: 23.7246 - val_accuracy: 0.3820\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0217 - accuracy: 0.7067 - val_loss: 22.6753 - val_accuracy: 0.3810\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0107 - accuracy: 0.7428 - val_loss: 22.1616 - val_accuracy: 0.3812\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0117 - accuracy: 0.7122 - val_loss: 20.9808 - val_accuracy: 0.3868\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0034 - accuracy: 0.7109 - val_loss: 23.9356 - val_accuracy: 0.3788\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0081 - accuracy: 0.7318 - val_loss: 20.6722 - val_accuracy: 0.3778\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0081 - accuracy: 0.7052 - val_loss: 20.0103 - val_accuracy: 0.3812\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0011 - accuracy: 0.7181 - val_loss: 23.4572 - val_accuracy: 0.3748\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0154 - accuracy: 0.7152 - val_loss: 20.1094 - val_accuracy: 0.3684\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0186 - accuracy: 0.7263 - val_loss: 20.0690 - val_accuracy: 0.3352\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9984 - accuracy: 0.7188 - val_loss: 25.7196 - val_accuracy: 0.2953\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0235 - accuracy: 0.7164 - val_loss: 20.3729 - val_accuracy: 0.2468\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9882 - accuracy: 0.7240 - val_loss: 20.1576 - val_accuracy: 0.2140\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9897 - accuracy: 0.7238 - val_loss: 21.4396 - val_accuracy: 0.2417\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0047 - accuracy: 0.7253 - val_loss: 18.9375 - val_accuracy: 0.2501\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0019 - accuracy: 0.7265 - val_loss: 19.2142 - val_accuracy: 0.2516\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9999 - accuracy: 0.7293 - val_loss: 24.2169 - val_accuracy: 0.2547\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9997 - accuracy: 0.7118 - val_loss: 16.8163 - val_accuracy: 0.2409\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9994 - accuracy: 0.7246 - val_loss: 20.3467 - val_accuracy: 0.2379\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0049 - accuracy: 0.7125 - val_loss: 19.2604 - val_accuracy: 0.2700\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0070 - accuracy: 0.7096 - val_loss: 17.7658 - val_accuracy: 0.2701\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0065 - accuracy: 0.7288 - val_loss: 22.8721 - val_accuracy: 0.2603\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0055 - accuracy: 0.6971 - val_loss: 18.6460 - val_accuracy: 0.2890\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0013 - accuracy: 0.7266 - val_loss: 20.1990 - val_accuracy: 0.2612\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0048 - accuracy: 0.7220 - val_loss: 22.4020 - val_accuracy: 0.2746\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9878 - accuracy: 0.7132 - val_loss: 21.0479 - val_accuracy: 0.2736\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9939 - accuracy: 0.7349 - val_loss: 18.2320 - val_accuracy: 0.2814\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0184 - accuracy: 0.7198 - val_loss: 21.5186 - val_accuracy: 0.2860\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9874 - accuracy: 0.7155 - val_loss: 28.5028 - val_accuracy: 0.2648\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9988 - accuracy: 0.7103 - val_loss: 53.7607 - val_accuracy: 0.2644\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 0.9909 - accuracy: 0.7332 - val_loss: 145.2149 - val_accuracy: 0.2673\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9833 - accuracy: 0.7084 - val_loss: 19.2475 - val_accuracy: 0.2846\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0020 - accuracy: 0.7239 - val_loss: 21.1643 - val_accuracy: 0.2927\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0022 - accuracy: 0.7138 - val_loss: 28.8324 - val_accuracy: 0.2815\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9958 - accuracy: 0.7060 - val_loss: 18.9616 - val_accuracy: 0.2768\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0008 - accuracy: 0.7365 - val_loss: 130.0725 - val_accuracy: 0.3031\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0007 - accuracy: 0.7094 - val_loss: 20.5028 - val_accuracy: 0.3123\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9964 - accuracy: 0.7375 - val_loss: 37.4783 - val_accuracy: 0.3231\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0134 - accuracy: 0.7076 - val_loss: 33.0952 - val_accuracy: 0.2944\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9871 - accuracy: 0.7212 - val_loss: 18.9712 - val_accuracy: 0.3081\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9804 - accuracy: 0.7167 - val_loss: 25.8683 - val_accuracy: 0.3053\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 181ms/step - loss: 0.9873 - accuracy: 0.7195 - val_loss: 149.0996 - val_accuracy: 0.3090\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.9759 - accuracy: 0.7132 - val_loss: 190.2923 - val_accuracy: 0.3034\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 5s 289ms/step - loss: 0.9965 - accuracy: 0.7153 - val_loss: 385.2105 - val_accuracy: 0.3066\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9924 - accuracy: 0.7168 - val_loss: 19.6698 - val_accuracy: 0.3111\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9724 - accuracy: 0.7280 - val_loss: 21.5702 - val_accuracy: 0.3128\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9865 - accuracy: 0.7129 - val_loss: 72.9085 - val_accuracy: 0.3283\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9936 - accuracy: 0.7239 - val_loss: 45.5269 - val_accuracy: 0.3157\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0115 - accuracy: 0.7130 - val_loss: 45.6028 - val_accuracy: 0.2955\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9813 - accuracy: 0.7074 - val_loss: 38.9286 - val_accuracy: 0.3113\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9846 - accuracy: 0.7241 - val_loss: 280.2810 - val_accuracy: 0.3023\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9768 - accuracy: 0.7185 - val_loss: 24.6623 - val_accuracy: 0.2981\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9869 - accuracy: 0.7098 - val_loss: 24.2174 - val_accuracy: 0.3150\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9851 - accuracy: 0.7216 - val_loss: 113.8978 - val_accuracy: 0.3055\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9888 - accuracy: 0.7050 - val_loss: 21.4764 - val_accuracy: 0.3454\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9905 - accuracy: 0.7162 - val_loss: 19.6602 - val_accuracy: 0.3096\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0001 - accuracy: 0.7114 - val_loss: 37.8878 - val_accuracy: 0.2714\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9871 - accuracy: 0.7097 - val_loss: 22.9044 - val_accuracy: 0.2884\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9728 - accuracy: 0.7133 - val_loss: 37.7238 - val_accuracy: 0.3128\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9809 - accuracy: 0.7265 - val_loss: 130.9149 - val_accuracy: 0.2590\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9794 - accuracy: 0.7054 - val_loss: 42.3492 - val_accuracy: 0.2843\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9701 - accuracy: 0.7179 - val_loss: 271.0384 - val_accuracy: 0.2840\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9824 - accuracy: 0.7137 - val_loss: 530.4095 - val_accuracy: 0.2837\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9835 - accuracy: 0.7105 - val_loss: 32.6492 - val_accuracy: 0.2999\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9848 - accuracy: 0.7272 - val_loss: 233.3203 - val_accuracy: 0.2924\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9735 - accuracy: 0.7094 - val_loss: 159.4727 - val_accuracy: 0.2837\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9946 - accuracy: 0.7151 - val_loss: 1693.9420 - val_accuracy: 0.2843\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9742 - accuracy: 0.7232 - val_loss: 567.0318 - val_accuracy: 0.2842\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9714 - accuracy: 0.7295 - val_loss: 548.2795 - val_accuracy: 0.2789\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9816 - accuracy: 0.7159 - val_loss: 113.4900 - val_accuracy: 0.2884\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9755 - accuracy: 0.7336 - val_loss: 243.3835 - val_accuracy: 0.2750\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9777 - accuracy: 0.7146 - val_loss: 79.8242 - val_accuracy: 0.2939\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9775 - accuracy: 0.7284 - val_loss: 356.1588 - val_accuracy: 0.2836\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9760 - accuracy: 0.7267 - val_loss: 469.0894 - val_accuracy: 0.2924\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9682 - accuracy: 0.7259 - val_loss: 519.0851 - val_accuracy: 0.2874\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9600 - accuracy: 0.7348 - val_loss: 549.5717 - val_accuracy: 0.2900\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9642 - accuracy: 0.7240 - val_loss: 135.1154 - val_accuracy: 0.2778\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9527 - accuracy: 0.7345 - val_loss: 582.4195 - val_accuracy: 0.2937\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9676 - accuracy: 0.7248 - val_loss: 3130.3418 - val_accuracy: 0.3135\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9609 - accuracy: 0.7100 - val_loss: 212.5777 - val_accuracy: 0.3033\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9861 - accuracy: 0.7097 - val_loss: 285.6675 - val_accuracy: 0.3113\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9673 - accuracy: 0.7340 - val_loss: 166.2860 - val_accuracy: 0.3135\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9651 - accuracy: 0.7253 - val_loss: 938.4742 - val_accuracy: 0.3186\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9850 - accuracy: 0.7544 - val_loss: 39.8151 - val_accuracy: 0.3537\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9698 - accuracy: 0.7318 - val_loss: 365.3724 - val_accuracy: 0.2825\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9896 - accuracy: 0.7349 - val_loss: 160.1867 - val_accuracy: 0.2830\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9583 - accuracy: 0.7388 - val_loss: 939.1359 - val_accuracy: 0.2957\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9584 - accuracy: 0.7408 - val_loss: 959.5307 - val_accuracy: 0.2693\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 180ms/step - loss: 0.9673 - accuracy: 0.7344 - val_loss: 3195.2922 - val_accuracy: 0.2768\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9515 - accuracy: 0.7399 - val_loss: 1452.3411 - val_accuracy: 0.2800\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9647 - accuracy: 0.7294 - val_loss: 124.7140 - val_accuracy: 0.2890\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9516 - accuracy: 0.7374 - val_loss: 264.0960 - val_accuracy: 0.2909\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9573 - accuracy: 0.7311 - val_loss: 256.9382 - val_accuracy: 0.2801\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9639 - accuracy: 0.7266 - val_loss: 236.3282 - val_accuracy: 0.2929\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9407 - accuracy: 0.7352 - val_loss: 75.8714 - val_accuracy: 0.2855\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9477 - accuracy: 0.7241 - val_loss: 87.8269 - val_accuracy: 0.3087\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9677 - accuracy: 0.7367 - val_loss: 87.5486 - val_accuracy: 0.3060\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9542 - accuracy: 0.7305 - val_loss: 237.2121 - val_accuracy: 0.3016\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9474 - accuracy: 0.7399 - val_loss: 79.9262 - val_accuracy: 0.2977\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9407 - accuracy: 0.7296 - val_loss: 3515.9958 - val_accuracy: 0.3026\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9583 - accuracy: 0.7427 - val_loss: 634.7646 - val_accuracy: 0.2942\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9514 - accuracy: 0.7483 - val_loss: 107.2306 - val_accuracy: 0.2881\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9568 - accuracy: 0.7296 - val_loss: 27.0429 - val_accuracy: 0.2802\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9743 - accuracy: 0.7370 - val_loss: 205.6224 - val_accuracy: 0.2816\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9456 - accuracy: 0.7348 - val_loss: 87.2232 - val_accuracy: 0.2955\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9418 - accuracy: 0.7319 - val_loss: 30.9517 - val_accuracy: 0.2859\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9575 - accuracy: 0.7289 - val_loss: 37.0401 - val_accuracy: 0.2763\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9358 - accuracy: 0.7335 - val_loss: 94.8449 - val_accuracy: 0.2804\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9460 - accuracy: 0.7477 - val_loss: 45.7279 - val_accuracy: 0.2994\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9509 - accuracy: 0.7385 - val_loss: 19.6169 - val_accuracy: 0.2973\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9460 - accuracy: 0.7418 - val_loss: 67.2692 - val_accuracy: 0.2887\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9483 - accuracy: 0.7335 - val_loss: 77.1403 - val_accuracy: 0.2709\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9512 - accuracy: 0.7315 - val_loss: 92.1597 - val_accuracy: 0.2540\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9519 - accuracy: 0.7330 - val_loss: 48.2125 - val_accuracy: 0.2680\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 3s 181ms/step - loss: 0.9418 - accuracy: 0.7326 - val_loss: 1958.4998 - val_accuracy: 0.2801\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9488 - accuracy: 0.7296 - val_loss: 11761.2988 - val_accuracy: 0.2690\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9532 - accuracy: 0.7390 - val_loss: 26.8090 - val_accuracy: 0.3153\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9504 - accuracy: 0.7353 - val_loss: 23.1034 - val_accuracy: 0.2918\n",
            "Epoch 00143: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAXpsGg6TeFj",
        "colab_type": "text"
      },
      "source": [
        "# ハイパーパラメータチューニング用の関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHOAs5F7NuEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from keras.callbacks import EarlyStopping \n",
        "\n",
        "DATA_PATH = \"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas_onehot/training_datas\"\n",
        "\n",
        "def objective(hyperparameters, datapath=DATA_PATH, num_samples=30490):\n",
        "    \"\"\"\n",
        "    hyperparameters:\n",
        "    LSTM units\n",
        "    LSTM activation\n",
        "\n",
        "    # ハイパーパラメータは、build_modelの引数に渡す。\n",
        "    後ほど実装。(今は引数なし)\n",
        "\n",
        "    \"\"\"\n",
        "    batch_size = 128\n",
        "    epochs = 500\n",
        "    patience = 10000\n",
        "\n",
        "    \n",
        "    kfold = KFold(n_splits=5)\n",
        "    History = []\n",
        "\n",
        "    for train_cv_idx, valid_cv_idx in kfold.split(np.arange(0, num_samples)):\n",
        "\n",
        "        X_CV_train_gen = ReccurentTrainGenerator(DataPath=datapath, batch_size=128, InputSteps=28, sample_indices=train_cv_idx)\n",
        "        X_CV_valid_gen = ReccurentTrainGenerator(DataPath=datapath, batch_size=128, InputSteps=28, sample_indices=valid_cv_idx)\n",
        "\n",
        "        model = build_model() # 引数にハイパーパラメータを入れられるようにする\n",
        "\n",
        "        early_stopping = EarlyStopping(patience=patience, verbose=1) \n",
        "\n",
        "        history = model.fit_generator(X_CV_train_gen, epochs=epochs, verbose=1, validation_data=X_CV_valid_gen, callbacks=[early_stopping])\n",
        "        History.append(history)\n",
        "\n",
        "    scores = [History[i].history[\"val_loss\"][-1] for i in range(len(History))]\n",
        "    mean_score = np.mean(scores)\n",
        "\n",
        "    return mean_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haQ8RUtAPcZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bcc82f67-4923-46b0-8b4c-55837228f0a2"
      },
      "source": [
        "mean_score = objective(\"hyperparameters\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3447 - accuracy: 0.5629 - val_loss: 3.5539 - val_accuracy: 0.6957\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3145 - accuracy: 0.5606 - val_loss: 2.8256 - val_accuracy: 0.6967\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2825 - accuracy: 0.5599 - val_loss: 2.6238 - val_accuracy: 0.7027\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.2400 - accuracy: 0.5645 - val_loss: 3.1014 - val_accuracy: 0.6978\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2230 - accuracy: 0.5671 - val_loss: 2.9916 - val_accuracy: 0.7033\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.1849 - accuracy: 0.5665 - val_loss: 3.4472 - val_accuracy: 0.7009\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1912 - accuracy: 0.5658 - val_loss: 2.6143 - val_accuracy: 0.6780\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1677 - accuracy: 0.5696 - val_loss: 3.8796 - val_accuracy: 0.6751\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1457 - accuracy: 0.5727 - val_loss: 2.5380 - val_accuracy: 0.6647\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1406 - accuracy: 0.5720 - val_loss: 3.5448 - val_accuracy: 0.6658\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1034 - accuracy: 0.5812 - val_loss: 3.3276 - val_accuracy: 0.6634\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0942 - accuracy: 0.5836 - val_loss: 2.5964 - val_accuracy: 0.6543\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0716 - accuracy: 0.5921 - val_loss: 3.3636 - val_accuracy: 0.6607\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0788 - accuracy: 0.5846 - val_loss: 3.2120 - val_accuracy: 0.6610\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0754 - accuracy: 0.5877 - val_loss: 3.9933 - val_accuracy: 0.6597\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.0556 - accuracy: 0.5894 - val_loss: 2.4481 - val_accuracy: 0.6678\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0528 - accuracy: 0.5925 - val_loss: 2.7866 - val_accuracy: 0.6845\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0360 - accuracy: 0.5951 - val_loss: 3.1662 - val_accuracy: 0.6783\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.0323 - accuracy: 0.5939 - val_loss: 3.2004 - val_accuracy: 0.6886\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0400 - accuracy: 0.5961 - val_loss: 4.8639 - val_accuracy: 0.6819\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.0479 - accuracy: 0.5915 - val_loss: 3.7058 - val_accuracy: 0.6930\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0322 - accuracy: 0.5913 - val_loss: 5.0643 - val_accuracy: 0.6829\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0301 - accuracy: 0.5966 - val_loss: 3.9388 - val_accuracy: 0.6861\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.0275 - accuracy: 0.5976 - val_loss: 6.6375 - val_accuracy: 0.6832\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0229 - accuracy: 0.5959 - val_loss: 3.2681 - val_accuracy: 0.6825\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0137 - accuracy: 0.5952 - val_loss: 3.8916 - val_accuracy: 0.6893\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0253 - accuracy: 0.5945 - val_loss: 2.3185 - val_accuracy: 0.6821\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 1.0251 - accuracy: 0.5938 - val_loss: 3.5249 - val_accuracy: 0.6808\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9929 - accuracy: 0.6031 - val_loss: 6.0348 - val_accuracy: 0.6900\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0098 - accuracy: 0.5963 - val_loss: 2.0271 - val_accuracy: 0.6746\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9958 - accuracy: 0.5979 - val_loss: 2.9650 - val_accuracy: 0.6739\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9971 - accuracy: 0.5990 - val_loss: 6.0087 - val_accuracy: 0.6403\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9946 - accuracy: 0.6008 - val_loss: 3.6985 - val_accuracy: 0.6537\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0008 - accuracy: 0.5974 - val_loss: 17.5073 - val_accuracy: 0.6326\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0005 - accuracy: 0.5991 - val_loss: 81.2919 - val_accuracy: 0.6232\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0057 - accuracy: 0.5965 - val_loss: 3.8645 - val_accuracy: 0.6327\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9906 - accuracy: 0.6019 - val_loss: 5.5773 - val_accuracy: 0.6407\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9954 - accuracy: 0.5981 - val_loss: 2.6384 - val_accuracy: 0.5919\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9749 - accuracy: 0.6077 - val_loss: 256.6933 - val_accuracy: 0.5761\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.9927 - accuracy: 0.6010 - val_loss: 3.4057 - val_accuracy: 0.6157\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.9969 - accuracy: 0.5993 - val_loss: 62.6693 - val_accuracy: 0.6307\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.9920 - accuracy: 0.5991 - val_loss: 1125.2308 - val_accuracy: 0.5029\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9890 - accuracy: 0.5994 - val_loss: 57.2949 - val_accuracy: 0.5234\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9821 - accuracy: 0.6009 - val_loss: 3.5837 - val_accuracy: 0.5447\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9721 - accuracy: 0.6007 - val_loss: 3.2851 - val_accuracy: 0.4893\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9648 - accuracy: 0.6010 - val_loss: 31.5070 - val_accuracy: 0.4794\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9652 - accuracy: 0.6079 - val_loss: 5.8473 - val_accuracy: 0.5186\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9779 - accuracy: 0.5980 - val_loss: 8.1205 - val_accuracy: 0.5536\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9737 - accuracy: 0.6027 - val_loss: 4.2089 - val_accuracy: 0.4907\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9780 - accuracy: 0.6014 - val_loss: 3.4506 - val_accuracy: 0.4652\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.1011 - accuracy: 0.5806 - val_loss: 58.5012 - val_accuracy: 0.3938\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3486 - accuracy: 0.5186 - val_loss: 6.6560 - val_accuracy: 0.1535\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.4314 - accuracy: 0.4935 - val_loss: 17.9412 - val_accuracy: 0.0756\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3441 - accuracy: 0.5235 - val_loss: 3.1999 - val_accuracy: 0.0945\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2054 - accuracy: 0.5382 - val_loss: 3.4502 - val_accuracy: 0.1186\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2647 - accuracy: 0.5429 - val_loss: 2.6215 - val_accuracy: 0.0929\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2365 - accuracy: 0.5463 - val_loss: 3.4794 - val_accuracy: 0.0963\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.1840 - accuracy: 0.5537 - val_loss: 3.6369 - val_accuracy: 0.0945\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1458 - accuracy: 0.5647 - val_loss: 3.3824 - val_accuracy: 0.0941\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1084 - accuracy: 0.5698 - val_loss: 3.3869 - val_accuracy: 0.0914\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0868 - accuracy: 0.5772 - val_loss: 3.2329 - val_accuracy: 0.0906\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0853 - accuracy: 0.5877 - val_loss: 2.9973 - val_accuracy: 0.0896\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0926 - accuracy: 0.5822 - val_loss: 2.5249 - val_accuracy: 0.0944\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0713 - accuracy: 0.5793 - val_loss: 4.2279 - val_accuracy: 0.1018\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0783 - accuracy: 0.5833 - val_loss: 4.5173 - val_accuracy: 0.1102\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0655 - accuracy: 0.5811 - val_loss: 2.8815 - val_accuracy: 0.2257\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0552 - accuracy: 0.5824 - val_loss: 9.7101 - val_accuracy: 0.2683\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0367 - accuracy: 0.5867 - val_loss: 17.7725 - val_accuracy: 0.2767\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0360 - accuracy: 0.5902 - val_loss: 20.1529 - val_accuracy: 0.3639\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0455 - accuracy: 0.5829 - val_loss: 20.7165 - val_accuracy: 0.4042\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0297 - accuracy: 0.5917 - val_loss: 46.6683 - val_accuracy: 0.3428\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0337 - accuracy: 0.5824 - val_loss: 75.7233 - val_accuracy: 0.3651\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0260 - accuracy: 0.5884 - val_loss: 63.5167 - val_accuracy: 0.4399\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0336 - accuracy: 0.5842 - val_loss: 45.4633 - val_accuracy: 0.4132\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0238 - accuracy: 0.5866 - val_loss: 23.9705 - val_accuracy: 0.4655\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0139 - accuracy: 0.5915 - val_loss: 110.0091 - val_accuracy: 0.4655\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0114 - accuracy: 0.5887 - val_loss: 180.6812 - val_accuracy: 0.4498\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0169 - accuracy: 0.5873 - val_loss: 1872.4271 - val_accuracy: 0.4370\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0109 - accuracy: 0.5883 - val_loss: 142.2923 - val_accuracy: 0.4379\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0080 - accuracy: 0.5887 - val_loss: 126.6791 - val_accuracy: 0.4564\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0094 - accuracy: 0.5934 - val_loss: 73.3371 - val_accuracy: 0.4585\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0063 - accuracy: 0.5889 - val_loss: 39.2920 - val_accuracy: 0.4509\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9917 - accuracy: 0.5917 - val_loss: 42.7797 - val_accuracy: 0.4316\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0019 - accuracy: 0.5935 - val_loss: 20.3793 - val_accuracy: 0.3737\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9984 - accuracy: 0.5914 - val_loss: 106.8139 - val_accuracy: 0.3295\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9983 - accuracy: 0.5902 - val_loss: 74.0396 - val_accuracy: 0.3097\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9901 - accuracy: 0.5922 - val_loss: 150.8721 - val_accuracy: 0.2761\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9957 - accuracy: 0.5921 - val_loss: 150.0727 - val_accuracy: 0.2844\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.9859 - accuracy: 0.5942 - val_loss: 15.7813 - val_accuracy: 0.3108\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9708 - accuracy: 0.5959 - val_loss: 177.7628 - val_accuracy: 0.2840\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9819 - accuracy: 0.5995 - val_loss: 129.8249 - val_accuracy: 0.3139\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9885 - accuracy: 0.5939 - val_loss: 119.3301 - val_accuracy: 0.3201\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9819 - accuracy: 0.5955 - val_loss: 100.0091 - val_accuracy: 0.3183\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9818 - accuracy: 0.5946 - val_loss: 21.8923 - val_accuracy: 0.2762\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9836 - accuracy: 0.5965 - val_loss: 86.6399 - val_accuracy: 0.2579\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9802 - accuracy: 0.5927 - val_loss: 28.2397 - val_accuracy: 0.2841\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.9632 - accuracy: 0.6015 - val_loss: 73.9118 - val_accuracy: 0.2987\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 4s 279ms/step - loss: 0.9640 - accuracy: 0.5980 - val_loss: 85.6026 - val_accuracy: 0.2874\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9618 - accuracy: 0.5999 - val_loss: 17.6414 - val_accuracy: 0.3052\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9660 - accuracy: 0.6020 - val_loss: 71.9447 - val_accuracy: 0.3147\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9675 - accuracy: 0.5989 - val_loss: 86.5619 - val_accuracy: 0.2947\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9714 - accuracy: 0.5938 - val_loss: 11.0855 - val_accuracy: 0.2780\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9848 - accuracy: 0.5954 - val_loss: 22.8140 - val_accuracy: 0.2308\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9597 - accuracy: 0.5963 - val_loss: 14.2142 - val_accuracy: 0.2187\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9624 - accuracy: 0.5990 - val_loss: 50.5942 - val_accuracy: 0.1764\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9585 - accuracy: 0.5974 - val_loss: 29.0632 - val_accuracy: 0.1755\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9584 - accuracy: 0.5989 - val_loss: 78.4848 - val_accuracy: 0.2080\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9555 - accuracy: 0.5975 - val_loss: 21.4121 - val_accuracy: 0.2604\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9643 - accuracy: 0.5973 - val_loss: 25.6301 - val_accuracy: 0.2608\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.9616 - accuracy: 0.5960 - val_loss: 12.7374 - val_accuracy: 0.2669\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.9582 - accuracy: 0.6003 - val_loss: 18.5900 - val_accuracy: 0.2736\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9463 - accuracy: 0.5993 - val_loss: 28.6114 - val_accuracy: 0.2908\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9456 - accuracy: 0.6033 - val_loss: 50.6079 - val_accuracy: 0.3342\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9504 - accuracy: 0.6049 - val_loss: 24.4348 - val_accuracy: 0.3037\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9495 - accuracy: 0.5999 - val_loss: 6.7179 - val_accuracy: 0.3209\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9608 - accuracy: 0.5941 - val_loss: 118.4430 - val_accuracy: 0.2660\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9424 - accuracy: 0.6008 - val_loss: 24.7107 - val_accuracy: 0.2968\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9561 - accuracy: 0.5990 - val_loss: 7.4026 - val_accuracy: 0.3402\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9551 - accuracy: 0.6001 - val_loss: 11.3760 - val_accuracy: 0.2775\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9351 - accuracy: 0.5987 - val_loss: 6.4259 - val_accuracy: 0.2717\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9449 - accuracy: 0.6007 - val_loss: 9.9988 - val_accuracy: 0.2104\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.9268 - accuracy: 0.6017 - val_loss: 7.5814 - val_accuracy: 0.2137\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9450 - accuracy: 0.5990 - val_loss: 8.2237 - val_accuracy: 0.1937\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9405 - accuracy: 0.6022 - val_loss: 10.3679 - val_accuracy: 0.1957\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9291 - accuracy: 0.6022 - val_loss: 6.9881 - val_accuracy: 0.2400\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9468 - accuracy: 0.6027 - val_loss: 6.0200 - val_accuracy: 0.2496\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9449 - accuracy: 0.5980 - val_loss: 3.9817 - val_accuracy: 0.3522\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9551 - accuracy: 0.5965 - val_loss: 6.1599 - val_accuracy: 0.2712\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9369 - accuracy: 0.6020 - val_loss: 5.1157 - val_accuracy: 0.2932\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9229 - accuracy: 0.6049 - val_loss: 5.5699 - val_accuracy: 0.2548\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9200 - accuracy: 0.6064 - val_loss: 3.3812 - val_accuracy: 0.2842\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9336 - accuracy: 0.6065 - val_loss: 3.7794 - val_accuracy: 0.2740\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9369 - accuracy: 0.6003 - val_loss: 4.4893 - val_accuracy: 0.2859\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9376 - accuracy: 0.5955 - val_loss: 3.6627 - val_accuracy: 0.2859\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9377 - accuracy: 0.6006 - val_loss: 4.6456 - val_accuracy: 0.2757\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9262 - accuracy: 0.6000 - val_loss: 4.7818 - val_accuracy: 0.2102\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9192 - accuracy: 0.6008 - val_loss: 4.8017 - val_accuracy: 0.2550\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9065 - accuracy: 0.6069 - val_loss: 4.6845 - val_accuracy: 0.2286\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9190 - accuracy: 0.6049 - val_loss: 5.8780 - val_accuracy: 0.2264\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9341 - accuracy: 0.5983 - val_loss: 5.4673 - val_accuracy: 0.2007\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9115 - accuracy: 0.6043 - val_loss: 4.8168 - val_accuracy: 0.2052\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9211 - accuracy: 0.6065 - val_loss: 4.5275 - val_accuracy: 0.2515\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9189 - accuracy: 0.6035 - val_loss: 13.5826 - val_accuracy: 0.2280\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9178 - accuracy: 0.6035 - val_loss: 3.7261 - val_accuracy: 0.2087\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9212 - accuracy: 0.6032 - val_loss: 14.5994 - val_accuracy: 0.2231\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9165 - accuracy: 0.6047 - val_loss: 3.6610 - val_accuracy: 0.2613\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9049 - accuracy: 0.6033 - val_loss: 4.6465 - val_accuracy: 0.2128\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9673 - accuracy: 0.5938 - val_loss: 3.0557 - val_accuracy: 0.2714\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0475 - accuracy: 0.5691 - val_loss: 3.8212 - val_accuracy: 0.1433\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9905 - accuracy: 0.5847 - val_loss: 6.2922 - val_accuracy: 0.1223\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9558 - accuracy: 0.5929 - val_loss: 5.3693 - val_accuracy: 0.1370\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9536 - accuracy: 0.5943 - val_loss: 5.3540 - val_accuracy: 0.1116\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9460 - accuracy: 0.5958 - val_loss: 7.7758 - val_accuracy: 0.1362\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9360 - accuracy: 0.5985 - val_loss: 8.5302 - val_accuracy: 0.1067\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9113 - accuracy: 0.6039 - val_loss: 10.5295 - val_accuracy: 0.0910\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9315 - accuracy: 0.6000 - val_loss: 10.5419 - val_accuracy: 0.0900\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9091 - accuracy: 0.6059 - val_loss: 9.7523 - val_accuracy: 0.0782\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9267 - accuracy: 0.6049 - val_loss: 125.8820 - val_accuracy: 0.0799\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9058 - accuracy: 0.6062 - val_loss: 18.2874 - val_accuracy: 0.0818\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9354 - accuracy: 0.6018 - val_loss: 86.8657 - val_accuracy: 0.0766\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9105 - accuracy: 0.6028 - val_loss: 11.2525 - val_accuracy: 0.0833\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.9117 - accuracy: 0.6076 - val_loss: 10.2481 - val_accuracy: 0.0737\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 0.9162 - accuracy: 0.6024 - val_loss: 13.4477 - val_accuracy: 0.0737\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9239 - accuracy: 0.6088 - val_loss: 12.0863 - val_accuracy: 0.0725\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9108 - accuracy: 0.6026 - val_loss: 17.7294 - val_accuracy: 0.0686\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9060 - accuracy: 0.6047 - val_loss: 69.6207 - val_accuracy: 0.0648\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9078 - accuracy: 0.6051 - val_loss: 414.6410 - val_accuracy: 0.0665\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9138 - accuracy: 0.6029 - val_loss: 21.6152 - val_accuracy: 0.0604\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9034 - accuracy: 0.6066 - val_loss: 13.4748 - val_accuracy: 0.0653\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.9004 - accuracy: 0.6076 - val_loss: 17.3952 - val_accuracy: 0.0624\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8889 - accuracy: 0.6090 - val_loss: 30.9644 - val_accuracy: 0.0664\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9279 - accuracy: 0.6041 - val_loss: 22.4242 - val_accuracy: 0.0650\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9152 - accuracy: 0.5967 - val_loss: 28.2103 - val_accuracy: 0.0626\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9103 - accuracy: 0.6069 - val_loss: 26.4739 - val_accuracy: 0.0635\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8919 - accuracy: 0.6095 - val_loss: 14.1232 - val_accuracy: 0.0661\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8910 - accuracy: 0.6074 - val_loss: 15.5357 - val_accuracy: 0.0673\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9173 - accuracy: 0.6051 - val_loss: 17.0360 - val_accuracy: 0.0637\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9064 - accuracy: 0.6037 - val_loss: 33.3320 - val_accuracy: 0.0639\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8877 - accuracy: 0.6093 - val_loss: 45.9229 - val_accuracy: 0.0526\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8971 - accuracy: 0.6077 - val_loss: 29.2774 - val_accuracy: 0.0662\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.8990 - accuracy: 0.6056 - val_loss: 10.9615 - val_accuracy: 0.0691\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 0.9126 - accuracy: 0.5983 - val_loss: 18.3330 - val_accuracy: 0.0687\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.9088 - accuracy: 0.6029 - val_loss: 21.6790 - val_accuracy: 0.0632\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9011 - accuracy: 0.6067 - val_loss: 17.1429 - val_accuracy: 0.0686\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8801 - accuracy: 0.6132 - val_loss: 26.4220 - val_accuracy: 0.0662\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8790 - accuracy: 0.6082 - val_loss: 24.3308 - val_accuracy: 0.0647\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8861 - accuracy: 0.6094 - val_loss: 30.8139 - val_accuracy: 0.0562\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8886 - accuracy: 0.6102 - val_loss: 24.0509 - val_accuracy: 0.0642\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8995 - accuracy: 0.6038 - val_loss: 20.2523 - val_accuracy: 0.0696\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9048 - accuracy: 0.6050 - val_loss: 11.3871 - val_accuracy: 0.0899\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8985 - accuracy: 0.6036 - val_loss: 15.2122 - val_accuracy: 0.0865\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8790 - accuracy: 0.6053 - val_loss: 28.1453 - val_accuracy: 0.0668\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8872 - accuracy: 0.6054 - val_loss: 18.9013 - val_accuracy: 0.1169\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8790 - accuracy: 0.6096 - val_loss: 19.7348 - val_accuracy: 0.1305\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8740 - accuracy: 0.6069 - val_loss: 25.4873 - val_accuracy: 0.1192\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8872 - accuracy: 0.6090 - val_loss: 20.5005 - val_accuracy: 0.0844\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8779 - accuracy: 0.6128 - val_loss: 30.6098 - val_accuracy: 0.0791\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8832 - accuracy: 0.6077 - val_loss: 18.7039 - val_accuracy: 0.0793\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8900 - accuracy: 0.6068 - val_loss: 17.8233 - val_accuracy: 0.0997\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8882 - accuracy: 0.6109 - val_loss: 26.8504 - val_accuracy: 0.0630\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8896 - accuracy: 0.6098 - val_loss: 21.3090 - val_accuracy: 0.0682\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8696 - accuracy: 0.6109 - val_loss: 53.8986 - val_accuracy: 0.0859\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8769 - accuracy: 0.6085 - val_loss: 39.0487 - val_accuracy: 0.0440\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8782 - accuracy: 0.6071 - val_loss: 34.1547 - val_accuracy: 0.0422\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8755 - accuracy: 0.6117 - val_loss: 46.6101 - val_accuracy: 0.0455\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9129 - accuracy: 0.6007 - val_loss: 24.3346 - val_accuracy: 0.0879\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8861 - accuracy: 0.6091 - val_loss: 28.0579 - val_accuracy: 0.0688\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8721 - accuracy: 0.6073 - val_loss: 23.0932 - val_accuracy: 0.0875\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8638 - accuracy: 0.6118 - val_loss: 16.9649 - val_accuracy: 0.0685\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8599 - accuracy: 0.6115 - val_loss: 17.9943 - val_accuracy: 0.0596\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8669 - accuracy: 0.6133 - val_loss: 16.5820 - val_accuracy: 0.0756\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8643 - accuracy: 0.6139 - val_loss: 35.0614 - val_accuracy: 0.0876\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8768 - accuracy: 0.6118 - val_loss: 31.3041 - val_accuracy: 0.0944\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8571 - accuracy: 0.6154 - val_loss: 31.3478 - val_accuracy: 0.0592\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8824 - accuracy: 0.6100 - val_loss: 38.4457 - val_accuracy: 0.0856\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8672 - accuracy: 0.6127 - val_loss: 30.8432 - val_accuracy: 0.0894\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8613 - accuracy: 0.6085 - val_loss: 22.4351 - val_accuracy: 0.0852\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.8679 - accuracy: 0.6126 - val_loss: 19.0143 - val_accuracy: 0.0794\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8712 - accuracy: 0.6112 - val_loss: 19.5552 - val_accuracy: 0.0970\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8566 - accuracy: 0.6133 - val_loss: 37.1191 - val_accuracy: 0.1044\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8672 - accuracy: 0.6093 - val_loss: 32.0508 - val_accuracy: 0.0970\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8643 - accuracy: 0.6113 - val_loss: 17.1590 - val_accuracy: 0.1328\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8816 - accuracy: 0.6069 - val_loss: 20.0216 - val_accuracy: 0.0995\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8689 - accuracy: 0.6086 - val_loss: 15.5439 - val_accuracy: 0.1292\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8580 - accuracy: 0.6166 - val_loss: 30.7982 - val_accuracy: 0.0949\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8804 - accuracy: 0.6078 - val_loss: 37.6089 - val_accuracy: 0.0645\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.8766 - accuracy: 0.6102 - val_loss: 20.0243 - val_accuracy: 0.0846\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8721 - accuracy: 0.6070 - val_loss: 18.0847 - val_accuracy: 0.1177\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8700 - accuracy: 0.6089 - val_loss: 16.2376 - val_accuracy: 0.1688\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8453 - accuracy: 0.6137 - val_loss: 10.9100 - val_accuracy: 0.1268\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8540 - accuracy: 0.6105 - val_loss: 18.0681 - val_accuracy: 0.0846\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8533 - accuracy: 0.6182 - val_loss: 11.4254 - val_accuracy: 0.1344\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8552 - accuracy: 0.6129 - val_loss: 10.4682 - val_accuracy: 0.1693\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.8581 - accuracy: 0.6133 - val_loss: 22.9901 - val_accuracy: 0.1032\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8553 - accuracy: 0.6130 - val_loss: 23.7675 - val_accuracy: 0.0712\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 0.8479 - accuracy: 0.6116 - val_loss: 31.6939 - val_accuracy: 0.0898\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8483 - accuracy: 0.6152 - val_loss: 15.8289 - val_accuracy: 0.0794\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 4s 256ms/step - loss: 0.8503 - accuracy: 0.6159 - val_loss: 17.5676 - val_accuracy: 0.0881\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8524 - accuracy: 0.6175 - val_loss: 17.5347 - val_accuracy: 0.0886\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.8514 - accuracy: 0.6146 - val_loss: 16.1922 - val_accuracy: 0.1040\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8625 - accuracy: 0.6097 - val_loss: 20.0259 - val_accuracy: 0.1418\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8376 - accuracy: 0.6171 - val_loss: 16.5597 - val_accuracy: 0.1032\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8446 - accuracy: 0.6143 - val_loss: 16.5443 - val_accuracy: 0.0860\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8434 - accuracy: 0.6157 - val_loss: 12.7745 - val_accuracy: 0.1275\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8563 - accuracy: 0.6136 - val_loss: 9.0962 - val_accuracy: 0.1138\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8660 - accuracy: 0.6112 - val_loss: 28.0521 - val_accuracy: 0.1108\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8509 - accuracy: 0.6116 - val_loss: 9.9997 - val_accuracy: 0.1164\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8491 - accuracy: 0.6115 - val_loss: 17.3485 - val_accuracy: 0.0888\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8627 - accuracy: 0.6113 - val_loss: 9.9084 - val_accuracy: 0.1170\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8561 - accuracy: 0.6119 - val_loss: 14.6115 - val_accuracy: 0.0644\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.8489 - accuracy: 0.6110 - val_loss: 16.3404 - val_accuracy: 0.0741\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.8247 - accuracy: 0.6181 - val_loss: 11.0906 - val_accuracy: 0.0675\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.8274 - accuracy: 0.6186 - val_loss: 13.7472 - val_accuracy: 0.0757\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8431 - accuracy: 0.6134 - val_loss: 20.4285 - val_accuracy: 0.0547\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8565 - accuracy: 0.6172 - val_loss: 29.1926 - val_accuracy: 0.0667\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8665 - accuracy: 0.6110 - val_loss: 11.0821 - val_accuracy: 0.0733\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8484 - accuracy: 0.6182 - val_loss: 12.1450 - val_accuracy: 0.0760\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8279 - accuracy: 0.6131 - val_loss: 31.3807 - val_accuracy: 0.0774\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8488 - accuracy: 0.6144 - val_loss: 14.7414 - val_accuracy: 0.0698\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8234 - accuracy: 0.6207 - val_loss: 17.2670 - val_accuracy: 0.0599\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8280 - accuracy: 0.6183 - val_loss: 13.1998 - val_accuracy: 0.0631\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8518 - accuracy: 0.6158 - val_loss: 20.3179 - val_accuracy: 0.0496\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8383 - accuracy: 0.6168 - val_loss: 18.1204 - val_accuracy: 0.0647\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8421 - accuracy: 0.6176 - val_loss: 12.5909 - val_accuracy: 0.0875\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8379 - accuracy: 0.6179 - val_loss: 20.9017 - val_accuracy: 0.0740\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8265 - accuracy: 0.6154 - val_loss: 16.9092 - val_accuracy: 0.0466\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8248 - accuracy: 0.6226 - val_loss: 10.5686 - val_accuracy: 0.0585\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8512 - accuracy: 0.6166 - val_loss: 16.7359 - val_accuracy: 0.0500\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.8442 - accuracy: 0.6127 - val_loss: 13.1630 - val_accuracy: 0.0543\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8387 - accuracy: 0.6105 - val_loss: 17.5039 - val_accuracy: 0.0518\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.8451 - accuracy: 0.6169 - val_loss: 11.3428 - val_accuracy: 0.0671\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8432 - accuracy: 0.6131 - val_loss: 15.9778 - val_accuracy: 0.0522\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8243 - accuracy: 0.6196 - val_loss: 16.7615 - val_accuracy: 0.0520\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8501 - accuracy: 0.6124 - val_loss: 15.0588 - val_accuracy: 0.0642\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8193 - accuracy: 0.6170 - val_loss: 16.3975 - val_accuracy: 0.0586\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8061 - accuracy: 0.6217 - val_loss: 17.9072 - val_accuracy: 0.0519\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8348 - accuracy: 0.6178 - val_loss: 19.5453 - val_accuracy: 0.0461\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8302 - accuracy: 0.6170 - val_loss: 17.4297 - val_accuracy: 0.0572\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8446 - accuracy: 0.6155 - val_loss: 19.9626 - val_accuracy: 0.0556\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8248 - accuracy: 0.6184 - val_loss: 19.2289 - val_accuracy: 0.0539\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8234 - accuracy: 0.6183 - val_loss: 20.2855 - val_accuracy: 0.0502\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8362 - accuracy: 0.6177 - val_loss: 14.4194 - val_accuracy: 0.0707\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.8273 - accuracy: 0.6166 - val_loss: 22.4499 - val_accuracy: 0.0558\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8287 - accuracy: 0.6144 - val_loss: 18.3055 - val_accuracy: 0.0702\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8205 - accuracy: 0.6222 - val_loss: 25.3941 - val_accuracy: 0.0529\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8259 - accuracy: 0.6165 - val_loss: 23.4834 - val_accuracy: 0.0550\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8400 - accuracy: 0.6128 - val_loss: 16.9597 - val_accuracy: 0.0562\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8324 - accuracy: 0.6165 - val_loss: 20.3666 - val_accuracy: 0.0531\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8152 - accuracy: 0.6206 - val_loss: 15.5483 - val_accuracy: 0.0691\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8236 - accuracy: 0.6194 - val_loss: 14.5330 - val_accuracy: 0.0597\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8231 - accuracy: 0.6195 - val_loss: 15.6201 - val_accuracy: 0.0609\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8493 - accuracy: 0.6174 - val_loss: 16.5846 - val_accuracy: 0.0646\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8120 - accuracy: 0.6190 - val_loss: 20.7536 - val_accuracy: 0.0589\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8141 - accuracy: 0.6180 - val_loss: 18.5691 - val_accuracy: 0.0601\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8191 - accuracy: 0.6185 - val_loss: 23.0773 - val_accuracy: 0.0746\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8035 - accuracy: 0.6168 - val_loss: 23.3503 - val_accuracy: 0.0734\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8122 - accuracy: 0.6213 - val_loss: 19.4452 - val_accuracy: 0.0630\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7929 - accuracy: 0.6251 - val_loss: 22.7320 - val_accuracy: 0.0775\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8155 - accuracy: 0.6207 - val_loss: 19.0563 - val_accuracy: 0.0821\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8178 - accuracy: 0.6184 - val_loss: 17.6142 - val_accuracy: 0.0676\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8212 - accuracy: 0.6216 - val_loss: 24.1112 - val_accuracy: 0.0628\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.8209 - accuracy: 0.6187 - val_loss: 15.2530 - val_accuracy: 0.0703\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8033 - accuracy: 0.6226 - val_loss: 23.1096 - val_accuracy: 0.0552\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8096 - accuracy: 0.6268 - val_loss: 23.0014 - val_accuracy: 0.0632\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8273 - accuracy: 0.6191 - val_loss: 25.2295 - val_accuracy: 0.0751\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8105 - accuracy: 0.6210 - val_loss: 47.3350 - val_accuracy: 0.0722\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8320 - accuracy: 0.6164 - val_loss: 24.6076 - val_accuracy: 0.0687\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8130 - accuracy: 0.6228 - val_loss: 21.7778 - val_accuracy: 0.0623\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8124 - accuracy: 0.6164 - val_loss: 30.1054 - val_accuracy: 0.0480\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8078 - accuracy: 0.6201 - val_loss: 26.3522 - val_accuracy: 0.0533\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8012 - accuracy: 0.6245 - val_loss: 30.2713 - val_accuracy: 0.0473\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.7891 - accuracy: 0.6235 - val_loss: 29.3634 - val_accuracy: 0.0624\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8030 - accuracy: 0.6215 - val_loss: 28.7945 - val_accuracy: 0.0584\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8110 - accuracy: 0.6235 - val_loss: 30.7482 - val_accuracy: 0.0970\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8330 - accuracy: 0.6174 - val_loss: 38.9671 - val_accuracy: 0.0864\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8251 - accuracy: 0.6183 - val_loss: 26.9592 - val_accuracy: 0.0630\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8307 - accuracy: 0.6138 - val_loss: 36.8088 - val_accuracy: 0.0682\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8178 - accuracy: 0.6224 - val_loss: 43.0050 - val_accuracy: 0.0815\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7988 - accuracy: 0.6239 - val_loss: 56.9481 - val_accuracy: 0.0843\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8003 - accuracy: 0.6222 - val_loss: 198.5542 - val_accuracy: 0.1042\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7940 - accuracy: 0.6239 - val_loss: 91.1227 - val_accuracy: 0.1037\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8195 - accuracy: 0.6206 - val_loss: 317.5799 - val_accuracy: 0.1605\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.8060 - accuracy: 0.6203 - val_loss: 263.5008 - val_accuracy: 0.1716\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.8000 - accuracy: 0.6209 - val_loss: 133.5159 - val_accuracy: 0.1726\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.8137 - accuracy: 0.6195 - val_loss: 140.3089 - val_accuracy: 0.1875\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7933 - accuracy: 0.6269 - val_loss: 140.8406 - val_accuracy: 0.1700\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7937 - accuracy: 0.6234 - val_loss: 281.6711 - val_accuracy: 0.1980\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7914 - accuracy: 0.6240 - val_loss: 225.0766 - val_accuracy: 0.1863\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8030 - accuracy: 0.6218 - val_loss: 86.7730 - val_accuracy: 0.1649\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8029 - accuracy: 0.6211 - val_loss: 82.6003 - val_accuracy: 0.1984\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8180 - accuracy: 0.6215 - val_loss: 232.2416 - val_accuracy: 0.1928\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7952 - accuracy: 0.6268 - val_loss: 245.3587 - val_accuracy: 0.1826\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7808 - accuracy: 0.6276 - val_loss: 58.7665 - val_accuracy: 0.1856\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7850 - accuracy: 0.6255 - val_loss: 154.6405 - val_accuracy: 0.1383\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7979 - accuracy: 0.6245 - val_loss: 109.0864 - val_accuracy: 0.1376\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7811 - accuracy: 0.6282 - val_loss: 139.3166 - val_accuracy: 0.1307\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7956 - accuracy: 0.6239 - val_loss: 138.8301 - val_accuracy: 0.1449\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7956 - accuracy: 0.6243 - val_loss: 112.9069 - val_accuracy: 0.1500\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7918 - accuracy: 0.6234 - val_loss: 63.3461 - val_accuracy: 0.1501\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7706 - accuracy: 0.6306 - val_loss: 75.2736 - val_accuracy: 0.2020\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.7875 - accuracy: 0.6257 - val_loss: 119.5701 - val_accuracy: 0.1988\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.7888 - accuracy: 0.6275 - val_loss: 182.8500 - val_accuracy: 0.1483\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7973 - accuracy: 0.6273 - val_loss: 82.0920 - val_accuracy: 0.1149\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7861 - accuracy: 0.6266 - val_loss: 69.4680 - val_accuracy: 0.1489\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7907 - accuracy: 0.6239 - val_loss: 100.0570 - val_accuracy: 0.1377\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7985 - accuracy: 0.6232 - val_loss: 88.6718 - val_accuracy: 0.1414\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8131 - accuracy: 0.6250 - val_loss: 72.0552 - val_accuracy: 0.1249\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7960 - accuracy: 0.6257 - val_loss: 99.7149 - val_accuracy: 0.1054\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7742 - accuracy: 0.6276 - val_loss: 143.1507 - val_accuracy: 0.1060\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7882 - accuracy: 0.6256 - val_loss: 128.3269 - val_accuracy: 0.1065\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.7831 - accuracy: 0.6267 - val_loss: 62.4893 - val_accuracy: 0.1091\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7888 - accuracy: 0.6274 - val_loss: 35.3858 - val_accuracy: 0.1031\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7794 - accuracy: 0.6261 - val_loss: 72.0908 - val_accuracy: 0.1051\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7927 - accuracy: 0.6253 - val_loss: 99.7467 - val_accuracy: 0.1040\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7945 - accuracy: 0.6230 - val_loss: 47.8769 - val_accuracy: 0.0976\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7955 - accuracy: 0.6278 - val_loss: 44.2693 - val_accuracy: 0.1157\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.8021 - accuracy: 0.6236 - val_loss: 79.9778 - val_accuracy: 0.1361\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7849 - accuracy: 0.6240 - val_loss: 66.9985 - val_accuracy: 0.1178\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7745 - accuracy: 0.6275 - val_loss: 31.5981 - val_accuracy: 0.0979\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 4s 231ms/step - loss: 0.8029 - accuracy: 0.6250 - val_loss: 54.0534 - val_accuracy: 0.0902\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7784 - accuracy: 0.6279 - val_loss: 40.4572 - val_accuracy: 0.0973\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7604 - accuracy: 0.6295 - val_loss: 95.4330 - val_accuracy: 0.1146\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7787 - accuracy: 0.6259 - val_loss: 104.7986 - val_accuracy: 0.1274\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7746 - accuracy: 0.6280 - val_loss: 60.8012 - val_accuracy: 0.1335\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.7788 - accuracy: 0.6283 - val_loss: 43.9087 - val_accuracy: 0.1087\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.7796 - accuracy: 0.6271 - val_loss: 60.2817 - val_accuracy: 0.1059\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.7673 - accuracy: 0.6338 - val_loss: 35.0933 - val_accuracy: 0.1013\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7661 - accuracy: 0.6309 - val_loss: 29.5997 - val_accuracy: 0.0963\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7891 - accuracy: 0.6260 - val_loss: 54.0088 - val_accuracy: 0.1072\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7859 - accuracy: 0.6249 - val_loss: 50.8596 - val_accuracy: 0.1225\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 0.7744 - accuracy: 0.6282 - val_loss: 47.4560 - val_accuracy: 0.1133\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.7857 - accuracy: 0.6263 - val_loss: 68.9203 - val_accuracy: 0.1145\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7896 - accuracy: 0.6246 - val_loss: 40.6015 - val_accuracy: 0.1006\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7760 - accuracy: 0.6251 - val_loss: 48.0872 - val_accuracy: 0.1088\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7804 - accuracy: 0.6286 - val_loss: 41.8202 - val_accuracy: 0.0919\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7938 - accuracy: 0.6210 - val_loss: 68.9464 - val_accuracy: 0.0786\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7766 - accuracy: 0.6251 - val_loss: 68.0407 - val_accuracy: 0.1276\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7777 - accuracy: 0.6289 - val_loss: 70.8730 - val_accuracy: 0.1237\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7780 - accuracy: 0.6291 - val_loss: 44.2000 - val_accuracy: 0.1320\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7682 - accuracy: 0.6254 - val_loss: 53.1217 - val_accuracy: 0.1045\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7714 - accuracy: 0.6309 - val_loss: 24.7198 - val_accuracy: 0.0978\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7995 - accuracy: 0.6227 - val_loss: 39.5279 - val_accuracy: 0.0923\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7947 - accuracy: 0.6278 - val_loss: 26.4039 - val_accuracy: 0.1147\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7799 - accuracy: 0.6208 - val_loss: 27.7545 - val_accuracy: 0.1448\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7690 - accuracy: 0.6274 - val_loss: 23.8603 - val_accuracy: 0.1569\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7523 - accuracy: 0.6342 - val_loss: 28.7645 - val_accuracy: 0.1266\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7930 - accuracy: 0.6251 - val_loss: 27.0336 - val_accuracy: 0.1296\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7624 - accuracy: 0.6322 - val_loss: 28.4982 - val_accuracy: 0.1323\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.7713 - accuracy: 0.6319 - val_loss: 79.7246 - val_accuracy: 0.1187\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7646 - accuracy: 0.6298 - val_loss: 32.6302 - val_accuracy: 0.1695\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7798 - accuracy: 0.6263 - val_loss: 81.4766 - val_accuracy: 0.1393\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.7573 - accuracy: 0.6323 - val_loss: 72.0848 - val_accuracy: 0.1093\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.7609 - accuracy: 0.6314 - val_loss: 61.3596 - val_accuracy: 0.1273\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.7749 - accuracy: 0.6307 - val_loss: 42.7381 - val_accuracy: 0.1309\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.7637 - accuracy: 0.6308 - val_loss: 82.1306 - val_accuracy: 0.1302\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.7603 - accuracy: 0.6316 - val_loss: 44.6719 - val_accuracy: 0.1233\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7687 - accuracy: 0.6297 - val_loss: 50.5109 - val_accuracy: 0.1001\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7795 - accuracy: 0.6238 - val_loss: 42.5276 - val_accuracy: 0.0843\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7735 - accuracy: 0.6276 - val_loss: 41.1535 - val_accuracy: 0.0734\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.7597 - accuracy: 0.6293 - val_loss: 41.7127 - val_accuracy: 0.0800\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7551 - accuracy: 0.6301 - val_loss: 55.5544 - val_accuracy: 0.1044\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7630 - accuracy: 0.6286 - val_loss: 38.9436 - val_accuracy: 0.0983\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8037 - accuracy: 0.6288 - val_loss: 37.1178 - val_accuracy: 0.0744\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7805 - accuracy: 0.6286 - val_loss: 36.8184 - val_accuracy: 0.0619\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7739 - accuracy: 0.6265 - val_loss: 56.4972 - val_accuracy: 0.0589\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7426 - accuracy: 0.6346 - val_loss: 30.9124 - val_accuracy: 0.0793\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7625 - accuracy: 0.6272 - val_loss: 38.7293 - val_accuracy: 0.0836\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7550 - accuracy: 0.6317 - val_loss: 45.6735 - val_accuracy: 0.0958\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7389 - accuracy: 0.6307 - val_loss: 35.5601 - val_accuracy: 0.0954\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7594 - accuracy: 0.6336 - val_loss: 30.8542 - val_accuracy: 0.0964\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7635 - accuracy: 0.6319 - val_loss: 43.3779 - val_accuracy: 0.1036\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7653 - accuracy: 0.6293 - val_loss: 36.6906 - val_accuracy: 0.0904\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7356 - accuracy: 0.6320 - val_loss: 70.4615 - val_accuracy: 0.0905\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.7452 - accuracy: 0.6330 - val_loss: 75.4212 - val_accuracy: 0.0995\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7755 - accuracy: 0.6294 - val_loss: 49.9251 - val_accuracy: 0.0827\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7597 - accuracy: 0.6317 - val_loss: 60.4601 - val_accuracy: 0.0762\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7463 - accuracy: 0.6343 - val_loss: 51.5742 - val_accuracy: 0.1112\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7456 - accuracy: 0.6318 - val_loss: 53.1925 - val_accuracy: 0.1252\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7486 - accuracy: 0.6316 - val_loss: 67.4392 - val_accuracy: 0.1035\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7517 - accuracy: 0.6280 - val_loss: 64.3228 - val_accuracy: 0.0982\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7613 - accuracy: 0.6307 - val_loss: 53.9030 - val_accuracy: 0.1072\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7496 - accuracy: 0.6317 - val_loss: 54.9658 - val_accuracy: 0.1127\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7674 - accuracy: 0.6322 - val_loss: 47.5540 - val_accuracy: 0.1380\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7809 - accuracy: 0.6258 - val_loss: 48.8218 - val_accuracy: 0.1480\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7554 - accuracy: 0.6307 - val_loss: 41.2123 - val_accuracy: 0.1340\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7514 - accuracy: 0.6320 - val_loss: 61.8035 - val_accuracy: 0.1049\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7383 - accuracy: 0.6349 - val_loss: 59.6552 - val_accuracy: 0.1016\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7370 - accuracy: 0.6309 - val_loss: 53.9314 - val_accuracy: 0.1035\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7443 - accuracy: 0.6353 - val_loss: 68.4970 - val_accuracy: 0.0918\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7474 - accuracy: 0.6289 - val_loss: 44.9901 - val_accuracy: 0.1176\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7758 - accuracy: 0.6328 - val_loss: 49.3113 - val_accuracy: 0.0867\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7867 - accuracy: 0.6274 - val_loss: 61.6878 - val_accuracy: 0.0762\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7594 - accuracy: 0.6285 - val_loss: 57.2540 - val_accuracy: 0.1036\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7345 - accuracy: 0.6383 - val_loss: 39.9449 - val_accuracy: 0.1138\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7347 - accuracy: 0.6357 - val_loss: 35.3182 - val_accuracy: 0.1319\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7616 - accuracy: 0.6336 - val_loss: 27.3942 - val_accuracy: 0.1333\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7554 - accuracy: 0.6316 - val_loss: 31.8852 - val_accuracy: 0.1287\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.7418 - accuracy: 0.6333 - val_loss: 36.1902 - val_accuracy: 0.1060\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7710 - accuracy: 0.6265 - val_loss: 35.9799 - val_accuracy: 0.1502\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.7556 - accuracy: 0.6349 - val_loss: 33.9586 - val_accuracy: 0.1245\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7435 - accuracy: 0.6374 - val_loss: 52.3597 - val_accuracy: 0.1280\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7802 - accuracy: 0.6271 - val_loss: 62.5577 - val_accuracy: 0.1225\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7436 - accuracy: 0.6319 - val_loss: 47.0743 - val_accuracy: 0.1170\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7432 - accuracy: 0.6324 - val_loss: 47.2947 - val_accuracy: 0.1461\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7423 - accuracy: 0.6331 - val_loss: 45.2464 - val_accuracy: 0.1499\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7592 - accuracy: 0.6315 - val_loss: 42.6610 - val_accuracy: 0.1656\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.7680 - accuracy: 0.6326 - val_loss: 61.6873 - val_accuracy: 0.1447\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.7482 - accuracy: 0.6357 - val_loss: 47.4469 - val_accuracy: 0.1257\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.7400 - accuracy: 0.6341 - val_loss: 35.7829 - val_accuracy: 0.1468\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7566 - accuracy: 0.6271 - val_loss: 59.1370 - val_accuracy: 0.1473\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.7393 - accuracy: 0.6333 - val_loss: 44.7872 - val_accuracy: 0.1579\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7369 - accuracy: 0.6336 - val_loss: 39.8924 - val_accuracy: 0.1744\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.7320 - accuracy: 0.6366 - val_loss: 38.4048 - val_accuracy: 0.1496\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7453 - accuracy: 0.6289 - val_loss: 39.1390 - val_accuracy: 0.1791\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7570 - accuracy: 0.6316 - val_loss: 32.0722 - val_accuracy: 0.1735\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7226 - accuracy: 0.6342 - val_loss: 33.7942 - val_accuracy: 0.1348\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7348 - accuracy: 0.6349 - val_loss: 42.9134 - val_accuracy: 0.1793\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7360 - accuracy: 0.6328 - val_loss: 31.3445 - val_accuracy: 0.1508\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7296 - accuracy: 0.6361 - val_loss: 23.4449 - val_accuracy: 0.1719\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.7357 - accuracy: 0.6350 - val_loss: 54.6831 - val_accuracy: 0.1818\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.7246 - accuracy: 0.6366 - val_loss: 27.5210 - val_accuracy: 0.1689\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7234 - accuracy: 0.6356 - val_loss: 39.1358 - val_accuracy: 0.1906\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7258 - accuracy: 0.6370 - val_loss: 38.5154 - val_accuracy: 0.1680\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7203 - accuracy: 0.6356 - val_loss: 33.5218 - val_accuracy: 0.1790\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7421 - accuracy: 0.6331 - val_loss: 36.6743 - val_accuracy: 0.1831\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7591 - accuracy: 0.6300 - val_loss: 37.9783 - val_accuracy: 0.1861\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7355 - accuracy: 0.6368 - val_loss: 40.3574 - val_accuracy: 0.1866\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7292 - accuracy: 0.6340 - val_loss: 41.4809 - val_accuracy: 0.1654\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.7124 - accuracy: 0.6408 - val_loss: 43.9517 - val_accuracy: 0.2252\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.7252 - accuracy: 0.6398 - val_loss: 66.4500 - val_accuracy: 0.2013\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7285 - accuracy: 0.6355 - val_loss: 44.8240 - val_accuracy: 0.2077\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7314 - accuracy: 0.6352 - val_loss: 46.2595 - val_accuracy: 0.2139\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7495 - accuracy: 0.6358 - val_loss: 40.0091 - val_accuracy: 0.2302\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7390 - accuracy: 0.6349 - val_loss: 47.2715 - val_accuracy: 0.2323\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7277 - accuracy: 0.6357 - val_loss: 36.1907 - val_accuracy: 0.2417\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7217 - accuracy: 0.6379 - val_loss: 37.1649 - val_accuracy: 0.2377\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7410 - accuracy: 0.6391 - val_loss: 39.1631 - val_accuracy: 0.2345\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7465 - accuracy: 0.6343 - val_loss: 37.6198 - val_accuracy: 0.2090\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7393 - accuracy: 0.6341 - val_loss: 34.3609 - val_accuracy: 0.2200\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7511 - accuracy: 0.6320 - val_loss: 36.0692 - val_accuracy: 0.2208\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7299 - accuracy: 0.6380 - val_loss: 30.3707 - val_accuracy: 0.1939\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7321 - accuracy: 0.6321 - val_loss: 37.5212 - val_accuracy: 0.2313\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7255 - accuracy: 0.6369 - val_loss: 34.8422 - val_accuracy: 0.2116\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7025 - accuracy: 0.6417 - val_loss: 28.5172 - val_accuracy: 0.2226\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.7235 - accuracy: 0.6339 - val_loss: 45.3356 - val_accuracy: 0.2262\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7229 - accuracy: 0.6374 - val_loss: 48.1977 - val_accuracy: 0.1974\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7390 - accuracy: 0.6397 - val_loss: 43.7527 - val_accuracy: 0.2073\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7381 - accuracy: 0.6380 - val_loss: 57.0456 - val_accuracy: 0.2140\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7588 - accuracy: 0.6302 - val_loss: 48.5182 - val_accuracy: 0.2036\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7391 - accuracy: 0.6317 - val_loss: 65.0165 - val_accuracy: 0.1796\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7462 - accuracy: 0.6347 - val_loss: 46.5873 - val_accuracy: 0.2100\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7571 - accuracy: 0.6343 - val_loss: 40.8222 - val_accuracy: 0.2178\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7104 - accuracy: 0.6369 - val_loss: 41.5586 - val_accuracy: 0.1808\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7004 - accuracy: 0.6422 - val_loss: 47.9618 - val_accuracy: 0.2027\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7474 - accuracy: 0.6355 - val_loss: 40.3357 - val_accuracy: 0.1568\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7314 - accuracy: 0.6347 - val_loss: 44.2287 - val_accuracy: 0.1872\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7073 - accuracy: 0.6384 - val_loss: 41.2818 - val_accuracy: 0.1951\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.6978 - accuracy: 0.6379 - val_loss: 34.2421 - val_accuracy: 0.2007\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 276ms/step - loss: 2.6390 - accuracy: 0.5966 - val_loss: 1.6316 - val_accuracy: 0.6157\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2967 - accuracy: 0.6195 - val_loss: 1.8653 - val_accuracy: 0.6104\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.1960 - accuracy: 0.6230 - val_loss: 1.7868 - val_accuracy: 0.6050\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1596 - accuracy: 0.6212 - val_loss: 1.6220 - val_accuracy: 0.2930\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0704 - accuracy: 0.6196 - val_loss: 1.5816 - val_accuracy: 0.1491\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0487 - accuracy: 0.6206 - val_loss: 1.4143 - val_accuracy: 0.1504\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 6s 399ms/step - loss: 2.0234 - accuracy: 0.6220 - val_loss: 1.5402 - val_accuracy: 0.1510\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 4s 256ms/step - loss: 1.9382 - accuracy: 0.6185 - val_loss: 1.6571 - val_accuracy: 0.1548\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.8754 - accuracy: 0.6210 - val_loss: 1.5195 - val_accuracy: 0.1566\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.8367 - accuracy: 0.6225 - val_loss: 1.4836 - val_accuracy: 0.1539\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.8449 - accuracy: 0.6233 - val_loss: 1.6359 - val_accuracy: 0.1398\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.8698 - accuracy: 0.6131 - val_loss: 1.8980 - val_accuracy: 0.1269\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.7635 - accuracy: 0.6244 - val_loss: 1.5235 - val_accuracy: 0.1570\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.8109 - accuracy: 0.6181 - val_loss: 1.4929 - val_accuracy: 0.1485\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.7646 - accuracy: 0.6215 - val_loss: 1.8775 - val_accuracy: 0.1314\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.7988 - accuracy: 0.6196 - val_loss: 1.4274 - val_accuracy: 0.1530\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.7583 - accuracy: 0.6240 - val_loss: 2.0706 - val_accuracy: 0.1270\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.7330 - accuracy: 0.6257 - val_loss: 1.6615 - val_accuracy: 0.1420\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.7808 - accuracy: 0.6214 - val_loss: 1.5525 - val_accuracy: 0.1557\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7455 - accuracy: 0.6256 - val_loss: 2.0638 - val_accuracy: 0.1315\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.6914 - accuracy: 0.6292 - val_loss: 2.2795 - val_accuracy: 0.1249\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.7043 - accuracy: 0.6270 - val_loss: 2.1089 - val_accuracy: 0.1268\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.7238 - accuracy: 0.6275 - val_loss: 15.3214 - val_accuracy: 0.0451\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.8722 - accuracy: 0.6217 - val_loss: 20.7626 - val_accuracy: 0.0447\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.8238 - accuracy: 0.6203 - val_loss: 23.5171 - val_accuracy: 0.0660\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.8137 - accuracy: 0.6224 - val_loss: 1.6564 - val_accuracy: 0.1551\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.7851 - accuracy: 0.6242 - val_loss: 3.3243 - val_accuracy: 0.1833\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.7342 - accuracy: 0.6244 - val_loss: 1.9792 - val_accuracy: 0.1553\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.7048 - accuracy: 0.6279 - val_loss: 2.1598 - val_accuracy: 0.1461\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.7059 - accuracy: 0.6244 - val_loss: 2.3241 - val_accuracy: 0.1243\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6720 - accuracy: 0.6292 - val_loss: 2.2285 - val_accuracy: 0.2072\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.6612 - accuracy: 0.6303 - val_loss: 1.4763 - val_accuracy: 0.2631\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.6559 - accuracy: 0.6236 - val_loss: 4.0402 - val_accuracy: 0.1486\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6420 - accuracy: 0.6304 - val_loss: 2.8583 - val_accuracy: 0.1819\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6250 - accuracy: 0.6332 - val_loss: 5.5993 - val_accuracy: 0.1268\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.6125 - accuracy: 0.6338 - val_loss: 2.9224 - val_accuracy: 0.2149\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6119 - accuracy: 0.6311 - val_loss: 9.6243 - val_accuracy: 0.1805\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7202 - accuracy: 0.6307 - val_loss: 4.4273 - val_accuracy: 0.0919\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.6779 - accuracy: 0.6270 - val_loss: 6.1445 - val_accuracy: 0.1488\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6574 - accuracy: 0.6256 - val_loss: 3.4782 - val_accuracy: 0.1266\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.5981 - accuracy: 0.6317 - val_loss: 6.8283 - val_accuracy: 0.1539\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.6048 - accuracy: 0.6357 - val_loss: 3.1571 - val_accuracy: 0.1719\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6293 - accuracy: 0.6297 - val_loss: 5.1511 - val_accuracy: 0.1659\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5906 - accuracy: 0.6341 - val_loss: 7.0279 - val_accuracy: 0.1646\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.5877 - accuracy: 0.6337 - val_loss: 4.1717 - val_accuracy: 0.1605\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5595 - accuracy: 0.6345 - val_loss: 6.2125 - val_accuracy: 0.1249\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5449 - accuracy: 0.6361 - val_loss: 6.4995 - val_accuracy: 0.1557\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5089 - accuracy: 0.6397 - val_loss: 4.2371 - val_accuracy: 0.1759\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.5332 - accuracy: 0.6392 - val_loss: 5.8450 - val_accuracy: 0.1566\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5360 - accuracy: 0.6428 - val_loss: 5.0138 - val_accuracy: 0.1390\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5454 - accuracy: 0.6356 - val_loss: 4.4142 - val_accuracy: 0.1261\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.5354 - accuracy: 0.6386 - val_loss: 4.0569 - val_accuracy: 0.1219\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.5783 - accuracy: 0.6313 - val_loss: 3.0051 - val_accuracy: 0.1522\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4970 - accuracy: 0.6433 - val_loss: 3.4439 - val_accuracy: 0.1408\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5135 - accuracy: 0.6439 - val_loss: 4.0667 - val_accuracy: 0.1629\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5195 - accuracy: 0.6425 - val_loss: 6.8626 - val_accuracy: 0.0964\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5645 - accuracy: 0.6322 - val_loss: 7.1630 - val_accuracy: 0.1052\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.5834 - accuracy: 0.6440 - val_loss: 2.9496 - val_accuracy: 0.1586\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5751 - accuracy: 0.6401 - val_loss: 5.1994 - val_accuracy: 0.1481\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5129 - accuracy: 0.6412 - val_loss: 5.9029 - val_accuracy: 0.1403\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5230 - accuracy: 0.6447 - val_loss: 9.4210 - val_accuracy: 0.1083\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5231 - accuracy: 0.6396 - val_loss: 9.5791 - val_accuracy: 0.1048\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.4896 - accuracy: 0.6420 - val_loss: 10.4809 - val_accuracy: 0.1100\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.4849 - accuracy: 0.6447 - val_loss: 25.2367 - val_accuracy: 0.0908\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.4705 - accuracy: 0.6501 - val_loss: 12.7237 - val_accuracy: 0.1076\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4908 - accuracy: 0.6437 - val_loss: 27.2628 - val_accuracy: 0.0626\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4525 - accuracy: 0.6497 - val_loss: 34.8686 - val_accuracy: 0.0548\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4458 - accuracy: 0.6494 - val_loss: 31.2839 - val_accuracy: 0.0875\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.4957 - accuracy: 0.6465 - val_loss: 37.9062 - val_accuracy: 0.0748\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.4972 - accuracy: 0.6472 - val_loss: 29.5002 - val_accuracy: 0.1038\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.4812 - accuracy: 0.6466 - val_loss: 77.0348 - val_accuracy: 0.0471\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.4988 - accuracy: 0.6497 - val_loss: 22.1661 - val_accuracy: 0.0592\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.5050 - accuracy: 0.6433 - val_loss: 266.8128 - val_accuracy: 0.0657\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.4737 - accuracy: 0.6490 - val_loss: 126.9428 - val_accuracy: 0.0385\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5578 - accuracy: 0.6496 - val_loss: 130.5169 - val_accuracy: 0.0164\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.6880 - accuracy: 0.6321 - val_loss: 12.3887 - val_accuracy: 0.0757\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.5787 - accuracy: 0.6361 - val_loss: 9.5055 - val_accuracy: 0.0942\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5924 - accuracy: 0.6390 - val_loss: 6.2703 - val_accuracy: 0.1261\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.5421 - accuracy: 0.6362 - val_loss: 9.5036 - val_accuracy: 0.1448\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.4951 - accuracy: 0.6352 - val_loss: 8.4049 - val_accuracy: 0.1228\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4884 - accuracy: 0.6384 - val_loss: 11.7980 - val_accuracy: 0.1458\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4593 - accuracy: 0.6466 - val_loss: 14.5223 - val_accuracy: 0.0936\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4700 - accuracy: 0.6415 - val_loss: 12.1214 - val_accuracy: 0.1202\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4667 - accuracy: 0.6497 - val_loss: 16.4278 - val_accuracy: 0.1227\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5245 - accuracy: 0.6406 - val_loss: 14.7401 - val_accuracy: 0.0751\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4811 - accuracy: 0.6465 - val_loss: 11.6393 - val_accuracy: 0.0930\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4736 - accuracy: 0.6464 - val_loss: 9.4766 - val_accuracy: 0.1037\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4457 - accuracy: 0.6481 - val_loss: 7.8358 - val_accuracy: 0.1058\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.3952 - accuracy: 0.6549 - val_loss: 21.8693 - val_accuracy: 0.1197\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4060 - accuracy: 0.6528 - val_loss: 13.5585 - val_accuracy: 0.0989\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4645 - accuracy: 0.6490 - val_loss: 25.3281 - val_accuracy: 0.1138\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.4235 - accuracy: 0.6528 - val_loss: 12.8068 - val_accuracy: 0.1097\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.3753 - accuracy: 0.6601 - val_loss: 20.2580 - val_accuracy: 0.1176\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3953 - accuracy: 0.6576 - val_loss: 11.5385 - val_accuracy: 0.1023\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4176 - accuracy: 0.6511 - val_loss: 17.0330 - val_accuracy: 0.1241\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3855 - accuracy: 0.6548 - val_loss: 14.3249 - val_accuracy: 0.1015\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3796 - accuracy: 0.6555 - val_loss: 36.5138 - val_accuracy: 0.0908\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4346 - accuracy: 0.6478 - val_loss: 35.9337 - val_accuracy: 0.1191\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.3967 - accuracy: 0.6571 - val_loss: 17.9111 - val_accuracy: 0.1158\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3825 - accuracy: 0.6546 - val_loss: 26.6771 - val_accuracy: 0.0968\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3479 - accuracy: 0.6581 - val_loss: 45.2931 - val_accuracy: 0.1282\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3698 - accuracy: 0.6551 - val_loss: 30.0883 - val_accuracy: 0.0866\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3653 - accuracy: 0.6606 - val_loss: 28.7720 - val_accuracy: 0.1197\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3558 - accuracy: 0.6612 - val_loss: 27.5764 - val_accuracy: 0.1191\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3671 - accuracy: 0.6602 - val_loss: 38.0904 - val_accuracy: 0.0920\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3924 - accuracy: 0.6548 - val_loss: 33.6978 - val_accuracy: 0.0950\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3715 - accuracy: 0.6598 - val_loss: 35.9671 - val_accuracy: 0.0956\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.3378 - accuracy: 0.6571 - val_loss: 28.3228 - val_accuracy: 0.0922\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.3371 - accuracy: 0.6637 - val_loss: 23.6021 - val_accuracy: 0.1326\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3263 - accuracy: 0.6629 - val_loss: 27.6447 - val_accuracy: 0.1164\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3325 - accuracy: 0.6619 - val_loss: 39.3470 - val_accuracy: 0.1147\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3801 - accuracy: 0.6537 - val_loss: 67.2266 - val_accuracy: 0.0539\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4104 - accuracy: 0.6595 - val_loss: 61.7349 - val_accuracy: 0.0996\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3630 - accuracy: 0.6582 - val_loss: 24.4359 - val_accuracy: 0.1187\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3490 - accuracy: 0.6637 - val_loss: 86.1441 - val_accuracy: 0.0874\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3210 - accuracy: 0.6638 - val_loss: 54.1644 - val_accuracy: 0.0993\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2927 - accuracy: 0.6710 - val_loss: 77.4765 - val_accuracy: 0.0925\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3154 - accuracy: 0.6643 - val_loss: 33.6397 - val_accuracy: 0.1034\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.3201 - accuracy: 0.6626 - val_loss: 86.8488 - val_accuracy: 0.0978\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.2721 - accuracy: 0.6661 - val_loss: 46.0924 - val_accuracy: 0.0970\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.2884 - accuracy: 0.6697 - val_loss: 66.7192 - val_accuracy: 0.0643\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3036 - accuracy: 0.6658 - val_loss: 72.6367 - val_accuracy: 0.0572\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.2952 - accuracy: 0.6693 - val_loss: 127.0640 - val_accuracy: 0.0619\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2954 - accuracy: 0.6688 - val_loss: 102.3082 - val_accuracy: 0.1033\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3242 - accuracy: 0.6658 - val_loss: 42.9671 - val_accuracy: 0.0951\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2892 - accuracy: 0.6655 - val_loss: 46.1832 - val_accuracy: 0.0654\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2752 - accuracy: 0.6704 - val_loss: 85.1458 - val_accuracy: 0.0619\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3153 - accuracy: 0.6654 - val_loss: 31.6587 - val_accuracy: 0.1895\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.3546 - accuracy: 0.6633 - val_loss: 49.4990 - val_accuracy: 0.1362\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.3561 - accuracy: 0.6509 - val_loss: 15.2351 - val_accuracy: 0.1232\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3624 - accuracy: 0.6623 - val_loss: 20.6924 - val_accuracy: 0.1525\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4864 - accuracy: 0.6516 - val_loss: 2074.5916 - val_accuracy: 0.1313\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4855 - accuracy: 0.6571 - val_loss: 4166.3120 - val_accuracy: 0.1290\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5260 - accuracy: 0.6551 - val_loss: 19821.0508 - val_accuracy: 0.0892\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5431 - accuracy: 0.6550 - val_loss: 8569.6260 - val_accuracy: 0.0210\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4330 - accuracy: 0.6597 - val_loss: 1993.8732 - val_accuracy: 0.0110\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4227 - accuracy: 0.6472 - val_loss: 645.5900 - val_accuracy: 0.0109\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3350 - accuracy: 0.6591 - val_loss: 500.8604 - val_accuracy: 0.0086\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3452 - accuracy: 0.6622 - val_loss: 704.6860 - val_accuracy: 0.0081\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2942 - accuracy: 0.6594 - val_loss: 632.3255 - val_accuracy: 0.0109\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2898 - accuracy: 0.6662 - val_loss: 686.4457 - val_accuracy: 0.0085\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2797 - accuracy: 0.6678 - val_loss: 540.3590 - val_accuracy: 0.0177\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3559 - accuracy: 0.6593 - val_loss: 1277.5690 - val_accuracy: 0.0131\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2503 - accuracy: 0.6714 - val_loss: 1781.1512 - val_accuracy: 0.0071\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2399 - accuracy: 0.6669 - val_loss: 1126.2400 - val_accuracy: 0.0067\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3078 - accuracy: 0.6721 - val_loss: 962.0472 - val_accuracy: 0.0219\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2899 - accuracy: 0.6675 - val_loss: 611.0142 - val_accuracy: 0.0175\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2000 - accuracy: 0.6741 - val_loss: 1765.4343 - val_accuracy: 0.0211\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2555 - accuracy: 0.6655 - val_loss: 1425.7070 - val_accuracy: 0.0264\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2395 - accuracy: 0.6734 - val_loss: 2477.5371 - val_accuracy: 0.0297\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.2269 - accuracy: 0.6710 - val_loss: 3032.0312 - val_accuracy: 0.0433\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.3930 - accuracy: 0.6701 - val_loss: 428.3853 - val_accuracy: 0.0481\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3131 - accuracy: 0.6712 - val_loss: 1474.9115 - val_accuracy: 0.0297\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2661 - accuracy: 0.6705 - val_loss: 1674.1019 - val_accuracy: 0.0289\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.2573 - accuracy: 0.6743 - val_loss: 816.8817 - val_accuracy: 0.0277\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2523 - accuracy: 0.6713 - val_loss: 679.0137 - val_accuracy: 0.0393\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2454 - accuracy: 0.6729 - val_loss: 1539.3290 - val_accuracy: 0.0381\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2392 - accuracy: 0.6749 - val_loss: 1396.1914 - val_accuracy: 0.0702\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1912 - accuracy: 0.6789 - val_loss: 1340.5310 - val_accuracy: 0.0472\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.2574 - accuracy: 0.6681 - val_loss: 1341.8920 - val_accuracy: 0.0469\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2026 - accuracy: 0.6743 - val_loss: 592.6173 - val_accuracy: 0.0615\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.2003 - accuracy: 0.6792 - val_loss: 243.1049 - val_accuracy: 0.0470\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2053 - accuracy: 0.6760 - val_loss: 597.3732 - val_accuracy: 0.0455\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2574 - accuracy: 0.6734 - val_loss: 344.4361 - val_accuracy: 0.0271\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2223 - accuracy: 0.6757 - val_loss: 244.2242 - val_accuracy: 0.0314\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1956 - accuracy: 0.6765 - val_loss: 84.1479 - val_accuracy: 0.0687\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2340 - accuracy: 0.6759 - val_loss: 269.6064 - val_accuracy: 0.0213\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2052 - accuracy: 0.6776 - val_loss: 135.8757 - val_accuracy: 0.0312\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.2240 - accuracy: 0.6721 - val_loss: 146.4117 - val_accuracy: 0.0342\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1707 - accuracy: 0.6810 - val_loss: 136.8192 - val_accuracy: 0.0435\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2111 - accuracy: 0.6757 - val_loss: 256.9232 - val_accuracy: 0.0404\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1315 - accuracy: 0.6161 - val_loss: 1064.8260 - val_accuracy: 0.0904\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.5360 - accuracy: 0.5945 - val_loss: 91.8835 - val_accuracy: 0.1245\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.7403 - accuracy: 0.4544 - val_loss: 2.2879 - val_accuracy: 0.5014\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 2.5311 - accuracy: 0.4863 - val_loss: 2.0656 - val_accuracy: 0.2444\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.5660 - accuracy: 0.5271 - val_loss: 1.9604 - val_accuracy: 0.3629\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.6456 - accuracy: 0.4823 - val_loss: 1.8505 - val_accuracy: 0.3210\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.5109 - accuracy: 0.4987 - val_loss: 1.7202 - val_accuracy: 0.2277\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.5503 - accuracy: 0.4999 - val_loss: 2.0588 - val_accuracy: 0.4231\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.3309 - accuracy: 0.5399 - val_loss: 1.6598 - val_accuracy: 0.3381\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.2875 - accuracy: 0.5698 - val_loss: 1.7673 - val_accuracy: 0.3000\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1942 - accuracy: 0.5864 - val_loss: 1.6758 - val_accuracy: 0.2838\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.2734 - accuracy: 0.5976 - val_loss: 1.5786 - val_accuracy: 0.2698\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1811 - accuracy: 0.6052 - val_loss: 1.6665 - val_accuracy: 0.2210\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.2210 - accuracy: 0.6050 - val_loss: 1.6799 - val_accuracy: 0.3039\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1903 - accuracy: 0.6078 - val_loss: 1.7113 - val_accuracy: 0.2732\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.2060 - accuracy: 0.6093 - val_loss: 1.4980 - val_accuracy: 0.2261\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.2687 - accuracy: 0.6058 - val_loss: 1.7101 - val_accuracy: 0.2755\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1539 - accuracy: 0.6123 - val_loss: 1.6801 - val_accuracy: 0.2762\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.2112 - accuracy: 0.6002 - val_loss: 1.7406 - val_accuracy: 0.3238\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.2602 - accuracy: 0.6124 - val_loss: 1.6396 - val_accuracy: 0.2721\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2379 - accuracy: 0.6118 - val_loss: 1.7553 - val_accuracy: 0.2146\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.2128 - accuracy: 0.6118 - val_loss: 1.8671 - val_accuracy: 0.1794\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1869 - accuracy: 0.6149 - val_loss: 1.7739 - val_accuracy: 0.1916\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1941 - accuracy: 0.6168 - val_loss: 1.7790 - val_accuracy: 0.1958\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1921 - accuracy: 0.6162 - val_loss: 1.8160 - val_accuracy: 0.1995\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2314 - accuracy: 0.6195 - val_loss: 1.8353 - val_accuracy: 0.2117\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1619 - accuracy: 0.6178 - val_loss: 1.8644 - val_accuracy: 0.2227\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1490 - accuracy: 0.6188 - val_loss: 1.8325 - val_accuracy: 0.2286\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1320 - accuracy: 0.6145 - val_loss: 1.6965 - val_accuracy: 0.2590\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1839 - accuracy: 0.6121 - val_loss: 1.9372 - val_accuracy: 0.2048\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1815 - accuracy: 0.6149 - val_loss: 2.1480 - val_accuracy: 0.1466\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.1037 - accuracy: 0.6216 - val_loss: 2.2713 - val_accuracy: 0.1456\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1943 - accuracy: 0.6190 - val_loss: 2.2337 - val_accuracy: 0.1466\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1900 - accuracy: 0.6147 - val_loss: 2.2158 - val_accuracy: 0.1460\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 4s 241ms/step - loss: 2.2642 - accuracy: 0.6121 - val_loss: 2.0683 - val_accuracy: 0.1495\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1786 - accuracy: 0.6177 - val_loss: 2.1292 - val_accuracy: 0.1503\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1592 - accuracy: 0.6226 - val_loss: 2.0045 - val_accuracy: 0.1565\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0910 - accuracy: 0.6201 - val_loss: 2.0370 - val_accuracy: 0.1587\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1442 - accuracy: 0.6201 - val_loss: 1.9690 - val_accuracy: 0.1580\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 2.2080 - accuracy: 0.6123 - val_loss: 2.0113 - val_accuracy: 0.1567\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.1761 - accuracy: 0.6193 - val_loss: 2.0516 - val_accuracy: 0.1586\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 2.1664 - accuracy: 0.6222 - val_loss: 1.9165 - val_accuracy: 0.1614\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1488 - accuracy: 0.6238 - val_loss: 1.9837 - val_accuracy: 0.1628\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1138 - accuracy: 0.6202 - val_loss: 1.9012 - val_accuracy: 0.1719\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1329 - accuracy: 0.6226 - val_loss: 2.0178 - val_accuracy: 0.1742\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1679 - accuracy: 0.6185 - val_loss: 1.8308 - val_accuracy: 0.1796\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1269 - accuracy: 0.6163 - val_loss: 1.9400 - val_accuracy: 0.1794\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1221 - accuracy: 0.6238 - val_loss: 1.9860 - val_accuracy: 0.1845\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1367 - accuracy: 0.6184 - val_loss: 2.1843 - val_accuracy: 0.1869\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1587 - accuracy: 0.6181 - val_loss: 2.0714 - val_accuracy: 0.1974\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1223 - accuracy: 0.6182 - val_loss: 2.0729 - val_accuracy: 0.2062\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1273 - accuracy: 0.6172 - val_loss: 1.9166 - val_accuracy: 0.2265\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0900 - accuracy: 0.6150 - val_loss: 1.9153 - val_accuracy: 0.2560\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1187 - accuracy: 0.6170 - val_loss: 1.9455 - val_accuracy: 0.2412\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1208 - accuracy: 0.6158 - val_loss: 1.8806 - val_accuracy: 0.2341\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1709 - accuracy: 0.6166 - val_loss: 1.9913 - val_accuracy: 0.2527\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1113 - accuracy: 0.6210 - val_loss: 1.8290 - val_accuracy: 0.2541\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1242 - accuracy: 0.6152 - val_loss: 1.6756 - val_accuracy: 0.3216\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1670 - accuracy: 0.6188 - val_loss: 1.8115 - val_accuracy: 0.3175\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1636 - accuracy: 0.6106 - val_loss: 1.8410 - val_accuracy: 0.3005\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1383 - accuracy: 0.6155 - val_loss: 1.9082 - val_accuracy: 0.2989\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1421 - accuracy: 0.6067 - val_loss: 1.8301 - val_accuracy: 0.2780\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1019 - accuracy: 0.6142 - val_loss: 2.2629 - val_accuracy: 0.3143\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1379 - accuracy: 0.6126 - val_loss: 2.6890 - val_accuracy: 0.2592\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1082 - accuracy: 0.6191 - val_loss: 2.2163 - val_accuracy: 0.2627\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 10s 616ms/step - loss: 2.1183 - accuracy: 0.6176 - val_loss: 2.7005 - val_accuracy: 0.2781\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.1351 - accuracy: 0.6150 - val_loss: 2.0597 - val_accuracy: 0.2829\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1825 - accuracy: 0.6142 - val_loss: 2.3894 - val_accuracy: 0.2725\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 2.1496 - accuracy: 0.6184 - val_loss: 2.6835 - val_accuracy: 0.2675\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1305 - accuracy: 0.6206 - val_loss: 2.1592 - val_accuracy: 0.2604\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1267 - accuracy: 0.6181 - val_loss: 2.9002 - val_accuracy: 0.2548\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1275 - accuracy: 0.6165 - val_loss: 2.4113 - val_accuracy: 0.2570\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1603 - accuracy: 0.6134 - val_loss: 2.7295 - val_accuracy: 0.2736\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1254 - accuracy: 0.6140 - val_loss: 2.9260 - val_accuracy: 0.2780\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1330 - accuracy: 0.6185 - val_loss: 2.6590 - val_accuracy: 0.2576\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 2.1132 - accuracy: 0.6180 - val_loss: 2.5288 - val_accuracy: 0.2439\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0873 - accuracy: 0.6195 - val_loss: 2.6425 - val_accuracy: 0.2330\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0925 - accuracy: 0.6185 - val_loss: 2.4782 - val_accuracy: 0.1964\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0761 - accuracy: 0.6226 - val_loss: 2.6326 - val_accuracy: 0.1875\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1333 - accuracy: 0.6185 - val_loss: 2.4562 - val_accuracy: 0.1824\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0891 - accuracy: 0.6189 - val_loss: 2.1829 - val_accuracy: 0.1908\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1196 - accuracy: 0.6225 - val_loss: 2.3582 - val_accuracy: 0.1959\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0944 - accuracy: 0.6243 - val_loss: 2.4624 - val_accuracy: 0.2176\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1090 - accuracy: 0.6211 - val_loss: 2.1930 - val_accuracy: 0.2179\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0737 - accuracy: 0.6206 - val_loss: 2.1513 - val_accuracy: 0.2471\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1273 - accuracy: 0.6189 - val_loss: 2.2609 - val_accuracy: 0.2763\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1182 - accuracy: 0.6201 - val_loss: 2.2011 - val_accuracy: 0.2383\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1237 - accuracy: 0.6211 - val_loss: 2.3438 - val_accuracy: 0.2321\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1130 - accuracy: 0.6161 - val_loss: 1.9960 - val_accuracy: 0.2591\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1702 - accuracy: 0.6144 - val_loss: 2.3329 - val_accuracy: 0.2383\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0716 - accuracy: 0.6268 - val_loss: 2.3787 - val_accuracy: 0.2330\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0970 - accuracy: 0.6207 - val_loss: 1.9629 - val_accuracy: 0.2628\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0819 - accuracy: 0.6228 - val_loss: 2.2433 - val_accuracy: 0.2469\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2405 - accuracy: 0.6253 - val_loss: 172.6993 - val_accuracy: 0.1499\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.2363 - accuracy: 0.6268 - val_loss: 2.6898 - val_accuracy: 0.1724\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.2108 - accuracy: 0.6175 - val_loss: 2.2128 - val_accuracy: 0.4555\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.2322 - accuracy: 0.6206 - val_loss: 2.0178 - val_accuracy: 0.3414\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.2689 - accuracy: 0.6157 - val_loss: 2.1043 - val_accuracy: 0.5839\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.2346 - accuracy: 0.6122 - val_loss: 1.9866 - val_accuracy: 0.3248\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.2971 - accuracy: 0.5978 - val_loss: 1.6059 - val_accuracy: 0.3684\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1591 - accuracy: 0.6112 - val_loss: 1.5551 - val_accuracy: 0.3503\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.2034 - accuracy: 0.6138 - val_loss: 1.6084 - val_accuracy: 0.3626\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.2051 - accuracy: 0.6187 - val_loss: 1.7943 - val_accuracy: 0.3628\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.2465 - accuracy: 0.6132 - val_loss: 1.7020 - val_accuracy: 0.4823\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1374 - accuracy: 0.6210 - val_loss: 1.7584 - val_accuracy: 0.3645\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1939 - accuracy: 0.6211 - val_loss: 1.6196 - val_accuracy: 0.3661\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.2611 - accuracy: 0.6164 - val_loss: 1.6110 - val_accuracy: 0.3384\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1264 - accuracy: 0.6223 - val_loss: 1.4307 - val_accuracy: 0.3252\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1990 - accuracy: 0.6150 - val_loss: 1.5945 - val_accuracy: 0.3306\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1146 - accuracy: 0.6200 - val_loss: 1.4820 - val_accuracy: 0.3427\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1433 - accuracy: 0.6190 - val_loss: 1.3671 - val_accuracy: 0.3501\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1846 - accuracy: 0.6131 - val_loss: 1.4679 - val_accuracy: 0.3472\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 2.0926 - accuracy: 0.6234 - val_loss: 1.5701 - val_accuracy: 0.3541\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.1637 - accuracy: 0.6151 - val_loss: 1.5967 - val_accuracy: 0.3515\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 2.1653 - accuracy: 0.6154 - val_loss: 1.8493 - val_accuracy: 0.3529\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1942 - accuracy: 0.6162 - val_loss: 1.6207 - val_accuracy: 0.3478\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1163 - accuracy: 0.6210 - val_loss: 1.5942 - val_accuracy: 0.3582\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1966 - accuracy: 0.6160 - val_loss: 1.4944 - val_accuracy: 0.3660\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.2704 - accuracy: 0.6135 - val_loss: 1.7268 - val_accuracy: 0.3665\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0984 - accuracy: 0.6196 - val_loss: 1.9545 - val_accuracy: 0.5480\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1937 - accuracy: 0.6144 - val_loss: 1.6573 - val_accuracy: 0.5701\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1734 - accuracy: 0.6138 - val_loss: 1.8947 - val_accuracy: 0.5337\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1008 - accuracy: 0.6221 - val_loss: 1.8395 - val_accuracy: 0.4948\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1894 - accuracy: 0.6120 - val_loss: 1.7153 - val_accuracy: 0.4685\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1313 - accuracy: 0.6179 - val_loss: 1.6150 - val_accuracy: 0.4405\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1109 - accuracy: 0.6200 - val_loss: 1.5385 - val_accuracy: 0.4243\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1546 - accuracy: 0.6174 - val_loss: 1.5127 - val_accuracy: 0.4207\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1689 - accuracy: 0.6121 - val_loss: 1.3982 - val_accuracy: 0.4149\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1534 - accuracy: 0.6166 - val_loss: 1.6617 - val_accuracy: 0.4054\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1300 - accuracy: 0.6192 - val_loss: 1.2970 - val_accuracy: 0.4125\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1798 - accuracy: 0.6159 - val_loss: 1.3689 - val_accuracy: 0.3995\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0822 - accuracy: 0.6215 - val_loss: 1.5698 - val_accuracy: 0.4054\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1263 - accuracy: 0.6214 - val_loss: 1.7634 - val_accuracy: 0.4054\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1396 - accuracy: 0.6204 - val_loss: 1.4965 - val_accuracy: 0.3948\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1761 - accuracy: 0.6158 - val_loss: 1.6193 - val_accuracy: 0.3777\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1265 - accuracy: 0.6200 - val_loss: 1.4953 - val_accuracy: 0.3879\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.2320 - accuracy: 0.6154 - val_loss: 2.2118 - val_accuracy: 0.6162\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.2897 - accuracy: 0.5949 - val_loss: 2.6057 - val_accuracy: 0.1885\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.2425 - accuracy: 0.5940 - val_loss: 3.4526 - val_accuracy: 0.3757\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.2095 - accuracy: 0.6021 - val_loss: 1.7286 - val_accuracy: 0.3978\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.2169 - accuracy: 0.6145 - val_loss: 1.6803 - val_accuracy: 0.4630\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1882 - accuracy: 0.6181 - val_loss: 1.4698 - val_accuracy: 0.4302\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1979 - accuracy: 0.6177 - val_loss: 1.6970 - val_accuracy: 0.4170\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1717 - accuracy: 0.6227 - val_loss: 1.5417 - val_accuracy: 0.4098\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1696 - accuracy: 0.6181 - val_loss: 1.8443 - val_accuracy: 0.4013\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1632 - accuracy: 0.6184 - val_loss: 1.3245 - val_accuracy: 0.4122\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1871 - accuracy: 0.6183 - val_loss: 1.3982 - val_accuracy: 0.4091\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1350 - accuracy: 0.6246 - val_loss: 1.6070 - val_accuracy: 0.4268\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1293 - accuracy: 0.6221 - val_loss: 1.4603 - val_accuracy: 0.4418\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1213 - accuracy: 0.6249 - val_loss: 1.4215 - val_accuracy: 0.4429\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1568 - accuracy: 0.6273 - val_loss: 1.4264 - val_accuracy: 0.4416\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1186 - accuracy: 0.6217 - val_loss: 1.7226 - val_accuracy: 0.4375\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.2055 - accuracy: 0.6202 - val_loss: 1.3976 - val_accuracy: 0.4436\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2157 - accuracy: 0.6192 - val_loss: 1.4554 - val_accuracy: 0.4362\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1969 - accuracy: 0.6159 - val_loss: 1.5162 - val_accuracy: 0.4268\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1462 - accuracy: 0.6160 - val_loss: 1.3313 - val_accuracy: 0.4263\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.0835 - accuracy: 0.6221 - val_loss: 1.4520 - val_accuracy: 0.4152\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1856 - accuracy: 0.6231 - val_loss: 1.3013 - val_accuracy: 0.4219\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1603 - accuracy: 0.6195 - val_loss: 1.5299 - val_accuracy: 0.4103\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1050 - accuracy: 0.6253 - val_loss: 1.4622 - val_accuracy: 0.4013\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1402 - accuracy: 0.6198 - val_loss: 1.4103 - val_accuracy: 0.4011\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1015 - accuracy: 0.6249 - val_loss: 1.4906 - val_accuracy: 0.4027\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1255 - accuracy: 0.6191 - val_loss: 1.3893 - val_accuracy: 0.3876\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1662 - accuracy: 0.6192 - val_loss: 1.5998 - val_accuracy: 0.3770\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1445 - accuracy: 0.6197 - val_loss: 1.4999 - val_accuracy: 0.3821\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1538 - accuracy: 0.6192 - val_loss: 1.6840 - val_accuracy: 0.3779\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1136 - accuracy: 0.6161 - val_loss: 1.5543 - val_accuracy: 0.3721\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1464 - accuracy: 0.6157 - val_loss: 1.5826 - val_accuracy: 0.3689\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1238 - accuracy: 0.6231 - val_loss: 1.4538 - val_accuracy: 0.3633\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1574 - accuracy: 0.6207 - val_loss: 1.3973 - val_accuracy: 0.3585\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1156 - accuracy: 0.6197 - val_loss: 1.4836 - val_accuracy: 0.3662\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.1075 - accuracy: 0.6186 - val_loss: 1.6806 - val_accuracy: 0.3545\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1816 - accuracy: 0.6204 - val_loss: 1.5571 - val_accuracy: 0.3509\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1261 - accuracy: 0.6189 - val_loss: 1.2968 - val_accuracy: 0.3460\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1179 - accuracy: 0.6243 - val_loss: 1.5137 - val_accuracy: 0.3416\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0596 - accuracy: 0.6234 - val_loss: 1.3788 - val_accuracy: 0.3307\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.0881 - accuracy: 0.6222 - val_loss: 1.7443 - val_accuracy: 0.3276\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 2.0734 - accuracy: 0.6228 - val_loss: 1.5259 - val_accuracy: 0.3245\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1095 - accuracy: 0.6189 - val_loss: 1.3767 - val_accuracy: 0.3069\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1717 - accuracy: 0.6157 - val_loss: 1.5874 - val_accuracy: 0.3012\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.1328 - accuracy: 0.6207 - val_loss: 1.4117 - val_accuracy: 0.3117\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1072 - accuracy: 0.6206 - val_loss: 1.4984 - val_accuracy: 0.2955\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.1506 - accuracy: 0.6217 - val_loss: 1.6079 - val_accuracy: 0.2855\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0934 - accuracy: 0.6185 - val_loss: 1.4176 - val_accuracy: 0.2746\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1515 - accuracy: 0.6226 - val_loss: 1.6338 - val_accuracy: 0.2563\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1039 - accuracy: 0.6176 - val_loss: 1.7095 - val_accuracy: 0.2488\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1268 - accuracy: 0.6185 - val_loss: 1.3251 - val_accuracy: 0.2479\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0864 - accuracy: 0.6202 - val_loss: 1.5522 - val_accuracy: 0.2528\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0972 - accuracy: 0.6199 - val_loss: 1.3966 - val_accuracy: 0.2487\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 2.1400 - accuracy: 0.6196 - val_loss: 1.5738 - val_accuracy: 0.2384\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0842 - accuracy: 0.6232 - val_loss: 1.5848 - val_accuracy: 0.2441\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1002 - accuracy: 0.6200 - val_loss: 1.5368 - val_accuracy: 0.2430\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0798 - accuracy: 0.6247 - val_loss: 1.6196 - val_accuracy: 0.2420\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1275 - accuracy: 0.6178 - val_loss: 1.5702 - val_accuracy: 0.2396\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1280 - accuracy: 0.6188 - val_loss: 1.5397 - val_accuracy: 0.2387\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0875 - accuracy: 0.6183 - val_loss: 1.4637 - val_accuracy: 0.2365\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.1115 - accuracy: 0.6195 - val_loss: 1.4376 - val_accuracy: 0.2333\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 2.1402 - accuracy: 0.6211 - val_loss: 1.4963 - val_accuracy: 0.2351\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0736 - accuracy: 0.6224 - val_loss: 1.4425 - val_accuracy: 0.2314\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1112 - accuracy: 0.6153 - val_loss: 1.5133 - val_accuracy: 0.2239\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0912 - accuracy: 0.6196 - val_loss: 1.5200 - val_accuracy: 0.2235\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0819 - accuracy: 0.6229 - val_loss: 1.4082 - val_accuracy: 0.2335\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0860 - accuracy: 0.6206 - val_loss: 1.3722 - val_accuracy: 0.2323\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0809 - accuracy: 0.6235 - val_loss: 1.2648 - val_accuracy: 0.2264\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0736 - accuracy: 0.6208 - val_loss: 1.5553 - val_accuracy: 0.2287\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0835 - accuracy: 0.6227 - val_loss: 1.5965 - val_accuracy: 0.2279\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0590 - accuracy: 0.6240 - val_loss: 1.4099 - val_accuracy: 0.2257\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0929 - accuracy: 0.6176 - val_loss: 1.4779 - val_accuracy: 0.2242\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1038 - accuracy: 0.6187 - val_loss: 1.5267 - val_accuracy: 0.2225\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0893 - accuracy: 0.6159 - val_loss: 1.4971 - val_accuracy: 0.2242\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0832 - accuracy: 0.6195 - val_loss: 1.5522 - val_accuracy: 0.2235\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0879 - accuracy: 0.6243 - val_loss: 1.5689 - val_accuracy: 0.2374\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0763 - accuracy: 0.6180 - val_loss: 1.4596 - val_accuracy: 0.2272\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0787 - accuracy: 0.6259 - val_loss: 1.5554 - val_accuracy: 0.2334\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0815 - accuracy: 0.6181 - val_loss: 1.5124 - val_accuracy: 0.2278\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0974 - accuracy: 0.6171 - val_loss: 1.5691 - val_accuracy: 0.2308\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0177 - accuracy: 0.6239 - val_loss: 1.6839 - val_accuracy: 0.2353\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1478 - accuracy: 0.6193 - val_loss: 1.6051 - val_accuracy: 0.2261\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0514 - accuracy: 0.6190 - val_loss: 1.4385 - val_accuracy: 0.2283\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0581 - accuracy: 0.6236 - val_loss: 1.4498 - val_accuracy: 0.2319\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0649 - accuracy: 0.6200 - val_loss: 1.6284 - val_accuracy: 0.2317\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0406 - accuracy: 0.6225 - val_loss: 1.5836 - val_accuracy: 0.2332\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0296 - accuracy: 0.6244 - val_loss: 1.5545 - val_accuracy: 0.2310\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0492 - accuracy: 0.6229 - val_loss: 1.5121 - val_accuracy: 0.2326\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.0797 - accuracy: 0.6193 - val_loss: 1.6142 - val_accuracy: 0.2317\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0773 - accuracy: 0.6180 - val_loss: 1.5777 - val_accuracy: 0.2271\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0763 - accuracy: 0.6130 - val_loss: 1.4256 - val_accuracy: 0.2277\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0636 - accuracy: 0.6183 - val_loss: 1.5759 - val_accuracy: 0.2335\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0737 - accuracy: 0.6192 - val_loss: 1.5235 - val_accuracy: 0.2322\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0656 - accuracy: 0.6180 - val_loss: 1.6720 - val_accuracy: 0.2357\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0622 - accuracy: 0.6188 - val_loss: 1.6202 - val_accuracy: 0.2345\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0681 - accuracy: 0.6208 - val_loss: 1.6309 - val_accuracy: 0.2309\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0774 - accuracy: 0.6222 - val_loss: 1.5114 - val_accuracy: 0.2206\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0495 - accuracy: 0.6207 - val_loss: 1.5110 - val_accuracy: 0.2239\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0275 - accuracy: 0.6266 - val_loss: 1.4702 - val_accuracy: 0.2361\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1164 - accuracy: 0.6214 - val_loss: 1.5781 - val_accuracy: 0.2299\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0893 - accuracy: 0.6221 - val_loss: 1.5214 - val_accuracy: 0.2233\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0875 - accuracy: 0.6166 - val_loss: 1.6310 - val_accuracy: 0.2200\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 2.1318 - accuracy: 0.6179 - val_loss: 1.7327 - val_accuracy: 0.2125\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0669 - accuracy: 0.6162 - val_loss: 1.5138 - val_accuracy: 0.2219\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1039 - accuracy: 0.6173 - val_loss: 1.7569 - val_accuracy: 0.2099\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0828 - accuracy: 0.6218 - val_loss: 1.7038 - val_accuracy: 0.2080\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0001 - accuracy: 0.6194 - val_loss: 1.6301 - val_accuracy: 0.2060\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0699 - accuracy: 0.6185 - val_loss: 1.9184 - val_accuracy: 0.2066\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0761 - accuracy: 0.6208 - val_loss: 1.9912 - val_accuracy: 0.1948\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0500 - accuracy: 0.6204 - val_loss: 2.5603 - val_accuracy: 0.2016\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0356 - accuracy: 0.6222 - val_loss: 1.7914 - val_accuracy: 0.1904\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0351 - accuracy: 0.6225 - val_loss: 2.4946 - val_accuracy: 0.1981\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0743 - accuracy: 0.6177 - val_loss: 2.1328 - val_accuracy: 0.1832\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0842 - accuracy: 0.6231 - val_loss: 2.0090 - val_accuracy: 0.1878\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0311 - accuracy: 0.6232 - val_loss: 1.6539 - val_accuracy: 0.1924\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0456 - accuracy: 0.6185 - val_loss: 4.0179 - val_accuracy: 0.1794\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0755 - accuracy: 0.6212 - val_loss: 2.8810 - val_accuracy: 0.1746\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0586 - accuracy: 0.6211 - val_loss: 5.6047 - val_accuracy: 0.1678\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0933 - accuracy: 0.6171 - val_loss: 5.8883 - val_accuracy: 0.1585\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0449 - accuracy: 0.6175 - val_loss: 3.0511 - val_accuracy: 0.1596\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0485 - accuracy: 0.6163 - val_loss: 5.3743 - val_accuracy: 0.1571\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0633 - accuracy: 0.6223 - val_loss: 7.7700 - val_accuracy: 0.1438\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0196 - accuracy: 0.6253 - val_loss: 5.6888 - val_accuracy: 0.1481\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0572 - accuracy: 0.6200 - val_loss: 11.3676 - val_accuracy: 0.1409\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0142 - accuracy: 0.6260 - val_loss: 4.8001 - val_accuracy: 0.1551\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0362 - accuracy: 0.6247 - val_loss: 11.8525 - val_accuracy: 0.1404\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0200 - accuracy: 0.6260 - val_loss: 9.8465 - val_accuracy: 0.1446\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0400 - accuracy: 0.6213 - val_loss: 4.0354 - val_accuracy: 0.1610\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0534 - accuracy: 0.6190 - val_loss: 12.4615 - val_accuracy: 0.1360\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.0508 - accuracy: 0.6233 - val_loss: 9.5167 - val_accuracy: 0.1473\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.0208 - accuracy: 0.6230 - val_loss: 3.0525 - val_accuracy: 0.4342\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0336 - accuracy: 0.6243 - val_loss: 9.4818 - val_accuracy: 0.1531\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1105 - accuracy: 0.6207 - val_loss: 84.2107 - val_accuracy: 0.0837\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0885 - accuracy: 0.6198 - val_loss: 49.4083 - val_accuracy: 0.0733\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0815 - accuracy: 0.6226 - val_loss: 57.4096 - val_accuracy: 0.0741\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0697 - accuracy: 0.6188 - val_loss: 44.6235 - val_accuracy: 0.0933\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0533 - accuracy: 0.6251 - val_loss: 62.6474 - val_accuracy: 0.0807\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0332 - accuracy: 0.6187 - val_loss: 36.6533 - val_accuracy: 0.0861\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0358 - accuracy: 0.6261 - val_loss: 32.5902 - val_accuracy: 0.1188\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0455 - accuracy: 0.6225 - val_loss: 23.6834 - val_accuracy: 0.1128\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.0282 - accuracy: 0.6218 - val_loss: 35.1958 - val_accuracy: 0.0995\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0241 - accuracy: 0.6238 - val_loss: 37.5229 - val_accuracy: 0.1065\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0418 - accuracy: 0.6202 - val_loss: 11.8877 - val_accuracy: 0.1257\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.0361 - accuracy: 0.6236 - val_loss: 26.4598 - val_accuracy: 0.1149\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 2.0213 - accuracy: 0.6269 - val_loss: 13.2515 - val_accuracy: 0.1289\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.0235 - accuracy: 0.6210 - val_loss: 23.3953 - val_accuracy: 0.1217\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0353 - accuracy: 0.6199 - val_loss: 17.3889 - val_accuracy: 0.1214\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.1061 - accuracy: 0.6201 - val_loss: 17.1489 - val_accuracy: 0.1213\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0615 - accuracy: 0.6205 - val_loss: 24.2184 - val_accuracy: 0.1304\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0647 - accuracy: 0.6189 - val_loss: 14.0352 - val_accuracy: 0.1253\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0168 - accuracy: 0.6245 - val_loss: 9.0164 - val_accuracy: 0.1387\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0560 - accuracy: 0.6209 - val_loss: 7.2729 - val_accuracy: 0.1366\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0570 - accuracy: 0.6240 - val_loss: 12.7809 - val_accuracy: 0.1389\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0961 - accuracy: 0.6204 - val_loss: 16.9200 - val_accuracy: 0.1455\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0684 - accuracy: 0.6177 - val_loss: 22.2248 - val_accuracy: 0.1428\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0251 - accuracy: 0.6221 - val_loss: 18.2480 - val_accuracy: 0.1416\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0605 - accuracy: 0.6223 - val_loss: 6.4944 - val_accuracy: 0.1580\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0662 - accuracy: 0.6212 - val_loss: 12.7192 - val_accuracy: 0.1374\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0617 - accuracy: 0.6212 - val_loss: 7.5689 - val_accuracy: 0.1510\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.0567 - accuracy: 0.6219 - val_loss: 15.8067 - val_accuracy: 0.1464\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0311 - accuracy: 0.6195 - val_loss: 10.4278 - val_accuracy: 0.1471\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.9884 - accuracy: 0.6210 - val_loss: 6.8557 - val_accuracy: 0.1578\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0355 - accuracy: 0.6216 - val_loss: 6.7529 - val_accuracy: 0.1522\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0436 - accuracy: 0.6220 - val_loss: 5.1509 - val_accuracy: 0.1549\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0483 - accuracy: 0.6193 - val_loss: 6.3536 - val_accuracy: 0.1565\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0076 - accuracy: 0.6239 - val_loss: 17.7372 - val_accuracy: 0.1564\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0540 - accuracy: 0.6200 - val_loss: 20.5342 - val_accuracy: 0.1430\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0347 - accuracy: 0.6205 - val_loss: 4.6300 - val_accuracy: 0.1578\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0454 - accuracy: 0.6210 - val_loss: 11.5155 - val_accuracy: 0.1438\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0193 - accuracy: 0.6235 - val_loss: 7.7271 - val_accuracy: 0.1682\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0323 - accuracy: 0.6220 - val_loss: 6.7837 - val_accuracy: 0.1877\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0538 - accuracy: 0.6180 - val_loss: 9.9737 - val_accuracy: 0.1554\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0230 - accuracy: 0.6277 - val_loss: 5.4616 - val_accuracy: 0.1735\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0172 - accuracy: 0.6208 - val_loss: 16.5480 - val_accuracy: 0.1443\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0786 - accuracy: 0.6188 - val_loss: 5.3949 - val_accuracy: 0.1699\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0581 - accuracy: 0.6193 - val_loss: 14.7226 - val_accuracy: 0.1466\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0182 - accuracy: 0.6223 - val_loss: 8.2851 - val_accuracy: 0.1701\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0300 - accuracy: 0.6240 - val_loss: 10.5790 - val_accuracy: 0.1392\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0678 - accuracy: 0.6216 - val_loss: 10.7705 - val_accuracy: 0.1393\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.0367 - accuracy: 0.6231 - val_loss: 18.5522 - val_accuracy: 0.1608\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0642 - accuracy: 0.6218 - val_loss: 6.9680 - val_accuracy: 0.1559\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0289 - accuracy: 0.6221 - val_loss: 9.8601 - val_accuracy: 0.1579\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0424 - accuracy: 0.6203 - val_loss: 5.2188 - val_accuracy: 0.1535\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.0145 - accuracy: 0.6228 - val_loss: 6.3835 - val_accuracy: 0.1664\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.9894 - accuracy: 0.6240 - val_loss: 10.0520 - val_accuracy: 0.1609\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0148 - accuracy: 0.6284 - val_loss: 5.0154 - val_accuracy: 0.1553\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0247 - accuracy: 0.6234 - val_loss: 5.0898 - val_accuracy: 0.1563\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 2.0516 - accuracy: 0.6177 - val_loss: 5.3378 - val_accuracy: 0.1666\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0476 - accuracy: 0.6170 - val_loss: 9.5233 - val_accuracy: 0.1459\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0178 - accuracy: 0.6203 - val_loss: 6.8481 - val_accuracy: 0.1541\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0349 - accuracy: 0.6195 - val_loss: 4.5616 - val_accuracy: 0.1549\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.0212 - accuracy: 0.6231 - val_loss: 8.6177 - val_accuracy: 0.1498\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0204 - accuracy: 0.6211 - val_loss: 10.7786 - val_accuracy: 0.1639\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 273ms/step - loss: 2.4410 - accuracy: 0.6113 - val_loss: 15.4737 - val_accuracy: 0.3409\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1958 - accuracy: 0.6143 - val_loss: 16.1462 - val_accuracy: 0.3414\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1726 - accuracy: 0.6112 - val_loss: 15.4422 - val_accuracy: 0.3422\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.0291 - accuracy: 0.6195 - val_loss: 15.6642 - val_accuracy: 0.3428\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.9997 - accuracy: 0.6166 - val_loss: 19.1397 - val_accuracy: 0.3419\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0119 - accuracy: 0.6183 - val_loss: 16.3760 - val_accuracy: 0.3466\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0154 - accuracy: 0.6228 - val_loss: 16.1305 - val_accuracy: 0.3373\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0740 - accuracy: 0.6216 - val_loss: 13.1262 - val_accuracy: 0.3289\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0241 - accuracy: 0.6146 - val_loss: 12.8618 - val_accuracy: 0.3021\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.9894 - accuracy: 0.6172 - val_loss: 11.9756 - val_accuracy: 0.1965\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.9046 - accuracy: 0.6177 - val_loss: 10.4904 - val_accuracy: 0.1892\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.8279 - accuracy: 0.6251 - val_loss: 13.9527 - val_accuracy: 0.1074\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.8343 - accuracy: 0.6196 - val_loss: 12.8492 - val_accuracy: 0.1070\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.7934 - accuracy: 0.6225 - val_loss: 11.6961 - val_accuracy: 0.1076\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.7779 - accuracy: 0.6255 - val_loss: 13.1032 - val_accuracy: 0.1083\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.7764 - accuracy: 0.6228 - val_loss: 12.9890 - val_accuracy: 0.1073\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.7684 - accuracy: 0.6218 - val_loss: 13.3769 - val_accuracy: 0.1106\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.7362 - accuracy: 0.6198 - val_loss: 11.1050 - val_accuracy: 0.1080\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.7603 - accuracy: 0.6219 - val_loss: 12.3379 - val_accuracy: 0.1100\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.7055 - accuracy: 0.6281 - val_loss: 12.8139 - val_accuracy: 0.1085\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6852 - accuracy: 0.6292 - val_loss: 14.2055 - val_accuracy: 0.1068\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.7183 - accuracy: 0.6243 - val_loss: 12.9141 - val_accuracy: 0.1134\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.7279 - accuracy: 0.6223 - val_loss: 11.4122 - val_accuracy: 0.1142\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.6817 - accuracy: 0.6300 - val_loss: 10.9164 - val_accuracy: 0.1131\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.6964 - accuracy: 0.6240 - val_loss: 11.0234 - val_accuracy: 0.1116\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.6789 - accuracy: 0.6290 - val_loss: 12.1382 - val_accuracy: 0.1095\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.6522 - accuracy: 0.6290 - val_loss: 14.0525 - val_accuracy: 0.1082\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.6664 - accuracy: 0.6313 - val_loss: 13.6167 - val_accuracy: 0.1120\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6468 - accuracy: 0.6294 - val_loss: 13.1548 - val_accuracy: 0.1125\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6082 - accuracy: 0.6327 - val_loss: 14.0764 - val_accuracy: 0.1149\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.6175 - accuracy: 0.6324 - val_loss: 12.1008 - val_accuracy: 0.1094\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.6426 - accuracy: 0.6298 - val_loss: 11.3627 - val_accuracy: 0.1090\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.6249 - accuracy: 0.6341 - val_loss: 11.6605 - val_accuracy: 0.1057\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.6187 - accuracy: 0.6331 - val_loss: 13.3842 - val_accuracy: 0.1168\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.5964 - accuracy: 0.6338 - val_loss: 11.6445 - val_accuracy: 0.1040\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.6040 - accuracy: 0.6381 - val_loss: 12.7721 - val_accuracy: 0.1022\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.5937 - accuracy: 0.6363 - val_loss: 11.5026 - val_accuracy: 0.1046\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.6084 - accuracy: 0.6380 - val_loss: 11.2418 - val_accuracy: 0.1077\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5803 - accuracy: 0.6359 - val_loss: 11.3234 - val_accuracy: 0.1232\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5637 - accuracy: 0.6409 - val_loss: 11.1103 - val_accuracy: 0.1923\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5605 - accuracy: 0.6327 - val_loss: 14.0870 - val_accuracy: 0.1555\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5471 - accuracy: 0.6396 - val_loss: 13.9060 - val_accuracy: 0.2018\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5381 - accuracy: 0.6383 - val_loss: 11.0219 - val_accuracy: 0.2361\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.5209 - accuracy: 0.6440 - val_loss: 13.8658 - val_accuracy: 0.2662\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4781 - accuracy: 0.6516 - val_loss: 14.1542 - val_accuracy: 0.3004\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5486 - accuracy: 0.6419 - val_loss: 11.4540 - val_accuracy: 0.3007\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5409 - accuracy: 0.6396 - val_loss: 13.2340 - val_accuracy: 0.3018\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5112 - accuracy: 0.6447 - val_loss: 9.7165 - val_accuracy: 0.2709\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.5644 - accuracy: 0.6429 - val_loss: 14.6354 - val_accuracy: 0.2697\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 4s 274ms/step - loss: 1.5002 - accuracy: 0.6463 - val_loss: 10.2591 - val_accuracy: 0.2591\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 1.4515 - accuracy: 0.6463 - val_loss: 13.1673 - val_accuracy: 0.2983\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 1.4518 - accuracy: 0.6508 - val_loss: 12.5018 - val_accuracy: 0.3146\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4665 - accuracy: 0.6443 - val_loss: 14.1459 - val_accuracy: 0.2823\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4683 - accuracy: 0.6491 - val_loss: 13.9445 - val_accuracy: 0.2979\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.4647 - accuracy: 0.6452 - val_loss: 13.6655 - val_accuracy: 0.3046\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4890 - accuracy: 0.6530 - val_loss: 13.6263 - val_accuracy: 0.3066\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4684 - accuracy: 0.6467 - val_loss: 13.6518 - val_accuracy: 0.2949\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4706 - accuracy: 0.6492 - val_loss: 13.2975 - val_accuracy: 0.3028\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4143 - accuracy: 0.6546 - val_loss: 10.8597 - val_accuracy: 0.2695\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.4460 - accuracy: 0.6536 - val_loss: 11.8898 - val_accuracy: 0.2224\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4547 - accuracy: 0.6533 - val_loss: 13.7531 - val_accuracy: 0.3028\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4379 - accuracy: 0.6526 - val_loss: 13.3043 - val_accuracy: 0.3052\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4419 - accuracy: 0.6559 - val_loss: 13.9241 - val_accuracy: 0.2758\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4493 - accuracy: 0.6543 - val_loss: 13.4894 - val_accuracy: 0.2887\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.4360 - accuracy: 0.6500 - val_loss: 13.7343 - val_accuracy: 0.3055\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4229 - accuracy: 0.6535 - val_loss: 12.4898 - val_accuracy: 0.3176\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.4291 - accuracy: 0.6501 - val_loss: 15.0982 - val_accuracy: 0.3162\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.3991 - accuracy: 0.6579 - val_loss: 13.8025 - val_accuracy: 0.3238\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.4076 - accuracy: 0.6533 - val_loss: 12.1600 - val_accuracy: 0.3255\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 1.3990 - accuracy: 0.6617 - val_loss: 16.3490 - val_accuracy: 0.3153\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4378 - accuracy: 0.6593 - val_loss: 12.3969 - val_accuracy: 0.3156\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3661 - accuracy: 0.6591 - val_loss: 15.9779 - val_accuracy: 0.3138\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3698 - accuracy: 0.6589 - val_loss: 11.8657 - val_accuracy: 0.3208\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3858 - accuracy: 0.6640 - val_loss: 11.4810 - val_accuracy: 0.3252\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.4032 - accuracy: 0.6608 - val_loss: 11.8796 - val_accuracy: 0.3075\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3748 - accuracy: 0.6665 - val_loss: 12.2641 - val_accuracy: 0.3009\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3632 - accuracy: 0.6595 - val_loss: 13.5770 - val_accuracy: 0.3044\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3614 - accuracy: 0.6617 - val_loss: 10.8404 - val_accuracy: 0.3297\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3025 - accuracy: 0.6650 - val_loss: 10.8559 - val_accuracy: 0.3260\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.3499 - accuracy: 0.6662 - val_loss: 11.1352 - val_accuracy: 0.3205\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3233 - accuracy: 0.6640 - val_loss: 11.1460 - val_accuracy: 0.3146\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3102 - accuracy: 0.6656 - val_loss: 11.1835 - val_accuracy: 0.3254\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3526 - accuracy: 0.6653 - val_loss: 11.3219 - val_accuracy: 0.3186\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3206 - accuracy: 0.6680 - val_loss: 11.4400 - val_accuracy: 0.3197\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3383 - accuracy: 0.6646 - val_loss: 11.1782 - val_accuracy: 0.3214\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3124 - accuracy: 0.6668 - val_loss: 12.4526 - val_accuracy: 0.3262\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3110 - accuracy: 0.6651 - val_loss: 10.9996 - val_accuracy: 0.3155\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3271 - accuracy: 0.6680 - val_loss: 10.5618 - val_accuracy: 0.3103\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3381 - accuracy: 0.6616 - val_loss: 12.8655 - val_accuracy: 0.2943\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3619 - accuracy: 0.6650 - val_loss: 10.3844 - val_accuracy: 0.3217\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3841 - accuracy: 0.6610 - val_loss: 10.3660 - val_accuracy: 0.3126\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3250 - accuracy: 0.6660 - val_loss: 10.4503 - val_accuracy: 0.3140\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3018 - accuracy: 0.6674 - val_loss: 10.5969 - val_accuracy: 0.2992\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2982 - accuracy: 0.6705 - val_loss: 9.0867 - val_accuracy: 0.3231\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2745 - accuracy: 0.6683 - val_loss: 9.0974 - val_accuracy: 0.3068\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2881 - accuracy: 0.6687 - val_loss: 11.7490 - val_accuracy: 0.3025\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2865 - accuracy: 0.6720 - val_loss: 11.1589 - val_accuracy: 0.3060\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3344 - accuracy: 0.6663 - val_loss: 10.6625 - val_accuracy: 0.3132\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3557 - accuracy: 0.6633 - val_loss: 10.4634 - val_accuracy: 0.2807\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2651 - accuracy: 0.6724 - val_loss: 9.7841 - val_accuracy: 0.2792\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2655 - accuracy: 0.6765 - val_loss: 11.5210 - val_accuracy: 0.2668\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2899 - accuracy: 0.6721 - val_loss: 10.5426 - val_accuracy: 0.3140\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3279 - accuracy: 0.6729 - val_loss: 11.0570 - val_accuracy: 0.3138\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2519 - accuracy: 0.6719 - val_loss: 10.7531 - val_accuracy: 0.2925\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.2659 - accuracy: 0.6685 - val_loss: 11.6219 - val_accuracy: 0.3007\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2434 - accuracy: 0.6715 - val_loss: 11.3435 - val_accuracy: 0.3055\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.2308 - accuracy: 0.6729 - val_loss: 11.6200 - val_accuracy: 0.3057\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2670 - accuracy: 0.6732 - val_loss: 9.5770 - val_accuracy: 0.3086\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.2475 - accuracy: 0.6720 - val_loss: 9.8803 - val_accuracy: 0.3172\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2301 - accuracy: 0.6725 - val_loss: 11.8121 - val_accuracy: 0.3003\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2256 - accuracy: 0.6759 - val_loss: 11.3344 - val_accuracy: 0.3153\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.3373 - accuracy: 0.6669 - val_loss: 11.7135 - val_accuracy: 0.2468\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2908 - accuracy: 0.6760 - val_loss: 10.1267 - val_accuracy: 0.3038\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2358 - accuracy: 0.6742 - val_loss: 11.0083 - val_accuracy: 0.2980\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2770 - accuracy: 0.6709 - val_loss: 10.3234 - val_accuracy: 0.3078\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2472 - accuracy: 0.6716 - val_loss: 9.8643 - val_accuracy: 0.2736\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2090 - accuracy: 0.6789 - val_loss: 10.3239 - val_accuracy: 0.2815\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2795 - accuracy: 0.6677 - val_loss: 9.4177 - val_accuracy: 0.2799\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.2916 - accuracy: 0.6671 - val_loss: 9.4835 - val_accuracy: 0.2509\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.2814 - accuracy: 0.6681 - val_loss: 9.7168 - val_accuracy: 0.2455\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.2714 - accuracy: 0.6729 - val_loss: 9.6299 - val_accuracy: 0.2680\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2033 - accuracy: 0.6755 - val_loss: 10.0133 - val_accuracy: 0.2717\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2247 - accuracy: 0.6767 - val_loss: 10.7310 - val_accuracy: 0.2230\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2520 - accuracy: 0.6744 - val_loss: 11.2034 - val_accuracy: 0.2305\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3440 - accuracy: 0.6674 - val_loss: 10.3051 - val_accuracy: 0.2605\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2519 - accuracy: 0.6776 - val_loss: 8.9289 - val_accuracy: 0.2971\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2160 - accuracy: 0.6745 - val_loss: 11.3490 - val_accuracy: 0.2160\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2067 - accuracy: 0.6746 - val_loss: 12.0015 - val_accuracy: 0.2519\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1927 - accuracy: 0.6773 - val_loss: 9.8997 - val_accuracy: 0.2565\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.2919 - accuracy: 0.6723 - val_loss: 9.5684 - val_accuracy: 0.2402\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2157 - accuracy: 0.6777 - val_loss: 11.9445 - val_accuracy: 0.1792\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1915 - accuracy: 0.6811 - val_loss: 9.8898 - val_accuracy: 0.2071\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2598 - accuracy: 0.6721 - val_loss: 12.0419 - val_accuracy: 0.2725\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2692 - accuracy: 0.6731 - val_loss: 11.9532 - val_accuracy: 0.1983\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2111 - accuracy: 0.6747 - val_loss: 10.4323 - val_accuracy: 0.2003\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2107 - accuracy: 0.6735 - val_loss: 10.3202 - val_accuracy: 0.2462\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.2231 - accuracy: 0.6768 - val_loss: 10.4832 - val_accuracy: 0.2390\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1716 - accuracy: 0.6794 - val_loss: 12.0829 - val_accuracy: 0.1643\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2126 - accuracy: 0.6798 - val_loss: 14.2880 - val_accuracy: 0.1625\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2526 - accuracy: 0.6749 - val_loss: 11.9845 - val_accuracy: 0.1587\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2260 - accuracy: 0.6777 - val_loss: 12.7057 - val_accuracy: 0.1629\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1359 - accuracy: 0.6818 - val_loss: 11.7852 - val_accuracy: 0.1597\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2319 - accuracy: 0.6794 - val_loss: 11.2496 - val_accuracy: 0.1555\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2120 - accuracy: 0.6782 - val_loss: 11.6145 - val_accuracy: 0.1608\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2069 - accuracy: 0.6788 - val_loss: 13.1628 - val_accuracy: 0.1633\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2109 - accuracy: 0.6748 - val_loss: 10.4279 - val_accuracy: 0.2008\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2590 - accuracy: 0.6753 - val_loss: 11.2631 - val_accuracy: 0.1841\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2012 - accuracy: 0.6801 - val_loss: 10.9599 - val_accuracy: 0.1598\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.2153 - accuracy: 0.6754 - val_loss: 11.5380 - val_accuracy: 0.1663\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2078 - accuracy: 0.6821 - val_loss: 11.9076 - val_accuracy: 0.1342\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.2356 - accuracy: 0.6715 - val_loss: 9.9532 - val_accuracy: 0.1519\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2329 - accuracy: 0.6743 - val_loss: 10.8980 - val_accuracy: 0.1664\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1657 - accuracy: 0.6795 - val_loss: 11.0531 - val_accuracy: 0.1534\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1673 - accuracy: 0.6782 - val_loss: 10.7681 - val_accuracy: 0.1467\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.1696 - accuracy: 0.6832 - val_loss: 11.6884 - val_accuracy: 0.1407\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.2733 - accuracy: 0.6741 - val_loss: 12.7192 - val_accuracy: 0.1406\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.2190 - accuracy: 0.6754 - val_loss: 12.2236 - val_accuracy: 0.1517\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2342 - accuracy: 0.6795 - val_loss: 12.7767 - val_accuracy: 0.1310\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2314 - accuracy: 0.6782 - val_loss: 11.3093 - val_accuracy: 0.1410\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1921 - accuracy: 0.6727 - val_loss: 11.1055 - val_accuracy: 0.1407\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2101 - accuracy: 0.6765 - val_loss: 11.1241 - val_accuracy: 0.1467\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.1793 - accuracy: 0.6827 - val_loss: 10.2880 - val_accuracy: 0.1560\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2080 - accuracy: 0.6731 - val_loss: 11.2429 - val_accuracy: 0.1410\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.1562 - accuracy: 0.6798 - val_loss: 10.4180 - val_accuracy: 0.1475\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2142 - accuracy: 0.6730 - val_loss: 9.8290 - val_accuracy: 0.1461\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.1882 - accuracy: 0.6830 - val_loss: 12.3862 - val_accuracy: 0.1464\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1637 - accuracy: 0.6825 - val_loss: 11.2204 - val_accuracy: 0.1480\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1645 - accuracy: 0.6787 - val_loss: 13.1357 - val_accuracy: 0.1686\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1600 - accuracy: 0.6768 - val_loss: 10.4962 - val_accuracy: 0.1649\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1742 - accuracy: 0.6794 - val_loss: 11.9947 - val_accuracy: 0.1432\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1259 - accuracy: 0.6807 - val_loss: 10.4274 - val_accuracy: 0.1445\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1751 - accuracy: 0.6820 - val_loss: 12.9726 - val_accuracy: 0.1463\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1336 - accuracy: 0.6878 - val_loss: 11.1855 - val_accuracy: 0.1454\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1175 - accuracy: 0.6877 - val_loss: 10.8154 - val_accuracy: 0.1484\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.1672 - accuracy: 0.6787 - val_loss: 10.7888 - val_accuracy: 0.1705\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1513 - accuracy: 0.6830 - val_loss: 10.8778 - val_accuracy: 0.1610\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.1629 - accuracy: 0.6798 - val_loss: 11.4729 - val_accuracy: 0.1545\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1729 - accuracy: 0.6795 - val_loss: 11.6800 - val_accuracy: 0.1608\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1226 - accuracy: 0.6798 - val_loss: 11.4363 - val_accuracy: 0.1737\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.1321 - accuracy: 0.6840 - val_loss: 10.5130 - val_accuracy: 0.1689\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.1480 - accuracy: 0.6848 - val_loss: 12.2429 - val_accuracy: 0.1632\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.1941 - accuracy: 0.6805 - val_loss: 11.4655 - val_accuracy: 0.1698\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1834 - accuracy: 0.6803 - val_loss: 10.2983 - val_accuracy: 0.1780\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1082 - accuracy: 0.6828 - val_loss: 9.8702 - val_accuracy: 0.1874\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0976 - accuracy: 0.6858 - val_loss: 11.3489 - val_accuracy: 0.1396\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1168 - accuracy: 0.6858 - val_loss: 12.9308 - val_accuracy: 0.1440\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1289 - accuracy: 0.6826 - val_loss: 11.2236 - val_accuracy: 0.1399\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0716 - accuracy: 0.6881 - val_loss: 10.6364 - val_accuracy: 0.1307\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1615 - accuracy: 0.6861 - val_loss: 10.8618 - val_accuracy: 0.1260\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1536 - accuracy: 0.6856 - val_loss: 11.4979 - val_accuracy: 0.1315\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0857 - accuracy: 0.6864 - val_loss: 10.9030 - val_accuracy: 0.1320\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1333 - accuracy: 0.6844 - val_loss: 10.2747 - val_accuracy: 0.1246\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1436 - accuracy: 0.6815 - val_loss: 11.2451 - val_accuracy: 0.1187\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1018 - accuracy: 0.6917 - val_loss: 9.1627 - val_accuracy: 0.1330\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.1564 - accuracy: 0.6831 - val_loss: 13.7718 - val_accuracy: 0.1232\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1776 - accuracy: 0.6798 - val_loss: 10.6556 - val_accuracy: 0.1362\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1482 - accuracy: 0.6820 - val_loss: 12.3354 - val_accuracy: 0.1379\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1018 - accuracy: 0.6853 - val_loss: 11.1770 - val_accuracy: 0.1310\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0755 - accuracy: 0.6871 - val_loss: 12.9248 - val_accuracy: 0.1206\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0982 - accuracy: 0.6900 - val_loss: 12.0785 - val_accuracy: 0.1280\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1692 - accuracy: 0.6831 - val_loss: 11.1981 - val_accuracy: 0.1217\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1894 - accuracy: 0.6859 - val_loss: 12.1184 - val_accuracy: 0.1258\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.1202 - accuracy: 0.6847 - val_loss: 11.8280 - val_accuracy: 0.1190\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1075 - accuracy: 0.6840 - val_loss: 11.7949 - val_accuracy: 0.1244\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1176 - accuracy: 0.6833 - val_loss: 15.0799 - val_accuracy: 0.1322\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0750 - accuracy: 0.6891 - val_loss: 9.8117 - val_accuracy: 0.1425\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0907 - accuracy: 0.6871 - val_loss: 10.7189 - val_accuracy: 0.1234\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0993 - accuracy: 0.6941 - val_loss: 10.9617 - val_accuracy: 0.1268\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1038 - accuracy: 0.6850 - val_loss: 10.5723 - val_accuracy: 0.1206\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 4s 253ms/step - loss: 1.1913 - accuracy: 0.6816 - val_loss: 12.6674 - val_accuracy: 0.1179\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.1041 - accuracy: 0.6846 - val_loss: 16.8912 - val_accuracy: 0.1136\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.0575 - accuracy: 0.6860 - val_loss: 11.7521 - val_accuracy: 0.1111\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0730 - accuracy: 0.6893 - val_loss: 9.8821 - val_accuracy: 0.1156\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0482 - accuracy: 0.6904 - val_loss: 11.7249 - val_accuracy: 0.1137\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1533 - accuracy: 0.6823 - val_loss: 12.0547 - val_accuracy: 0.1122\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1628 - accuracy: 0.6815 - val_loss: 12.2038 - val_accuracy: 0.1080\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1308 - accuracy: 0.6847 - val_loss: 13.3346 - val_accuracy: 0.1136\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1122 - accuracy: 0.6883 - val_loss: 12.2114 - val_accuracy: 0.1093\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0935 - accuracy: 0.6875 - val_loss: 12.5558 - val_accuracy: 0.1095\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1173 - accuracy: 0.6868 - val_loss: 11.3374 - val_accuracy: 0.1147\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0582 - accuracy: 0.6897 - val_loss: 12.4178 - val_accuracy: 0.1156\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0948 - accuracy: 0.6877 - val_loss: 12.0842 - val_accuracy: 0.1129\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1072 - accuracy: 0.6841 - val_loss: 13.5007 - val_accuracy: 0.1101\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1282 - accuracy: 0.6866 - val_loss: 15.8352 - val_accuracy: 0.1098\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0919 - accuracy: 0.6892 - val_loss: 13.2160 - val_accuracy: 0.1129\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.0794 - accuracy: 0.6844 - val_loss: 14.5711 - val_accuracy: 0.1076\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0839 - accuracy: 0.6907 - val_loss: 16.0863 - val_accuracy: 0.1080\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.1014 - accuracy: 0.6871 - val_loss: 13.9488 - val_accuracy: 0.1033\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0588 - accuracy: 0.6941 - val_loss: 14.4294 - val_accuracy: 0.0988\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.0838 - accuracy: 0.6835 - val_loss: 12.3771 - val_accuracy: 0.1112\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.0790 - accuracy: 0.6890 - val_loss: 14.0412 - val_accuracy: 0.1056\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0946 - accuracy: 0.6909 - val_loss: 13.7969 - val_accuracy: 0.1079\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0884 - accuracy: 0.6923 - val_loss: 12.4029 - val_accuracy: 0.1092\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0795 - accuracy: 0.6923 - val_loss: 13.0974 - val_accuracy: 0.1096\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0904 - accuracy: 0.6886 - val_loss: 12.0956 - val_accuracy: 0.1112\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0981 - accuracy: 0.6843 - val_loss: 12.3608 - val_accuracy: 0.1053\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0270 - accuracy: 0.6924 - val_loss: 13.1105 - val_accuracy: 0.1053\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0538 - accuracy: 0.6881 - val_loss: 10.9684 - val_accuracy: 0.1122\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2076 - accuracy: 0.6780 - val_loss: 11.9698 - val_accuracy: 0.1149\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.1676 - accuracy: 0.6848 - val_loss: 17.0727 - val_accuracy: 0.1074\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.1373 - accuracy: 0.6839 - val_loss: 13.2486 - val_accuracy: 0.1128\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0725 - accuracy: 0.6869 - val_loss: 13.1286 - val_accuracy: 0.1135\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0958 - accuracy: 0.6841 - val_loss: 14.8231 - val_accuracy: 0.1152\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0824 - accuracy: 0.6837 - val_loss: 12.3142 - val_accuracy: 0.1135\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.1119 - accuracy: 0.6897 - val_loss: 12.9213 - val_accuracy: 0.1136\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.1020 - accuracy: 0.6883 - val_loss: 13.9474 - val_accuracy: 0.1146\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0565 - accuracy: 0.6899 - val_loss: 13.4740 - val_accuracy: 0.1128\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.0559 - accuracy: 0.6905 - val_loss: 14.2310 - val_accuracy: 0.1110\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0970 - accuracy: 0.6918 - val_loss: 13.4629 - val_accuracy: 0.1120\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0213 - accuracy: 0.6921 - val_loss: 15.5581 - val_accuracy: 0.1069\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1031 - accuracy: 0.6939 - val_loss: 13.4029 - val_accuracy: 0.1083\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1015 - accuracy: 0.6906 - val_loss: 13.8204 - val_accuracy: 0.1101\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0636 - accuracy: 0.6902 - val_loss: 13.6144 - val_accuracy: 0.1103\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0601 - accuracy: 0.6919 - val_loss: 14.8092 - val_accuracy: 0.1064\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0330 - accuracy: 0.6937 - val_loss: 14.3059 - val_accuracy: 0.1149\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0817 - accuracy: 0.6897 - val_loss: 12.7106 - val_accuracy: 0.1096\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0233 - accuracy: 0.6927 - val_loss: 12.9610 - val_accuracy: 0.1095\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0166 - accuracy: 0.6962 - val_loss: 13.1724 - val_accuracy: 0.1084\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0359 - accuracy: 0.6926 - val_loss: 12.5112 - val_accuracy: 0.1092\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0135 - accuracy: 0.6946 - val_loss: 13.1990 - val_accuracy: 0.1080\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0263 - accuracy: 0.6960 - val_loss: 13.2747 - val_accuracy: 0.1107\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9802 - accuracy: 0.6917 - val_loss: 15.9623 - val_accuracy: 0.1084\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0072 - accuracy: 0.6961 - val_loss: 12.8862 - val_accuracy: 0.1109\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0131 - accuracy: 0.6948 - val_loss: 13.3994 - val_accuracy: 0.1097\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0687 - accuracy: 0.6959 - val_loss: 12.2062 - val_accuracy: 0.1087\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0172 - accuracy: 0.6946 - val_loss: 10.9433 - val_accuracy: 0.1136\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9910 - accuracy: 0.6970 - val_loss: 12.3264 - val_accuracy: 0.1095\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0430 - accuracy: 0.6926 - val_loss: 11.6478 - val_accuracy: 0.1113\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0619 - accuracy: 0.6959 - val_loss: 12.9312 - val_accuracy: 0.1113\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0139 - accuracy: 0.6921 - val_loss: 13.5683 - val_accuracy: 0.1126\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9921 - accuracy: 0.6976 - val_loss: 13.2421 - val_accuracy: 0.1105\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9782 - accuracy: 0.6975 - val_loss: 15.0253 - val_accuracy: 0.1046\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0381 - accuracy: 0.6906 - val_loss: 12.4803 - val_accuracy: 0.1099\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1036 - accuracy: 0.6890 - val_loss: 12.3860 - val_accuracy: 0.1108\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0745 - accuracy: 0.6863 - val_loss: 11.4779 - val_accuracy: 0.1148\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.0587 - accuracy: 0.6947 - val_loss: 14.1515 - val_accuracy: 0.1092\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0085 - accuracy: 0.6925 - val_loss: 14.1090 - val_accuracy: 0.1106\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.0731 - accuracy: 0.6893 - val_loss: 12.8378 - val_accuracy: 0.1118\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0178 - accuracy: 0.6937 - val_loss: 13.2306 - val_accuracy: 0.1071\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9492 - accuracy: 0.7010 - val_loss: 12.8148 - val_accuracy: 0.1058\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9589 - accuracy: 0.6974 - val_loss: 13.6200 - val_accuracy: 0.1057\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9808 - accuracy: 0.6980 - val_loss: 15.0051 - val_accuracy: 0.1056\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0247 - accuracy: 0.6929 - val_loss: 14.4123 - val_accuracy: 0.1046\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0196 - accuracy: 0.6933 - val_loss: 12.5748 - val_accuracy: 0.1041\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9781 - accuracy: 0.6961 - val_loss: 15.2250 - val_accuracy: 0.1087\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0017 - accuracy: 0.6931 - val_loss: 12.8101 - val_accuracy: 0.1107\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0080 - accuracy: 0.6915 - val_loss: 12.6302 - val_accuracy: 0.1079\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9693 - accuracy: 0.6966 - val_loss: 15.4374 - val_accuracy: 0.1073\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9734 - accuracy: 0.6983 - val_loss: 13.2201 - val_accuracy: 0.1086\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0965 - accuracy: 0.6888 - val_loss: 13.8278 - val_accuracy: 0.1085\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0482 - accuracy: 0.6919 - val_loss: 13.1438 - val_accuracy: 0.1089\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0008 - accuracy: 0.6960 - val_loss: 12.5758 - val_accuracy: 0.1097\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0533 - accuracy: 0.6972 - val_loss: 12.2856 - val_accuracy: 0.1083\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0519 - accuracy: 0.6898 - val_loss: 14.5429 - val_accuracy: 0.1120\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0001 - accuracy: 0.6934 - val_loss: 14.2453 - val_accuracy: 0.1105\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9392 - accuracy: 0.7031 - val_loss: 14.4656 - val_accuracy: 0.1089\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9553 - accuracy: 0.7041 - val_loss: 14.1285 - val_accuracy: 0.1086\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.0481 - accuracy: 0.6904 - val_loss: 12.6003 - val_accuracy: 0.1090\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0016 - accuracy: 0.6970 - val_loss: 13.7488 - val_accuracy: 0.1061\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9831 - accuracy: 0.6934 - val_loss: 14.4027 - val_accuracy: 0.1068\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0151 - accuracy: 0.6906 - val_loss: 12.2331 - val_accuracy: 0.1055\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9646 - accuracy: 0.7009 - val_loss: 14.8010 - val_accuracy: 0.1007\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0120 - accuracy: 0.6999 - val_loss: 11.6367 - val_accuracy: 0.1064\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9948 - accuracy: 0.6998 - val_loss: 12.9897 - val_accuracy: 0.1057\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9726 - accuracy: 0.6988 - val_loss: 13.6865 - val_accuracy: 0.1036\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9797 - accuracy: 0.6966 - val_loss: 12.3538 - val_accuracy: 0.1064\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0374 - accuracy: 0.6951 - val_loss: 14.1742 - val_accuracy: 0.1072\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9735 - accuracy: 0.6984 - val_loss: 11.9903 - val_accuracy: 0.1045\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9736 - accuracy: 0.6986 - val_loss: 11.3123 - val_accuracy: 0.1100\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9870 - accuracy: 0.6976 - val_loss: 14.1066 - val_accuracy: 0.1077\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0045 - accuracy: 0.6980 - val_loss: 12.8409 - val_accuracy: 0.1052\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.0256 - accuracy: 0.6994 - val_loss: 14.5655 - val_accuracy: 0.1052\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.9726 - accuracy: 0.6976 - val_loss: 12.1596 - val_accuracy: 0.1036\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9548 - accuracy: 0.7012 - val_loss: 17.0589 - val_accuracy: 0.1039\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9323 - accuracy: 0.6997 - val_loss: 12.1030 - val_accuracy: 0.1065\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0539 - accuracy: 0.6938 - val_loss: 11.6639 - val_accuracy: 0.1053\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0182 - accuracy: 0.6972 - val_loss: 14.0286 - val_accuracy: 0.1063\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9642 - accuracy: 0.6981 - val_loss: 11.9018 - val_accuracy: 0.1043\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0032 - accuracy: 0.6982 - val_loss: 12.3319 - val_accuracy: 0.1094\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0304 - accuracy: 0.6969 - val_loss: 12.6728 - val_accuracy: 0.1016\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9612 - accuracy: 0.6954 - val_loss: 12.6972 - val_accuracy: 0.1037\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9190 - accuracy: 0.7033 - val_loss: 13.4975 - val_accuracy: 0.1075\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9742 - accuracy: 0.6995 - val_loss: 11.3944 - val_accuracy: 0.1094\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9912 - accuracy: 0.6959 - val_loss: 10.9709 - val_accuracy: 0.1042\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0148 - accuracy: 0.6990 - val_loss: 12.5246 - val_accuracy: 0.1042\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9864 - accuracy: 0.6937 - val_loss: 11.9221 - val_accuracy: 0.1046\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9619 - accuracy: 0.6999 - val_loss: 12.1030 - val_accuracy: 0.1005\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9744 - accuracy: 0.7012 - val_loss: 12.0573 - val_accuracy: 0.1038\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9373 - accuracy: 0.7009 - val_loss: 12.6545 - val_accuracy: 0.1052\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9418 - accuracy: 0.7015 - val_loss: 11.6482 - val_accuracy: 0.1052\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0288 - accuracy: 0.6985 - val_loss: 12.4356 - val_accuracy: 0.1027\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0050 - accuracy: 0.6972 - val_loss: 13.5230 - val_accuracy: 0.1064\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9576 - accuracy: 0.6940 - val_loss: 12.0023 - val_accuracy: 0.1051\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9487 - accuracy: 0.7055 - val_loss: 13.6359 - val_accuracy: 0.1035\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9259 - accuracy: 0.7070 - val_loss: 11.4885 - val_accuracy: 0.1052\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9746 - accuracy: 0.7001 - val_loss: 13.1229 - val_accuracy: 0.1007\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9771 - accuracy: 0.6993 - val_loss: 11.9173 - val_accuracy: 0.1035\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9810 - accuracy: 0.6973 - val_loss: 13.7784 - val_accuracy: 0.1054\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9701 - accuracy: 0.6990 - val_loss: 14.9661 - val_accuracy: 0.1060\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9502 - accuracy: 0.7005 - val_loss: 13.2116 - val_accuracy: 0.1050\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9376 - accuracy: 0.6983 - val_loss: 13.5685 - val_accuracy: 0.1061\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9629 - accuracy: 0.7036 - val_loss: 11.8934 - val_accuracy: 0.1093\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9775 - accuracy: 0.7025 - val_loss: 13.4022 - val_accuracy: 0.1041\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9638 - accuracy: 0.7069 - val_loss: 13.1113 - val_accuracy: 0.1048\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.9833 - accuracy: 0.7002 - val_loss: 11.8508 - val_accuracy: 0.1048\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9873 - accuracy: 0.6978 - val_loss: 12.8805 - val_accuracy: 0.1044\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9098 - accuracy: 0.7005 - val_loss: 12.0018 - val_accuracy: 0.1078\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8834 - accuracy: 0.7029 - val_loss: 12.1895 - val_accuracy: 0.1063\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8633 - accuracy: 0.7080 - val_loss: 12.1994 - val_accuracy: 0.1037\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8968 - accuracy: 0.7056 - val_loss: 13.4222 - val_accuracy: 0.1046\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9289 - accuracy: 0.7029 - val_loss: 13.8402 - val_accuracy: 0.1065\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0325 - accuracy: 0.6999 - val_loss: 12.4297 - val_accuracy: 0.1023\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0179 - accuracy: 0.6983 - val_loss: 12.0033 - val_accuracy: 0.1043\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9344 - accuracy: 0.7033 - val_loss: 14.7255 - val_accuracy: 0.1052\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9439 - accuracy: 0.7038 - val_loss: 12.7588 - val_accuracy: 0.1046\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9185 - accuracy: 0.7038 - val_loss: 11.9289 - val_accuracy: 0.1042\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9110 - accuracy: 0.7017 - val_loss: 13.0895 - val_accuracy: 0.1059\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8841 - accuracy: 0.7042 - val_loss: 12.9384 - val_accuracy: 0.1031\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.9081 - accuracy: 0.7035 - val_loss: 13.5797 - val_accuracy: 0.1049\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 0.9000 - accuracy: 0.7026 - val_loss: 11.5615 - val_accuracy: 0.1059\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.9115 - accuracy: 0.7048 - val_loss: 13.5620 - val_accuracy: 0.1045\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9240 - accuracy: 0.7002 - val_loss: 12.1272 - val_accuracy: 0.1053\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9021 - accuracy: 0.7039 - val_loss: 12.2225 - val_accuracy: 0.1046\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9096 - accuracy: 0.7069 - val_loss: 11.8984 - val_accuracy: 0.1077\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9046 - accuracy: 0.7047 - val_loss: 11.9764 - val_accuracy: 0.1034\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9800 - accuracy: 0.7005 - val_loss: 11.8794 - val_accuracy: 0.1041\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.8999 - accuracy: 0.7029 - val_loss: 10.9258 - val_accuracy: 0.1043\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9496 - accuracy: 0.7079 - val_loss: 11.3338 - val_accuracy: 0.1060\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9388 - accuracy: 0.7019 - val_loss: 11.6855 - val_accuracy: 0.1081\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8750 - accuracy: 0.7081 - val_loss: 12.4506 - val_accuracy: 0.1040\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9214 - accuracy: 0.7051 - val_loss: 11.5495 - val_accuracy: 0.1071\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8655 - accuracy: 0.7053 - val_loss: 13.2058 - val_accuracy: 0.1055\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8692 - accuracy: 0.7057 - val_loss: 11.5682 - val_accuracy: 0.1050\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9056 - accuracy: 0.7067 - val_loss: 13.9014 - val_accuracy: 0.1057\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9285 - accuracy: 0.7056 - val_loss: 13.0365 - val_accuracy: 0.1064\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9531 - accuracy: 0.7016 - val_loss: 12.7087 - val_accuracy: 0.1043\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9558 - accuracy: 0.7045 - val_loss: 11.9908 - val_accuracy: 0.1076\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9855 - accuracy: 0.7045 - val_loss: 12.6427 - val_accuracy: 0.1030\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9031 - accuracy: 0.7043 - val_loss: 11.9438 - val_accuracy: 0.1049\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8590 - accuracy: 0.7106 - val_loss: 12.9568 - val_accuracy: 0.1047\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9680 - accuracy: 0.7072 - val_loss: 12.4704 - val_accuracy: 0.1075\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9694 - accuracy: 0.6975 - val_loss: 11.3601 - val_accuracy: 0.1040\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8793 - accuracy: 0.7072 - val_loss: 11.8020 - val_accuracy: 0.1048\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8991 - accuracy: 0.7063 - val_loss: 11.3884 - val_accuracy: 0.1086\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8822 - accuracy: 0.7080 - val_loss: 12.8413 - val_accuracy: 0.1064\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8189 - accuracy: 0.7113 - val_loss: 13.6587 - val_accuracy: 0.1043\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8530 - accuracy: 0.7079 - val_loss: 12.2260 - val_accuracy: 0.1050\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9111 - accuracy: 0.7013 - val_loss: 13.6795 - val_accuracy: 0.1074\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8622 - accuracy: 0.7080 - val_loss: 11.9791 - val_accuracy: 0.1046\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9158 - accuracy: 0.7071 - val_loss: 12.5775 - val_accuracy: 0.1039\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9528 - accuracy: 0.7013 - val_loss: 11.8646 - val_accuracy: 0.1048\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9083 - accuracy: 0.7060 - val_loss: 12.4094 - val_accuracy: 0.1024\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9391 - accuracy: 0.7042 - val_loss: 12.9538 - val_accuracy: 0.1036\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.9215 - accuracy: 0.7036 - val_loss: 12.3228 - val_accuracy: 0.1045\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9431 - accuracy: 0.7059 - val_loss: 11.0616 - val_accuracy: 0.1069\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9429 - accuracy: 0.7027 - val_loss: 12.9194 - val_accuracy: 0.1061\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9738 - accuracy: 0.7000 - val_loss: 11.6054 - val_accuracy: 0.1044\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9816 - accuracy: 0.7022 - val_loss: 12.6050 - val_accuracy: 0.1074\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9300 - accuracy: 0.7053 - val_loss: 13.4911 - val_accuracy: 0.1069\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9173 - accuracy: 0.7024 - val_loss: 11.8955 - val_accuracy: 0.1076\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9449 - accuracy: 0.7057 - val_loss: 13.8070 - val_accuracy: 0.1036\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8963 - accuracy: 0.7126 - val_loss: 13.3317 - val_accuracy: 0.1036\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9046 - accuracy: 0.7133 - val_loss: 11.8985 - val_accuracy: 0.1086\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.9275 - accuracy: 0.7043 - val_loss: 13.7074 - val_accuracy: 0.1055\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8987 - accuracy: 0.7037 - val_loss: 13.8005 - val_accuracy: 0.1060\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8725 - accuracy: 0.7058 - val_loss: 11.9850 - val_accuracy: 0.1061\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8799 - accuracy: 0.7106 - val_loss: 12.3575 - val_accuracy: 0.1008\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8886 - accuracy: 0.7087 - val_loss: 13.5763 - val_accuracy: 0.1029\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8621 - accuracy: 0.7094 - val_loss: 14.2565 - val_accuracy: 0.1047\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8781 - accuracy: 0.7092 - val_loss: 14.1246 - val_accuracy: 0.1016\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8491 - accuracy: 0.7040 - val_loss: 11.6144 - val_accuracy: 0.1008\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8022 - accuracy: 0.7098 - val_loss: 13.0779 - val_accuracy: 0.1055\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8252 - accuracy: 0.7108 - val_loss: 12.2281 - val_accuracy: 0.1034\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8689 - accuracy: 0.7065 - val_loss: 10.8007 - val_accuracy: 0.1040\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8719 - accuracy: 0.7100 - val_loss: 12.2813 - val_accuracy: 0.1059\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8507 - accuracy: 0.7116 - val_loss: 12.0300 - val_accuracy: 0.1054\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8318 - accuracy: 0.7093 - val_loss: 15.0000 - val_accuracy: 0.1046\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8170 - accuracy: 0.7075 - val_loss: 13.7227 - val_accuracy: 0.1015\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7946 - accuracy: 0.7129 - val_loss: 12.5613 - val_accuracy: 0.1070\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8434 - accuracy: 0.7067 - val_loss: 13.9228 - val_accuracy: 0.1048\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8986 - accuracy: 0.7076 - val_loss: 12.0745 - val_accuracy: 0.1041\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8916 - accuracy: 0.7092 - val_loss: 12.2549 - val_accuracy: 0.1033\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8023 - accuracy: 0.7119 - val_loss: 13.7234 - val_accuracy: 0.1038\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8269 - accuracy: 0.7167 - val_loss: 11.2834 - val_accuracy: 0.1035\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8861 - accuracy: 0.7119 - val_loss: 14.0488 - val_accuracy: 0.1026\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8826 - accuracy: 0.7050 - val_loss: 13.0548 - val_accuracy: 0.1027\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8615 - accuracy: 0.7078 - val_loss: 14.0972 - val_accuracy: 0.1025\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9213 - accuracy: 0.7086 - val_loss: 12.3151 - val_accuracy: 0.1030\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.9642 - accuracy: 0.7018 - val_loss: 13.1624 - val_accuracy: 0.1027\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9328 - accuracy: 0.7065 - val_loss: 13.3706 - val_accuracy: 0.1026\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8021 - accuracy: 0.7146 - val_loss: 12.1532 - val_accuracy: 0.1032\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8057 - accuracy: 0.7159 - val_loss: 11.5805 - val_accuracy: 0.1058\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8346 - accuracy: 0.7174 - val_loss: 12.0005 - val_accuracy: 0.1032\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8210 - accuracy: 0.7110 - val_loss: 12.8397 - val_accuracy: 0.0998\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7991 - accuracy: 0.7150 - val_loss: 12.6531 - val_accuracy: 0.1024\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8694 - accuracy: 0.7093 - val_loss: 11.2183 - val_accuracy: 0.1017\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8351 - accuracy: 0.7154 - val_loss: 12.9277 - val_accuracy: 0.1008\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8722 - accuracy: 0.7061 - val_loss: 14.0188 - val_accuracy: 0.1029\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8393 - accuracy: 0.7136 - val_loss: 12.0229 - val_accuracy: 0.1023\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8264 - accuracy: 0.7115 - val_loss: 11.7258 - val_accuracy: 0.1043\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8732 - accuracy: 0.7128 - val_loss: 11.6450 - val_accuracy: 0.1016\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.9324 - accuracy: 0.7075 - val_loss: 12.0614 - val_accuracy: 0.1046\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.8941 - accuracy: 0.7061 - val_loss: 11.2327 - val_accuracy: 0.1053\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 0.8823 - accuracy: 0.7074 - val_loss: 11.8915 - val_accuracy: 0.1046\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9495 - accuracy: 0.7085 - val_loss: 13.1256 - val_accuracy: 0.1021\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0042 - accuracy: 0.7030 - val_loss: 11.5817 - val_accuracy: 0.1022\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9442 - accuracy: 0.7059 - val_loss: 12.4446 - val_accuracy: 0.1012\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8154 - accuracy: 0.7104 - val_loss: 12.9933 - val_accuracy: 0.1019\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8567 - accuracy: 0.7125 - val_loss: 14.1679 - val_accuracy: 0.0981\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8275 - accuracy: 0.7138 - val_loss: 11.4282 - val_accuracy: 0.1033\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8680 - accuracy: 0.7083 - val_loss: 12.9376 - val_accuracy: 0.1046\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8533 - accuracy: 0.7127 - val_loss: 12.0266 - val_accuracy: 0.1017\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8507 - accuracy: 0.7072 - val_loss: 12.5226 - val_accuracy: 0.0982\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7626 - accuracy: 0.7186 - val_loss: 12.7659 - val_accuracy: 0.1007\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8098 - accuracy: 0.7128 - val_loss: 12.5840 - val_accuracy: 0.1038\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8475 - accuracy: 0.7139 - val_loss: 13.6701 - val_accuracy: 0.1003\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8024 - accuracy: 0.7067 - val_loss: 12.8228 - val_accuracy: 0.0998\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8505 - accuracy: 0.7125 - val_loss: 12.7437 - val_accuracy: 0.1019\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8987 - accuracy: 0.7096 - val_loss: 12.2137 - val_accuracy: 0.1015\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8138 - accuracy: 0.7130 - val_loss: 13.4727 - val_accuracy: 0.1007\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7749 - accuracy: 0.7146 - val_loss: 13.0375 - val_accuracy: 0.0998\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7886 - accuracy: 0.7152 - val_loss: 13.5170 - val_accuracy: 0.1000\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7810 - accuracy: 0.7219 - val_loss: 12.2461 - val_accuracy: 0.1025\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8078 - accuracy: 0.7104 - val_loss: 12.5708 - val_accuracy: 0.1014\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8720 - accuracy: 0.7141 - val_loss: 11.9150 - val_accuracy: 0.1007\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8489 - accuracy: 0.7154 - val_loss: 11.2242 - val_accuracy: 0.1053\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8281 - accuracy: 0.7107 - val_loss: 13.4857 - val_accuracy: 0.1074\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.8402 - accuracy: 0.7180 - val_loss: 12.3313 - val_accuracy: 0.1017\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9636 - accuracy: 0.7066 - val_loss: 11.0878 - val_accuracy: 0.1039\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8877 - accuracy: 0.7120 - val_loss: 11.5136 - val_accuracy: 0.1027\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 4s 246ms/step - loss: 0.9449 - accuracy: 0.7087 - val_loss: 11.5576 - val_accuracy: 0.1030\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9050 - accuracy: 0.7064 - val_loss: 12.3878 - val_accuracy: 0.1007\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.8441 - accuracy: 0.7116 - val_loss: 13.7229 - val_accuracy: 0.1054\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7968 - accuracy: 0.7139 - val_loss: 12.3026 - val_accuracy: 0.1045\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.7646 - accuracy: 0.7226 - val_loss: 12.8631 - val_accuracy: 0.1037\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8248 - accuracy: 0.7162 - val_loss: 12.8021 - val_accuracy: 0.1022\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8660 - accuracy: 0.7089 - val_loss: 11.7630 - val_accuracy: 0.1020\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8597 - accuracy: 0.7072 - val_loss: 13.6551 - val_accuracy: 0.0999\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8186 - accuracy: 0.7100 - val_loss: 14.3149 - val_accuracy: 0.1015\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0087 - accuracy: 0.7063 - val_loss: 13.2653 - val_accuracy: 0.1044\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9480 - accuracy: 0.7060 - val_loss: 12.9800 - val_accuracy: 0.1042\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8034 - accuracy: 0.7155 - val_loss: 14.3032 - val_accuracy: 0.1038\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8231 - accuracy: 0.7143 - val_loss: 12.8374 - val_accuracy: 0.1031\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8894 - accuracy: 0.7109 - val_loss: 13.3510 - val_accuracy: 0.1051\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8630 - accuracy: 0.7114 - val_loss: 11.7836 - val_accuracy: 0.1053\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7990 - accuracy: 0.7204 - val_loss: 11.7847 - val_accuracy: 0.1063\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8419 - accuracy: 0.7154 - val_loss: 12.0819 - val_accuracy: 0.1029\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8165 - accuracy: 0.7167 - val_loss: 13.1159 - val_accuracy: 0.1050\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7892 - accuracy: 0.7140 - val_loss: 12.7493 - val_accuracy: 0.1020\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8274 - accuracy: 0.7177 - val_loss: 12.0274 - val_accuracy: 0.1004\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8602 - accuracy: 0.7100 - val_loss: 10.9835 - val_accuracy: 0.1047\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7802 - accuracy: 0.7174 - val_loss: 12.1068 - val_accuracy: 0.0997\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8307 - accuracy: 0.7159 - val_loss: 11.1121 - val_accuracy: 0.1010\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8209 - accuracy: 0.7159 - val_loss: 12.0241 - val_accuracy: 0.1064\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7915 - accuracy: 0.7149 - val_loss: 13.2134 - val_accuracy: 0.1039\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7971 - accuracy: 0.7164 - val_loss: 11.9112 - val_accuracy: 0.1047\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7354 - accuracy: 0.7194 - val_loss: 13.2731 - val_accuracy: 0.1040\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7765 - accuracy: 0.7130 - val_loss: 13.3848 - val_accuracy: 0.1034\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8528 - accuracy: 0.7104 - val_loss: 13.5092 - val_accuracy: 0.1001\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7936 - accuracy: 0.7159 - val_loss: 10.8142 - val_accuracy: 0.1040\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 279ms/step - loss: 2.4557 - accuracy: 0.6121 - val_loss: 0.5018 - val_accuracy: 0.8143\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.2193 - accuracy: 0.6121 - val_loss: 0.5354 - val_accuracy: 0.8175\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0677 - accuracy: 0.6184 - val_loss: 0.5520 - val_accuracy: 0.8147\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.0084 - accuracy: 0.6178 - val_loss: 0.6448 - val_accuracy: 0.6751\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.9203 - accuracy: 0.6258 - val_loss: 0.5383 - val_accuracy: 0.7153\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.8742 - accuracy: 0.6256 - val_loss: 0.5713 - val_accuracy: 0.6870\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8261 - accuracy: 0.6251 - val_loss: 0.5195 - val_accuracy: 0.6537\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7755 - accuracy: 0.6272 - val_loss: 0.6287 - val_accuracy: 0.5283\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.7504 - accuracy: 0.6323 - val_loss: 0.4943 - val_accuracy: 0.5643\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.7526 - accuracy: 0.6309 - val_loss: 0.6205 - val_accuracy: 0.5317\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7366 - accuracy: 0.6275 - val_loss: 0.5901 - val_accuracy: 0.5187\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.7267 - accuracy: 0.6324 - val_loss: 0.6491 - val_accuracy: 0.5081\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.6888 - accuracy: 0.6287 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.7692 - accuracy: 0.6259 - val_loss: 0.9355 - val_accuracy: 0.4865\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6571 - accuracy: 0.6407 - val_loss: 0.8937 - val_accuracy: 0.5298\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.7027 - accuracy: 0.6306 - val_loss: 0.8659 - val_accuracy: 0.5223\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.7053 - accuracy: 0.6311 - val_loss: 0.8169 - val_accuracy: 0.4999\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.6633 - accuracy: 0.6351 - val_loss: 1.0474 - val_accuracy: 0.4775\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6379 - accuracy: 0.6347 - val_loss: 1.3191 - val_accuracy: 0.4632\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.6602 - accuracy: 0.6305 - val_loss: 1.3711 - val_accuracy: 0.4277\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.6034 - accuracy: 0.6332 - val_loss: 1.4182 - val_accuracy: 0.3716\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.5867 - accuracy: 0.6396 - val_loss: 4.5992 - val_accuracy: 0.2945\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6067 - accuracy: 0.6422 - val_loss: 2.6968 - val_accuracy: 0.3962\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.5882 - accuracy: 0.6396 - val_loss: 3.4314 - val_accuracy: 0.3428\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.5527 - accuracy: 0.6433 - val_loss: 11.5315 - val_accuracy: 0.2806\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.6083 - accuracy: 0.6330 - val_loss: 20.9731 - val_accuracy: 0.2536\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.6315 - accuracy: 0.6349 - val_loss: 196.3050 - val_accuracy: 0.2218\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.5620 - accuracy: 0.6397 - val_loss: 116.5178 - val_accuracy: 0.2284\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.6173 - accuracy: 0.6288 - val_loss: 275.0684 - val_accuracy: 0.2163\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5789 - accuracy: 0.6396 - val_loss: 162.6279 - val_accuracy: 0.2517\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5637 - accuracy: 0.6407 - val_loss: 16.8908 - val_accuracy: 0.2450\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5143 - accuracy: 0.6417 - val_loss: 7.6948 - val_accuracy: 0.2771\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5253 - accuracy: 0.6444 - val_loss: 13.6559 - val_accuracy: 0.2471\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.5405 - accuracy: 0.6393 - val_loss: 22.3032 - val_accuracy: 0.2348\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5366 - accuracy: 0.6409 - val_loss: 70.6125 - val_accuracy: 0.2744\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5247 - accuracy: 0.6410 - val_loss: 56.9582 - val_accuracy: 0.5101\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5105 - accuracy: 0.6452 - val_loss: 46.6689 - val_accuracy: 0.2562\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.5175 - accuracy: 0.6350 - val_loss: 29.6535 - val_accuracy: 0.2596\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5131 - accuracy: 0.6417 - val_loss: 72.9033 - val_accuracy: 0.3057\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.5581 - accuracy: 0.6427 - val_loss: 78.2975 - val_accuracy: 0.2376\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4910 - accuracy: 0.6394 - val_loss: 126.0349 - val_accuracy: 0.2525\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5499 - accuracy: 0.6407 - val_loss: 18.8169 - val_accuracy: 0.3115\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4676 - accuracy: 0.6448 - val_loss: 165.3836 - val_accuracy: 0.3167\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4632 - accuracy: 0.6445 - val_loss: 62.5530 - val_accuracy: 0.3082\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4876 - accuracy: 0.6397 - val_loss: 72.3789 - val_accuracy: 0.2463\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4501 - accuracy: 0.6449 - val_loss: 430.1825 - val_accuracy: 0.3012\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4721 - accuracy: 0.6432 - val_loss: 1277.1039 - val_accuracy: 0.3108\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4346 - accuracy: 0.6478 - val_loss: 105.5225 - val_accuracy: 0.2981\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.4058 - accuracy: 0.6481 - val_loss: 25.1878 - val_accuracy: 0.2966\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3969 - accuracy: 0.6548 - val_loss: 159.2748 - val_accuracy: 0.2850\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4414 - accuracy: 0.6519 - val_loss: 26.9677 - val_accuracy: 0.2905\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4390 - accuracy: 0.6491 - val_loss: 29.1003 - val_accuracy: 0.2681\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.4170 - accuracy: 0.6505 - val_loss: 1545.1632 - val_accuracy: 0.2428\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4194 - accuracy: 0.6478 - val_loss: 3470.0139 - val_accuracy: 0.2422\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4061 - accuracy: 0.6503 - val_loss: 4047.6038 - val_accuracy: 0.2553\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4106 - accuracy: 0.6520 - val_loss: 2824.4448 - val_accuracy: 0.2609\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4049 - accuracy: 0.6536 - val_loss: 1504.6992 - val_accuracy: 0.2652\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3835 - accuracy: 0.6528 - val_loss: 3303.5505 - val_accuracy: 0.2732\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4023 - accuracy: 0.6514 - val_loss: 561.5343 - val_accuracy: 0.3018\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4424 - accuracy: 0.6538 - val_loss: 6262.3003 - val_accuracy: 0.2584\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3700 - accuracy: 0.6602 - val_loss: 4979.0835 - val_accuracy: 0.2541\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4471 - accuracy: 0.6487 - val_loss: 1204.0529 - val_accuracy: 0.2606\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4105 - accuracy: 0.6532 - val_loss: 54.8789 - val_accuracy: 0.2970\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3335 - accuracy: 0.6625 - val_loss: 355.8527 - val_accuracy: 0.3180\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3326 - accuracy: 0.6631 - val_loss: 2521.5737 - val_accuracy: 0.2802\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3135 - accuracy: 0.6612 - val_loss: 3451.6021 - val_accuracy: 0.2947\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3439 - accuracy: 0.6544 - val_loss: 1641.9119 - val_accuracy: 0.3087\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3896 - accuracy: 0.6545 - val_loss: 1063.6967 - val_accuracy: 0.2847\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3405 - accuracy: 0.6599 - val_loss: 1889.5208 - val_accuracy: 0.2813\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3814 - accuracy: 0.6619 - val_loss: 1195.0848 - val_accuracy: 0.2966\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3757 - accuracy: 0.6504 - val_loss: 1126.1533 - val_accuracy: 0.3259\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3324 - accuracy: 0.6643 - val_loss: 3911.0325 - val_accuracy: 0.3225\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3339 - accuracy: 0.6572 - val_loss: 426.7691 - val_accuracy: 0.3237\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3203 - accuracy: 0.6634 - val_loss: 175.0635 - val_accuracy: 0.3278\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3341 - accuracy: 0.6607 - val_loss: 10380.0137 - val_accuracy: 0.3225\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3309 - accuracy: 0.6642 - val_loss: 253.9808 - val_accuracy: 0.3153\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3219 - accuracy: 0.6648 - val_loss: 162.4840 - val_accuracy: 0.3040\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.2961 - accuracy: 0.6689 - val_loss: 1607.2059 - val_accuracy: 0.3025\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3014 - accuracy: 0.6680 - val_loss: 122.7831 - val_accuracy: 0.3017\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3054 - accuracy: 0.6646 - val_loss: 132.2783 - val_accuracy: 0.3303\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2806 - accuracy: 0.6682 - val_loss: 121.0814 - val_accuracy: 0.3219\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3457 - accuracy: 0.6603 - val_loss: 46.5403 - val_accuracy: 0.3481\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3045 - accuracy: 0.6714 - val_loss: 39.6250 - val_accuracy: 0.3585\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3359 - accuracy: 0.6678 - val_loss: 125.6133 - val_accuracy: 0.3480\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.3180 - accuracy: 0.6661 - val_loss: 34.8655 - val_accuracy: 0.3781\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3313 - accuracy: 0.6589 - val_loss: 27.1544 - val_accuracy: 0.4318\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3022 - accuracy: 0.6597 - val_loss: 46.0828 - val_accuracy: 0.3318\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3185 - accuracy: 0.6629 - val_loss: 111.9864 - val_accuracy: 0.3437\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3143 - accuracy: 0.6610 - val_loss: 58.6220 - val_accuracy: 0.3555\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2715 - accuracy: 0.6708 - val_loss: 8.8848 - val_accuracy: 0.4109\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2962 - accuracy: 0.6688 - val_loss: 27.0985 - val_accuracy: 0.3432\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3158 - accuracy: 0.6643 - val_loss: 55.0595 - val_accuracy: 0.3214\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2839 - accuracy: 0.6639 - val_loss: 17.3968 - val_accuracy: 0.3471\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2710 - accuracy: 0.6735 - val_loss: 12.7710 - val_accuracy: 0.3690\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.2428 - accuracy: 0.6739 - val_loss: 17.9189 - val_accuracy: 0.3253\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2663 - accuracy: 0.6730 - val_loss: 55.3743 - val_accuracy: 0.3088\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.2926 - accuracy: 0.6616 - val_loss: 156.1533 - val_accuracy: 0.3719\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2981 - accuracy: 0.6686 - val_loss: 8.0142 - val_accuracy: 0.3773\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2919 - accuracy: 0.6698 - val_loss: 140.6422 - val_accuracy: 0.3473\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3262 - accuracy: 0.6730 - val_loss: 23.0067 - val_accuracy: 0.3231\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3075 - accuracy: 0.6662 - val_loss: 11.6652 - val_accuracy: 0.3587\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2511 - accuracy: 0.6739 - val_loss: 17.3447 - val_accuracy: 0.3228\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.2674 - accuracy: 0.6730 - val_loss: 30.6236 - val_accuracy: 0.3226\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2993 - accuracy: 0.6756 - val_loss: 31.5538 - val_accuracy: 0.3543\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2397 - accuracy: 0.6729 - val_loss: 40.3114 - val_accuracy: 0.3694\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2441 - accuracy: 0.6771 - val_loss: 15.9535 - val_accuracy: 0.3759\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2297 - accuracy: 0.6826 - val_loss: 14.8178 - val_accuracy: 0.3273\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2189 - accuracy: 0.6750 - val_loss: 28.7546 - val_accuracy: 0.3317\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.2278 - accuracy: 0.6749 - val_loss: 13.4012 - val_accuracy: 0.3300\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.2436 - accuracy: 0.6709 - val_loss: 25.4029 - val_accuracy: 0.3278\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.1916 - accuracy: 0.6780 - val_loss: 10.1390 - val_accuracy: 0.3334\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2206 - accuracy: 0.6787 - val_loss: 16.2042 - val_accuracy: 0.3610\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2195 - accuracy: 0.6789 - val_loss: 27.1365 - val_accuracy: 0.3702\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2023 - accuracy: 0.6778 - val_loss: 14.6590 - val_accuracy: 0.3357\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1976 - accuracy: 0.6747 - val_loss: 32.2528 - val_accuracy: 0.3265\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1508 - accuracy: 0.6788 - val_loss: 18.7153 - val_accuracy: 0.3206\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2218 - accuracy: 0.6799 - val_loss: 9.3133 - val_accuracy: 0.3417\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.2089 - accuracy: 0.6775 - val_loss: 11.6043 - val_accuracy: 0.3027\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1984 - accuracy: 0.6795 - val_loss: 16.6590 - val_accuracy: 0.3020\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1634 - accuracy: 0.6799 - val_loss: 19.9053 - val_accuracy: 0.2927\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1946 - accuracy: 0.6828 - val_loss: 27.4728 - val_accuracy: 0.3502\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2121 - accuracy: 0.6788 - val_loss: 30.8837 - val_accuracy: 0.3915\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1951 - accuracy: 0.6806 - val_loss: 28.5698 - val_accuracy: 0.3276\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1268 - accuracy: 0.6843 - val_loss: 21.8026 - val_accuracy: 0.3678\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1766 - accuracy: 0.6827 - val_loss: 20.1203 - val_accuracy: 0.3685\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1952 - accuracy: 0.6782 - val_loss: 22.7482 - val_accuracy: 0.2816\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1463 - accuracy: 0.6859 - val_loss: 25.9366 - val_accuracy: 0.2908\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1640 - accuracy: 0.6827 - val_loss: 14.2668 - val_accuracy: 0.2998\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.1791 - accuracy: 0.6802 - val_loss: 46.8702 - val_accuracy: 0.2998\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1663 - accuracy: 0.6778 - val_loss: 20.2876 - val_accuracy: 0.3045\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1755 - accuracy: 0.6766 - val_loss: 40.4954 - val_accuracy: 0.3045\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.1672 - accuracy: 0.6844 - val_loss: 23.1034 - val_accuracy: 0.2886\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1621 - accuracy: 0.6841 - val_loss: 43.9052 - val_accuracy: 0.2932\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.1429 - accuracy: 0.6861 - val_loss: 97.6001 - val_accuracy: 0.2856\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1550 - accuracy: 0.6862 - val_loss: 55.4516 - val_accuracy: 0.2867\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1666 - accuracy: 0.6848 - val_loss: 53.2712 - val_accuracy: 0.3386\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1527 - accuracy: 0.6876 - val_loss: 68.4054 - val_accuracy: 0.2689\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2050 - accuracy: 0.6794 - val_loss: 85.3251 - val_accuracy: 0.2786\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1376 - accuracy: 0.6839 - val_loss: 29.6988 - val_accuracy: 0.2665\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1215 - accuracy: 0.6857 - val_loss: 47.2797 - val_accuracy: 0.2810\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1673 - accuracy: 0.6883 - val_loss: 117.3809 - val_accuracy: 0.2776\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1211 - accuracy: 0.6890 - val_loss: 79.5773 - val_accuracy: 0.2962\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1284 - accuracy: 0.6831 - val_loss: 88.0685 - val_accuracy: 0.2814\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1335 - accuracy: 0.6814 - val_loss: 49.4699 - val_accuracy: 0.2878\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0973 - accuracy: 0.6896 - val_loss: 35.9426 - val_accuracy: 0.2996\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1071 - accuracy: 0.6869 - val_loss: 97.5308 - val_accuracy: 0.2587\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0706 - accuracy: 0.6914 - val_loss: 48.8575 - val_accuracy: 0.2574\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 4s 237ms/step - loss: 1.1150 - accuracy: 0.6895 - val_loss: 24.0685 - val_accuracy: 0.2841\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1592 - accuracy: 0.6841 - val_loss: 57.7364 - val_accuracy: 0.2720\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.2156 - accuracy: 0.6803 - val_loss: 142.8360 - val_accuracy: 0.2601\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1977 - accuracy: 0.6820 - val_loss: 71.0586 - val_accuracy: 0.2960\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.1542 - accuracy: 0.6881 - val_loss: 54.2319 - val_accuracy: 0.3028\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1545 - accuracy: 0.6824 - val_loss: 12.2851 - val_accuracy: 0.3389\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1051 - accuracy: 0.6893 - val_loss: 44.5219 - val_accuracy: 0.2819\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1092 - accuracy: 0.6849 - val_loss: 10.7262 - val_accuracy: 0.2974\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1331 - accuracy: 0.6843 - val_loss: 31.8540 - val_accuracy: 0.2689\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1564 - accuracy: 0.6850 - val_loss: 18.0352 - val_accuracy: 0.2667\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1575 - accuracy: 0.6859 - val_loss: 24.9312 - val_accuracy: 0.2648\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1382 - accuracy: 0.6859 - val_loss: 69.0250 - val_accuracy: 0.2872\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.1502 - accuracy: 0.6871 - val_loss: 26.8975 - val_accuracy: 0.2588\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1202 - accuracy: 0.6862 - val_loss: 66.3876 - val_accuracy: 0.2731\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1067 - accuracy: 0.6853 - val_loss: 53.3229 - val_accuracy: 0.2666\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0961 - accuracy: 0.6891 - val_loss: 98.1538 - val_accuracy: 0.2765\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1303 - accuracy: 0.6867 - val_loss: 41.2809 - val_accuracy: 0.2456\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.1375 - accuracy: 0.6859 - val_loss: 50.8733 - val_accuracy: 0.2951\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1557 - accuracy: 0.6845 - val_loss: 28.6510 - val_accuracy: 0.2578\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1382 - accuracy: 0.6842 - val_loss: 51.1188 - val_accuracy: 0.3340\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0793 - accuracy: 0.6937 - val_loss: 53.8114 - val_accuracy: 0.2494\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0593 - accuracy: 0.6899 - val_loss: 42.4436 - val_accuracy: 0.3170\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0791 - accuracy: 0.6896 - val_loss: 71.8407 - val_accuracy: 0.3333\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1183 - accuracy: 0.6878 - val_loss: 36.6343 - val_accuracy: 0.3396\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0708 - accuracy: 0.6934 - val_loss: 55.0730 - val_accuracy: 0.3128\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1007 - accuracy: 0.6900 - val_loss: 81.3101 - val_accuracy: 0.2780\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0888 - accuracy: 0.6964 - val_loss: 22.6458 - val_accuracy: 0.3205\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1115 - accuracy: 0.6896 - val_loss: 24.7435 - val_accuracy: 0.2638\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1100 - accuracy: 0.6936 - val_loss: 25.2971 - val_accuracy: 0.3251\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0861 - accuracy: 0.6930 - val_loss: 56.9451 - val_accuracy: 0.2648\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0687 - accuracy: 0.6943 - val_loss: 37.6292 - val_accuracy: 0.2752\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0646 - accuracy: 0.6917 - val_loss: 37.8567 - val_accuracy: 0.2451\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0942 - accuracy: 0.6921 - val_loss: 28.1654 - val_accuracy: 0.2807\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1072 - accuracy: 0.6903 - val_loss: 51.5529 - val_accuracy: 0.2620\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1192 - accuracy: 0.6873 - val_loss: 69.4063 - val_accuracy: 0.2816\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0791 - accuracy: 0.6952 - val_loss: 46.5986 - val_accuracy: 0.2893\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0698 - accuracy: 0.6930 - val_loss: 64.2105 - val_accuracy: 0.3376\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.0456 - accuracy: 0.6937 - val_loss: 43.6966 - val_accuracy: 0.3057\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.0523 - accuracy: 0.6944 - val_loss: 18.6568 - val_accuracy: 0.3455\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1375 - accuracy: 0.6884 - val_loss: 27.2928 - val_accuracy: 0.3059\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1723 - accuracy: 0.6825 - val_loss: 30.8058 - val_accuracy: 0.3007\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0622 - accuracy: 0.6924 - val_loss: 37.4306 - val_accuracy: 0.3068\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0391 - accuracy: 0.6967 - val_loss: 33.7057 - val_accuracy: 0.3086\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0147 - accuracy: 0.6921 - val_loss: 25.7279 - val_accuracy: 0.3351\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1025 - accuracy: 0.6953 - val_loss: 21.9176 - val_accuracy: 0.3091\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1236 - accuracy: 0.6854 - val_loss: 16.4879 - val_accuracy: 0.3687\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0957 - accuracy: 0.6912 - val_loss: 33.2758 - val_accuracy: 0.3182\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0390 - accuracy: 0.6950 - val_loss: 30.5072 - val_accuracy: 0.3343\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0223 - accuracy: 0.6955 - val_loss: 31.0352 - val_accuracy: 0.3576\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0333 - accuracy: 0.6971 - val_loss: 44.2121 - val_accuracy: 0.3571\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0253 - accuracy: 0.6963 - val_loss: 28.2166 - val_accuracy: 0.2881\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0377 - accuracy: 0.6992 - val_loss: 29.1814 - val_accuracy: 0.3161\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1072 - accuracy: 0.6920 - val_loss: 21.4324 - val_accuracy: 0.3698\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0488 - accuracy: 0.6955 - val_loss: 43.1133 - val_accuracy: 0.3311\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0429 - accuracy: 0.6955 - val_loss: 27.6965 - val_accuracy: 0.3594\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0539 - accuracy: 0.6957 - val_loss: 36.6036 - val_accuracy: 0.3651\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0352 - accuracy: 0.7000 - val_loss: 26.0580 - val_accuracy: 0.3643\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0555 - accuracy: 0.7006 - val_loss: 36.0398 - val_accuracy: 0.3528\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1154 - accuracy: 0.6958 - val_loss: 14.9136 - val_accuracy: 0.3561\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0522 - accuracy: 0.6902 - val_loss: 25.6545 - val_accuracy: 0.3756\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0278 - accuracy: 0.6937 - val_loss: 34.3293 - val_accuracy: 0.3448\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0022 - accuracy: 0.6964 - val_loss: 14.3816 - val_accuracy: 0.3506\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0199 - accuracy: 0.6948 - val_loss: 25.1249 - val_accuracy: 0.3349\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0307 - accuracy: 0.6975 - val_loss: 20.3103 - val_accuracy: 0.2752\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.0583 - accuracy: 0.6954 - val_loss: 37.8894 - val_accuracy: 0.3723\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.0367 - accuracy: 0.6967 - val_loss: 5.6998 - val_accuracy: 0.3175\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.0761 - accuracy: 0.6944 - val_loss: 17.5279 - val_accuracy: 0.3764\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0624 - accuracy: 0.6972 - val_loss: 15.5046 - val_accuracy: 0.3100\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0141 - accuracy: 0.6986 - val_loss: 13.7654 - val_accuracy: 0.2783\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9912 - accuracy: 0.6983 - val_loss: 11.8762 - val_accuracy: 0.3085\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0305 - accuracy: 0.6931 - val_loss: 11.8451 - val_accuracy: 0.3006\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0107 - accuracy: 0.6957 - val_loss: 12.1077 - val_accuracy: 0.3237\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0240 - accuracy: 0.6941 - val_loss: 15.8332 - val_accuracy: 0.3164\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0010 - accuracy: 0.6994 - val_loss: 8.1182 - val_accuracy: 0.3534\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0141 - accuracy: 0.6985 - val_loss: 16.2719 - val_accuracy: 0.3004\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1816 - accuracy: 0.6946 - val_loss: 17.5208 - val_accuracy: 0.2591\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0642 - accuracy: 0.6924 - val_loss: 22.1503 - val_accuracy: 0.2881\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0939 - accuracy: 0.6937 - val_loss: 17.7314 - val_accuracy: 0.2777\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0317 - accuracy: 0.6966 - val_loss: 19.9614 - val_accuracy: 0.2924\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9684 - accuracy: 0.7011 - val_loss: 22.0193 - val_accuracy: 0.3023\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0344 - accuracy: 0.6967 - val_loss: 11.6905 - val_accuracy: 0.3240\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0260 - accuracy: 0.6982 - val_loss: 15.2330 - val_accuracy: 0.3043\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0471 - accuracy: 0.6985 - val_loss: 24.0071 - val_accuracy: 0.3022\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0184 - accuracy: 0.6992 - val_loss: 15.4393 - val_accuracy: 0.3603\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9799 - accuracy: 0.6990 - val_loss: 13.6502 - val_accuracy: 0.2882\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0500 - accuracy: 0.6956 - val_loss: 14.9437 - val_accuracy: 0.2896\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0175 - accuracy: 0.6970 - val_loss: 18.6743 - val_accuracy: 0.2847\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9793 - accuracy: 0.7019 - val_loss: 21.5282 - val_accuracy: 0.2722\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9445 - accuracy: 0.7036 - val_loss: 25.3042 - val_accuracy: 0.2906\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9649 - accuracy: 0.7024 - val_loss: 33.7316 - val_accuracy: 0.3001\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9997 - accuracy: 0.7007 - val_loss: 15.4258 - val_accuracy: 0.3001\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0140 - accuracy: 0.6964 - val_loss: 22.8836 - val_accuracy: 0.2853\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9560 - accuracy: 0.7023 - val_loss: 17.9423 - val_accuracy: 0.2900\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9499 - accuracy: 0.7036 - val_loss: 18.8803 - val_accuracy: 0.2975\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9621 - accuracy: 0.7046 - val_loss: 12.6299 - val_accuracy: 0.2878\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9421 - accuracy: 0.7071 - val_loss: 10.8078 - val_accuracy: 0.3089\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9951 - accuracy: 0.6983 - val_loss: 16.4725 - val_accuracy: 0.2784\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9612 - accuracy: 0.7028 - val_loss: 15.1635 - val_accuracy: 0.2935\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9936 - accuracy: 0.7009 - val_loss: 12.6934 - val_accuracy: 0.2425\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9876 - accuracy: 0.7042 - val_loss: 11.7747 - val_accuracy: 0.2864\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0395 - accuracy: 0.6973 - val_loss: 13.6679 - val_accuracy: 0.2914\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.9971 - accuracy: 0.7006 - val_loss: 10.7277 - val_accuracy: 0.2927\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.0598 - accuracy: 0.6990 - val_loss: 10.2439 - val_accuracy: 0.2839\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9991 - accuracy: 0.6964 - val_loss: 10.8860 - val_accuracy: 0.3349\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9510 - accuracy: 0.7020 - val_loss: 9.2417 - val_accuracy: 0.3057\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9465 - accuracy: 0.6992 - val_loss: 12.3149 - val_accuracy: 0.3211\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9624 - accuracy: 0.7014 - val_loss: 10.9569 - val_accuracy: 0.3417\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9261 - accuracy: 0.6979 - val_loss: 15.0069 - val_accuracy: 0.3384\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9620 - accuracy: 0.7017 - val_loss: 8.8567 - val_accuracy: 0.3231\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9631 - accuracy: 0.7010 - val_loss: 13.1905 - val_accuracy: 0.2942\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0451 - accuracy: 0.6980 - val_loss: 9.0940 - val_accuracy: 0.2991\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0136 - accuracy: 0.6972 - val_loss: 10.4118 - val_accuracy: 0.2790\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0057 - accuracy: 0.6969 - val_loss: 9.6683 - val_accuracy: 0.2610\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9628 - accuracy: 0.6996 - val_loss: 10.5526 - val_accuracy: 0.2938\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9731 - accuracy: 0.7053 - val_loss: 11.6403 - val_accuracy: 0.3218\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9839 - accuracy: 0.6990 - val_loss: 15.5432 - val_accuracy: 0.2774\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9795 - accuracy: 0.6997 - val_loss: 9.3785 - val_accuracy: 0.2991\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9318 - accuracy: 0.7068 - val_loss: 11.1968 - val_accuracy: 0.2640\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9495 - accuracy: 0.7013 - val_loss: 10.3977 - val_accuracy: 0.3179\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.9569 - accuracy: 0.7037 - val_loss: 8.0779 - val_accuracy: 0.2915\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.9467 - accuracy: 0.7021 - val_loss: 22.3574 - val_accuracy: 0.2383\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.9485 - accuracy: 0.7070 - val_loss: 11.5138 - val_accuracy: 0.2905\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.9619 - accuracy: 0.6978 - val_loss: 9.6434 - val_accuracy: 0.2957\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9662 - accuracy: 0.7026 - val_loss: 6.3235 - val_accuracy: 0.3525\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9400 - accuracy: 0.7006 - val_loss: 12.0344 - val_accuracy: 0.3267\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9252 - accuracy: 0.7027 - val_loss: 7.4812 - val_accuracy: 0.3251\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.9906 - accuracy: 0.7032 - val_loss: 6.2082 - val_accuracy: 0.3154\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0286 - accuracy: 0.6964 - val_loss: 8.2009 - val_accuracy: 0.2991\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9344 - accuracy: 0.7046 - val_loss: 8.6317 - val_accuracy: 0.3657\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9254 - accuracy: 0.7026 - val_loss: 7.7664 - val_accuracy: 0.2680\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8829 - accuracy: 0.7076 - val_loss: 8.3966 - val_accuracy: 0.3389\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9087 - accuracy: 0.7042 - val_loss: 20.1423 - val_accuracy: 0.2768\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8987 - accuracy: 0.7062 - val_loss: 7.6937 - val_accuracy: 0.3191\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9202 - accuracy: 0.7062 - val_loss: 11.8892 - val_accuracy: 0.3150\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9609 - accuracy: 0.7114 - val_loss: 9.5606 - val_accuracy: 0.2953\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9391 - accuracy: 0.7022 - val_loss: 13.1579 - val_accuracy: 0.2712\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9109 - accuracy: 0.7097 - val_loss: 11.7835 - val_accuracy: 0.2971\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8960 - accuracy: 0.7051 - val_loss: 11.6593 - val_accuracy: 0.2840\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9034 - accuracy: 0.7056 - val_loss: 15.4227 - val_accuracy: 0.2960\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8978 - accuracy: 0.7079 - val_loss: 5.8908 - val_accuracy: 0.2931\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9420 - accuracy: 0.6989 - val_loss: 5.8257 - val_accuracy: 0.3283\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9338 - accuracy: 0.7060 - val_loss: 8.7219 - val_accuracy: 0.3024\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9197 - accuracy: 0.7055 - val_loss: 7.1302 - val_accuracy: 0.2900\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0346 - accuracy: 0.7012 - val_loss: 5.2410 - val_accuracy: 0.2947\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0001 - accuracy: 0.7016 - val_loss: 3.6444 - val_accuracy: 0.3408\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9390 - accuracy: 0.7051 - val_loss: 9.3028 - val_accuracy: 0.2769\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9603 - accuracy: 0.7059 - val_loss: 12.1883 - val_accuracy: 0.2496\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9505 - accuracy: 0.7022 - val_loss: 8.2041 - val_accuracy: 0.2821\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.0286 - accuracy: 0.7007 - val_loss: 8.8872 - val_accuracy: 0.2758\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.9841 - accuracy: 0.7003 - val_loss: 5.9732 - val_accuracy: 0.3132\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9161 - accuracy: 0.7084 - val_loss: 8.3439 - val_accuracy: 0.3140\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9232 - accuracy: 0.7016 - val_loss: 6.3648 - val_accuracy: 0.3020\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9052 - accuracy: 0.7042 - val_loss: 7.9926 - val_accuracy: 0.2882\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8938 - accuracy: 0.7051 - val_loss: 7.5283 - val_accuracy: 0.3090\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8336 - accuracy: 0.7125 - val_loss: 8.8456 - val_accuracy: 0.3543\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.8458 - accuracy: 0.7129 - val_loss: 9.4619 - val_accuracy: 0.2829\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8414 - accuracy: 0.7082 - val_loss: 8.7390 - val_accuracy: 0.3419\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8920 - accuracy: 0.7104 - val_loss: 11.1030 - val_accuracy: 0.3013\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.9904 - accuracy: 0.7053 - val_loss: 9.5407 - val_accuracy: 0.3160\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9333 - accuracy: 0.7040 - val_loss: 6.1364 - val_accuracy: 0.3696\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9439 - accuracy: 0.7069 - val_loss: 5.8917 - val_accuracy: 0.3198\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9784 - accuracy: 0.7025 - val_loss: 8.4510 - val_accuracy: 0.2427\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8992 - accuracy: 0.7020 - val_loss: 8.6665 - val_accuracy: 0.2851\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8831 - accuracy: 0.7085 - val_loss: 8.2481 - val_accuracy: 0.3108\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9011 - accuracy: 0.7067 - val_loss: 6.7675 - val_accuracy: 0.3147\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9152 - accuracy: 0.7108 - val_loss: 5.3401 - val_accuracy: 0.3461\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9521 - accuracy: 0.7034 - val_loss: 6.9102 - val_accuracy: 0.3311\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9268 - accuracy: 0.7015 - val_loss: 7.5675 - val_accuracy: 0.3367\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8598 - accuracy: 0.7122 - val_loss: 6.2777 - val_accuracy: 0.3035\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8556 - accuracy: 0.7111 - val_loss: 7.5303 - val_accuracy: 0.3138\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9009 - accuracy: 0.7102 - val_loss: 7.8065 - val_accuracy: 0.2839\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 0.9704 - accuracy: 0.6978 - val_loss: 6.0515 - val_accuracy: 0.3115\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9517 - accuracy: 0.7089 - val_loss: 5.1326 - val_accuracy: 0.3478\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9661 - accuracy: 0.7027 - val_loss: 5.3928 - val_accuracy: 0.3546\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8936 - accuracy: 0.7079 - val_loss: 6.8792 - val_accuracy: 0.3838\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8737 - accuracy: 0.7115 - val_loss: 8.8951 - val_accuracy: 0.3137\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9457 - accuracy: 0.7055 - val_loss: 8.0726 - val_accuracy: 0.2862\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9001 - accuracy: 0.7087 - val_loss: 7.1479 - val_accuracy: 0.2940\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8964 - accuracy: 0.7087 - val_loss: 7.0850 - val_accuracy: 0.3108\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8887 - accuracy: 0.7059 - val_loss: 8.4678 - val_accuracy: 0.3510\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8853 - accuracy: 0.7116 - val_loss: 7.2243 - val_accuracy: 0.3016\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9027 - accuracy: 0.7111 - val_loss: 5.4572 - val_accuracy: 0.3578\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.9348 - accuracy: 0.7106 - val_loss: 6.2521 - val_accuracy: 0.3069\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9169 - accuracy: 0.7060 - val_loss: 7.8533 - val_accuracy: 0.2826\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9193 - accuracy: 0.7050 - val_loss: 8.3722 - val_accuracy: 0.2928\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8911 - accuracy: 0.7074 - val_loss: 6.8430 - val_accuracy: 0.3107\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0456 - accuracy: 0.7025 - val_loss: 6.7585 - val_accuracy: 0.3178\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9791 - accuracy: 0.7016 - val_loss: 6.2148 - val_accuracy: 0.3119\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8801 - accuracy: 0.7106 - val_loss: 8.7630 - val_accuracy: 0.3458\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9099 - accuracy: 0.7100 - val_loss: 7.7107 - val_accuracy: 0.3392\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.0474 - accuracy: 0.7031 - val_loss: 7.9584 - val_accuracy: 0.3172\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0069 - accuracy: 0.6998 - val_loss: 7.0776 - val_accuracy: 0.2779\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9469 - accuracy: 0.7053 - val_loss: 5.9296 - val_accuracy: 0.3683\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9041 - accuracy: 0.7041 - val_loss: 7.3097 - val_accuracy: 0.3119\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9299 - accuracy: 0.7063 - val_loss: 4.2701 - val_accuracy: 0.4360\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9525 - accuracy: 0.7074 - val_loss: 7.0661 - val_accuracy: 0.3402\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9284 - accuracy: 0.7032 - val_loss: 5.7329 - val_accuracy: 0.3490\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9225 - accuracy: 0.7105 - val_loss: 6.1734 - val_accuracy: 0.3651\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8602 - accuracy: 0.7096 - val_loss: 7.3537 - val_accuracy: 0.3420\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9939 - accuracy: 0.7049 - val_loss: 7.0684 - val_accuracy: 0.3289\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9524 - accuracy: 0.7036 - val_loss: 8.1573 - val_accuracy: 0.3254\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8964 - accuracy: 0.7107 - val_loss: 6.3621 - val_accuracy: 0.3724\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9117 - accuracy: 0.7089 - val_loss: 7.0041 - val_accuracy: 0.3481\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.8785 - accuracy: 0.7123 - val_loss: 6.0374 - val_accuracy: 0.4107\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.8524 - accuracy: 0.7105 - val_loss: 5.7713 - val_accuracy: 0.3538\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.8806 - accuracy: 0.7070 - val_loss: 8.0078 - val_accuracy: 0.3264\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9046 - accuracy: 0.7135 - val_loss: 7.2344 - val_accuracy: 0.3449\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9181 - accuracy: 0.7089 - val_loss: 6.6512 - val_accuracy: 0.3233\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8672 - accuracy: 0.7124 - val_loss: 8.3923 - val_accuracy: 0.3738\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8774 - accuracy: 0.7130 - val_loss: 5.2708 - val_accuracy: 0.3281\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8817 - accuracy: 0.7111 - val_loss: 9.1316 - val_accuracy: 0.3560\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9123 - accuracy: 0.7076 - val_loss: 8.1999 - val_accuracy: 0.3192\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9012 - accuracy: 0.7116 - val_loss: 7.8728 - val_accuracy: 0.3231\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9252 - accuracy: 0.7088 - val_loss: 9.4299 - val_accuracy: 0.2991\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9243 - accuracy: 0.7096 - val_loss: 9.1300 - val_accuracy: 0.2529\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8905 - accuracy: 0.7110 - val_loss: 7.9199 - val_accuracy: 0.2690\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8632 - accuracy: 0.7165 - val_loss: 7.5180 - val_accuracy: 0.2900\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8184 - accuracy: 0.7147 - val_loss: 7.8029 - val_accuracy: 0.3369\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8377 - accuracy: 0.7161 - val_loss: 8.0692 - val_accuracy: 0.3067\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8594 - accuracy: 0.7117 - val_loss: 5.8051 - val_accuracy: 0.3337\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8711 - accuracy: 0.7150 - val_loss: 8.1474 - val_accuracy: 0.3386\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8140 - accuracy: 0.7174 - val_loss: 7.1010 - val_accuracy: 0.3318\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 4s 258ms/step - loss: 0.8059 - accuracy: 0.7156 - val_loss: 10.8319 - val_accuracy: 0.3540\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8007 - accuracy: 0.7120 - val_loss: 6.8658 - val_accuracy: 0.3535\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9204 - accuracy: 0.7115 - val_loss: 4.6120 - val_accuracy: 0.3772\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9976 - accuracy: 0.7124 - val_loss: 6.2626 - val_accuracy: 0.3512\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9275 - accuracy: 0.7084 - val_loss: 6.2027 - val_accuracy: 0.3196\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8730 - accuracy: 0.7114 - val_loss: 8.3886 - val_accuracy: 0.3347\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8588 - accuracy: 0.7124 - val_loss: 9.5085 - val_accuracy: 0.3617\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8831 - accuracy: 0.7079 - val_loss: 12.0494 - val_accuracy: 0.2931\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.9134 - accuracy: 0.7113 - val_loss: 10.9726 - val_accuracy: 0.3372\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8544 - accuracy: 0.7130 - val_loss: 8.3228 - val_accuracy: 0.2698\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8544 - accuracy: 0.7142 - val_loss: 8.0530 - val_accuracy: 0.2842\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8984 - accuracy: 0.7113 - val_loss: 7.9180 - val_accuracy: 0.3263\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8620 - accuracy: 0.7117 - val_loss: 8.5681 - val_accuracy: 0.3007\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8629 - accuracy: 0.7159 - val_loss: 7.8276 - val_accuracy: 0.2566\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8358 - accuracy: 0.7102 - val_loss: 8.4755 - val_accuracy: 0.2650\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8613 - accuracy: 0.7097 - val_loss: 9.4725 - val_accuracy: 0.3160\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8632 - accuracy: 0.7146 - val_loss: 7.5203 - val_accuracy: 0.3255\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8916 - accuracy: 0.7148 - val_loss: 8.0007 - val_accuracy: 0.2858\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8720 - accuracy: 0.7127 - val_loss: 6.2589 - val_accuracy: 0.3490\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8052 - accuracy: 0.7191 - val_loss: 11.1814 - val_accuracy: 0.2677\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 0.8315 - accuracy: 0.7128 - val_loss: 9.5723 - val_accuracy: 0.2842\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8570 - accuracy: 0.7115 - val_loss: 7.5818 - val_accuracy: 0.3049\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8586 - accuracy: 0.7068 - val_loss: 11.3327 - val_accuracy: 0.2893\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8259 - accuracy: 0.7163 - val_loss: 10.0341 - val_accuracy: 0.3065\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9145 - accuracy: 0.7106 - val_loss: 6.8656 - val_accuracy: 0.3444\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8913 - accuracy: 0.7072 - val_loss: 8.1153 - val_accuracy: 0.3058\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8862 - accuracy: 0.7117 - val_loss: 7.7177 - val_accuracy: 0.3413\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8538 - accuracy: 0.7136 - val_loss: 6.6201 - val_accuracy: 0.3747\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8416 - accuracy: 0.7143 - val_loss: 7.9447 - val_accuracy: 0.2908\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8307 - accuracy: 0.7104 - val_loss: 8.3413 - val_accuracy: 0.3151\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.7830 - accuracy: 0.7186 - val_loss: 6.9942 - val_accuracy: 0.3799\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8078 - accuracy: 0.7155 - val_loss: 9.1517 - val_accuracy: 0.2916\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8399 - accuracy: 0.7146 - val_loss: 7.6503 - val_accuracy: 0.3672\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8432 - accuracy: 0.7178 - val_loss: 6.1971 - val_accuracy: 0.3589\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8665 - accuracy: 0.7115 - val_loss: 7.9542 - val_accuracy: 0.3287\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8680 - accuracy: 0.7096 - val_loss: 6.4004 - val_accuracy: 0.3966\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7871 - accuracy: 0.7170 - val_loss: 7.2545 - val_accuracy: 0.3832\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8477 - accuracy: 0.7148 - val_loss: 9.3891 - val_accuracy: 0.3415\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8233 - accuracy: 0.7143 - val_loss: 8.8437 - val_accuracy: 0.3407\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7957 - accuracy: 0.7171 - val_loss: 6.6940 - val_accuracy: 0.3727\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9161 - accuracy: 0.7117 - val_loss: 6.6207 - val_accuracy: 0.3706\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8584 - accuracy: 0.7086 - val_loss: 5.7679 - val_accuracy: 0.3801\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8116 - accuracy: 0.7151 - val_loss: 6.3755 - val_accuracy: 0.3578\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9378 - accuracy: 0.7098 - val_loss: 6.1915 - val_accuracy: 0.3871\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.8643 - accuracy: 0.7140 - val_loss: 8.7722 - val_accuracy: 0.3957\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8271 - accuracy: 0.7134 - val_loss: 7.4651 - val_accuracy: 0.3517\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8898 - accuracy: 0.7134 - val_loss: 5.7023 - val_accuracy: 0.3276\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8541 - accuracy: 0.7144 - val_loss: 6.4080 - val_accuracy: 0.3675\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8841 - accuracy: 0.7113 - val_loss: 6.9932 - val_accuracy: 0.3931\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8411 - accuracy: 0.7155 - val_loss: 10.4397 - val_accuracy: 0.2785\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8159 - accuracy: 0.7138 - val_loss: 9.9942 - val_accuracy: 0.3440\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8402 - accuracy: 0.7136 - val_loss: 5.7396 - val_accuracy: 0.4576\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8686 - accuracy: 0.7138 - val_loss: 5.8527 - val_accuracy: 0.3781\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8362 - accuracy: 0.7127 - val_loss: 11.9306 - val_accuracy: 0.4109\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8486 - accuracy: 0.7116 - val_loss: 9.9386 - val_accuracy: 0.3206\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8333 - accuracy: 0.7162 - val_loss: 8.5785 - val_accuracy: 0.3737\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8138 - accuracy: 0.7152 - val_loss: 8.0951 - val_accuracy: 0.3319\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8317 - accuracy: 0.7166 - val_loss: 6.0580 - val_accuracy: 0.3883\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.8475 - accuracy: 0.7163 - val_loss: 7.9452 - val_accuracy: 0.3926\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9006 - accuracy: 0.7177 - val_loss: 7.1048 - val_accuracy: 0.3491\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.8144 - accuracy: 0.7164 - val_loss: 5.2150 - val_accuracy: 0.4139\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7895 - accuracy: 0.7183 - val_loss: 7.4107 - val_accuracy: 0.3853\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7848 - accuracy: 0.7193 - val_loss: 7.0573 - val_accuracy: 0.4054\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7763 - accuracy: 0.7222 - val_loss: 7.3432 - val_accuracy: 0.3578\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.8075 - accuracy: 0.7170 - val_loss: 5.6981 - val_accuracy: 0.4386\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 0.7778 - accuracy: 0.7233 - val_loss: 6.2801 - val_accuracy: 0.3991\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8076 - accuracy: 0.7171 - val_loss: 5.7158 - val_accuracy: 0.4222\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8079 - accuracy: 0.7166 - val_loss: 7.4515 - val_accuracy: 0.3636\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7511 - accuracy: 0.7242 - val_loss: 6.7110 - val_accuracy: 0.4052\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.7706 - accuracy: 0.7234 - val_loss: 7.3984 - val_accuracy: 0.3863\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8127 - accuracy: 0.7178 - val_loss: 9.7382 - val_accuracy: 0.3885\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8282 - accuracy: 0.7180 - val_loss: 8.1801 - val_accuracy: 0.3473\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8625 - accuracy: 0.7180 - val_loss: 7.4464 - val_accuracy: 0.3590\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8102 - accuracy: 0.7191 - val_loss: 7.5719 - val_accuracy: 0.3771\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8316 - accuracy: 0.7196 - val_loss: 10.1513 - val_accuracy: 0.3471\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.8387 - accuracy: 0.7130 - val_loss: 7.2096 - val_accuracy: 0.4238\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7885 - accuracy: 0.7159 - val_loss: 5.4107 - val_accuracy: 0.4210\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.7704 - accuracy: 0.7231 - val_loss: 6.6001 - val_accuracy: 0.4287\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.8085 - accuracy: 0.7220 - val_loss: 11.3986 - val_accuracy: 0.3590\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.7972 - accuracy: 0.7203 - val_loss: 6.7957 - val_accuracy: 0.3730\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 7s 407ms/step - loss: 0.8112 - accuracy: 0.7211 - val_loss: 10.3428 - val_accuracy: 0.3472\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.7440 - accuracy: 0.7202 - val_loss: 7.2834 - val_accuracy: 0.4054\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8381 - accuracy: 0.7174 - val_loss: 6.7277 - val_accuracy: 0.3516\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8364 - accuracy: 0.7153 - val_loss: 6.5857 - val_accuracy: 0.3456\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.8151 - accuracy: 0.7165 - val_loss: 6.7498 - val_accuracy: 0.3490\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8215 - accuracy: 0.7157 - val_loss: 9.3778 - val_accuracy: 0.3290\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.7518 - accuracy: 0.7216 - val_loss: 7.4666 - val_accuracy: 0.3800\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7597 - accuracy: 0.7216 - val_loss: 8.7024 - val_accuracy: 0.3987\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.8985 - accuracy: 0.7161 - val_loss: 9.0486 - val_accuracy: 0.3542\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.9005 - accuracy: 0.7126 - val_loss: 7.7639 - val_accuracy: 0.3808\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8866 - accuracy: 0.7127 - val_loss: 5.8228 - val_accuracy: 0.3889\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8170 - accuracy: 0.7191 - val_loss: 4.4605 - val_accuracy: 0.4145\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7344 - accuracy: 0.7295 - val_loss: 6.0495 - val_accuracy: 0.4186\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7712 - accuracy: 0.7158 - val_loss: 6.1469 - val_accuracy: 0.4262\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8593 - accuracy: 0.7145 - val_loss: 5.9890 - val_accuracy: 0.3903\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8498 - accuracy: 0.7144 - val_loss: 7.7809 - val_accuracy: 0.3918\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.8339 - accuracy: 0.7146 - val_loss: 6.0994 - val_accuracy: 0.3964\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.7838 - accuracy: 0.7155 - val_loss: 6.0281 - val_accuracy: 0.3836\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8508 - accuracy: 0.7195 - val_loss: 6.0343 - val_accuracy: 0.3733\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8741 - accuracy: 0.7072 - val_loss: 9.6841 - val_accuracy: 0.3075\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7626 - accuracy: 0.7230 - val_loss: 6.4432 - val_accuracy: 0.3567\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7816 - accuracy: 0.7197 - val_loss: 6.4337 - val_accuracy: 0.4258\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7212 - accuracy: 0.7275 - val_loss: 7.0349 - val_accuracy: 0.3685\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7866 - accuracy: 0.7222 - val_loss: 5.7064 - val_accuracy: 0.3909\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0534 - accuracy: 0.7070 - val_loss: 6.1156 - val_accuracy: 0.3696\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0159 - accuracy: 0.7012 - val_loss: 10.9054 - val_accuracy: 0.3199\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0431 - accuracy: 0.6990 - val_loss: 10.2905 - val_accuracy: 0.4212\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.9747 - accuracy: 0.7070 - val_loss: 6.8144 - val_accuracy: 0.4321\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.9514 - accuracy: 0.7107 - val_loss: 7.7835 - val_accuracy: 0.4519\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8710 - accuracy: 0.7159 - val_loss: 6.8543 - val_accuracy: 0.4310\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 0.8397 - accuracy: 0.7129 - val_loss: 6.0085 - val_accuracy: 0.4624\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8559 - accuracy: 0.7174 - val_loss: 5.8297 - val_accuracy: 0.4109\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.8978 - accuracy: 0.7208 - val_loss: 5.0439 - val_accuracy: 0.4815\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.8463 - accuracy: 0.7174 - val_loss: 7.5648 - val_accuracy: 0.3669\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7874 - accuracy: 0.7219 - val_loss: 5.6032 - val_accuracy: 0.3932\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8175 - accuracy: 0.7193 - val_loss: 6.0122 - val_accuracy: 0.4541\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.8356 - accuracy: 0.7195 - val_loss: 6.3184 - val_accuracy: 0.4234\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.7712 - accuracy: 0.7231 - val_loss: 7.0940 - val_accuracy: 0.3683\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8225 - accuracy: 0.7178 - val_loss: 5.7984 - val_accuracy: 0.4136\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8307 - accuracy: 0.7172 - val_loss: 9.0941 - val_accuracy: 0.3599\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.8207 - accuracy: 0.7224 - val_loss: 5.1755 - val_accuracy: 0.4765\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.7893 - accuracy: 0.7186 - val_loss: 6.0517 - val_accuracy: 0.3782\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8693 - accuracy: 0.7136 - val_loss: 5.8849 - val_accuracy: 0.4265\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8069 - accuracy: 0.7178 - val_loss: 5.9987 - val_accuracy: 0.3919\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7390 - accuracy: 0.7232 - val_loss: 6.6499 - val_accuracy: 0.4225\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7408 - accuracy: 0.7266 - val_loss: 5.1143 - val_accuracy: 0.4258\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7671 - accuracy: 0.7224 - val_loss: 5.3504 - val_accuracy: 0.4070\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.7907 - accuracy: 0.7187 - val_loss: 6.3524 - val_accuracy: 0.3816\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7936 - accuracy: 0.7216 - val_loss: 6.9630 - val_accuracy: 0.3660\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7702 - accuracy: 0.7194 - val_loss: 5.1946 - val_accuracy: 0.4431\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7494 - accuracy: 0.7235 - val_loss: 5.0908 - val_accuracy: 0.4668\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 279ms/step - loss: 2.7474 - accuracy: 0.5835 - val_loss: 21.7525 - val_accuracy: 0.1561\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.3570 - accuracy: 0.6078 - val_loss: 21.9987 - val_accuracy: 0.1601\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 2.2673 - accuracy: 0.6155 - val_loss: 16.6866 - val_accuracy: 0.1691\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.3277 - accuracy: 0.6041 - val_loss: 34.9061 - val_accuracy: 0.1747\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.3705 - accuracy: 0.6171 - val_loss: 47.6874 - val_accuracy: 0.1294\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.7037 - accuracy: 0.6156 - val_loss: 161.8979 - val_accuracy: 0.1184\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 2.7007 - accuracy: 0.6051 - val_loss: 2240.7686 - val_accuracy: 0.0762\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.5136 - accuracy: 0.5998 - val_loss: 26.7263 - val_accuracy: 0.0963\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.3671 - accuracy: 0.6078 - val_loss: 19.8052 - val_accuracy: 0.1028\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.2606 - accuracy: 0.6086 - val_loss: 21.3760 - val_accuracy: 0.1147\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2855 - accuracy: 0.6167 - val_loss: 21.9166 - val_accuracy: 0.1398\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.2699 - accuracy: 0.6184 - val_loss: 20.0329 - val_accuracy: 0.1181\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 2.3060 - accuracy: 0.6116 - val_loss: 27.3569 - val_accuracy: 0.1318\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.2682 - accuracy: 0.6140 - val_loss: 16.6325 - val_accuracy: 0.1294\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 2.1609 - accuracy: 0.6175 - val_loss: 16.8352 - val_accuracy: 0.1750\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 2.2093 - accuracy: 0.6128 - val_loss: 12.6077 - val_accuracy: 0.1411\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1198 - accuracy: 0.6202 - val_loss: 12.9571 - val_accuracy: 0.1697\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1621 - accuracy: 0.6142 - val_loss: 13.9743 - val_accuracy: 0.1729\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 2.1407 - accuracy: 0.6210 - val_loss: 17.4819 - val_accuracy: 0.1586\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1028 - accuracy: 0.6176 - val_loss: 14.9829 - val_accuracy: 0.1724\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0624 - accuracy: 0.6242 - val_loss: 17.1859 - val_accuracy: 0.1650\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0466 - accuracy: 0.6231 - val_loss: 20.9269 - val_accuracy: 0.1555\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.0902 - accuracy: 0.6215 - val_loss: 20.5154 - val_accuracy: 0.1080\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0841 - accuracy: 0.6178 - val_loss: 20.2194 - val_accuracy: 0.1032\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0991 - accuracy: 0.6170 - val_loss: 21.7351 - val_accuracy: 0.1035\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0265 - accuracy: 0.6183 - val_loss: 22.0280 - val_accuracy: 0.1452\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0944 - accuracy: 0.6194 - val_loss: 18.4656 - val_accuracy: 0.1462\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0243 - accuracy: 0.6233 - val_loss: 19.9069 - val_accuracy: 0.1007\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 2.1088 - accuracy: 0.6165 - val_loss: 31.5796 - val_accuracy: 0.0838\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1240 - accuracy: 0.6156 - val_loss: 19.1845 - val_accuracy: 0.1122\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0914 - accuracy: 0.6206 - val_loss: 19.0675 - val_accuracy: 0.1059\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0402 - accuracy: 0.6192 - val_loss: 17.2755 - val_accuracy: 0.1054\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0235 - accuracy: 0.6233 - val_loss: 11.8688 - val_accuracy: 0.1392\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0687 - accuracy: 0.6167 - val_loss: 17.0885 - val_accuracy: 0.1053\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0254 - accuracy: 0.6178 - val_loss: 25.4655 - val_accuracy: 0.0826\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.9990 - accuracy: 0.6177 - val_loss: 36.7682 - val_accuracy: 0.0705\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 2.0038 - accuracy: 0.6211 - val_loss: 68.5363 - val_accuracy: 0.0678\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.9811 - accuracy: 0.6260 - val_loss: 141.9491 - val_accuracy: 0.0197\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.9673 - accuracy: 0.6195 - val_loss: 93.3294 - val_accuracy: 0.0623\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.9586 - accuracy: 0.6221 - val_loss: 47.0826 - val_accuracy: 0.0720\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.0002 - accuracy: 0.6232 - val_loss: 106.7266 - val_accuracy: 0.0596\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.9614 - accuracy: 0.6171 - val_loss: 62.6320 - val_accuracy: 0.0687\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.9237 - accuracy: 0.6204 - val_loss: 80.5562 - val_accuracy: 0.0550\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.9052 - accuracy: 0.6226 - val_loss: 46.1048 - val_accuracy: 0.0615\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.9114 - accuracy: 0.6254 - val_loss: 46.9617 - val_accuracy: 0.0708\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.9511 - accuracy: 0.6187 - val_loss: 48.2531 - val_accuracy: 0.0810\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 1.9249 - accuracy: 0.6205 - val_loss: 43.2209 - val_accuracy: 0.0740\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.9496 - accuracy: 0.6167 - val_loss: 67.1584 - val_accuracy: 0.0570\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.9083 - accuracy: 0.6147 - val_loss: 150.3161 - val_accuracy: 0.0560\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8830 - accuracy: 0.6190 - val_loss: 81.1472 - val_accuracy: 0.0599\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.9486 - accuracy: 0.6191 - val_loss: 205.1544 - val_accuracy: 0.0422\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.8854 - accuracy: 0.6202 - val_loss: 126.3826 - val_accuracy: 0.0524\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8122 - accuracy: 0.6221 - val_loss: 101.0523 - val_accuracy: 0.0486\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8464 - accuracy: 0.6180 - val_loss: 121.4504 - val_accuracy: 0.0502\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.8052 - accuracy: 0.6212 - val_loss: 167.3867 - val_accuracy: 0.0431\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.8358 - accuracy: 0.6178 - val_loss: 216.3366 - val_accuracy: 0.0137\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8230 - accuracy: 0.6219 - val_loss: 303.5394 - val_accuracy: 0.0201\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.8111 - accuracy: 0.6231 - val_loss: 161.5829 - val_accuracy: 0.0235\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.8531 - accuracy: 0.6162 - val_loss: 178.1315 - val_accuracy: 0.0304\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.8512 - accuracy: 0.6203 - val_loss: 80.7674 - val_accuracy: 0.0317\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.7898 - accuracy: 0.6240 - val_loss: 62.0627 - val_accuracy: 0.0365\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.8260 - accuracy: 0.6184 - val_loss: 122.3125 - val_accuracy: 0.0301\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7898 - accuracy: 0.6249 - val_loss: 79.0203 - val_accuracy: 0.0369\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.8079 - accuracy: 0.6233 - val_loss: 70.8329 - val_accuracy: 0.0359\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.7992 - accuracy: 0.6246 - val_loss: 69.9657 - val_accuracy: 0.0399\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.7980 - accuracy: 0.6221 - val_loss: 4019553536.0000 - val_accuracy: 0.0277\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.5501 - accuracy: 0.5812 - val_loss: 116853.8750 - val_accuracy: 0.0755\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.3668 - accuracy: 0.6072 - val_loss: 283.1472 - val_accuracy: 0.0179\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.2835 - accuracy: 0.6118 - val_loss: 15.9600 - val_accuracy: 0.0988\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.2312 - accuracy: 0.6148 - val_loss: 9.9499 - val_accuracy: 0.1243\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1967 - accuracy: 0.6186 - val_loss: 10.4147 - val_accuracy: 0.1302\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1643 - accuracy: 0.6214 - val_loss: 12.3590 - val_accuracy: 0.1293\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.1535 - accuracy: 0.6220 - val_loss: 10.7851 - val_accuracy: 0.1262\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.1902 - accuracy: 0.6240 - val_loss: 12.3975 - val_accuracy: 0.1301\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.2460 - accuracy: 0.6160 - val_loss: 12.6027 - val_accuracy: 0.1297\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1834 - accuracy: 0.6151 - val_loss: 12.4823 - val_accuracy: 0.1265\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0960 - accuracy: 0.6219 - val_loss: 13.5595 - val_accuracy: 0.1276\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 2.1426 - accuracy: 0.6170 - val_loss: 10.7091 - val_accuracy: 0.1271\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1190 - accuracy: 0.6196 - val_loss: 10.9651 - val_accuracy: 0.1305\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 2.2170 - accuracy: 0.6193 - val_loss: 11.5545 - val_accuracy: 0.1277\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1542 - accuracy: 0.6209 - val_loss: 11.0360 - val_accuracy: 0.1266\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1079 - accuracy: 0.6201 - val_loss: 11.3415 - val_accuracy: 0.1253\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1335 - accuracy: 0.6211 - val_loss: 12.2985 - val_accuracy: 0.1187\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0924 - accuracy: 0.6177 - val_loss: 13.2129 - val_accuracy: 0.1212\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0955 - accuracy: 0.6241 - val_loss: 10.8433 - val_accuracy: 0.1131\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0995 - accuracy: 0.6233 - val_loss: 12.3964 - val_accuracy: 0.1091\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0818 - accuracy: 0.6218 - val_loss: 13.2752 - val_accuracy: 0.1048\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0830 - accuracy: 0.6147 - val_loss: 10.9509 - val_accuracy: 0.1101\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0262 - accuracy: 0.6186 - val_loss: 14.0262 - val_accuracy: 0.1096\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.0201 - accuracy: 0.6173 - val_loss: 12.0022 - val_accuracy: 0.1009\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 2.0245 - accuracy: 0.6209 - val_loss: 13.6581 - val_accuracy: 0.0966\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0100 - accuracy: 0.6220 - val_loss: 9.5128 - val_accuracy: 0.1387\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 2.0136 - accuracy: 0.6163 - val_loss: 12.2660 - val_accuracy: 0.1313\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 4s 234ms/step - loss: 1.9664 - accuracy: 0.6212 - val_loss: 12.6759 - val_accuracy: 0.1284\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.9599 - accuracy: 0.6226 - val_loss: 10.5866 - val_accuracy: 0.1247\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.9646 - accuracy: 0.6175 - val_loss: 12.0982 - val_accuracy: 0.1280\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.9277 - accuracy: 0.6227 - val_loss: 11.7639 - val_accuracy: 0.1328\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.9334 - accuracy: 0.6213 - val_loss: 11.5681 - val_accuracy: 0.1311\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.9832 - accuracy: 0.6116 - val_loss: 10.1176 - val_accuracy: 0.1357\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.9138 - accuracy: 0.6203 - val_loss: 12.2141 - val_accuracy: 0.1346\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.9711 - accuracy: 0.6171 - val_loss: 12.7346 - val_accuracy: 0.1327\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.9663 - accuracy: 0.6192 - val_loss: 11.7509 - val_accuracy: 0.1311\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.9797 - accuracy: 0.6140 - val_loss: 13.5402 - val_accuracy: 0.1204\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.9627 - accuracy: 0.6180 - val_loss: 14.8597 - val_accuracy: 0.1198\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.9157 - accuracy: 0.6223 - val_loss: 14.1455 - val_accuracy: 0.1205\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.9291 - accuracy: 0.6208 - val_loss: 15.9992 - val_accuracy: 0.1355\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0091 - accuracy: 0.6133 - val_loss: 12.5215 - val_accuracy: 0.1322\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.9090 - accuracy: 0.6160 - val_loss: 13.2502 - val_accuracy: 0.1411\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.9254 - accuracy: 0.6206 - val_loss: 13.3971 - val_accuracy: 0.1357\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.9120 - accuracy: 0.6197 - val_loss: 14.1574 - val_accuracy: 0.1351\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.9212 - accuracy: 0.6186 - val_loss: 12.8797 - val_accuracy: 0.1410\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.9079 - accuracy: 0.6186 - val_loss: 13.8884 - val_accuracy: 0.1353\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.9083 - accuracy: 0.6242 - val_loss: 12.2096 - val_accuracy: 0.1438\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8867 - accuracy: 0.6184 - val_loss: 13.6833 - val_accuracy: 0.1402\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.8979 - accuracy: 0.6193 - val_loss: 15.1789 - val_accuracy: 0.1368\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.8322 - accuracy: 0.6260 - val_loss: 12.1954 - val_accuracy: 0.1441\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.8773 - accuracy: 0.6217 - val_loss: 14.6631 - val_accuracy: 0.1389\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.8454 - accuracy: 0.6237 - val_loss: 13.0080 - val_accuracy: 0.1401\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.8597 - accuracy: 0.6233 - val_loss: 15.8782 - val_accuracy: 0.1391\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.8747 - accuracy: 0.6226 - val_loss: 16.2796 - val_accuracy: 0.1410\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.8589 - accuracy: 0.6169 - val_loss: 12.3352 - val_accuracy: 0.1435\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.8606 - accuracy: 0.6160 - val_loss: 13.7177 - val_accuracy: 0.1459\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.8453 - accuracy: 0.6150 - val_loss: 15.8310 - val_accuracy: 0.1446\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.8532 - accuracy: 0.6194 - val_loss: 10.7734 - val_accuracy: 0.1423\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.9637 - accuracy: 0.6140 - val_loss: 20.5074 - val_accuracy: 0.1423\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.8924 - accuracy: 0.6251 - val_loss: 18.4216 - val_accuracy: 0.1396\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.8651 - accuracy: 0.6238 - val_loss: 14.0864 - val_accuracy: 0.1556\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.8372 - accuracy: 0.6249 - val_loss: 16.1637 - val_accuracy: 0.1500\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8351 - accuracy: 0.6201 - val_loss: 14.0504 - val_accuracy: 0.1542\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.7966 - accuracy: 0.6218 - val_loss: 17.0136 - val_accuracy: 0.1522\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.8283 - accuracy: 0.6207 - val_loss: 15.7264 - val_accuracy: 0.1486\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.8054 - accuracy: 0.6223 - val_loss: 14.8889 - val_accuracy: 0.1465\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.7893 - accuracy: 0.6243 - val_loss: 10.5044 - val_accuracy: 0.1607\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.7945 - accuracy: 0.6165 - val_loss: 12.6504 - val_accuracy: 0.1527\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.8242 - accuracy: 0.6237 - val_loss: 15.7817 - val_accuracy: 0.1467\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.7667 - accuracy: 0.6274 - val_loss: 14.4622 - val_accuracy: 0.1474\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.7650 - accuracy: 0.6233 - val_loss: 11.7798 - val_accuracy: 0.1480\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.7191 - accuracy: 0.6220 - val_loss: 11.1144 - val_accuracy: 0.1364\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.8078 - accuracy: 0.6170 - val_loss: 14.7426 - val_accuracy: 0.1477\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.8025 - accuracy: 0.6155 - val_loss: 11.8013 - val_accuracy: 0.1488\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7523 - accuracy: 0.6235 - val_loss: 15.8421 - val_accuracy: 0.1397\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.7175 - accuracy: 0.6285 - val_loss: 14.6906 - val_accuracy: 0.1405\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.7331 - accuracy: 0.6236 - val_loss: 14.6398 - val_accuracy: 0.1430\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.7214 - accuracy: 0.6217 - val_loss: 14.8144 - val_accuracy: 0.1385\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.6958 - accuracy: 0.6250 - val_loss: 14.0625 - val_accuracy: 0.1435\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6768 - accuracy: 0.6241 - val_loss: 16.9098 - val_accuracy: 0.1424\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.7265 - accuracy: 0.6184 - val_loss: 12.3156 - val_accuracy: 0.1526\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.7086 - accuracy: 0.6227 - val_loss: 12.8423 - val_accuracy: 0.1472\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.7501 - accuracy: 0.6248 - val_loss: 13.7041 - val_accuracy: 0.1529\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.7265 - accuracy: 0.6211 - val_loss: 15.2267 - val_accuracy: 0.1363\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.7225 - accuracy: 0.6238 - val_loss: 13.4793 - val_accuracy: 0.1519\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.6906 - accuracy: 0.6291 - val_loss: 12.7031 - val_accuracy: 0.1667\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.6978 - accuracy: 0.6227 - val_loss: 13.8508 - val_accuracy: 0.1636\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.6842 - accuracy: 0.6237 - val_loss: 16.0770 - val_accuracy: 0.1526\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.6968 - accuracy: 0.6222 - val_loss: 11.5129 - val_accuracy: 0.1696\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.6939 - accuracy: 0.6228 - val_loss: 13.2335 - val_accuracy: 0.1538\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.6715 - accuracy: 0.6297 - val_loss: 11.5213 - val_accuracy: 0.1554\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.6815 - accuracy: 0.6252 - val_loss: 15.0340 - val_accuracy: 0.1529\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.6877 - accuracy: 0.6223 - val_loss: 14.0900 - val_accuracy: 0.1540\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.7005 - accuracy: 0.6286 - val_loss: 15.1697 - val_accuracy: 0.1502\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.6978 - accuracy: 0.6227 - val_loss: 14.6111 - val_accuracy: 0.1458\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7152 - accuracy: 0.6211 - val_loss: 11.2358 - val_accuracy: 0.1559\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6792 - accuracy: 0.6265 - val_loss: 22.5307 - val_accuracy: 0.1445\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.6626 - accuracy: 0.6289 - val_loss: 13.5012 - val_accuracy: 0.1531\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.6503 - accuracy: 0.6314 - val_loss: 29.7355 - val_accuracy: 0.1536\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6051 - accuracy: 0.6350 - val_loss: 14.8868 - val_accuracy: 0.1509\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.6278 - accuracy: 0.6296 - val_loss: 10.5392 - val_accuracy: 0.1587\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6175 - accuracy: 0.6298 - val_loss: 13.3729 - val_accuracy: 0.1555\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.6170 - accuracy: 0.6336 - val_loss: 43.7917 - val_accuracy: 0.1416\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6284 - accuracy: 0.6324 - val_loss: 16.6140 - val_accuracy: 0.1580\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.6430 - accuracy: 0.6292 - val_loss: 12.8781 - val_accuracy: 0.1532\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.6524 - accuracy: 0.6290 - val_loss: 12.0009 - val_accuracy: 0.1614\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.6526 - accuracy: 0.6315 - val_loss: 11.5009 - val_accuracy: 0.1608\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.6018 - accuracy: 0.6338 - val_loss: 12.5715 - val_accuracy: 0.1521\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.6181 - accuracy: 0.6337 - val_loss: 12.8250 - val_accuracy: 0.1551\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.6328 - accuracy: 0.6266 - val_loss: 10.9965 - val_accuracy: 0.1648\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.6064 - accuracy: 0.6367 - val_loss: 29.6651 - val_accuracy: 0.1584\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6469 - accuracy: 0.6306 - val_loss: 13.4169 - val_accuracy: 0.1440\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.6400 - accuracy: 0.6331 - val_loss: 20.5765 - val_accuracy: 0.1613\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.6096 - accuracy: 0.6326 - val_loss: 11.4275 - val_accuracy: 0.1528\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6029 - accuracy: 0.6332 - val_loss: 10.5932 - val_accuracy: 0.1618\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6400 - accuracy: 0.6305 - val_loss: 11.7391 - val_accuracy: 0.1518\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6413 - accuracy: 0.6278 - val_loss: 12.3640 - val_accuracy: 0.1504\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.6057 - accuracy: 0.6359 - val_loss: 11.7753 - val_accuracy: 0.1546\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6087 - accuracy: 0.6349 - val_loss: 11.9938 - val_accuracy: 0.1624\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5912 - accuracy: 0.6349 - val_loss: 20.6085 - val_accuracy: 0.1603\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6090 - accuracy: 0.6305 - val_loss: 22.6742 - val_accuracy: 0.1549\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.6236 - accuracy: 0.6316 - val_loss: 16.0710 - val_accuracy: 0.1460\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5785 - accuracy: 0.6368 - val_loss: 10.4884 - val_accuracy: 0.1558\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5741 - accuracy: 0.6361 - val_loss: 11.9570 - val_accuracy: 0.1509\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.5550 - accuracy: 0.6401 - val_loss: 12.2282 - val_accuracy: 0.1432\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6205 - accuracy: 0.6311 - val_loss: 14.2827 - val_accuracy: 0.1411\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.6452 - accuracy: 0.6349 - val_loss: 12.4677 - val_accuracy: 0.1449\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5974 - accuracy: 0.6375 - val_loss: 13.5136 - val_accuracy: 0.1492\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.6007 - accuracy: 0.6306 - val_loss: 10.4233 - val_accuracy: 0.1441\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5438 - accuracy: 0.6428 - val_loss: 11.6243 - val_accuracy: 0.1530\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.6144 - accuracy: 0.6364 - val_loss: 12.3889 - val_accuracy: 0.1436\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.5512 - accuracy: 0.6436 - val_loss: 72.0086 - val_accuracy: 0.1457\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.5572 - accuracy: 0.6399 - val_loss: 12.7815 - val_accuracy: 0.1458\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6124 - accuracy: 0.6326 - val_loss: 13.5361 - val_accuracy: 0.1525\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.5638 - accuracy: 0.6381 - val_loss: 11.2621 - val_accuracy: 0.1437\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.5772 - accuracy: 0.6387 - val_loss: 12.6650 - val_accuracy: 0.1512\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5920 - accuracy: 0.6313 - val_loss: 18.9802 - val_accuracy: 0.1362\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.5693 - accuracy: 0.6380 - val_loss: 10.5031 - val_accuracy: 0.1487\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.5171 - accuracy: 0.6435 - val_loss: 11.9568 - val_accuracy: 0.1463\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5440 - accuracy: 0.6412 - val_loss: 13.0831 - val_accuracy: 0.1427\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.5163 - accuracy: 0.6463 - val_loss: 12.4350 - val_accuracy: 0.1414\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.5296 - accuracy: 0.6413 - val_loss: 11.2499 - val_accuracy: 0.1466\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5351 - accuracy: 0.6364 - val_loss: 10.9546 - val_accuracy: 0.1438\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5268 - accuracy: 0.6425 - val_loss: 15.0648 - val_accuracy: 0.1366\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5312 - accuracy: 0.6390 - val_loss: 11.0612 - val_accuracy: 0.1443\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.6854 - accuracy: 0.6337 - val_loss: 29.3235 - val_accuracy: 0.1338\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.7249 - accuracy: 0.6345 - val_loss: 21.1404 - val_accuracy: 0.1324\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.6798 - accuracy: 0.6284 - val_loss: 13.2246 - val_accuracy: 0.1410\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.6179 - accuracy: 0.6357 - val_loss: 10.8149 - val_accuracy: 0.1426\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5844 - accuracy: 0.6356 - val_loss: 13.7353 - val_accuracy: 0.1419\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5884 - accuracy: 0.6325 - val_loss: 12.7111 - val_accuracy: 0.1395\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5529 - accuracy: 0.6364 - val_loss: 11.3374 - val_accuracy: 0.1446\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5420 - accuracy: 0.6404 - val_loss: 11.7946 - val_accuracy: 0.1417\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5605 - accuracy: 0.6399 - val_loss: 12.0695 - val_accuracy: 0.1483\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.5636 - accuracy: 0.6343 - val_loss: 14.8720 - val_accuracy: 0.1388\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5436 - accuracy: 0.6410 - val_loss: 14.7818 - val_accuracy: 0.1395\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5378 - accuracy: 0.6395 - val_loss: 14.5702 - val_accuracy: 0.1443\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.5718 - accuracy: 0.6409 - val_loss: 17.5956 - val_accuracy: 0.1349\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5441 - accuracy: 0.6394 - val_loss: 17.0921 - val_accuracy: 0.1336\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.5531 - accuracy: 0.6361 - val_loss: 15.6742 - val_accuracy: 0.1368\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5261 - accuracy: 0.6369 - val_loss: 14.9459 - val_accuracy: 0.1406\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.5224 - accuracy: 0.6415 - val_loss: 18.8252 - val_accuracy: 0.1358\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5289 - accuracy: 0.6421 - val_loss: 20.8074 - val_accuracy: 0.1384\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5570 - accuracy: 0.6364 - val_loss: 18.2920 - val_accuracy: 0.1390\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5165 - accuracy: 0.6419 - val_loss: 22.8614 - val_accuracy: 0.1331\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5340 - accuracy: 0.6429 - val_loss: 16.9619 - val_accuracy: 0.1341\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.5165 - accuracy: 0.6412 - val_loss: 13.1296 - val_accuracy: 0.1406\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.5149 - accuracy: 0.6431 - val_loss: 20.1386 - val_accuracy: 0.1377\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5562 - accuracy: 0.6433 - val_loss: 23.7659 - val_accuracy: 0.1346\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5658 - accuracy: 0.6401 - val_loss: 14.4674 - val_accuracy: 0.1415\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5351 - accuracy: 0.6433 - val_loss: 18.5072 - val_accuracy: 0.1453\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4897 - accuracy: 0.6443 - val_loss: 21.0971 - val_accuracy: 0.1310\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5417 - accuracy: 0.6477 - val_loss: 17.9425 - val_accuracy: 0.1349\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.5377 - accuracy: 0.6430 - val_loss: 24.5315 - val_accuracy: 0.1462\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5107 - accuracy: 0.6447 - val_loss: 19.5426 - val_accuracy: 0.1405\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5128 - accuracy: 0.6368 - val_loss: 15.6389 - val_accuracy: 0.1444\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5594 - accuracy: 0.6415 - val_loss: 14.9577 - val_accuracy: 0.1428\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5199 - accuracy: 0.6353 - val_loss: 12.8384 - val_accuracy: 0.1516\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4861 - accuracy: 0.6445 - val_loss: 19.9469 - val_accuracy: 0.1429\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.5112 - accuracy: 0.6460 - val_loss: 13.6231 - val_accuracy: 0.1480\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5417 - accuracy: 0.6369 - val_loss: 10.2242 - val_accuracy: 0.1515\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4922 - accuracy: 0.6490 - val_loss: 13.8895 - val_accuracy: 0.1481\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4996 - accuracy: 0.6457 - val_loss: 15.8737 - val_accuracy: 0.1459\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4998 - accuracy: 0.6445 - val_loss: 17.5451 - val_accuracy: 0.1484\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.4525 - accuracy: 0.6478 - val_loss: 31.9956 - val_accuracy: 0.1392\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.4673 - accuracy: 0.6414 - val_loss: 26.3705 - val_accuracy: 0.1479\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4745 - accuracy: 0.6463 - val_loss: 36.9913 - val_accuracy: 0.1392\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4419 - accuracy: 0.6444 - val_loss: 15.2193 - val_accuracy: 0.1473\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4644 - accuracy: 0.6473 - val_loss: 20.1541 - val_accuracy: 0.1432\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4739 - accuracy: 0.6415 - val_loss: 19.1593 - val_accuracy: 0.1487\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.4929 - accuracy: 0.6419 - val_loss: 11.7476 - val_accuracy: 0.1530\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.4590 - accuracy: 0.6524 - val_loss: 13.6703 - val_accuracy: 0.1509\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.4588 - accuracy: 0.6518 - val_loss: 17.2795 - val_accuracy: 0.1472\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.4493 - accuracy: 0.6495 - val_loss: 18.9128 - val_accuracy: 0.1480\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4224 - accuracy: 0.6521 - val_loss: 12.8172 - val_accuracy: 0.1548\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4618 - accuracy: 0.6520 - val_loss: 14.9792 - val_accuracy: 0.1498\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4689 - accuracy: 0.6445 - val_loss: 14.8627 - val_accuracy: 0.1507\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.5385 - accuracy: 0.6486 - val_loss: 14.3163 - val_accuracy: 0.1645\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4705 - accuracy: 0.6450 - val_loss: 10.7631 - val_accuracy: 0.1664\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4479 - accuracy: 0.6530 - val_loss: 10.4169 - val_accuracy: 0.1578\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4601 - accuracy: 0.6467 - val_loss: 13.6987 - val_accuracy: 0.1568\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.4304 - accuracy: 0.6492 - val_loss: 16.8411 - val_accuracy: 0.1518\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.4584 - accuracy: 0.6507 - val_loss: 16.4867 - val_accuracy: 0.1537\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.4408 - accuracy: 0.6489 - val_loss: 13.2363 - val_accuracy: 0.1562\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4942 - accuracy: 0.6404 - val_loss: 16.1027 - val_accuracy: 0.1428\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4530 - accuracy: 0.6516 - val_loss: 26.5064 - val_accuracy: 0.1302\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.4551 - accuracy: 0.6461 - val_loss: 24.4013 - val_accuracy: 0.1360\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4262 - accuracy: 0.6502 - val_loss: 23.7075 - val_accuracy: 0.1394\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4707 - accuracy: 0.6477 - val_loss: 20.7752 - val_accuracy: 0.1432\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4645 - accuracy: 0.6459 - val_loss: 32.9502 - val_accuracy: 0.1373\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.4726 - accuracy: 0.6460 - val_loss: 39.2863 - val_accuracy: 0.1379\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.4369 - accuracy: 0.6498 - val_loss: 39.8875 - val_accuracy: 0.1385\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5027 - accuracy: 0.6441 - val_loss: 19.2065 - val_accuracy: 0.1413\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4510 - accuracy: 0.6425 - val_loss: 57.5874 - val_accuracy: 0.1380\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4374 - accuracy: 0.6542 - val_loss: 27.8408 - val_accuracy: 0.1394\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4625 - accuracy: 0.6428 - val_loss: 31.4793 - val_accuracy: 0.1330\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4198 - accuracy: 0.6546 - val_loss: 23.5491 - val_accuracy: 0.1400\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4489 - accuracy: 0.6460 - val_loss: 26.7082 - val_accuracy: 0.1361\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4523 - accuracy: 0.6482 - val_loss: 28.6944 - val_accuracy: 0.1432\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4323 - accuracy: 0.6474 - val_loss: 17.2283 - val_accuracy: 0.1465\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.4637 - accuracy: 0.6453 - val_loss: 22.6294 - val_accuracy: 0.1525\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4145 - accuracy: 0.6507 - val_loss: 16.1355 - val_accuracy: 0.1469\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.4307 - accuracy: 0.6523 - val_loss: 22.9462 - val_accuracy: 0.1374\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4903 - accuracy: 0.6418 - val_loss: 26.0871 - val_accuracy: 0.1414\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.4295 - accuracy: 0.6505 - val_loss: 18.0902 - val_accuracy: 0.1400\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 4s 231ms/step - loss: 1.4331 - accuracy: 0.6454 - val_loss: 18.9977 - val_accuracy: 0.1376\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.4498 - accuracy: 0.6452 - val_loss: 21.2197 - val_accuracy: 0.1366\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 4s 231ms/step - loss: 1.4375 - accuracy: 0.6493 - val_loss: 20.9420 - val_accuracy: 0.1396\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 1.4244 - accuracy: 0.6480 - val_loss: 25.8400 - val_accuracy: 0.1250\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.4373 - accuracy: 0.6517 - val_loss: 26.9555 - val_accuracy: 0.1312\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.3934 - accuracy: 0.6552 - val_loss: 19.1979 - val_accuracy: 0.1451\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.4624 - accuracy: 0.6491 - val_loss: 34.4375 - val_accuracy: 0.1289\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.5054 - accuracy: 0.6484 - val_loss: 17.5678 - val_accuracy: 0.1408\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4850 - accuracy: 0.6484 - val_loss: 18.1562 - val_accuracy: 0.1437\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4482 - accuracy: 0.6524 - val_loss: 18.2797 - val_accuracy: 0.1324\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4687 - accuracy: 0.6464 - val_loss: 15.7734 - val_accuracy: 0.1374\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4616 - accuracy: 0.6469 - val_loss: 17.3907 - val_accuracy: 0.1383\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4459 - accuracy: 0.6497 - val_loss: 19.3101 - val_accuracy: 0.1321\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4251 - accuracy: 0.6550 - val_loss: 18.5323 - val_accuracy: 0.1363\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3970 - accuracy: 0.6535 - val_loss: 22.0406 - val_accuracy: 0.1289\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4295 - accuracy: 0.6481 - val_loss: 38.0301 - val_accuracy: 0.1323\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4038 - accuracy: 0.6524 - val_loss: 45.0803 - val_accuracy: 0.1281\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4143 - accuracy: 0.6550 - val_loss: 24.6456 - val_accuracy: 0.1334\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4813 - accuracy: 0.6456 - val_loss: 19.7455 - val_accuracy: 0.1308\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4571 - accuracy: 0.6497 - val_loss: 14.8302 - val_accuracy: 0.1441\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4237 - accuracy: 0.6513 - val_loss: 15.9242 - val_accuracy: 0.1408\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4200 - accuracy: 0.6493 - val_loss: 29.7655 - val_accuracy: 0.1265\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4470 - accuracy: 0.6482 - val_loss: 10.5812 - val_accuracy: 0.1552\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4367 - accuracy: 0.6493 - val_loss: 19.2363 - val_accuracy: 0.1334\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4555 - accuracy: 0.6487 - val_loss: 12.9759 - val_accuracy: 0.1441\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.3984 - accuracy: 0.6546 - val_loss: 15.0486 - val_accuracy: 0.1389\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3920 - accuracy: 0.6517 - val_loss: 25.1241 - val_accuracy: 0.1305\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4111 - accuracy: 0.6541 - val_loss: 28.6699 - val_accuracy: 0.1272\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.4077 - accuracy: 0.6519 - val_loss: 22.9515 - val_accuracy: 0.1367\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3509 - accuracy: 0.6595 - val_loss: 26.9077 - val_accuracy: 0.1322\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3582 - accuracy: 0.6574 - val_loss: 14.8826 - val_accuracy: 0.1422\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4000 - accuracy: 0.6515 - val_loss: 15.8119 - val_accuracy: 0.1413\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4120 - accuracy: 0.6537 - val_loss: 18.3059 - val_accuracy: 0.1349\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3992 - accuracy: 0.6552 - val_loss: 16.6904 - val_accuracy: 0.1332\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4168 - accuracy: 0.6508 - val_loss: 20.7273 - val_accuracy: 0.1307\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3769 - accuracy: 0.6556 - val_loss: 26.9727 - val_accuracy: 0.1340\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3745 - accuracy: 0.6546 - val_loss: 29.8345 - val_accuracy: 0.1355\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3808 - accuracy: 0.6559 - val_loss: 39.4490 - val_accuracy: 0.1284\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4077 - accuracy: 0.6539 - val_loss: 17.4696 - val_accuracy: 0.1388\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.3776 - accuracy: 0.6583 - val_loss: 27.7167 - val_accuracy: 0.1326\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3760 - accuracy: 0.6566 - val_loss: 33.7068 - val_accuracy: 0.1390\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4332 - accuracy: 0.6488 - val_loss: 20.7322 - val_accuracy: 0.1409\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4025 - accuracy: 0.6502 - val_loss: 16.5350 - val_accuracy: 0.1448\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3749 - accuracy: 0.6573 - val_loss: 20.6126 - val_accuracy: 0.1413\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3694 - accuracy: 0.6565 - val_loss: 40.6908 - val_accuracy: 0.1338\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3934 - accuracy: 0.6595 - val_loss: 17.6915 - val_accuracy: 0.1421\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.3877 - accuracy: 0.6519 - val_loss: 17.3931 - val_accuracy: 0.1348\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.3822 - accuracy: 0.6539 - val_loss: 19.0364 - val_accuracy: 0.1353\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.3487 - accuracy: 0.6612 - val_loss: 14.6406 - val_accuracy: 0.1458\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4131 - accuracy: 0.6498 - val_loss: 19.9173 - val_accuracy: 0.1391\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4382 - accuracy: 0.6537 - val_loss: 12.6698 - val_accuracy: 0.1518\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3641 - accuracy: 0.6585 - val_loss: 14.6159 - val_accuracy: 0.1366\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.4020 - accuracy: 0.6503 - val_loss: 17.5673 - val_accuracy: 0.1434\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3747 - accuracy: 0.6551 - val_loss: 19.9030 - val_accuracy: 0.1410\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3977 - accuracy: 0.6505 - val_loss: 12.2969 - val_accuracy: 0.1464\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3924 - accuracy: 0.6531 - val_loss: 15.0331 - val_accuracy: 0.1494\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3446 - accuracy: 0.6580 - val_loss: 15.3519 - val_accuracy: 0.1464\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3369 - accuracy: 0.6611 - val_loss: 12.3361 - val_accuracy: 0.1415\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3970 - accuracy: 0.6532 - val_loss: 16.0631 - val_accuracy: 0.1393\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3914 - accuracy: 0.6565 - val_loss: 15.6136 - val_accuracy: 0.1436\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3526 - accuracy: 0.6551 - val_loss: 18.6315 - val_accuracy: 0.1385\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3467 - accuracy: 0.6581 - val_loss: 26.1462 - val_accuracy: 0.1343\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3545 - accuracy: 0.6542 - val_loss: 19.5647 - val_accuracy: 0.1454\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3927 - accuracy: 0.6566 - val_loss: 13.3825 - val_accuracy: 0.1513\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3339 - accuracy: 0.6600 - val_loss: 33.7001 - val_accuracy: 0.1372\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3462 - accuracy: 0.6599 - val_loss: 16.8901 - val_accuracy: 0.1405\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 9s 575ms/step - loss: 1.4336 - accuracy: 0.6536 - val_loss: 13.4543 - val_accuracy: 0.1380\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3777 - accuracy: 0.6580 - val_loss: 21.1541 - val_accuracy: 0.1421\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.3399 - accuracy: 0.6577 - val_loss: 20.4165 - val_accuracy: 0.1328\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3088 - accuracy: 0.6665 - val_loss: 19.4536 - val_accuracy: 0.1305\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3470 - accuracy: 0.6588 - val_loss: 22.8719 - val_accuracy: 0.1348\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3395 - accuracy: 0.6612 - val_loss: 18.1798 - val_accuracy: 0.1466\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3405 - accuracy: 0.6600 - val_loss: 18.4085 - val_accuracy: 0.1385\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4007 - accuracy: 0.6536 - val_loss: 15.6220 - val_accuracy: 0.1463\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3290 - accuracy: 0.6594 - val_loss: 19.4394 - val_accuracy: 0.1401\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.3363 - accuracy: 0.6651 - val_loss: 18.9579 - val_accuracy: 0.1363\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.3426 - accuracy: 0.6605 - val_loss: 21.3096 - val_accuracy: 0.1361\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3655 - accuracy: 0.6573 - val_loss: 20.6546 - val_accuracy: 0.1391\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3425 - accuracy: 0.6580 - val_loss: 17.9797 - val_accuracy: 0.1398\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3611 - accuracy: 0.6631 - val_loss: 16.7882 - val_accuracy: 0.1404\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3463 - accuracy: 0.6624 - val_loss: 16.7784 - val_accuracy: 0.1462\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3516 - accuracy: 0.6566 - val_loss: 18.1690 - val_accuracy: 0.1460\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3783 - accuracy: 0.6540 - val_loss: 20.6230 - val_accuracy: 0.1451\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3523 - accuracy: 0.6598 - val_loss: 18.7094 - val_accuracy: 0.1432\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3365 - accuracy: 0.6587 - val_loss: 15.1069 - val_accuracy: 0.1468\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3397 - accuracy: 0.6607 - val_loss: 15.9966 - val_accuracy: 0.1456\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3616 - accuracy: 0.6549 - val_loss: 15.8202 - val_accuracy: 0.1382\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3591 - accuracy: 0.6597 - val_loss: 16.1357 - val_accuracy: 0.1427\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3487 - accuracy: 0.6591 - val_loss: 17.2529 - val_accuracy: 0.1393\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3141 - accuracy: 0.6657 - val_loss: 20.8251 - val_accuracy: 0.1430\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3258 - accuracy: 0.6617 - val_loss: 19.1353 - val_accuracy: 0.1387\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3194 - accuracy: 0.6565 - val_loss: 16.3722 - val_accuracy: 0.1447\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3497 - accuracy: 0.6605 - val_loss: 13.6695 - val_accuracy: 0.1572\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3735 - accuracy: 0.6604 - val_loss: 13.0004 - val_accuracy: 0.1504\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3645 - accuracy: 0.6601 - val_loss: 17.5243 - val_accuracy: 0.1379\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3728 - accuracy: 0.6571 - val_loss: 12.8202 - val_accuracy: 0.1563\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3513 - accuracy: 0.6587 - val_loss: 13.2444 - val_accuracy: 0.1466\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3348 - accuracy: 0.6626 - val_loss: 22.4225 - val_accuracy: 0.1411\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3140 - accuracy: 0.6599 - val_loss: 34.9305 - val_accuracy: 0.1363\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3456 - accuracy: 0.6579 - val_loss: 18.2673 - val_accuracy: 0.1456\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3502 - accuracy: 0.6558 - val_loss: 21.0826 - val_accuracy: 0.1450\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3390 - accuracy: 0.6578 - val_loss: 18.7844 - val_accuracy: 0.1341\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3331 - accuracy: 0.6588 - val_loss: 17.5245 - val_accuracy: 0.1439\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3626 - accuracy: 0.6564 - val_loss: 20.7583 - val_accuracy: 0.1490\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3519 - accuracy: 0.6581 - val_loss: 25.3146 - val_accuracy: 0.1421\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3300 - accuracy: 0.6635 - val_loss: 16.9850 - val_accuracy: 0.1493\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3114 - accuracy: 0.6636 - val_loss: 19.4247 - val_accuracy: 0.1377\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3051 - accuracy: 0.6609 - val_loss: 19.8374 - val_accuracy: 0.1428\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3267 - accuracy: 0.6635 - val_loss: 21.7322 - val_accuracy: 0.1333\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3140 - accuracy: 0.6651 - val_loss: 28.8938 - val_accuracy: 0.1353\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.3005 - accuracy: 0.6641 - val_loss: 17.0148 - val_accuracy: 0.1493\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3239 - accuracy: 0.6629 - val_loss: 41.7571 - val_accuracy: 0.1309\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3438 - accuracy: 0.6619 - val_loss: 24.4249 - val_accuracy: 0.1357\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3343 - accuracy: 0.6577 - val_loss: 33.1935 - val_accuracy: 0.1318\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3208 - accuracy: 0.6585 - val_loss: 31.5296 - val_accuracy: 0.1302\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.2995 - accuracy: 0.6661 - val_loss: 65.2039 - val_accuracy: 0.1316\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3384 - accuracy: 0.6634 - val_loss: 49.4422 - val_accuracy: 0.1259\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3296 - accuracy: 0.6601 - val_loss: 45.0652 - val_accuracy: 0.1334\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.5173 - accuracy: 0.6400 - val_loss: 20.1187 - val_accuracy: 0.1391\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.5770 - accuracy: 0.5020 - val_loss: 109706768.0000 - val_accuracy: 0.0994\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.9029 - accuracy: 0.4878 - val_loss: 3846.0938 - val_accuracy: 0.1028\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.5029 - accuracy: 0.5126 - val_loss: 23.7797 - val_accuracy: 0.0872\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.3105 - accuracy: 0.5672 - val_loss: 13.4584 - val_accuracy: 0.1231\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.3045 - accuracy: 0.5908 - val_loss: 14.1115 - val_accuracy: 0.1250\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.2612 - accuracy: 0.5927 - val_loss: 13.4691 - val_accuracy: 0.1230\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2135 - accuracy: 0.5999 - val_loss: 13.5897 - val_accuracy: 0.1159\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1710 - accuracy: 0.6057 - val_loss: 14.5312 - val_accuracy: 0.1116\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2364 - accuracy: 0.6092 - val_loss: 13.4256 - val_accuracy: 0.1173\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.2419 - accuracy: 0.6099 - val_loss: 12.9490 - val_accuracy: 0.1169\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1641 - accuracy: 0.6114 - val_loss: 14.7746 - val_accuracy: 0.1160\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 2.2103 - accuracy: 0.6120 - val_loss: 13.7300 - val_accuracy: 0.1197\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 2.1949 - accuracy: 0.6116 - val_loss: 12.9308 - val_accuracy: 0.1235\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.2035 - accuracy: 0.6163 - val_loss: 13.3144 - val_accuracy: 0.1257\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1566 - accuracy: 0.6168 - val_loss: 13.0757 - val_accuracy: 0.1220\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1453 - accuracy: 0.6184 - val_loss: 12.5460 - val_accuracy: 0.1266\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1491 - accuracy: 0.6181 - val_loss: 12.8930 - val_accuracy: 0.1262\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1859 - accuracy: 0.6144 - val_loss: 12.2700 - val_accuracy: 0.1249\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1537 - accuracy: 0.6166 - val_loss: 11.5478 - val_accuracy: 0.1275\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.1886 - accuracy: 0.6203 - val_loss: 12.2159 - val_accuracy: 0.1229\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1554 - accuracy: 0.6218 - val_loss: 14.1669 - val_accuracy: 0.1282\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1169 - accuracy: 0.6196 - val_loss: 15.1996 - val_accuracy: 0.1281\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1427 - accuracy: 0.6160 - val_loss: 14.3911 - val_accuracy: 0.1230\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1346 - accuracy: 0.6166 - val_loss: 14.5812 - val_accuracy: 0.1256\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2276 - accuracy: 0.6135 - val_loss: 14.8740 - val_accuracy: 0.1355\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.1226 - accuracy: 0.6194 - val_loss: 13.9955 - val_accuracy: 0.1327\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1071 - accuracy: 0.6185 - val_loss: 16.7948 - val_accuracy: 0.1369\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1586 - accuracy: 0.6198 - val_loss: 15.8342 - val_accuracy: 0.1383\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.1428 - accuracy: 0.6149 - val_loss: 15.6588 - val_accuracy: 0.1357\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.1541 - accuracy: 0.6134 - val_loss: 15.0437 - val_accuracy: 0.1372\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.1053 - accuracy: 0.6195 - val_loss: 15.9931 - val_accuracy: 0.1401\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1362 - accuracy: 0.6195 - val_loss: 18.9852 - val_accuracy: 0.1427\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1803 - accuracy: 0.6181 - val_loss: 17.4495 - val_accuracy: 0.1446\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0992 - accuracy: 0.6200 - val_loss: 16.0756 - val_accuracy: 0.1434\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1873 - accuracy: 0.6149 - val_loss: 15.8950 - val_accuracy: 0.1409\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 12s 733ms/step - loss: 2.1294 - accuracy: 0.6218 - val_loss: 20.5295 - val_accuracy: 0.1426\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1379 - accuracy: 0.6206 - val_loss: 20.1311 - val_accuracy: 0.1447\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.2147 - accuracy: 0.6155 - val_loss: 19.6760 - val_accuracy: 0.1455\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.1303 - accuracy: 0.6177 - val_loss: 138.0018 - val_accuracy: 0.1476\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1721 - accuracy: 0.6051 - val_loss: 67.1684 - val_accuracy: 0.1414\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.2550 - accuracy: 0.5982 - val_loss: 17.9001 - val_accuracy: 0.1562\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.2937 - accuracy: 0.6147 - val_loss: 26.3877 - val_accuracy: 0.1406\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.2545 - accuracy: 0.6030 - val_loss: 22.2777 - val_accuracy: 0.1515\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.2109 - accuracy: 0.6081 - val_loss: 22.2268 - val_accuracy: 0.1483\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 2.2080 - accuracy: 0.6136 - val_loss: 18.3491 - val_accuracy: 0.1475\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1842 - accuracy: 0.6133 - val_loss: 18.9506 - val_accuracy: 0.1442\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.2072 - accuracy: 0.6126 - val_loss: 18.0752 - val_accuracy: 0.1465\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1566 - accuracy: 0.6144 - val_loss: 19.3183 - val_accuracy: 0.1486\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0861 - accuracy: 0.6201 - val_loss: 19.9121 - val_accuracy: 0.1483\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.1768 - accuracy: 0.6116 - val_loss: 18.2587 - val_accuracy: 0.1489\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1665 - accuracy: 0.6130 - val_loss: 18.3300 - val_accuracy: 0.1516\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1536 - accuracy: 0.6148 - val_loss: 20.6270 - val_accuracy: 0.1532\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1226 - accuracy: 0.6148 - val_loss: 20.4115 - val_accuracy: 0.1507\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 2.1253 - accuracy: 0.6172 - val_loss: 21.3138 - val_accuracy: 0.1546\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1569 - accuracy: 0.6146 - val_loss: 19.8439 - val_accuracy: 0.1552\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1040 - accuracy: 0.6169 - val_loss: 26.5070 - val_accuracy: 0.1500\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1329 - accuracy: 0.6170 - val_loss: 30.5068 - val_accuracy: 0.1496\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1517 - accuracy: 0.6136 - val_loss: 18.3319 - val_accuracy: 0.1571\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1061 - accuracy: 0.6139 - val_loss: 20.1191 - val_accuracy: 0.1543\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1670 - accuracy: 0.6173 - val_loss: 19.4424 - val_accuracy: 0.1526\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1072 - accuracy: 0.6121 - val_loss: 19.2373 - val_accuracy: 0.1570\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0831 - accuracy: 0.6173 - val_loss: 18.9830 - val_accuracy: 0.1538\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1559 - accuracy: 0.6063 - val_loss: 22.4466 - val_accuracy: 0.1566\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1407 - accuracy: 0.6174 - val_loss: 20.8574 - val_accuracy: 0.1545\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1522 - accuracy: 0.6168 - val_loss: 18.2751 - val_accuracy: 0.1536\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1383 - accuracy: 0.6156 - val_loss: 18.7701 - val_accuracy: 0.1595\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1555 - accuracy: 0.6135 - val_loss: 20.9517 - val_accuracy: 0.1545\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1387 - accuracy: 0.6159 - val_loss: 20.1277 - val_accuracy: 0.1527\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0455 - accuracy: 0.6180 - val_loss: 18.5054 - val_accuracy: 0.1555\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1182 - accuracy: 0.6155 - val_loss: 19.7594 - val_accuracy: 0.1551\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0840 - accuracy: 0.6187 - val_loss: 19.6916 - val_accuracy: 0.1552\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0538 - accuracy: 0.6222 - val_loss: 23.3660 - val_accuracy: 0.1544\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1051 - accuracy: 0.6166 - val_loss: 18.7972 - val_accuracy: 0.1547\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0649 - accuracy: 0.6163 - val_loss: 19.9680 - val_accuracy: 0.1539\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1113 - accuracy: 0.6118 - val_loss: 21.5837 - val_accuracy: 0.1549\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0526 - accuracy: 0.6230 - val_loss: 20.2720 - val_accuracy: 0.1535\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.1464 - accuracy: 0.6139 - val_loss: 23.1011 - val_accuracy: 0.1567\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0856 - accuracy: 0.6179 - val_loss: 22.4245 - val_accuracy: 0.1514\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0502 - accuracy: 0.6203 - val_loss: 55.5131 - val_accuracy: 0.1523\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0596 - accuracy: 0.6168 - val_loss: 21.9474 - val_accuracy: 0.1539\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0980 - accuracy: 0.6081 - val_loss: 31.1374 - val_accuracy: 0.1543\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1187 - accuracy: 0.6135 - val_loss: 22.2040 - val_accuracy: 0.1547\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0492 - accuracy: 0.6192 - val_loss: 20.8892 - val_accuracy: 0.1565\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.0925 - accuracy: 0.6161 - val_loss: 26.2205 - val_accuracy: 0.1528\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0847 - accuracy: 0.6179 - val_loss: 19.6894 - val_accuracy: 0.1551\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0096 - accuracy: 0.6234 - val_loss: 22.0821 - val_accuracy: 0.1545\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0220 - accuracy: 0.6167 - val_loss: 20.7016 - val_accuracy: 0.1556\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0716 - accuracy: 0.6203 - val_loss: 18.7602 - val_accuracy: 0.1561\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0686 - accuracy: 0.6189 - val_loss: 79.4149 - val_accuracy: 0.1544\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0079 - accuracy: 0.6241 - val_loss: 25.7367 - val_accuracy: 0.1545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xwz6XVxTCbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}