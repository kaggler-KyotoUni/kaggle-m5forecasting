{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureCreation_For_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1mJs9d9G9vQ866wPPFiFdcPvpto6UnD1I",
      "authorship_tag": "ABX9TyNZTBowiBifPW9wltlPdaoi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaggler-KyotoUni/kaggle-m5forecasting/blob/potedo_branch/FeatureCreation_For_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq7j6-Ba649p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import os \n",
        "from itertools import cycle\n",
        "color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7YD3eY4AvAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIR = \"./drive/My Drive/kaggle/m5-forecasting/datas\"\n",
        "\n",
        "def read_data():\n",
        "    cal = pd.read_csv(f\"{INPUT_DIR}/calendar.csv\")\n",
        "    stv = pd.read_csv(f\"{INPUT_DIR}/sales_train_validation.csv\")\n",
        "    ste = pd.read_csv(f\"{INPUT_DIR}/sales_train_evaluation.csv\")\n",
        "    ss = pd.read_csv(f\"{INPUT_DIR}/sample_submission.csv\")\n",
        "    sellp = pd.read_csv(f\"{INPUT_DIR}/sell_prices.csv\")\n",
        "    \n",
        "    return cal, stv, ste, ss, sellp"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C2uBW94Awel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    \"\"\"\n",
        "    目的：メモリサイズの削減\n",
        "    df: メモリを削減したい DataFrame (pandas.DataFrame)\n",
        "    verbose: 実行時に、メモリ削減の情報を出力するかどうかを指定(bool)\n",
        "\n",
        "    ■ 基本思想\n",
        "    【前提知識】\n",
        "    pandas で作成したデータフレームのうち数値データは、特に dtype を指定しない場合\n",
        "    int64 または float64 でデータを作成するので、\n",
        "    実際のデータよりもこの型が大きいと余計なメモリサイズを確保してしまう。\n",
        "\n",
        "    【処理内容】\n",
        "    (1) 入力された DataFrame の column の型を全てチェック(for loop)\n",
        "    (2) その型が大きい数値データ(int16~int64, float16~float64)ならば、\n",
        "        そのデータフレームの最大値・最小値をチェック。\n",
        "        現在処理中のカラムを、上記の最大値・最小値を表せる必要最低限の型に変換する。\n",
        "        int と floatに分けて処理。\n",
        "\n",
        "    ────────────────────────────────────────────────────────────────────────\n",
        "    【変更履歴】\n",
        "    2020/06/06:\n",
        "    ■ 35行目\n",
        "    ifのネストが深かったので、リファクタ。\n",
        "    Early Continueを入れたので可読性が向上(したはず)。\n",
        "\n",
        "    ■ 46行目・71行目(置き換え・追加)\n",
        "    説明変数(関数?)で置き換え。\n",
        "    columnのtypeがintであるか否かを判定する関数を噛ませている。\n",
        "    (返り値はbool値)\n",
        "    \"\"\"\n",
        "\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    # main loop    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "\n",
        "        if col_type not in numerics: \n",
        "            continue # Early continue if column type is not numeric\n",
        "        \n",
        "        c_min = df[col].min()\n",
        "        c_max = df[col].max()\n",
        "\n",
        "        if IsInt(col_type):\n",
        "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                df[col] = df[col].astype(np.int8)\n",
        "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                df[col] = df[col].astype(np.int16)\n",
        "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                df[col] = df[col].astype(np.int32)\n",
        "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                df[col] = df[col].astype(np.int64)  \n",
        "        else:\n",
        "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                df[col] = df[col].astype(np.float16)\n",
        "            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                df[col] = df[col].astype(np.float32)\n",
        "            else:\n",
        "                df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    if verbose: \n",
        "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def IsInt(col_type):\n",
        "    return str(col_type)[:3] == 'int'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxiWVbUQBAyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cal, stv, ste, ss, sellp = read_data()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARN1fnaNBCQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "605e9966-fddc-4167-e271-f9b8a976108e"
      },
      "source": [
        "dfs = [cal, stv, ste, ss, sellp]\n",
        "for df in dfs:\n",
        "    df = reduce_mem_usage(df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
            "Mem. usage decreased to 95.00 Mb (78.7% reduction)\n",
            "Mem. usage decreased to 96.13 Mb (78.8% reduction)\n",
            "Mem. usage decreased to  2.09 Mb (84.5% reduction)\n",
            "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGPgg7SVgdko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_sales = ste\n",
        "calendar = cal\n",
        "sell_prices = pd.read_csv(f\"{INPUT_DIR}/sell_prices.csv\")\n",
        "# pd.pivot() を使うときに、メモリサイズを削減したものだとエラーになる模様。なので再度読み直し。対応策はないのか？\n",
        "submission_file = ss"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ76dAGqhkZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform(data):\n",
        "    \n",
        "    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
        "    for feature in nan_features:\n",
        "        data[feature].fillna('unknown', inplace = True)\n",
        "        \n",
        "    cat = ['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']\n",
        "    for feature in cat:\n",
        "        data[feature] = pd.get_dummies(data[feature])\n",
        "    \n",
        "    return data\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1COf0qoixLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "days = range(1, 1970)\n",
        "time_series_columns = [f'd_{i}' for i in days]\n",
        "\n",
        "event_snap_columns = ['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']\n",
        "\n",
        "transfer_cal = pd.DataFrame(calendar[event_snap_columns].values.T,\n",
        "                            index=event_snap_columns,\n",
        "                            columns=time_series_columns)\n",
        "transfer_cal = transfer_cal.fillna(0)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwD7OAXMixq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "8d77e40c-93ba-4b55-f7a8-5afc539cc94b"
      },
      "source": [
        "\"\"\"\n",
        "※注意※\n",
        "\n",
        "ここで、使用メモリを減らすためにcalenderの範囲が減らされている。\n",
        "増やすと単純に精度向上が可能？\n",
        "-> もしフルに使うと、ローカルのメモリが死ぬ\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "calendar['date'] = pd.to_datetime(calendar['date'])\n",
        "#calendar = calendar[calendar['date']>= '2014-3-15']  #reduce memory\n",
        "#calendar = calendar[calendar[\"date\"] <= \"2016-05-22\"] #eliminate evaluate date\n",
        "#使うデータを少なくします -> TrainingDataのステップ数が800になるよう設定\n",
        "calendar= transform(calendar)\n",
        "# Attempts to convert events into time series data.\n",
        "transfer_cal = pd.DataFrame(calendar[event_snap_columns + [\"date\", \"d\"]].values.T,\n",
        "                            index=event_snap_columns + [\"date\", \"d\"])\n",
        "transfer_cal"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>1929</th>\n",
              "      <th>1930</th>\n",
              "      <th>1931</th>\n",
              "      <th>1932</th>\n",
              "      <th>1933</th>\n",
              "      <th>1934</th>\n",
              "      <th>1935</th>\n",
              "      <th>1936</th>\n",
              "      <th>1937</th>\n",
              "      <th>1938</th>\n",
              "      <th>1939</th>\n",
              "      <th>1940</th>\n",
              "      <th>1941</th>\n",
              "      <th>1942</th>\n",
              "      <th>1943</th>\n",
              "      <th>1944</th>\n",
              "      <th>1945</th>\n",
              "      <th>1946</th>\n",
              "      <th>1947</th>\n",
              "      <th>1948</th>\n",
              "      <th>1949</th>\n",
              "      <th>1950</th>\n",
              "      <th>1951</th>\n",
              "      <th>1952</th>\n",
              "      <th>1953</th>\n",
              "      <th>1954</th>\n",
              "      <th>1955</th>\n",
              "      <th>1956</th>\n",
              "      <th>1957</th>\n",
              "      <th>1958</th>\n",
              "      <th>1959</th>\n",
              "      <th>1960</th>\n",
              "      <th>1961</th>\n",
              "      <th>1962</th>\n",
              "      <th>1963</th>\n",
              "      <th>1964</th>\n",
              "      <th>1965</th>\n",
              "      <th>1966</th>\n",
              "      <th>1967</th>\n",
              "      <th>1968</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>event_name_1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>event_type_1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>event_name_2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>event_type_2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>snap_CA</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>snap_TX</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>snap_WI</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>2011-01-29 00:00:00</td>\n",
              "      <td>2011-01-30 00:00:00</td>\n",
              "      <td>2011-01-31 00:00:00</td>\n",
              "      <td>2011-02-01 00:00:00</td>\n",
              "      <td>2011-02-02 00:00:00</td>\n",
              "      <td>2011-02-03 00:00:00</td>\n",
              "      <td>2011-02-04 00:00:00</td>\n",
              "      <td>2011-02-05 00:00:00</td>\n",
              "      <td>2011-02-06 00:00:00</td>\n",
              "      <td>2011-02-07 00:00:00</td>\n",
              "      <td>2011-02-08 00:00:00</td>\n",
              "      <td>2011-02-09 00:00:00</td>\n",
              "      <td>2011-02-10 00:00:00</td>\n",
              "      <td>2011-02-11 00:00:00</td>\n",
              "      <td>2011-02-12 00:00:00</td>\n",
              "      <td>2011-02-13 00:00:00</td>\n",
              "      <td>2011-02-14 00:00:00</td>\n",
              "      <td>2011-02-15 00:00:00</td>\n",
              "      <td>2011-02-16 00:00:00</td>\n",
              "      <td>2011-02-17 00:00:00</td>\n",
              "      <td>2011-02-18 00:00:00</td>\n",
              "      <td>2011-02-19 00:00:00</td>\n",
              "      <td>2011-02-20 00:00:00</td>\n",
              "      <td>2011-02-21 00:00:00</td>\n",
              "      <td>2011-02-22 00:00:00</td>\n",
              "      <td>2011-02-23 00:00:00</td>\n",
              "      <td>2011-02-24 00:00:00</td>\n",
              "      <td>2011-02-25 00:00:00</td>\n",
              "      <td>2011-02-26 00:00:00</td>\n",
              "      <td>2011-02-27 00:00:00</td>\n",
              "      <td>2011-02-28 00:00:00</td>\n",
              "      <td>2011-03-01 00:00:00</td>\n",
              "      <td>2011-03-02 00:00:00</td>\n",
              "      <td>2011-03-03 00:00:00</td>\n",
              "      <td>2011-03-04 00:00:00</td>\n",
              "      <td>2011-03-05 00:00:00</td>\n",
              "      <td>2011-03-06 00:00:00</td>\n",
              "      <td>2011-03-07 00:00:00</td>\n",
              "      <td>2011-03-08 00:00:00</td>\n",
              "      <td>2011-03-09 00:00:00</td>\n",
              "      <td>...</td>\n",
              "      <td>2016-05-11 00:00:00</td>\n",
              "      <td>2016-05-12 00:00:00</td>\n",
              "      <td>2016-05-13 00:00:00</td>\n",
              "      <td>2016-05-14 00:00:00</td>\n",
              "      <td>2016-05-15 00:00:00</td>\n",
              "      <td>2016-05-16 00:00:00</td>\n",
              "      <td>2016-05-17 00:00:00</td>\n",
              "      <td>2016-05-18 00:00:00</td>\n",
              "      <td>2016-05-19 00:00:00</td>\n",
              "      <td>2016-05-20 00:00:00</td>\n",
              "      <td>2016-05-21 00:00:00</td>\n",
              "      <td>2016-05-22 00:00:00</td>\n",
              "      <td>2016-05-23 00:00:00</td>\n",
              "      <td>2016-05-24 00:00:00</td>\n",
              "      <td>2016-05-25 00:00:00</td>\n",
              "      <td>2016-05-26 00:00:00</td>\n",
              "      <td>2016-05-27 00:00:00</td>\n",
              "      <td>2016-05-28 00:00:00</td>\n",
              "      <td>2016-05-29 00:00:00</td>\n",
              "      <td>2016-05-30 00:00:00</td>\n",
              "      <td>2016-05-31 00:00:00</td>\n",
              "      <td>2016-06-01 00:00:00</td>\n",
              "      <td>2016-06-02 00:00:00</td>\n",
              "      <td>2016-06-03 00:00:00</td>\n",
              "      <td>2016-06-04 00:00:00</td>\n",
              "      <td>2016-06-05 00:00:00</td>\n",
              "      <td>2016-06-06 00:00:00</td>\n",
              "      <td>2016-06-07 00:00:00</td>\n",
              "      <td>2016-06-08 00:00:00</td>\n",
              "      <td>2016-06-09 00:00:00</td>\n",
              "      <td>2016-06-10 00:00:00</td>\n",
              "      <td>2016-06-11 00:00:00</td>\n",
              "      <td>2016-06-12 00:00:00</td>\n",
              "      <td>2016-06-13 00:00:00</td>\n",
              "      <td>2016-06-14 00:00:00</td>\n",
              "      <td>2016-06-15 00:00:00</td>\n",
              "      <td>2016-06-16 00:00:00</td>\n",
              "      <td>2016-06-17 00:00:00</td>\n",
              "      <td>2016-06-18 00:00:00</td>\n",
              "      <td>2016-06-19 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d</th>\n",
              "      <td>d_1</td>\n",
              "      <td>d_2</td>\n",
              "      <td>d_3</td>\n",
              "      <td>d_4</td>\n",
              "      <td>d_5</td>\n",
              "      <td>d_6</td>\n",
              "      <td>d_7</td>\n",
              "      <td>d_8</td>\n",
              "      <td>d_9</td>\n",
              "      <td>d_10</td>\n",
              "      <td>d_11</td>\n",
              "      <td>d_12</td>\n",
              "      <td>d_13</td>\n",
              "      <td>d_14</td>\n",
              "      <td>d_15</td>\n",
              "      <td>d_16</td>\n",
              "      <td>d_17</td>\n",
              "      <td>d_18</td>\n",
              "      <td>d_19</td>\n",
              "      <td>d_20</td>\n",
              "      <td>d_21</td>\n",
              "      <td>d_22</td>\n",
              "      <td>d_23</td>\n",
              "      <td>d_24</td>\n",
              "      <td>d_25</td>\n",
              "      <td>d_26</td>\n",
              "      <td>d_27</td>\n",
              "      <td>d_28</td>\n",
              "      <td>d_29</td>\n",
              "      <td>d_30</td>\n",
              "      <td>d_31</td>\n",
              "      <td>d_32</td>\n",
              "      <td>d_33</td>\n",
              "      <td>d_34</td>\n",
              "      <td>d_35</td>\n",
              "      <td>d_36</td>\n",
              "      <td>d_37</td>\n",
              "      <td>d_38</td>\n",
              "      <td>d_39</td>\n",
              "      <td>d_40</td>\n",
              "      <td>...</td>\n",
              "      <td>d_1930</td>\n",
              "      <td>d_1931</td>\n",
              "      <td>d_1932</td>\n",
              "      <td>d_1933</td>\n",
              "      <td>d_1934</td>\n",
              "      <td>d_1935</td>\n",
              "      <td>d_1936</td>\n",
              "      <td>d_1937</td>\n",
              "      <td>d_1938</td>\n",
              "      <td>d_1939</td>\n",
              "      <td>d_1940</td>\n",
              "      <td>d_1941</td>\n",
              "      <td>d_1942</td>\n",
              "      <td>d_1943</td>\n",
              "      <td>d_1944</td>\n",
              "      <td>d_1945</td>\n",
              "      <td>d_1946</td>\n",
              "      <td>d_1947</td>\n",
              "      <td>d_1948</td>\n",
              "      <td>d_1949</td>\n",
              "      <td>d_1950</td>\n",
              "      <td>d_1951</td>\n",
              "      <td>d_1952</td>\n",
              "      <td>d_1953</td>\n",
              "      <td>d_1954</td>\n",
              "      <td>d_1955</td>\n",
              "      <td>d_1956</td>\n",
              "      <td>d_1957</td>\n",
              "      <td>d_1958</td>\n",
              "      <td>d_1959</td>\n",
              "      <td>d_1960</td>\n",
              "      <td>d_1961</td>\n",
              "      <td>d_1962</td>\n",
              "      <td>d_1963</td>\n",
              "      <td>d_1964</td>\n",
              "      <td>d_1965</td>\n",
              "      <td>d_1966</td>\n",
              "      <td>d_1967</td>\n",
              "      <td>d_1968</td>\n",
              "      <td>d_1969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9 rows × 1969 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                0  ...                 1968\n",
              "event_name_1                    0  ...                    0\n",
              "event_type_1                    0  ...                    0\n",
              "event_name_2                    0  ...                    0\n",
              "event_type_2                    0  ...                    1\n",
              "snap_CA                         1  ...                    1\n",
              "snap_TX                         1  ...                    1\n",
              "snap_WI                         1  ...                    1\n",
              "date          2011-01-29 00:00:00  ...  2016-06-19 00:00:00\n",
              "d                             d_1  ...               d_1969\n",
              "\n",
              "[9 rows x 1969 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i7Dh9_Di1Kc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "4d77754a-a3bb-415a-ab2d-fcab53c166d5"
      },
      "source": [
        "calendar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>weekday</th>\n",
              "      <th>wday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>d</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-30</td>\n",
              "      <td>11101</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-31</td>\n",
              "      <td>11101</td>\n",
              "      <td>Monday</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-02-01</td>\n",
              "      <td>11101</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-02-02</td>\n",
              "      <td>11101</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>2016-06-15</td>\n",
              "      <td>11620</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>d_1965</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1965</th>\n",
              "      <td>2016-06-16</td>\n",
              "      <td>11620</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>d_1966</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>2016-06-17</td>\n",
              "      <td>11620</td>\n",
              "      <td>Friday</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>d_1967</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1967</th>\n",
              "      <td>2016-06-18</td>\n",
              "      <td>11621</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>d_1968</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1968</th>\n",
              "      <td>2016-06-19</td>\n",
              "      <td>11621</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>d_1969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1969 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  wm_yr_wk    weekday  ...  snap_CA  snap_TX  snap_WI\n",
              "0    2011-01-29     11101   Saturday  ...        1        1        1\n",
              "1    2011-01-30     11101     Sunday  ...        1        1        1\n",
              "2    2011-01-31     11101     Monday  ...        1        1        1\n",
              "3    2011-02-01     11101    Tuesday  ...        0        0        1\n",
              "4    2011-02-02     11101  Wednesday  ...        0        1        0\n",
              "...         ...       ...        ...  ...      ...      ...      ...\n",
              "1964 2016-06-15     11620  Wednesday  ...        1        0        0\n",
              "1965 2016-06-16     11620   Thursday  ...        1        1        1\n",
              "1966 2016-06-17     11620     Friday  ...        1        1        1\n",
              "1967 2016-06-18     11621   Saturday  ...        1        1        1\n",
              "1968 2016-06-19     11621     Sunday  ...        1        1        1\n",
              "\n",
              "[1969 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OtzZyiEjFf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "e03d68df-6005-40e3-e069-ab41bbe5c320"
      },
      "source": [
        "pd.get_dummies(stv[\"cat_id\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FOODS</th>\n",
              "      <th>HOBBIES</th>\n",
              "      <th>HOUSEHOLD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       FOODS  HOBBIES  HOUSEHOLD\n",
              "0          0        1          0\n",
              "1          0        1          0\n",
              "2          0        1          0\n",
              "3          0        1          0\n",
              "4          0        1          0\n",
              "...      ...      ...        ...\n",
              "30485      1        0          0\n",
              "30486      1        0          0\n",
              "30487      1        0          0\n",
              "30488      1        0          0\n",
              "30489      1        0          0\n",
              "\n",
              "[30490 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFayF3ZBjdT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "b1e54f56-a922-4992-9e22-f797d1775786"
      },
      "source": [
        "pd.get_dummies(stv[\"store_id\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CA_1</th>\n",
              "      <th>CA_2</th>\n",
              "      <th>CA_3</th>\n",
              "      <th>CA_4</th>\n",
              "      <th>TX_1</th>\n",
              "      <th>TX_2</th>\n",
              "      <th>TX_3</th>\n",
              "      <th>WI_1</th>\n",
              "      <th>WI_2</th>\n",
              "      <th>WI_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       CA_1  CA_2  CA_3  CA_4  TX_1  TX_2  TX_3  WI_1  WI_2  WI_3\n",
              "0         1     0     0     0     0     0     0     0     0     0\n",
              "1         1     0     0     0     0     0     0     0     0     0\n",
              "2         1     0     0     0     0     0     0     0     0     0\n",
              "3         1     0     0     0     0     0     0     0     0     0\n",
              "4         1     0     0     0     0     0     0     0     0     0\n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
              "30485     0     0     0     0     0     0     0     0     0     1\n",
              "30486     0     0     0     0     0     0     0     0     0     1\n",
              "30487     0     0     0     0     0     0     0     0     0     1\n",
              "30488     0     0     0     0     0     0     0     0     0     1\n",
              "30489     0     0     0     0     0     0     0     0     0     1\n",
              "\n",
              "[30490 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO1fp4q5jv5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "3eded4a5-f958-4071-de5d-7b27ef0e9431"
      },
      "source": [
        "stv.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1874</th>\n",
              "      <th>d_1875</th>\n",
              "      <th>d_1876</th>\n",
              "      <th>d_1877</th>\n",
              "      <th>d_1878</th>\n",
              "      <th>d_1879</th>\n",
              "      <th>d_1880</th>\n",
              "      <th>d_1881</th>\n",
              "      <th>d_1882</th>\n",
              "      <th>d_1883</th>\n",
              "      <th>d_1884</th>\n",
              "      <th>d_1885</th>\n",
              "      <th>d_1886</th>\n",
              "      <th>d_1887</th>\n",
              "      <th>d_1888</th>\n",
              "      <th>d_1889</th>\n",
              "      <th>d_1890</th>\n",
              "      <th>d_1891</th>\n",
              "      <th>d_1892</th>\n",
              "      <th>d_1893</th>\n",
              "      <th>d_1894</th>\n",
              "      <th>d_1895</th>\n",
              "      <th>d_1896</th>\n",
              "      <th>d_1897</th>\n",
              "      <th>d_1898</th>\n",
              "      <th>d_1899</th>\n",
              "      <th>d_1900</th>\n",
              "      <th>d_1901</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1919 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id        item_id  ... d_1912 d_1913\n",
              "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  ...      1      1\n",
              "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  ...      0      0\n",
              "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  ...      1      1\n",
              "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  ...      7      2\n",
              "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  ...      2      4\n",
              "\n",
              "[5 rows x 1919 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9SdeEmjjz5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "45a4332f-6f71-45f1-a4c6-9d4387de3cc1"
      },
      "source": [
        "pd.get_dummies(stv[\"dept_id\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FOODS_1</th>\n",
              "      <th>FOODS_2</th>\n",
              "      <th>FOODS_3</th>\n",
              "      <th>HOBBIES_1</th>\n",
              "      <th>HOBBIES_2</th>\n",
              "      <th>HOUSEHOLD_1</th>\n",
              "      <th>HOUSEHOLD_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       FOODS_1  FOODS_2  FOODS_3  ...  HOBBIES_2  HOUSEHOLD_1  HOUSEHOLD_2\n",
              "0            0        0        0  ...          0            0            0\n",
              "1            0        0        0  ...          0            0            0\n",
              "2            0        0        0  ...          0            0            0\n",
              "3            0        0        0  ...          0            0            0\n",
              "4            0        0        0  ...          0            0            0\n",
              "...        ...      ...      ...  ...        ...          ...          ...\n",
              "30485        0        0        1  ...          0            0            0\n",
              "30486        0        0        1  ...          0            0            0\n",
              "30487        0        0        1  ...          0            0            0\n",
              "30488        0        0        1  ...          0            0            0\n",
              "30489        0        0        1  ...          0            0            0\n",
              "\n",
              "[30490 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFC_nBookAfT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "5319f154-c05d-444a-9612-50d1ce97a866"
      },
      "source": [
        "pd.get_dummies(stv[\"item_id\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FOODS_1_001</th>\n",
              "      <th>FOODS_1_002</th>\n",
              "      <th>FOODS_1_003</th>\n",
              "      <th>FOODS_1_004</th>\n",
              "      <th>FOODS_1_005</th>\n",
              "      <th>FOODS_1_006</th>\n",
              "      <th>FOODS_1_008</th>\n",
              "      <th>FOODS_1_009</th>\n",
              "      <th>FOODS_1_010</th>\n",
              "      <th>FOODS_1_011</th>\n",
              "      <th>FOODS_1_012</th>\n",
              "      <th>FOODS_1_013</th>\n",
              "      <th>FOODS_1_014</th>\n",
              "      <th>FOODS_1_015</th>\n",
              "      <th>FOODS_1_016</th>\n",
              "      <th>FOODS_1_017</th>\n",
              "      <th>FOODS_1_018</th>\n",
              "      <th>FOODS_1_019</th>\n",
              "      <th>FOODS_1_020</th>\n",
              "      <th>FOODS_1_021</th>\n",
              "      <th>FOODS_1_022</th>\n",
              "      <th>FOODS_1_023</th>\n",
              "      <th>FOODS_1_024</th>\n",
              "      <th>FOODS_1_025</th>\n",
              "      <th>FOODS_1_026</th>\n",
              "      <th>FOODS_1_027</th>\n",
              "      <th>FOODS_1_028</th>\n",
              "      <th>FOODS_1_029</th>\n",
              "      <th>FOODS_1_030</th>\n",
              "      <th>FOODS_1_031</th>\n",
              "      <th>FOODS_1_032</th>\n",
              "      <th>FOODS_1_033</th>\n",
              "      <th>FOODS_1_034</th>\n",
              "      <th>FOODS_1_035</th>\n",
              "      <th>FOODS_1_036</th>\n",
              "      <th>FOODS_1_037</th>\n",
              "      <th>FOODS_1_038</th>\n",
              "      <th>FOODS_1_039</th>\n",
              "      <th>FOODS_1_040</th>\n",
              "      <th>FOODS_1_041</th>\n",
              "      <th>...</th>\n",
              "      <th>HOUSEHOLD_2_477</th>\n",
              "      <th>HOUSEHOLD_2_478</th>\n",
              "      <th>HOUSEHOLD_2_479</th>\n",
              "      <th>HOUSEHOLD_2_480</th>\n",
              "      <th>HOUSEHOLD_2_481</th>\n",
              "      <th>HOUSEHOLD_2_482</th>\n",
              "      <th>HOUSEHOLD_2_483</th>\n",
              "      <th>HOUSEHOLD_2_484</th>\n",
              "      <th>HOUSEHOLD_2_485</th>\n",
              "      <th>HOUSEHOLD_2_486</th>\n",
              "      <th>HOUSEHOLD_2_487</th>\n",
              "      <th>HOUSEHOLD_2_488</th>\n",
              "      <th>HOUSEHOLD_2_489</th>\n",
              "      <th>HOUSEHOLD_2_490</th>\n",
              "      <th>HOUSEHOLD_2_491</th>\n",
              "      <th>HOUSEHOLD_2_492</th>\n",
              "      <th>HOUSEHOLD_2_493</th>\n",
              "      <th>HOUSEHOLD_2_494</th>\n",
              "      <th>HOUSEHOLD_2_495</th>\n",
              "      <th>HOUSEHOLD_2_496</th>\n",
              "      <th>HOUSEHOLD_2_497</th>\n",
              "      <th>HOUSEHOLD_2_498</th>\n",
              "      <th>HOUSEHOLD_2_499</th>\n",
              "      <th>HOUSEHOLD_2_500</th>\n",
              "      <th>HOUSEHOLD_2_501</th>\n",
              "      <th>HOUSEHOLD_2_502</th>\n",
              "      <th>HOUSEHOLD_2_503</th>\n",
              "      <th>HOUSEHOLD_2_504</th>\n",
              "      <th>HOUSEHOLD_2_505</th>\n",
              "      <th>HOUSEHOLD_2_506</th>\n",
              "      <th>HOUSEHOLD_2_507</th>\n",
              "      <th>HOUSEHOLD_2_508</th>\n",
              "      <th>HOUSEHOLD_2_509</th>\n",
              "      <th>HOUSEHOLD_2_510</th>\n",
              "      <th>HOUSEHOLD_2_511</th>\n",
              "      <th>HOUSEHOLD_2_512</th>\n",
              "      <th>HOUSEHOLD_2_513</th>\n",
              "      <th>HOUSEHOLD_2_514</th>\n",
              "      <th>HOUSEHOLD_2_515</th>\n",
              "      <th>HOUSEHOLD_2_516</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 3049 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       FOODS_1_001  FOODS_1_002  ...  HOUSEHOLD_2_515  HOUSEHOLD_2_516\n",
              "0                0            0  ...                0                0\n",
              "1                0            0  ...                0                0\n",
              "2                0            0  ...                0                0\n",
              "3                0            0  ...                0                0\n",
              "4                0            0  ...                0                0\n",
              "...            ...          ...  ...              ...              ...\n",
              "30485            0            0  ...                0                0\n",
              "30486            0            0  ...                0                0\n",
              "30487            0            0  ...                0                0\n",
              "30488            0            0  ...                0                0\n",
              "30489            0            0  ...                0                0\n",
              "\n",
              "[30490 rows x 3049 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhVxo6Q0kEt1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "39779469-8ac5-4ed1-cf5f-4435c2d36faf"
      },
      "source": [
        "pd.get_dummies(stv[\"state_id\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CA</th>\n",
              "      <th>TX</th>\n",
              "      <th>WI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       CA  TX  WI\n",
              "0       1   0   0\n",
              "1       1   0   0\n",
              "2       1   0   0\n",
              "3       1   0   0\n",
              "4       1   0   0\n",
              "...    ..  ..  ..\n",
              "30485   0   0   1\n",
              "30486   0   0   1\n",
              "30487   0   0   1\n",
              "30488   0   0   1\n",
              "30489   0   0   1\n",
              "\n",
              "[30490 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Af-U1yP6sEF",
        "colab_type": "text"
      },
      "source": [
        "# エンコーディングの方針\n",
        "item_id はラベルエンコーディングしてEmbedding layerにぶち込む -> 余裕があれば最後にやる。最初はこの特徴量をそもそも入れない。<br />\n",
        "ほかのやつはone-hot encodingにする。<br />\n",
        "<br />\n",
        "ジェネレータも、圧縮ファイルから随時読み込む形に書き換える。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6QWoiWu7C3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calendar = cal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HVqhsT28x4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "28895df3-d97a-4d86-d8b2-b593dc395235"
      },
      "source": [
        "required_columns = [\"d\", \"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]\n",
        "calendar[required_columns].max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "d               d_999\n",
              "event_name_1        1\n",
              "event_name_2        1\n",
              "event_type_1        1\n",
              "event_type_2        1\n",
              "snap_CA             1\n",
              "snap_TX             1\n",
              "snap_WI             1\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAIj_R4P9R0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5065513-40b2-4998-ff79-da3dde7950af"
      },
      "source": [
        "cal[\"event_name_1\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTjZvJ1Q9qzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one-hot encodingしたものがあった\n",
        "cal = pd.read_csv(f\"{INPUT_DIR}/cal_dummies.csv\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ9wXkxZ97_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "a36ef3ff-5767-4f45-a507-a898fcbd807f"
      },
      "source": [
        "cal.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>date</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>weekday</th>\n",
              "      <th>wday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>d</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_name_1_Chanukah End</th>\n",
              "      <th>event_name_1_Christmas</th>\n",
              "      <th>event_name_1_Cinco De Mayo</th>\n",
              "      <th>event_name_1_ColumbusDay</th>\n",
              "      <th>event_name_1_Easter</th>\n",
              "      <th>event_name_1_Eid al-Fitr</th>\n",
              "      <th>event_name_1_EidAlAdha</th>\n",
              "      <th>event_name_1_Father's day</th>\n",
              "      <th>event_name_1_Halloween</th>\n",
              "      <th>event_name_1_IndependenceDay</th>\n",
              "      <th>event_name_1_LaborDay</th>\n",
              "      <th>event_name_1_LentStart</th>\n",
              "      <th>event_name_1_LentWeek2</th>\n",
              "      <th>event_name_1_MartinLutherKingDay</th>\n",
              "      <th>event_name_1_MemorialDay</th>\n",
              "      <th>event_name_1_Mother's day</th>\n",
              "      <th>event_name_1_NBAFinalsEnd</th>\n",
              "      <th>event_name_1_NBAFinalsStart</th>\n",
              "      <th>event_name_1_NewYear</th>\n",
              "      <th>event_name_1_OrthodoxChristmas</th>\n",
              "      <th>event_name_1_OrthodoxEaster</th>\n",
              "      <th>event_name_1_Pesach End</th>\n",
              "      <th>event_name_1_PresidentsDay</th>\n",
              "      <th>event_name_1_Purim End</th>\n",
              "      <th>event_name_1_Ramadan starts</th>\n",
              "      <th>event_name_1_StPatricksDay</th>\n",
              "      <th>event_name_1_SuperBowl</th>\n",
              "      <th>event_name_1_Thanksgiving</th>\n",
              "      <th>event_name_1_ValentinesDay</th>\n",
              "      <th>event_name_1_VeteransDay</th>\n",
              "      <th>event_type_1_Cultural</th>\n",
              "      <th>event_type_1_National</th>\n",
              "      <th>event_type_1_Religious</th>\n",
              "      <th>event_type_1_Sporting</th>\n",
              "      <th>event_name_2_Cinco De Mayo</th>\n",
              "      <th>event_name_2_Easter</th>\n",
              "      <th>event_name_2_Father's day</th>\n",
              "      <th>event_name_2_OrthodoxEaster</th>\n",
              "      <th>event_type_2_Cultural</th>\n",
              "      <th>event_type_2_Religious</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-30</td>\n",
              "      <td>11101</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-31</td>\n",
              "      <td>11101</td>\n",
              "      <td>Monday</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-02-01</td>\n",
              "      <td>11101</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-02-02</td>\n",
              "      <td>11101</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0        date  ...  event_type_2_Cultural event_type_2_Religious\n",
              "0           0  2011-01-29  ...                      0                      0\n",
              "1           1  2011-01-30  ...                      0                      0\n",
              "2           2  2011-01-31  ...                      0                      0\n",
              "3           3  2011-02-01  ...                      0                      0\n",
              "4           4  2011-02-02  ...                      0                      0\n",
              "\n",
              "[5 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsEAFrbu_mrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cal = cal.drop(columns=[\"Unnamed: 0\", \"date\", \"wm_yr_wk\", \"weekday\", \"wday\", \"month\", \"year\"])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrjte5UrAFd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "zipからデータ読み出し。\n",
        "展開しないのでディスク容量も圧迫せず済む\n",
        "\"\"\"\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "NUM_ITEMS = 30490\n",
        "DATA_PATH = \"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas.zip\"\n",
        "\n",
        "def df_csv_generator(num=NUM_ITEMS, datapath=DATA_PATH):\n",
        "    with zipfile.ZipFile(datapath) as myzip:\n",
        "        filelist = myzip.namelist()\n",
        "\n",
        "        for i, f_name in enumerate(filelist):\n",
        "\n",
        "            if i == 0:\n",
        "                continue\n",
        "\n",
        "            if i > num:\n",
        "                break\n",
        "\n",
        "            df = pd.read_csv(myzip.extract(f_name, \"./extract_dir\"))\n",
        "            df = reduce_mem_usage(df, verbose=False)\n",
        "            df = df.fillna(0)\n",
        "            shutil.rmtree(\"./extract_dir\")\n",
        "            yield df"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlR3glO6BBr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfg = df_csv_generator()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw7Wj15VBINb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "c4727670-fa0b-4aa8-d444-224dd4f02c89"
      },
      "source": [
        "next(dfg)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>sale</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>3.480469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1965</th>\n",
              "      <td>3.480469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>3.480469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1967</th>\n",
              "      <td>3.480469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1968</th>\n",
              "      <td>3.480469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1969 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         price  sale  item_id  dept_id  ...  event_type_2  snap_CA  snap_TX  snap_WI\n",
              "0     0.000000   0.0   1447.0      3.0  ...             2        0        0        0\n",
              "1     0.000000   0.0   1447.0      3.0  ...             2        0        0        0\n",
              "2     0.000000   0.0   1447.0      3.0  ...             2        0        0        0\n",
              "3     0.000000   0.0   1447.0      3.0  ...             2        1        1        0\n",
              "4     0.000000   0.0   1447.0      3.0  ...             2        1        0        1\n",
              "...        ...   ...      ...      ...  ...           ...      ...      ...      ...\n",
              "1964  3.480469   0.0   1447.0      3.0  ...             2        0        1        1\n",
              "1965  3.480469   0.0   1447.0      3.0  ...             2        0        0        0\n",
              "1966  3.480469   0.0   1447.0      3.0  ...             2        0        0        0\n",
              "1967  3.480469   0.0   1447.0      3.0  ...             2        0        0        0\n",
              "1968  3.480469   0.0   1447.0      3.0  ...             0        0        0        0\n",
              "\n",
              "[1969 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95umL7cYBJXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "0aad4d76-4c86-48d7-c379-f1b5ac66e355"
      },
      "source": [
        "drop_columns = [\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]\n",
        "test_df.drop(columns=drop_columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>sale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1965</th>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1967</th>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1968</th>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1969 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         price  sale\n",
              "0     0.000000   0.0\n",
              "1     0.000000   0.0\n",
              "2     0.000000   0.0\n",
              "3     0.000000   0.0\n",
              "4     0.000000   0.0\n",
              "...        ...   ...\n",
              "1964  8.382812   0.0\n",
              "1965  8.382812   0.0\n",
              "1966  8.382812   0.0\n",
              "1967  8.382812   0.0\n",
              "1968  8.382812   0.0\n",
              "\n",
              "[1969 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Safb0gCBDkTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "cfd14441-d272-477e-b970-88cc3346b872"
      },
      "source": [
        "pd.concat([cal.drop(columns=[\"d\"]), test_df.drop(columns=drop_columns)], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_name_1_Chanukah End</th>\n",
              "      <th>event_name_1_Christmas</th>\n",
              "      <th>event_name_1_Cinco De Mayo</th>\n",
              "      <th>event_name_1_ColumbusDay</th>\n",
              "      <th>event_name_1_Easter</th>\n",
              "      <th>event_name_1_Eid al-Fitr</th>\n",
              "      <th>event_name_1_EidAlAdha</th>\n",
              "      <th>event_name_1_Father's day</th>\n",
              "      <th>event_name_1_Halloween</th>\n",
              "      <th>event_name_1_IndependenceDay</th>\n",
              "      <th>event_name_1_LaborDay</th>\n",
              "      <th>event_name_1_LentStart</th>\n",
              "      <th>event_name_1_LentWeek2</th>\n",
              "      <th>event_name_1_MartinLutherKingDay</th>\n",
              "      <th>event_name_1_MemorialDay</th>\n",
              "      <th>event_name_1_Mother's day</th>\n",
              "      <th>event_name_1_NBAFinalsEnd</th>\n",
              "      <th>event_name_1_NBAFinalsStart</th>\n",
              "      <th>event_name_1_NewYear</th>\n",
              "      <th>event_name_1_OrthodoxChristmas</th>\n",
              "      <th>event_name_1_OrthodoxEaster</th>\n",
              "      <th>event_name_1_Pesach End</th>\n",
              "      <th>event_name_1_PresidentsDay</th>\n",
              "      <th>event_name_1_Purim End</th>\n",
              "      <th>event_name_1_Ramadan starts</th>\n",
              "      <th>event_name_1_StPatricksDay</th>\n",
              "      <th>event_name_1_SuperBowl</th>\n",
              "      <th>event_name_1_Thanksgiving</th>\n",
              "      <th>event_name_1_ValentinesDay</th>\n",
              "      <th>event_name_1_VeteransDay</th>\n",
              "      <th>event_type_1_Cultural</th>\n",
              "      <th>event_type_1_National</th>\n",
              "      <th>event_type_1_Religious</th>\n",
              "      <th>event_type_1_Sporting</th>\n",
              "      <th>event_name_2_Cinco De Mayo</th>\n",
              "      <th>event_name_2_Easter</th>\n",
              "      <th>event_name_2_Father's day</th>\n",
              "      <th>event_name_2_OrthodoxEaster</th>\n",
              "      <th>event_type_2_Cultural</th>\n",
              "      <th>event_type_2_Religious</th>\n",
              "      <th>price</th>\n",
              "      <th>sale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1965</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1967</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1968</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8.382812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1969 rows × 45 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      snap_CA  snap_TX  snap_WI  ...  event_type_2_Religious     price  sale\n",
              "0           0        0        0  ...                       0  0.000000   0.0\n",
              "1           0        0        0  ...                       0  0.000000   0.0\n",
              "2           0        0        0  ...                       0  0.000000   0.0\n",
              "3           1        1        0  ...                       0  0.000000   0.0\n",
              "4           1        0        1  ...                       0  0.000000   0.0\n",
              "...       ...      ...      ...  ...                     ...       ...   ...\n",
              "1964        0        1        1  ...                       0  8.382812   0.0\n",
              "1965        0        0        0  ...                       0  8.382812   0.0\n",
              "1966        0        0        0  ...                       0  8.382812   0.0\n",
              "1967        0        0        0  ...                       0  8.382812   0.0\n",
              "1968        0        0        0  ...                       0  8.382812   0.0\n",
              "\n",
              "[1969 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kadHHGoaD6AR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "a6611888-6c31-46c8-b4e7-8c2545f57591"
      },
      "source": [
        "ste = ste.rename(columns={\"id\": \"total_id\"})\n",
        "mod_ste = ste.drop(columns=[\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"])\n",
        "mod_ste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>d_35</th>\n",
              "      <th>d_36</th>\n",
              "      <th>d_37</th>\n",
              "      <th>d_38</th>\n",
              "      <th>d_39</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "      <th>d_1914</th>\n",
              "      <th>d_1915</th>\n",
              "      <th>d_1916</th>\n",
              "      <th>d_1917</th>\n",
              "      <th>d_1918</th>\n",
              "      <th>d_1919</th>\n",
              "      <th>d_1920</th>\n",
              "      <th>d_1921</th>\n",
              "      <th>d_1922</th>\n",
              "      <th>d_1923</th>\n",
              "      <th>d_1924</th>\n",
              "      <th>d_1925</th>\n",
              "      <th>d_1926</th>\n",
              "      <th>d_1927</th>\n",
              "      <th>d_1928</th>\n",
              "      <th>d_1929</th>\n",
              "      <th>d_1930</th>\n",
              "      <th>d_1931</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 1942 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            total_id  d_1  d_2  ...  d_1939  d_1940  d_1941\n",
              "0      HOBBIES_1_001_CA_1_evaluation    0    0  ...       3       0       1\n",
              "1      HOBBIES_1_002_CA_1_evaluation    0    0  ...       0       0       0\n",
              "2      HOBBIES_1_003_CA_1_evaluation    0    0  ...       3       0       1\n",
              "3      HOBBIES_1_004_CA_1_evaluation    0    0  ...       0       2       6\n",
              "4      HOBBIES_1_005_CA_1_evaluation    0    0  ...       2       1       0\n",
              "...                              ...  ...  ...  ...     ...     ...     ...\n",
              "30485    FOODS_3_823_WI_3_evaluation    0    0  ...       0       1       1\n",
              "30486    FOODS_3_824_WI_3_evaluation    0    0  ...       0       1       0\n",
              "30487    FOODS_3_825_WI_3_evaluation    0    6  ...       1       0       2\n",
              "30488    FOODS_3_826_WI_3_evaluation    0    0  ...       1       1       0\n",
              "30489    FOODS_3_827_WI_3_evaluation    0    0  ...       2       5       1\n",
              "\n",
              "[30490 rows x 1942 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LVbYumGE8YD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 各商品の属性(食品、地域など)を記載したデータフレーム作成(item_idだけ除外)\n",
        "ste = ste.rename(columns={\"id\": \"total_id\"})\n",
        "mod_ste = ste.drop(columns=[\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"])\n",
        "item_attribute_df = pd.DataFrame(ste[\"total_id\"])\n",
        "\n",
        "dummy_list = [\"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n",
        "for col in dummy_list:\n",
        "    item_attribute_df = pd.concat([item_attribute_df, pd.get_dummies(ste[col])], axis=1)\n",
        "\n",
        "item_cat_df = item_attribute_df.drop(columns=[\"total_id\"])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sByzCosyHY6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "dd873484-61fd-439e-fd39-7608758399b0"
      },
      "source": [
        "item_cat_df"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FOODS_1</th>\n",
              "      <th>FOODS_2</th>\n",
              "      <th>FOODS_3</th>\n",
              "      <th>HOBBIES_1</th>\n",
              "      <th>HOBBIES_2</th>\n",
              "      <th>HOUSEHOLD_1</th>\n",
              "      <th>HOUSEHOLD_2</th>\n",
              "      <th>FOODS</th>\n",
              "      <th>HOBBIES</th>\n",
              "      <th>HOUSEHOLD</th>\n",
              "      <th>CA_1</th>\n",
              "      <th>CA_2</th>\n",
              "      <th>CA_3</th>\n",
              "      <th>CA_4</th>\n",
              "      <th>TX_1</th>\n",
              "      <th>TX_2</th>\n",
              "      <th>TX_3</th>\n",
              "      <th>WI_1</th>\n",
              "      <th>WI_2</th>\n",
              "      <th>WI_3</th>\n",
              "      <th>CA</th>\n",
              "      <th>TX</th>\n",
              "      <th>WI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       FOODS_1  FOODS_2  FOODS_3  HOBBIES_1  HOBBIES_2  ...  WI_2  WI_3  CA  TX  WI\n",
              "0            0        0        0          1          0  ...     0     0   1   0   0\n",
              "1            0        0        0          1          0  ...     0     0   1   0   0\n",
              "2            0        0        0          1          0  ...     0     0   1   0   0\n",
              "3            0        0        0          1          0  ...     0     0   1   0   0\n",
              "4            0        0        0          1          0  ...     0     0   1   0   0\n",
              "...        ...      ...      ...        ...        ...  ...   ...   ...  ..  ..  ..\n",
              "30485        0        0        1          0          0  ...     0     1   0   0   1\n",
              "30486        0        0        1          0          0  ...     0     1   0   0   1\n",
              "30487        0        0        1          0          0  ...     0     1   0   0   1\n",
              "30488        0        0        1          0          0  ...     0     1   0   0   1\n",
              "30489        0        0        1          0          0  ...     0     1   0   0   1\n",
              "\n",
              "[30490 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rZAufskFQ-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attribute_df_generator(item_cat_df):\n",
        "    for i in range(item_cat_df.shape[0]):\n",
        "        yield item_cat_df.loc[i]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_MTK1gWHkGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "857e0a0f-cf6a-4a4e-b586-39fcc5402f73"
      },
      "source": [
        "atg = attribute_df_generator(item_cat_df)\n",
        "(next(atg).values * np.ones((1969, 1))).shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1969, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aisRLcGsHl4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop_columns = [\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]\n",
        "ste_days = ste.drop(columns=[\"total_id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"])\n",
        "\n",
        "def train_df_generator(item_cat_df, cat, ste_days ,num=30490):\n",
        "    dfg = df_csv_generator()\n",
        "    adg = attribute_df_generator(item_cat_df)\n",
        "    mv_avg_df_7 = ste_days.transpose().rolling(7).mean().fillna(0).reset_index(drop=True)\n",
        "    mv_avg_df_30 = ste_days.transpose().rolling(30).mean().fillna(0).reset_index(drop=True)\n",
        "\n",
        "    for i, df in enumerate(dfg):\n",
        "        if i >= num:\n",
        "            break\n",
        "        tmp_df = df.drop(columns=drop_columns)\n",
        "        tmp_cat_df = pd.DataFrame((next(adg).values * np.ones((1941, 1))).astype(int))\n",
        "        tmp_moving_average_df = ste_days\n",
        "        ret_df = pd.concat([cal.drop(columns=[\"d\"])[:-28], tmp_cat_df, mv_avg_df_7[i], mv_avg_df_30[i], tmp_df[:-28]], axis=1)\n",
        "        yield ret_df"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lNar2TSKB9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tdg = train_df_generator(item_cat_df, cal, ste_days, 10)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvzasvWxKKBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e5e8961-ac87-4127-830e-14cb391d4640"
      },
      "source": [
        "next(tdg).shape"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1941, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c33Y8vmaaS7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "a5715a66-28d1-4186-a7a5-4a21ab7836bc"
      },
      "source": [
        "next(tdg)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_name_1_Chanukah End</th>\n",
              "      <th>event_name_1_Christmas</th>\n",
              "      <th>event_name_1_Cinco De Mayo</th>\n",
              "      <th>event_name_1_ColumbusDay</th>\n",
              "      <th>event_name_1_Easter</th>\n",
              "      <th>event_name_1_Eid al-Fitr</th>\n",
              "      <th>event_name_1_EidAlAdha</th>\n",
              "      <th>event_name_1_Father's day</th>\n",
              "      <th>event_name_1_Halloween</th>\n",
              "      <th>event_name_1_IndependenceDay</th>\n",
              "      <th>event_name_1_LaborDay</th>\n",
              "      <th>event_name_1_LentStart</th>\n",
              "      <th>event_name_1_LentWeek2</th>\n",
              "      <th>event_name_1_MartinLutherKingDay</th>\n",
              "      <th>event_name_1_MemorialDay</th>\n",
              "      <th>event_name_1_Mother's day</th>\n",
              "      <th>event_name_1_NBAFinalsEnd</th>\n",
              "      <th>event_name_1_NBAFinalsStart</th>\n",
              "      <th>event_name_1_NewYear</th>\n",
              "      <th>event_name_1_OrthodoxChristmas</th>\n",
              "      <th>event_name_1_OrthodoxEaster</th>\n",
              "      <th>event_name_1_Pesach End</th>\n",
              "      <th>event_name_1_PresidentsDay</th>\n",
              "      <th>event_name_1_Purim End</th>\n",
              "      <th>event_name_1_Ramadan starts</th>\n",
              "      <th>event_name_1_StPatricksDay</th>\n",
              "      <th>event_name_1_SuperBowl</th>\n",
              "      <th>event_name_1_Thanksgiving</th>\n",
              "      <th>event_name_1_ValentinesDay</th>\n",
              "      <th>event_name_1_VeteransDay</th>\n",
              "      <th>event_type_1_Cultural</th>\n",
              "      <th>event_type_1_National</th>\n",
              "      <th>event_type_1_Religious</th>\n",
              "      <th>event_type_1_Sporting</th>\n",
              "      <th>event_name_2_Cinco De Mayo</th>\n",
              "      <th>event_name_2_Easter</th>\n",
              "      <th>event_name_2_Father's day</th>\n",
              "      <th>event_name_2_OrthodoxEaster</th>\n",
              "      <th>event_type_2_Cultural</th>\n",
              "      <th>event_type_2_Religious</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>1</th>\n",
              "      <th>price</th>\n",
              "      <th>sale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1936</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1937</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1938</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1939</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1940</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1941 rows × 69 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      snap_CA  snap_TX  snap_WI  ...         1     price  sale\n",
              "0           0        0        0  ...  0.000000  0.000000   0.0\n",
              "1           0        0        0  ...  0.000000  0.000000   0.0\n",
              "2           0        0        0  ...  0.000000  0.000000   0.0\n",
              "3           1        1        0  ...  0.000000  0.000000   0.0\n",
              "4           1        0        1  ...  0.000000  0.000000   0.0\n",
              "...       ...      ...      ...  ...       ...       ...   ...\n",
              "1936        0        0        0  ...  0.714286  3.970703   0.0\n",
              "1937        0        0        0  ...  0.714286  3.970703   0.0\n",
              "1938        0        0        0  ...  0.714286  3.970703   0.0\n",
              "1939        0        0        0  ...  0.571429  3.970703   0.0\n",
              "1940        0        0        0  ...  0.285714  3.970703   0.0\n",
              "\n",
              "[1941 rows x 69 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0qnx2wfZz4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "abb4bb0a-bf70-4f50-f8fc-a6c98d86edf6"
      },
      "source": [
        "mv_avg_df_7 = ste_days.transpose().rolling(7).mean().fillna(0)\n",
        "mv_avg_df_7"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>30450</th>\n",
              "      <th>30451</th>\n",
              "      <th>30452</th>\n",
              "      <th>30453</th>\n",
              "      <th>30454</th>\n",
              "      <th>30455</th>\n",
              "      <th>30456</th>\n",
              "      <th>30457</th>\n",
              "      <th>30458</th>\n",
              "      <th>30459</th>\n",
              "      <th>30460</th>\n",
              "      <th>30461</th>\n",
              "      <th>30462</th>\n",
              "      <th>30463</th>\n",
              "      <th>30464</th>\n",
              "      <th>30465</th>\n",
              "      <th>30466</th>\n",
              "      <th>30467</th>\n",
              "      <th>30468</th>\n",
              "      <th>30469</th>\n",
              "      <th>30470</th>\n",
              "      <th>30471</th>\n",
              "      <th>30472</th>\n",
              "      <th>30473</th>\n",
              "      <th>30474</th>\n",
              "      <th>30475</th>\n",
              "      <th>30476</th>\n",
              "      <th>30477</th>\n",
              "      <th>30478</th>\n",
              "      <th>30479</th>\n",
              "      <th>30480</th>\n",
              "      <th>30481</th>\n",
              "      <th>30482</th>\n",
              "      <th>30483</th>\n",
              "      <th>30484</th>\n",
              "      <th>30485</th>\n",
              "      <th>30486</th>\n",
              "      <th>30487</th>\n",
              "      <th>30488</th>\n",
              "      <th>30489</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d_1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1937</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>11.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>5.142857</td>\n",
              "      <td>8.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>10.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>3.285714</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1938</th>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>5.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>...</td>\n",
              "      <td>4.285714</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>10.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.571429</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1939</th>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>3.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>8.285714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>7.285714</td>\n",
              "      <td>3.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>26.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1940</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>10.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>5.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>4.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>8.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>6.714286</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>24.142857</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1941</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>13.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>4.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>6.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>...</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>7.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>7.142857</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>25.571429</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>2.714286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1941 rows × 30490 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2      ...     30487     30488     30489\n",
              "d_1     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "d_2     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "d_3     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "d_4     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "d_5     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "...          ...       ...       ...  ...       ...       ...       ...\n",
              "d_1937  0.857143  0.714286  0.428571  ...  0.714286  2.000000  1.714286\n",
              "d_1938  1.285714  0.714286  0.714286  ...  0.571429  2.000000  2.000000\n",
              "d_1939  1.428571  0.714286  1.000000  ...  0.714286  2.000000  2.142857\n",
              "d_1940  0.857143  0.571429  1.000000  ...  0.714286  2.000000  2.571429\n",
              "d_1941  1.000000  0.285714  0.857143  ...  0.857143  1.857143  2.714286\n",
              "\n",
              "[1941 rows x 30490 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCol-d6YaBPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "3bb755bc-f046-4361-f14b-59a46226ba3d"
      },
      "source": [
        "mv_avg_df_7[0]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "d_1       0.000000\n",
              "d_2       0.000000\n",
              "d_3       0.000000\n",
              "d_4       0.000000\n",
              "d_5       0.000000\n",
              "            ...   \n",
              "d_1937    0.857143\n",
              "d_1938    1.285714\n",
              "d_1939    1.428571\n",
              "d_1940    0.857143\n",
              "d_1941    1.000000\n",
              "Name: 0, Length: 1941, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQkfIue1YHyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c285ad80-a3e7-4713-8a7e-d83d7317afff"
      },
      "source": [
        "dfg = df_csv_generator()\n",
        "next(dfg).shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1969, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFGohfr5YoI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "23edaabc-d3ae-4980-f59e-7e9896d54863"
      },
      "source": [
        "ste_days.head()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>d_35</th>\n",
              "      <th>d_36</th>\n",
              "      <th>d_37</th>\n",
              "      <th>d_38</th>\n",
              "      <th>d_39</th>\n",
              "      <th>d_40</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "      <th>d_1914</th>\n",
              "      <th>d_1915</th>\n",
              "      <th>d_1916</th>\n",
              "      <th>d_1917</th>\n",
              "      <th>d_1918</th>\n",
              "      <th>d_1919</th>\n",
              "      <th>d_1920</th>\n",
              "      <th>d_1921</th>\n",
              "      <th>d_1922</th>\n",
              "      <th>d_1923</th>\n",
              "      <th>d_1924</th>\n",
              "      <th>d_1925</th>\n",
              "      <th>d_1926</th>\n",
              "      <th>d_1927</th>\n",
              "      <th>d_1928</th>\n",
              "      <th>d_1929</th>\n",
              "      <th>d_1930</th>\n",
              "      <th>d_1931</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1941 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   d_1  d_2  d_3  d_4  d_5  d_6  ...  d_1936  d_1937  d_1938  d_1939  d_1940  d_1941\n",
              "0    0    0    0    0    0    0  ...       0       0       3       3       0       1\n",
              "1    0    0    0    0    0    0  ...       1       0       0       0       0       0\n",
              "2    0    0    0    0    0    0  ...       0       0       2       3       0       1\n",
              "3    0    0    0    0    0    0  ...       0       1       3       0       2       6\n",
              "4    0    0    0    0    0    0  ...       1       0       0       2       1       0\n",
              "\n",
              "[5 rows x 1941 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrB_N4bfY7li",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "87a00494-a858-4dc8-bf62-dc3233bb6c58"
      },
      "source": [
        "cal[:-28]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_name_1_Chanukah End</th>\n",
              "      <th>event_name_1_Christmas</th>\n",
              "      <th>event_name_1_Cinco De Mayo</th>\n",
              "      <th>event_name_1_ColumbusDay</th>\n",
              "      <th>event_name_1_Easter</th>\n",
              "      <th>event_name_1_Eid al-Fitr</th>\n",
              "      <th>event_name_1_EidAlAdha</th>\n",
              "      <th>event_name_1_Father's day</th>\n",
              "      <th>event_name_1_Halloween</th>\n",
              "      <th>event_name_1_IndependenceDay</th>\n",
              "      <th>event_name_1_LaborDay</th>\n",
              "      <th>event_name_1_LentStart</th>\n",
              "      <th>event_name_1_LentWeek2</th>\n",
              "      <th>event_name_1_MartinLutherKingDay</th>\n",
              "      <th>event_name_1_MemorialDay</th>\n",
              "      <th>event_name_1_Mother's day</th>\n",
              "      <th>event_name_1_NBAFinalsEnd</th>\n",
              "      <th>event_name_1_NBAFinalsStart</th>\n",
              "      <th>event_name_1_NewYear</th>\n",
              "      <th>event_name_1_OrthodoxChristmas</th>\n",
              "      <th>event_name_1_OrthodoxEaster</th>\n",
              "      <th>event_name_1_Pesach End</th>\n",
              "      <th>event_name_1_PresidentsDay</th>\n",
              "      <th>event_name_1_Purim End</th>\n",
              "      <th>event_name_1_Ramadan starts</th>\n",
              "      <th>event_name_1_StPatricksDay</th>\n",
              "      <th>event_name_1_SuperBowl</th>\n",
              "      <th>event_name_1_Thanksgiving</th>\n",
              "      <th>event_name_1_ValentinesDay</th>\n",
              "      <th>event_name_1_VeteransDay</th>\n",
              "      <th>event_type_1_Cultural</th>\n",
              "      <th>event_type_1_National</th>\n",
              "      <th>event_type_1_Religious</th>\n",
              "      <th>event_type_1_Sporting</th>\n",
              "      <th>event_name_2_Cinco De Mayo</th>\n",
              "      <th>event_name_2_Easter</th>\n",
              "      <th>event_name_2_Father's day</th>\n",
              "      <th>event_name_2_OrthodoxEaster</th>\n",
              "      <th>event_type_2_Cultural</th>\n",
              "      <th>event_type_2_Religious</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d_2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d_3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d_4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d_5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1936</th>\n",
              "      <td>d_1937</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1937</th>\n",
              "      <td>d_1938</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1938</th>\n",
              "      <td>d_1939</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1939</th>\n",
              "      <td>d_1940</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1940</th>\n",
              "      <td>d_1941</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1941 rows × 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           d  snap_CA  ...  event_type_2_Cultural  event_type_2_Religious\n",
              "0        d_1        0  ...                      0                       0\n",
              "1        d_2        0  ...                      0                       0\n",
              "2        d_3        0  ...                      0                       0\n",
              "3        d_4        1  ...                      0                       0\n",
              "4        d_5        1  ...                      0                       0\n",
              "...      ...      ...  ...                    ...                     ...\n",
              "1936  d_1937        0  ...                      0                       0\n",
              "1937  d_1938        0  ...                      0                       0\n",
              "1938  d_1939        0  ...                      0                       0\n",
              "1939  d_1940        0  ...                      0                       0\n",
              "1940  d_1941        0  ...                      0                       0\n",
              "\n",
              "[1941 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLI7FW6-NEiZ",
        "colab_type": "text"
      },
      "source": [
        "# 20/06/19 移動平均のカラムを追加\n",
        "1週間と1ヶ月(30日)の平均を見る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4KCQ7ffNWkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "eef72bc3-560d-4e29-e4b3-41e20c129e4e"
      },
      "source": [
        "ste"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "      <th>d_1914</th>\n",
              "      <th>d_1915</th>\n",
              "      <th>d_1916</th>\n",
              "      <th>d_1917</th>\n",
              "      <th>d_1918</th>\n",
              "      <th>d_1919</th>\n",
              "      <th>d_1920</th>\n",
              "      <th>d_1921</th>\n",
              "      <th>d_1922</th>\n",
              "      <th>d_1923</th>\n",
              "      <th>d_1924</th>\n",
              "      <th>d_1925</th>\n",
              "      <th>d_1926</th>\n",
              "      <th>d_1927</th>\n",
              "      <th>d_1928</th>\n",
              "      <th>d_1929</th>\n",
              "      <th>d_1930</th>\n",
              "      <th>d_1931</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
              "      <td>FOODS_3_823</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
              "      <td>FOODS_3_824</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
              "      <td>FOODS_3_825</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
              "      <td>FOODS_3_826</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
              "      <td>FOODS_3_827</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 1947 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  id        item_id  ... d_1940 d_1941\n",
              "0      HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  ...      0      1\n",
              "1      HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  ...      0      0\n",
              "2      HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  ...      0      1\n",
              "3      HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  ...      2      6\n",
              "4      HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  ...      1      0\n",
              "...                              ...            ...  ...    ...    ...\n",
              "30485    FOODS_3_823_WI_3_evaluation    FOODS_3_823  ...      1      1\n",
              "30486    FOODS_3_824_WI_3_evaluation    FOODS_3_824  ...      1      0\n",
              "30487    FOODS_3_825_WI_3_evaluation    FOODS_3_825  ...      0      2\n",
              "30488    FOODS_3_826_WI_3_evaluation    FOODS_3_826  ...      1      0\n",
              "30489    FOODS_3_827_WI_3_evaluation    FOODS_3_827  ...      5      1\n",
              "\n",
              "[30490 rows x 1947 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74DTudKaNb-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "75621836-3b5f-48db-d379-03101511de0a"
      },
      "source": [
        "# 移動平均テスト\n",
        "ste.drop(columns=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]).loc[0].rolling(7).mean()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "d_1            NaN\n",
              "d_2            NaN\n",
              "d_3            NaN\n",
              "d_4            NaN\n",
              "d_5            NaN\n",
              "            ...   \n",
              "d_1937    0.857143\n",
              "d_1938    1.285714\n",
              "d_1939    1.428571\n",
              "d_1940    0.857143\n",
              "d_1941    1.000000\n",
              "Name: 0, Length: 1941, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOUYgwZxOZ_u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "c3a4ca7a-11f4-45c3-d998-709205959209"
      },
      "source": [
        "ste_id = ste[\"id\"]\n",
        "ste_days = ste.drop(columns=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"])\n",
        "ste_days"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>d_35</th>\n",
              "      <th>d_36</th>\n",
              "      <th>d_37</th>\n",
              "      <th>d_38</th>\n",
              "      <th>d_39</th>\n",
              "      <th>d_40</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "      <th>d_1914</th>\n",
              "      <th>d_1915</th>\n",
              "      <th>d_1916</th>\n",
              "      <th>d_1917</th>\n",
              "      <th>d_1918</th>\n",
              "      <th>d_1919</th>\n",
              "      <th>d_1920</th>\n",
              "      <th>d_1921</th>\n",
              "      <th>d_1922</th>\n",
              "      <th>d_1923</th>\n",
              "      <th>d_1924</th>\n",
              "      <th>d_1925</th>\n",
              "      <th>d_1926</th>\n",
              "      <th>d_1927</th>\n",
              "      <th>d_1928</th>\n",
              "      <th>d_1929</th>\n",
              "      <th>d_1930</th>\n",
              "      <th>d_1931</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 1941 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       d_1  d_2  d_3  d_4  d_5  ...  d_1937  d_1938  d_1939  d_1940  d_1941\n",
              "0        0    0    0    0    0  ...       0       3       3       0       1\n",
              "1        0    0    0    0    0  ...       0       0       0       0       0\n",
              "2        0    0    0    0    0  ...       0       2       3       0       1\n",
              "3        0    0    0    0    0  ...       1       3       0       2       6\n",
              "4        0    0    0    0    0  ...       0       0       2       1       0\n",
              "...    ...  ...  ...  ...  ...  ...     ...     ...     ...     ...     ...\n",
              "30485    0    0    2    2    0  ...       1       0       0       1       1\n",
              "30486    0    0    0    0    0  ...       0       1       0       1       0\n",
              "30487    0    6    0    2    2  ...       1       0       1       0       2\n",
              "30488    0    0    0    0    0  ...       0       1       1       1       0\n",
              "30489    0    0    0    0    0  ...       0       2       2       5       1\n",
              "\n",
              "[30490 rows x 1941 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU9cjhTbVLXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "3a2463e6-0f27-4147-c4c9-1a7490bc245b"
      },
      "source": [
        "ste_days.transpose().rolling(7).mean()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>30450</th>\n",
              "      <th>30451</th>\n",
              "      <th>30452</th>\n",
              "      <th>30453</th>\n",
              "      <th>30454</th>\n",
              "      <th>30455</th>\n",
              "      <th>30456</th>\n",
              "      <th>30457</th>\n",
              "      <th>30458</th>\n",
              "      <th>30459</th>\n",
              "      <th>30460</th>\n",
              "      <th>30461</th>\n",
              "      <th>30462</th>\n",
              "      <th>30463</th>\n",
              "      <th>30464</th>\n",
              "      <th>30465</th>\n",
              "      <th>30466</th>\n",
              "      <th>30467</th>\n",
              "      <th>30468</th>\n",
              "      <th>30469</th>\n",
              "      <th>30470</th>\n",
              "      <th>30471</th>\n",
              "      <th>30472</th>\n",
              "      <th>30473</th>\n",
              "      <th>30474</th>\n",
              "      <th>30475</th>\n",
              "      <th>30476</th>\n",
              "      <th>30477</th>\n",
              "      <th>30478</th>\n",
              "      <th>30479</th>\n",
              "      <th>30480</th>\n",
              "      <th>30481</th>\n",
              "      <th>30482</th>\n",
              "      <th>30483</th>\n",
              "      <th>30484</th>\n",
              "      <th>30485</th>\n",
              "      <th>30486</th>\n",
              "      <th>30487</th>\n",
              "      <th>30488</th>\n",
              "      <th>30489</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d_1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1937</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>11.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>5.142857</td>\n",
              "      <td>8.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>10.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>3.285714</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1938</th>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>5.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>...</td>\n",
              "      <td>4.285714</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>10.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.571429</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1939</th>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>3.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>8.285714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>7.285714</td>\n",
              "      <td>3.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>8.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>26.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1940</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>10.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>5.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>4.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>8.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>6.714286</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.285714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>24.142857</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1941</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>13.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>4.285714</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>6.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>...</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>7.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>7.142857</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>25.571429</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>2.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>2.714286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1941 rows × 30490 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2      ...     30487     30488     30489\n",
              "d_1          NaN       NaN       NaN  ...       NaN       NaN       NaN\n",
              "d_2          NaN       NaN       NaN  ...       NaN       NaN       NaN\n",
              "d_3          NaN       NaN       NaN  ...       NaN       NaN       NaN\n",
              "d_4          NaN       NaN       NaN  ...       NaN       NaN       NaN\n",
              "d_5          NaN       NaN       NaN  ...       NaN       NaN       NaN\n",
              "...          ...       ...       ...  ...       ...       ...       ...\n",
              "d_1937  0.857143  0.714286  0.428571  ...  0.714286  2.000000  1.714286\n",
              "d_1938  1.285714  0.714286  0.714286  ...  0.571429  2.000000  2.000000\n",
              "d_1939  1.428571  0.714286  1.000000  ...  0.714286  2.000000  2.142857\n",
              "d_1940  0.857143  0.571429  1.000000  ...  0.714286  2.000000  2.571429\n",
              "d_1941  1.000000  0.285714  0.857143  ...  0.857143  1.857143  2.714286\n",
              "\n",
              "[1941 rows x 30490 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_BW0ap_V5vG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "41793038-37d4-4f7e-bfa2-ce4a6715b669"
      },
      "source": [
        "ste_days.transpose().rolling(7).mean()[1]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "d_1            NaN\n",
              "d_2            NaN\n",
              "d_3            NaN\n",
              "d_4            NaN\n",
              "d_5            NaN\n",
              "            ...   \n",
              "d_1937    0.714286\n",
              "d_1938    0.714286\n",
              "d_1939    0.714286\n",
              "d_1940    0.571429\n",
              "d_1941    0.285714\n",
              "Name: 1, Length: 1941, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPfAGk5_OtZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d1ab2c16-e62b-4f59-f379-2213d8e425e2"
      },
      "source": [
        "\"\"\"for i in range(len(ste_days)):\n",
        "    if i // 1000 == i / 1000:\n",
        "        print(i)\n",
        "    tmp_df = ste_days.loc[i].rolling(7).mean()\n",
        "    tmp_df = tmp_df.fillna(0)\n",
        "    if i == 0:\n",
        "        moving_average_df = tmp_df.transpose()\n",
        "    else:\n",
        "        moving_average_df = pd.concat([moving_average_df, tmp_df.transpose()], axis=1) \n",
        "\n",
        "ジェネレータでやった方がよさげ        \n",
        "\"\"\""
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-8cbda1737e07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mste_days\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3550\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3552\u001b[0m             \u001b[0;31m# may need to box a datelike-scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;31m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36miget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    363\u001b[0m         )\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17nfglVbQadA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "7e69cd72-ab35-40cf-99e7-3bdc8e6c7eac"
      },
      "source": [
        "# 10個分でテスト\n",
        "moving_average_df"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d_1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1937</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>11.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1938</th>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>5.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1939</th>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1940</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>10.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d_1941</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>13.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1941 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0         1         2  ...          7         8         9\n",
              "d_1     0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000\n",
              "d_2     0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000\n",
              "d_3     0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000\n",
              "d_4     0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000\n",
              "d_5     0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000\n",
              "...          ...       ...       ...  ...        ...       ...       ...\n",
              "d_1937  0.857143  0.714286  0.428571  ...  11.428571  0.142857  0.714286\n",
              "d_1938  1.285714  0.714286  0.714286  ...   5.285714  0.142857  0.714286\n",
              "d_1939  1.428571  0.714286  1.000000  ...   4.428571  0.000000  0.714286\n",
              "d_1940  0.857143  0.571429  1.000000  ...  10.142857  0.142857  0.714286\n",
              "d_1941  1.000000  0.285714  0.857143  ...  13.857143  0.142857  0.714286\n",
              "\n",
              "[1941 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg8FLgdYKqSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1CuMRznK7iA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba74675c-bf3e-4787-d3d6-b6b9c50e7308"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkGgdpfkK-B2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a27075f2-4dcf-4084-b96d-9da808ea730e"
      },
      "source": [
        "os.path.isdir(\"./training_datas\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rba6L0nXnUf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"./training_datas\")"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQMBiNd9LTC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "15d98221-178d-462d-808d-eb0d81cede9f"
      },
      "source": [
        "OUTPUT_PATH = \"./training_datas/\"\n",
        "tdg = train_df_generator(item_cat_df, cal, ste_days)\n",
        "shape_list = []\n",
        "for i, df in enumerate(tdg):\n",
        "     if i / 1000 == i // 1000:\n",
        "         print(i)\n",
        "     #df.to_csv(OUTPUT_PATH + \"train_data\" + str(i) + \".csv\", index=False, compression=\"zip\")\n",
        "     df.to_pickle(OUTPUT_PATH + \"train_data\" + str(i) + \".zip\")\n",
        "     shape_list.append(df.shape)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG8kEeVpnivv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "048c3085-b5fc-4615-edab-17148ec3b44f"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with zipfile.ZipFile(\"./training_datas/train_data0.zip\") as zip:\n",
        "    for info in zip.infolist():\n",
        "        if info.is_dir():\n",
        "            continue\n",
        "        data = pickle.loads(zip.read(info.filename))\n",
        "        print(\"\\n\", data)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...         0     price  sale\n",
            "0           0        0        0  ...  0.000000  0.000000   0.0\n",
            "1           0        0        0  ...  0.000000  0.000000   0.0\n",
            "2           0        0        0  ...  0.000000  0.000000   0.0\n",
            "3           1        1        0  ...  0.000000  0.000000   0.0\n",
            "4           1        0        1  ...  0.000000  0.000000   0.0\n",
            "...       ...      ...      ...  ...       ...       ...   ...\n",
            "1936        0        0        0  ...  1.100000  8.382812   0.0\n",
            "1937        0        0        0  ...  1.166667  8.382812   3.0\n",
            "1938        0        0        0  ...  1.233333  8.382812   3.0\n",
            "1939        0        0        0  ...  1.133333  8.382812   0.0\n",
            "1940        0        0        0  ...  1.166667  8.382812   1.0\n",
            "\n",
            "[1941 rows x 70 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DdIqabDohUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "listdir = os.listdir(\"./training_datas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZsIcLiyosgv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "3d3e8fd9-0704-4963-d372-e06b75bd905f"
      },
      "source": [
        "# 以下二つは、作成したpickleファイルからジェネレートする際に必要\n",
        "\n",
        "listdir.sort()\n",
        "listdir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_data0.zip',\n",
              " 'train_data1.zip',\n",
              " 'train_data2.zip',\n",
              " 'train_data3.zip',\n",
              " 'train_data4.zip',\n",
              " 'train_data5.zip',\n",
              " 'train_data6.zip',\n",
              " 'train_data7.zip',\n",
              " 'train_data8.zip',\n",
              " 'train_data9.zip']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqR8XOJdpBST",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c5dfbdb-c9e2-4b0d-d51e-73d833a652b4"
      },
      "source": [
        "for i in range(len(listdir)):\n",
        "    with zipfile.ZipFile(\"./training_datas/\" + listdir[i]) as zip:\n",
        "        for info in zip.infolist():\n",
        "            if info.is_dir():\n",
        "                continue\n",
        "            data = pickle.loads(zip.read(info.filename))\n",
        "            print(\"\\n\", data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  8.382812   0.0\n",
            "1965        0        0        0  ...   0  8.382812   0.0\n",
            "1966        0        0        0  ...   0  8.382812   0.0\n",
            "1967        0        0        0  ...   0  8.382812   0.0\n",
            "1968        0        0        0  ...   0  8.382812   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  3.970703   0.0\n",
            "1965        0        0        0  ...   0  3.970703   0.0\n",
            "1966        0        0        0  ...   0  3.970703   0.0\n",
            "1967        0        0        0  ...   0  3.970703   0.0\n",
            "1968        0        0        0  ...   0  3.970703   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  3.480469   0.0\n",
            "1965        0        0        0  ...   0  3.480469   0.0\n",
            "1966        0        0        0  ...   0  3.480469   0.0\n",
            "1967        0        0        0  ...   0  3.480469   0.0\n",
            "1968        0        0        0  ...   0  3.480469   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  6.441406   0.0\n",
            "1           0        0        0  ...   0  6.441406   0.0\n",
            "2           0        0        0  ...   0  6.441406   1.0\n",
            "3           1        1        0  ...   0  6.441406   3.0\n",
            "4           1        0        1  ...   0  6.441406   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  6.679688   0.0\n",
            "1965        0        0        0  ...   0  6.679688   0.0\n",
            "1966        0        0        0  ...   0  6.679688   0.0\n",
            "1967        0        0        0  ...   0  6.679688   0.0\n",
            "1968        0        0        0  ...   0  6.679688   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  1.969727   0.0\n",
            "1965        0        0        0  ...   0  1.969727   0.0\n",
            "1966        0        0        0  ...   0  1.969727   0.0\n",
            "1967        0        0        0  ...   0  1.969727   0.0\n",
            "1968        0        0        0  ...   0  1.969727   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  2.980469   0.0\n",
            "1965        0        0        0  ...   0  2.980469   0.0\n",
            "1966        0        0        0  ...   0  2.980469   0.0\n",
            "1967        0        0        0  ...   0  2.980469   0.0\n",
            "1968        0        0        0  ...   0  2.980469   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22    price  sale\n",
            "0           0        0        0  ...   0  0.00000   0.0\n",
            "1           0        0        0  ...   0  0.00000   0.0\n",
            "2           0        0        0  ...   0  0.00000   0.0\n",
            "3           1        1        0  ...   0  0.00000   0.0\n",
            "4           1        0        1  ...   0  0.00000   0.0\n",
            "...       ...      ...      ...  ...  ..      ...   ...\n",
            "1964        0        1        1  ...   0  4.96875   0.0\n",
            "1965        0        0        0  ...   0  4.96875   0.0\n",
            "1966        0        0        0  ...   0  4.96875   0.0\n",
            "1967        0        0        0  ...   0  4.96875   0.0\n",
            "1968        0        0        0  ...   0  4.96875   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  7.941406   0.0\n",
            "1965        0        0        0  ...   0  7.941406   0.0\n",
            "1966        0        0        0  ...   0  7.941406   0.0\n",
            "1967        0        0        0  ...   0  7.941406   0.0\n",
            "1968        0        0        0  ...   0  7.941406   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  3.720703   0.0\n",
            "1965        0        0        0  ...   0  3.720703   0.0\n",
            "1966        0        0        0  ...   0  3.720703   0.0\n",
            "1967        0        0        0  ...   0  3.720703   0.0\n",
            "1968        0        0        0  ...   0  3.720703   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "\n",
            "       snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  5.269531   0.0\n",
            "1965        0        0        0  ...   0  5.269531   0.0\n",
            "1966        0        0        0  ...   0  5.269531   0.0\n",
            "1967        0        0        0  ...   0  5.269531   0.0\n",
            "1968        0        0        0  ...   0  5.269531   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-5s0i6aRno8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "850ab82c-78dd-44e1-90f9-93046a3200f9"
      },
      "source": [
        "!zip -r training_datas.zip ./training_datas"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "  adding: training_datas/train_data22586.zip (stored 0%)\n",
            "  adding: training_datas/train_data4114.zip (stored 0%)\n",
            "  adding: training_datas/train_data28298.zip (stored 0%)\n",
            "  adding: training_datas/train_data21834.zip (stored 0%)\n",
            "  adding: training_datas/train_data30159.zip (stored 0%)\n",
            "  adding: training_datas/train_data27591.zip (stored 0%)\n",
            "  adding: training_datas/train_data19314.zip (stored 0%)\n",
            "  adding: training_datas/train_data24863.zip (stored 0%)\n",
            "  adding: training_datas/train_data20693.zip (stored 0%)\n",
            "  adding: training_datas/train_data16423.zip (stored 0%)\n",
            "  adding: training_datas/train_data2086.zip (stored 0%)\n",
            "  adding: training_datas/train_data14186.zip (stored 0%)\n",
            "  adding: training_datas/train_data5602.zip (stored 0%)\n",
            "  adding: training_datas/train_data9052.zip (stored 0%)\n",
            "  adding: training_datas/train_data15380.zip (stored 0%)\n",
            "  adding: training_datas/train_data10922.zip (stored 0%)\n",
            "  adding: training_datas/train_data7026.zip (stored 0%)\n",
            "  adding: training_datas/train_data8418.zip (stored 0%)\n",
            "  adding: training_datas/train_data16488.zip (stored 0%)\n",
            "  adding: training_datas/train_data1763.zip (stored 0%)\n",
            "  adding: training_datas/train_data27281.zip (stored 0%)\n",
            "  adding: training_datas/train_data252.zip (stored 0%)\n",
            "  adding: training_datas/train_data6375.zip (stored 0%)\n",
            "  adding: training_datas/train_data26715.zip (stored 0%)\n",
            "  adding: training_datas/train_data2131.zip (stored 0%)\n",
            "  adding: training_datas/train_data1374.zip (stored 0%)\n",
            "  adding: training_datas/train_data2741.zip (stored 0%)\n",
            "  adding: training_datas/train_data5359.zip (stored 0%)\n",
            "  adding: training_datas/train_data3816.zip (stored 0%)\n",
            "  adding: training_datas/train_data821.zip (stored 0%)\n",
            "  adding: training_datas/train_data19134.zip (stored 0%)\n",
            "  adding: training_datas/train_data23632.zip (stored 0%)\n",
            "  adding: training_datas/train_data435.zip (stored 0%)\n",
            "  adding: training_datas/train_data15519.zip (stored 0%)\n",
            "  adding: training_datas/train_data23645.zip (stored 0%)\n",
            "  adding: training_datas/train_data22981.zip (stored 0%)\n",
            "  adding: training_datas/train_data15199.zip (stored 0%)\n",
            "  adding: training_datas/train_data25939.zip (stored 0%)\n",
            "  adding: training_datas/train_data5234.zip (stored 0%)\n",
            "  adding: training_datas/train_data28420.zip (stored 0%)\n",
            "  adding: training_datas/train_data4113.zip (stored 0%)\n",
            "  adding: training_datas/train_data24443.zip (stored 0%)\n",
            "  adding: training_datas/train_data30467.zip (stored 0%)\n",
            "  adding: training_datas/train_data18116.zip (stored 0%)\n",
            "  adding: training_datas/train_data20478.zip (stored 0%)\n",
            "  adding: training_datas/train_data25491.zip (stored 0%)\n",
            "  adding: training_datas/train_data13406.zip (stored 0%)\n",
            "  adding: training_datas/train_data24513.zip (stored 0%)\n",
            "  adding: training_datas/train_data1999.zip (stored 0%)\n",
            "  adding: training_datas/train_data23669.zip (stored 0%)\n",
            "  adding: training_datas/train_data10201.zip (stored 0%)\n",
            "  adding: training_datas/train_data28786.zip (stored 0%)\n",
            "  adding: training_datas/train_data5837.zip (stored 0%)\n",
            "  adding: training_datas/train_data14992.zip (stored 0%)\n",
            "  adding: training_datas/train_data22506.zip (stored 0%)\n",
            "  adding: training_datas/train_data15974.zip (stored 0%)\n",
            "  adding: training_datas/train_data28741.zip (stored 0%)\n",
            "  adding: training_datas/train_data25498.zip (stored 0%)\n",
            "  adding: training_datas/train_data22509.zip (stored 0%)\n",
            "  adding: training_datas/train_data15640.zip (stored 0%)\n",
            "  adding: training_datas/train_data13594.zip (stored 0%)\n",
            "  adding: training_datas/train_data4074.zip (stored 0%)\n",
            "  adding: training_datas/train_data24277.zip (stored 0%)\n",
            "  adding: training_datas/train_data304.zip (stored 0%)\n",
            "  adding: training_datas/train_data8514.zip (stored 0%)\n",
            "  adding: training_datas/train_data19999.zip (stored 0%)\n",
            "  adding: training_datas/train_data13254.zip (stored 0%)\n",
            "  adding: training_datas/train_data25154.zip (stored 0%)\n",
            "  adding: training_datas/train_data18783.zip (stored 0%)\n",
            "  adding: training_datas/train_data13290.zip (stored 0%)\n",
            "  adding: training_datas/train_data24569.zip (stored 0%)\n",
            "  adding: training_datas/train_data5435.zip (stored 0%)\n",
            "  adding: training_datas/train_data19872.zip (stored 0%)\n",
            "  adding: training_datas/train_data11349.zip (stored 0%)\n",
            "  adding: training_datas/train_data9169.zip (stored 0%)\n",
            "  adding: training_datas/train_data19200.zip (stored 0%)\n",
            "  adding: training_datas/train_data11995.zip (stored 0%)\n",
            "  adding: training_datas/train_data14449.zip (stored 0%)\n",
            "  adding: training_datas/train_data3375.zip (stored 0%)\n",
            "  adding: training_datas/train_data12001.zip (stored 0%)\n",
            "  adding: training_datas/train_data14741.zip (stored 0%)\n",
            "  adding: training_datas/train_data14099.zip (stored 0%)\n",
            "  adding: training_datas/train_data16977.zip (stored 0%)\n",
            "  adding: training_datas/train_data1679.zip (stored 0%)\n",
            "  adding: training_datas/train_data17311.zip (stored 0%)\n",
            "  adding: training_datas/train_data18591.zip (stored 0%)\n",
            "  adding: training_datas/train_data11743.zip (stored 0%)\n",
            "  adding: training_datas/train_data7454.zip (stored 0%)\n",
            "  adding: training_datas/train_data18996.zip (stored 0%)\n",
            "  adding: training_datas/train_data10795.zip (stored 0%)\n",
            "  adding: training_datas/train_data23049.zip (stored 0%)\n",
            "  adding: training_datas/train_data11167.zip (stored 0%)\n",
            "  adding: training_datas/train_data2942.zip (stored 0%)\n",
            "  adding: training_datas/train_data881.zip (stored 0%)\n",
            "  adding: training_datas/train_data4190.zip (stored 0%)\n",
            "  adding: training_datas/train_data28832.zip (stored 0%)\n",
            "  adding: training_datas/train_data17125.zip (stored 0%)\n",
            "  adding: training_datas/train_data22763.zip (stored 0%)\n",
            "  adding: training_datas/train_data25336.zip (stored 0%)\n",
            "  adding: training_datas/train_data8087.zip (stored 0%)\n",
            "  adding: training_datas/train_data7669.zip (stored 0%)\n",
            "  adding: training_datas/train_data10084.zip (stored 0%)\n",
            "  adding: training_datas/train_data1798.zip (stored 0%)\n",
            "  adding: training_datas/train_data7096.zip (stored 0%)\n",
            "  adding: training_datas/train_data20311.zip (stored 0%)\n",
            "  adding: training_datas/train_data15744.zip (stored 0%)\n",
            "  adding: training_datas/train_data14400.zip (stored 0%)\n",
            "  adding: training_datas/train_data9405.zip (stored 0%)\n",
            "  adding: training_datas/train_data7009.zip (stored 0%)\n",
            "  adding: training_datas/train_data9818.zip (stored 0%)\n",
            "  adding: training_datas/train_data1904.zip (stored 0%)\n",
            "  adding: training_datas/train_data22548.zip (stored 0%)\n",
            "  adding: training_datas/train_data6536.zip (stored 0%)\n",
            "  adding: training_datas/train_data15782.zip (stored 0%)\n",
            "  adding: training_datas/train_data3605.zip (stored 0%)\n",
            "  adding: training_datas/train_data5122.zip (stored 0%)\n",
            "  adding: training_datas/train_data7522.zip (stored 0%)\n",
            "  adding: training_datas/train_data3183.zip (stored 0%)\n",
            "  adding: training_datas/train_data3795.zip (stored 0%)\n",
            "  adding: training_datas/train_data8580.zip (stored 0%)\n",
            "  adding: training_datas/train_data28216.zip (stored 0%)\n",
            "  adding: training_datas/train_data15262.zip (stored 0%)\n",
            "  adding: training_datas/train_data9958.zip (stored 0%)\n",
            "  adding: training_datas/train_data17442.zip (stored 0%)\n",
            "  adding: training_datas/train_data15675.zip (stored 0%)\n",
            "  adding: training_datas/train_data7402.zip (stored 0%)\n",
            "  adding: training_datas/train_data14900.zip (stored 0%)\n",
            "  adding: training_datas/train_data17399.zip (stored 0%)\n",
            "  adding: training_datas/train_data20862.zip (stored 0%)\n",
            "  adding: training_datas/train_data21078.zip (stored 0%)\n",
            "  adding: training_datas/train_data14999.zip (stored 0%)\n",
            "  adding: training_datas/train_data20109.zip (stored 0%)\n",
            "  adding: training_datas/train_data7450.zip (stored 0%)\n",
            "  adding: training_datas/train_data30129.zip (stored 0%)\n",
            "  adding: training_datas/train_data6161.zip (stored 0%)\n",
            "  adding: training_datas/train_data9573.zip (stored 0%)\n",
            "  adding: training_datas/train_data20733.zip (stored 0%)\n",
            "  adding: training_datas/train_data12147.zip (stored 0%)\n",
            "  adding: training_datas/train_data5622.zip (stored 0%)\n",
            "  adding: training_datas/train_data26338.zip (stored 0%)\n",
            "  adding: training_datas/train_data13642.zip (stored 0%)\n",
            "  adding: training_datas/train_data1183.zip (stored 0%)\n",
            "  adding: training_datas/train_data28082.zip (stored 0%)\n",
            "  adding: training_datas/train_data21312.zip (stored 0%)\n",
            "  adding: training_datas/train_data24042.zip (stored 0%)\n",
            "  adding: training_datas/train_data7726.zip (stored 0%)\n",
            "  adding: training_datas/train_data24485.zip (stored 0%)\n",
            "  adding: training_datas/train_data20207.zip (stored 0%)\n",
            "  adding: training_datas/train_data19957.zip (stored 0%)\n",
            "  adding: training_datas/train_data15494.zip (stored 0%)\n",
            "  adding: training_datas/train_data24920.zip (stored 0%)\n",
            "  adding: training_datas/train_data1341.zip (stored 0%)\n",
            "  adding: training_datas/train_data5109.zip (stored 0%)\n",
            "  adding: training_datas/train_data25963.zip (stored 0%)\n",
            "  adding: training_datas/train_data8880.zip (stored 0%)\n",
            "  adding: training_datas/train_data22186.zip (stored 0%)\n",
            "  adding: training_datas/train_data38.zip (stored 0%)\n",
            "  adding: training_datas/train_data8887.zip (stored 0%)\n",
            "  adding: training_datas/train_data18700.zip (stored 0%)\n",
            "  adding: training_datas/train_data3140.zip (stored 0%)\n",
            "  adding: training_datas/train_data25365.zip (stored 0%)\n",
            "  adding: training_datas/train_data2478.zip (stored 0%)\n",
            "  adding: training_datas/train_data3849.zip (stored 0%)\n",
            "  adding: training_datas/train_data19026.zip (stored 0%)\n",
            "  adding: training_datas/train_data19565.zip (stored 0%)\n",
            "  adding: training_datas/train_data22089.zip (stored 0%)\n",
            "  adding: training_datas/train_data94.zip (stored 0%)\n",
            "  adding: training_datas/train_data823.zip (stored 0%)\n",
            "  adding: training_datas/train_data27065.zip (stored 0%)\n",
            "  adding: training_datas/train_data23637.zip (stored 0%)\n",
            "  adding: training_datas/train_data1326.zip (stored 0%)\n",
            "  adding: training_datas/train_data322.zip (stored 0%)\n",
            "  adding: training_datas/train_data25404.zip (stored 0%)\n",
            "  adding: training_datas/train_data12204.zip (stored 0%)\n",
            "  adding: training_datas/train_data13144.zip (stored 0%)\n",
            "  adding: training_datas/train_data13020.zip (stored 0%)\n",
            "  adding: training_datas/train_data1995.zip (stored 0%)\n",
            "  adding: training_datas/train_data15305.zip (stored 0%)\n",
            "  adding: training_datas/train_data29019.zip (stored 0%)\n",
            "  adding: training_datas/train_data22769.zip (stored 0%)\n",
            "  adding: training_datas/train_data11313.zip (stored 0%)\n",
            "  adding: training_datas/train_data21405.zip (stored 0%)\n",
            "  adding: training_datas/train_data7517.zip (stored 0%)\n",
            "  adding: training_datas/train_data1791.zip (stored 0%)\n",
            "  adding: training_datas/train_data18908.zip (stored 0%)\n",
            "  adding: training_datas/train_data21199.zip (stored 0%)\n",
            "  adding: training_datas/train_data14487.zip (stored 0%)\n",
            "  adding: training_datas/train_data16769.zip (stored 0%)\n",
            "  adding: training_datas/train_data601.zip (stored 0%)\n",
            "  adding: training_datas/train_data6776.zip (stored 0%)\n",
            "  adding: training_datas/train_data25094.zip (stored 0%)\n",
            "  adding: training_datas/train_data18906.zip (stored 0%)\n",
            "  adding: training_datas/train_data5858.zip (stored 0%)\n",
            "  adding: training_datas/train_data6340.zip (stored 0%)\n",
            "  adding: training_datas/train_data21285.zip (stored 0%)\n",
            "  adding: training_datas/train_data27252.zip (stored 0%)\n",
            "  adding: training_datas/train_data11117.zip (stored 0%)\n",
            "  adding: training_datas/train_data22656.zip (stored 0%)\n",
            "  adding: training_datas/train_data12673.zip (stored 0%)\n",
            "  adding: training_datas/train_data26986.zip (stored 0%)\n",
            "  adding: training_datas/train_data3937.zip (stored 0%)\n",
            "  adding: training_datas/train_data9923.zip (stored 0%)\n",
            "  adding: training_datas/train_data28848.zip (stored 0%)\n",
            "  adding: training_datas/train_data29324.zip (stored 0%)\n",
            "  adding: training_datas/train_data6688.zip (stored 0%)\n",
            "  adding: training_datas/train_data11716.zip (stored 0%)\n",
            "  adding: training_datas/train_data6182.zip (stored 0%)\n",
            "  adding: training_datas/train_data16964.zip (stored 0%)\n",
            "  adding: training_datas/train_data23231.zip (stored 0%)\n",
            "  adding: training_datas/train_data13731.zip (stored 0%)\n",
            "  adding: training_datas/train_data3908.zip (stored 0%)\n",
            "  adding: training_datas/train_data21473.zip (stored 0%)\n",
            "  adding: training_datas/train_data1880.zip (stored 0%)\n",
            "  adding: training_datas/train_data22756.zip (stored 0%)\n",
            "  adding: training_datas/train_data30021.zip (stored 0%)\n",
            "  adding: training_datas/train_data13794.zip (stored 0%)\n",
            "  adding: training_datas/train_data23440.zip (stored 0%)\n",
            "  adding: training_datas/train_data3236.zip (stored 0%)\n",
            "  adding: training_datas/train_data26233.zip (stored 0%)\n",
            "  adding: training_datas/train_data7024.zip (stored 0%)\n",
            "  adding: training_datas/train_data10348.zip (stored 0%)\n",
            "  adding: training_datas/train_data2806.zip (stored 0%)\n",
            "  adding: training_datas/train_data24088.zip (stored 0%)\n",
            "  adding: training_datas/train_data27509.zip (stored 0%)\n",
            "  adding: training_datas/train_data17747.zip (stored 0%)\n",
            "  adding: training_datas/train_data24098.zip (stored 0%)\n",
            "  adding: training_datas/train_data29330.zip (stored 0%)\n",
            "  adding: training_datas/train_data1529.zip (stored 0%)\n",
            "  adding: training_datas/train_data24007.zip (stored 0%)\n",
            "  adding: training_datas/train_data16503.zip (stored 0%)\n",
            "  adding: training_datas/train_data16551.zip (stored 0%)\n",
            "  adding: training_datas/train_data16035.zip (stored 0%)\n",
            "  adding: training_datas/train_data11518.zip (stored 0%)\n",
            "  adding: training_datas/train_data29651.zip (stored 0%)\n",
            "  adding: training_datas/train_data18407.zip (stored 0%)\n",
            "  adding: training_datas/train_data27365.zip (stored 0%)\n",
            "  adding: training_datas/train_data11508.zip (stored 0%)\n",
            "  adding: training_datas/train_data3655.zip (stored 0%)\n",
            "  adding: training_datas/train_data19527.zip (stored 0%)\n",
            "  adding: training_datas/train_data9555.zip (stored 0%)\n",
            "  adding: training_datas/train_data23644.zip (stored 0%)\n",
            "  adding: training_datas/train_data24464.zip (stored 0%)\n",
            "  adding: training_datas/train_data12125.zip (stored 0%)\n",
            "  adding: training_datas/train_data14136.zip (stored 0%)\n",
            "  adding: training_datas/train_data23918.zip (stored 0%)\n",
            "  adding: training_datas/train_data6187.zip (stored 0%)\n",
            "  adding: training_datas/train_data21659.zip (stored 0%)\n",
            "  adding: training_datas/train_data13644.zip (stored 0%)\n",
            "  adding: training_datas/train_data5395.zip (stored 0%)\n",
            "  adding: training_datas/train_data7393.zip (stored 0%)\n",
            "  adding: training_datas/train_data2230.zip (stored 0%)\n",
            "  adding: training_datas/train_data15132.zip (stored 0%)\n",
            "  adding: training_datas/train_data4084.zip (stored 0%)\n",
            "  adding: training_datas/train_data26821.zip (stored 0%)\n",
            "  adding: training_datas/train_data14758.zip (stored 0%)\n",
            "  adding: training_datas/train_data3029.zip (stored 0%)\n",
            "  adding: training_datas/train_data16738.zip (stored 0%)\n",
            "  adding: training_datas/train_data1524.zip (stored 0%)\n",
            "  adding: training_datas/train_data1035.zip (stored 0%)\n",
            "  adding: training_datas/train_data14067.zip (stored 0%)\n",
            "  adding: training_datas/train_data1737.zip (stored 0%)\n",
            "  adding: training_datas/train_data27248.zip (stored 0%)\n",
            "  adding: training_datas/train_data15755.zip (stored 0%)\n",
            "  adding: training_datas/train_data7381.zip (stored 0%)\n",
            "  adding: training_datas/train_data13362.zip (stored 0%)\n",
            "  adding: training_datas/train_data18916.zip (stored 0%)\n",
            "  adding: training_datas/train_data21390.zip (stored 0%)\n",
            "  adding: training_datas/train_data13160.zip (stored 0%)\n",
            "  adding: training_datas/train_data25831.zip (stored 0%)\n",
            "  adding: training_datas/train_data15855.zip (stored 0%)\n",
            "  adding: training_datas/train_data16395.zip (stored 0%)\n",
            "  adding: training_datas/train_data20015.zip (stored 0%)\n",
            "  adding: training_datas/train_data22392.zip (stored 0%)\n",
            "  adding: training_datas/train_data28952.zip (stored 0%)\n",
            "  adding: training_datas/train_data542.zip (stored 0%)\n",
            "  adding: training_datas/train_data29681.zip (stored 0%)\n",
            "  adding: training_datas/train_data12313.zip (stored 0%)\n",
            "  adding: training_datas/train_data15241.zip (stored 0%)\n",
            "  adding: training_datas/train_data27060.zip (stored 0%)\n",
            "  adding: training_datas/train_data28477.zip (stored 0%)\n",
            "  adding: training_datas/train_data8599.zip (stored 0%)\n",
            "  adding: training_datas/train_data19350.zip (stored 0%)\n",
            "  adding: training_datas/train_data14492.zip (stored 0%)\n",
            "  adding: training_datas/train_data15954.zip (stored 0%)\n",
            "  adding: training_datas/train_data22885.zip (stored 0%)\n",
            "  adding: training_datas/train_data16484.zip (stored 0%)\n",
            "  adding: training_datas/train_data5741.zip (stored 0%)\n",
            "  adding: training_datas/train_data12944.zip (stored 0%)\n",
            "  adding: training_datas/train_data23054.zip (stored 0%)\n",
            "  adding: training_datas/train_data18001.zip (stored 0%)\n",
            "  adding: training_datas/train_data20626.zip (stored 0%)\n",
            "  adding: training_datas/train_data25636.zip (stored 0%)\n",
            "  adding: training_datas/train_data24739.zip (stored 0%)\n",
            "  adding: training_datas/train_data10572.zip (stored 0%)\n",
            "  adding: training_datas/train_data15699.zip (stored 0%)\n",
            "  adding: training_datas/train_data16358.zip (stored 0%)\n",
            "  adding: training_datas/train_data4667.zip (stored 0%)\n",
            "  adding: training_datas/train_data25069.zip (stored 0%)\n",
            "  adding: training_datas/train_data3123.zip (stored 0%)\n",
            "  adding: training_datas/train_data3985.zip (stored 0%)\n",
            "  adding: training_datas/train_data3869.zip (stored 0%)\n",
            "  adding: training_datas/train_data5428.zip (stored 0%)\n",
            "  adding: training_datas/train_data16575.zip (stored 0%)\n",
            "  adding: training_datas/train_data20644.zip (stored 0%)\n",
            "  adding: training_datas/train_data25160.zip (stored 0%)\n",
            "  adding: training_datas/train_data3789.zip (stored 0%)\n",
            "  adding: training_datas/train_data23842.zip (stored 0%)\n",
            "  adding: training_datas/train_data1273.zip (stored 0%)\n",
            "  adding: training_datas/train_data12370.zip (stored 0%)\n",
            "  adding: training_datas/train_data9920.zip (stored 0%)\n",
            "  adding: training_datas/train_data13323.zip (stored 0%)\n",
            "  adding: training_datas/train_data13669.zip (stored 0%)\n",
            "  adding: training_datas/train_data17225.zip (stored 0%)\n",
            "  adding: training_datas/train_data26583.zip (stored 0%)\n",
            "  adding: training_datas/train_data6849.zip (stored 0%)\n",
            "  adding: training_datas/train_data12385.zip (stored 0%)\n",
            "  adding: training_datas/train_data19612.zip (stored 0%)\n",
            "  adding: training_datas/train_data11047.zip (stored 0%)\n",
            "  adding: training_datas/train_data24428.zip (stored 0%)\n",
            "  adding: training_datas/train_data10203.zip (stored 0%)\n",
            "  adding: training_datas/train_data59.zip (stored 0%)\n",
            "  adding: training_datas/train_data14069.zip (stored 0%)\n",
            "  adding: training_datas/train_data9800.zip (stored 0%)\n",
            "  adding: training_datas/train_data11554.zip (stored 0%)\n",
            "  adding: training_datas/train_data24683.zip (stored 0%)\n",
            "  adding: training_datas/train_data21083.zip (stored 0%)\n",
            "  adding: training_datas/train_data29959.zip (stored 0%)\n",
            "  adding: training_datas/train_data29468.zip (stored 0%)\n",
            "  adding: training_datas/train_data28990.zip (stored 0%)\n",
            "  adding: training_datas/train_data15225.zip (stored 0%)\n",
            "  adding: training_datas/train_data11381.zip (stored 0%)\n",
            "  adding: training_datas/train_data25539.zip (stored 0%)\n",
            "  adding: training_datas/train_data4766.zip (stored 0%)\n",
            "  adding: training_datas/train_data7653.zip (stored 0%)\n",
            "  adding: training_datas/train_data5664.zip (stored 0%)\n",
            "  adding: training_datas/train_data28047.zip (stored 0%)\n",
            "  adding: training_datas/train_data7292.zip (stored 0%)\n",
            "  adding: training_datas/train_data28146.zip (stored 0%)\n",
            "  adding: training_datas/train_data19929.zip (stored 0%)\n",
            "  adding: training_datas/train_data27153.zip (stored 0%)\n",
            "  adding: training_datas/train_data11533.zip (stored 0%)\n",
            "  adding: training_datas/train_data27224.zip (stored 0%)\n",
            "  adding: training_datas/train_data21263.zip (stored 0%)\n",
            "  adding: training_datas/train_data3958.zip (stored 0%)\n",
            "  adding: training_datas/train_data20897.zip (stored 0%)\n",
            "  adding: training_datas/train_data2104.zip (stored 0%)\n",
            "  adding: training_datas/train_data29458.zip (stored 0%)\n",
            "  adding: training_datas/train_data16885.zip (stored 0%)\n",
            "  adding: training_datas/train_data26875.zip (stored 0%)\n",
            "  adding: training_datas/train_data8924.zip (stored 0%)\n",
            "  adding: training_datas/train_data18960.zip (stored 0%)\n",
            "  adding: training_datas/train_data13950.zip (stored 0%)\n",
            "  adding: training_datas/train_data15861.zip (stored 0%)\n",
            "  adding: training_datas/train_data22901.zip (stored 0%)\n",
            "  adding: training_datas/train_data5113.zip (stored 0%)\n",
            "  adding: training_datas/train_data3964.zip (stored 0%)\n",
            "  adding: training_datas/train_data29880.zip (stored 0%)\n",
            "  adding: training_datas/train_data706.zip (stored 0%)\n",
            "  adding: training_datas/train_data16524.zip (stored 0%)\n",
            "  adding: training_datas/train_data17193.zip (stored 0%)\n",
            "  adding: training_datas/train_data7286.zip (stored 0%)\n",
            "  adding: training_datas/train_data9021.zip (stored 0%)\n",
            "  adding: training_datas/train_data14803.zip (stored 0%)\n",
            "  adding: training_datas/train_data18766.zip (stored 0%)\n",
            "  adding: training_datas/train_data2609.zip (stored 0%)\n",
            "  adding: training_datas/train_data28654.zip (stored 0%)\n",
            "  adding: training_datas/train_data2692.zip (stored 0%)\n",
            "  adding: training_datas/train_data28325.zip (stored 0%)\n",
            "  adding: training_datas/train_data22227.zip (stored 0%)\n",
            "  adding: training_datas/train_data18929.zip (stored 0%)\n",
            "  adding: training_datas/train_data28327.zip (stored 0%)\n",
            "  adding: training_datas/train_data27466.zip (stored 0%)\n",
            "  adding: training_datas/train_data4656.zip (stored 0%)\n",
            "  adding: training_datas/train_data23545.zip (stored 0%)\n",
            "  adding: training_datas/train_data17431.zip (stored 0%)\n",
            "  adding: training_datas/train_data1191.zip (stored 0%)\n",
            "  adding: training_datas/train_data9663.zip (stored 0%)\n",
            "  adding: training_datas/train_data29861.zip (stored 0%)\n",
            "  adding: training_datas/train_data2295.zip (stored 0%)\n",
            "  adding: training_datas/train_data30242.zip (stored 0%)\n",
            "  adding: training_datas/train_data21112.zip (stored 0%)\n",
            "  adding: training_datas/train_data18925.zip (stored 0%)\n",
            "  adding: training_datas/train_data4343.zip (stored 0%)\n",
            "  adding: training_datas/train_data378.zip (stored 0%)\n",
            "  adding: training_datas/train_data26665.zip (stored 0%)\n",
            "  adding: training_datas/train_data15577.zip (stored 0%)\n",
            "  adding: training_datas/train_data22043.zip (stored 0%)\n",
            "  adding: training_datas/train_data15583.zip (stored 0%)\n",
            "  adding: training_datas/train_data6672.zip (stored 0%)\n",
            "  adding: training_datas/train_data2424.zip (stored 0%)\n",
            "  adding: training_datas/train_data24401.zip (stored 0%)\n",
            "  adding: training_datas/train_data14394.zip (stored 0%)\n",
            "  adding: training_datas/train_data29702.zip (stored 0%)\n",
            "  adding: training_datas/train_data4593.zip (stored 0%)\n",
            "  adding: training_datas/train_data24289.zip (stored 0%)\n",
            "  adding: training_datas/train_data20833.zip (stored 0%)\n",
            "  adding: training_datas/train_data3352.zip (stored 0%)\n",
            "  adding: training_datas/train_data21201.zip (stored 0%)\n",
            "  adding: training_datas/train_data5540.zip (stored 0%)\n",
            "  adding: training_datas/train_data13597.zip (stored 0%)\n",
            "  adding: training_datas/train_data20661.zip (stored 0%)\n",
            "  adding: training_datas/train_data19671.zip (stored 0%)\n",
            "  adding: training_datas/train_data22150.zip (stored 0%)\n",
            "  adding: training_datas/train_data16904.zip (stored 0%)\n",
            "  adding: training_datas/train_data7116.zip (stored 0%)\n",
            "  adding: training_datas/train_data28397.zip (stored 0%)\n",
            "  adding: training_datas/train_data3445.zip (stored 0%)\n",
            "  adding: training_datas/train_data2626.zip (stored 0%)\n",
            "  adding: training_datas/train_data20936.zip (stored 0%)\n",
            "  adding: training_datas/train_data15772.zip (stored 0%)\n",
            "  adding: training_datas/train_data27832.zip (stored 0%)\n",
            "  adding: training_datas/train_data20503.zip (stored 0%)\n",
            "  adding: training_datas/train_data14205.zip (stored 0%)\n",
            "  adding: training_datas/train_data17633.zip (stored 0%)\n",
            "  adding: training_datas/train_data5835.zip (stored 0%)\n",
            "  adding: training_datas/train_data26308.zip (stored 0%)\n",
            "  adding: training_datas/train_data5104.zip (stored 0%)\n",
            "  adding: training_datas/train_data5628.zip (stored 0%)\n",
            "  adding: training_datas/train_data5364.zip (stored 0%)\n",
            "  adding: training_datas/train_data1145.zip (stored 0%)\n",
            "  adding: training_datas/train_data9248.zip (stored 0%)\n",
            "  adding: training_datas/train_data5832.zip (stored 0%)\n",
            "  adding: training_datas/train_data1530.zip (stored 0%)\n",
            "  adding: training_datas/train_data10408.zip (stored 0%)\n",
            "  adding: training_datas/train_data17561.zip (stored 0%)\n",
            "  adding: training_datas/train_data23785.zip (stored 0%)\n",
            "  adding: training_datas/train_data15695.zip (stored 0%)\n",
            "  adding: training_datas/train_data477.zip (stored 0%)\n",
            "  adding: training_datas/train_data26431.zip (stored 0%)\n",
            "  adding: training_datas/train_data8107.zip (stored 0%)\n",
            "  adding: training_datas/train_data25561.zip (stored 0%)\n",
            "  adding: training_datas/train_data3159.zip (stored 0%)\n",
            "  adding: training_datas/train_data7288.zip (stored 0%)\n",
            "  adding: training_datas/train_data13685.zip (stored 0%)\n",
            "  adding: training_datas/train_data2270.zip (stored 0%)\n",
            "  adding: training_datas/train_data17002.zip (stored 0%)\n",
            "  adding: training_datas/train_data17437.zip (stored 0%)\n",
            "  adding: training_datas/train_data6719.zip (stored 0%)\n",
            "  adding: training_datas/train_data15918.zip (stored 0%)\n",
            "  adding: training_datas/train_data14886.zip (stored 0%)\n",
            "  adding: training_datas/train_data5975.zip (stored 0%)\n",
            "  adding: training_datas/train_data8393.zip (stored 0%)\n",
            "  adding: training_datas/train_data9725.zip (stored 0%)\n",
            "  adding: training_datas/train_data20930.zip (stored 0%)\n",
            "  adding: training_datas/train_data1988.zip (stored 0%)\n",
            "  adding: training_datas/train_data3693.zip (stored 0%)\n",
            "  adding: training_datas/train_data22074.zip (stored 0%)\n",
            "  adding: training_datas/train_data28458.zip (stored 0%)\n",
            "  adding: training_datas/train_data26957.zip (stored 0%)\n",
            "  adding: training_datas/train_data14525.zip (stored 0%)\n",
            "  adding: training_datas/train_data1869.zip (stored 0%)\n",
            "  adding: training_datas/train_data5371.zip (stored 0%)\n",
            "  adding: training_datas/train_data499.zip (stored 0%)\n",
            "  adding: training_datas/train_data9632.zip (stored 0%)\n",
            "  adding: training_datas/train_data2622.zip (stored 0%)\n",
            "  adding: training_datas/train_data7418.zip (stored 0%)\n",
            "  adding: training_datas/train_data3116.zip (stored 0%)\n",
            "  adding: training_datas/train_data17326.zip (stored 0%)\n",
            "  adding: training_datas/train_data8250.zip (stored 0%)\n",
            "  adding: training_datas/train_data16133.zip (stored 0%)\n",
            "  adding: training_datas/train_data8928.zip (stored 0%)\n",
            "  adding: training_datas/train_data11768.zip (stored 0%)\n",
            "  adding: training_datas/train_data12646.zip (stored 0%)\n",
            "  adding: training_datas/train_data15779.zip (stored 0%)\n",
            "  adding: training_datas/train_data25230.zip (stored 0%)\n",
            "  adding: training_datas/train_data5086.zip (stored 0%)\n",
            "  adding: training_datas/train_data25733.zip (stored 0%)\n",
            "  adding: training_datas/train_data28314.zip (stored 0%)\n",
            "  adding: training_datas/train_data4753.zip (stored 0%)\n",
            "  adding: training_datas/train_data13891.zip (stored 0%)\n",
            "  adding: training_datas/train_data1943.zip (stored 0%)\n",
            "  adding: training_datas/train_data26764.zip (stored 0%)\n",
            "  adding: training_datas/train_data15716.zip (stored 0%)\n",
            "  adding: training_datas/train_data29444.zip (stored 0%)\n",
            "  adding: training_datas/train_data23019.zip (stored 0%)\n",
            "  adding: training_datas/train_data23931.zip (stored 0%)\n",
            "  adding: training_datas/train_data20353.zip (stored 0%)\n",
            "  adding: training_datas/train_data5175.zip (stored 0%)\n",
            "  adding: training_datas/train_data6328.zip (stored 0%)\n",
            "  adding: training_datas/train_data5126.zip (stored 0%)\n",
            "  adding: training_datas/train_data28444.zip (stored 0%)\n",
            "  adding: training_datas/train_data11783.zip (stored 0%)\n",
            "  adding: training_datas/train_data24868.zip (stored 0%)\n",
            "  adding: training_datas/train_data4586.zip (stored 0%)\n",
            "  adding: training_datas/train_data22157.zip (stored 0%)\n",
            "  adding: training_datas/train_data23070.zip (stored 0%)\n",
            "  adding: training_datas/train_data13972.zip (stored 0%)\n",
            "  adding: training_datas/train_data15035.zip (stored 0%)\n",
            "  adding: training_datas/train_data13869.zip (stored 0%)\n",
            "  adding: training_datas/train_data29109.zip (stored 0%)\n",
            "  adding: training_datas/train_data23392.zip (stored 0%)\n",
            "  adding: training_datas/train_data30201.zip (stored 0%)\n",
            "  adding: training_datas/train_data26461.zip (stored 0%)\n",
            "  adding: training_datas/train_data10168.zip (stored 0%)\n",
            "  adding: training_datas/train_data26322.zip (stored 0%)\n",
            "  adding: training_datas/train_data28443.zip (stored 0%)\n",
            "  adding: training_datas/train_data29842.zip (stored 0%)\n",
            "  adding: training_datas/train_data27110.zip (stored 0%)\n",
            "  adding: training_datas/train_data5385.zip (stored 0%)\n",
            "  adding: training_datas/train_data6347.zip (stored 0%)\n",
            "  adding: training_datas/train_data17091.zip (stored 0%)\n",
            "  adding: training_datas/train_data28517.zip (stored 0%)\n",
            "  adding: training_datas/train_data13329.zip (stored 0%)\n",
            "  adding: training_datas/train_data14458.zip (stored 0%)\n",
            "  adding: training_datas/train_data10179.zip (stored 0%)\n",
            "  adding: training_datas/train_data16072.zip (stored 0%)\n",
            "  adding: training_datas/train_data4728.zip (stored 0%)\n",
            "  adding: training_datas/train_data2157.zip (stored 0%)\n",
            "  adding: training_datas/train_data10632.zip (stored 0%)\n",
            "  adding: training_datas/train_data17818.zip (stored 0%)\n",
            "  adding: training_datas/train_data10516.zip (stored 0%)\n",
            "  adding: training_datas/train_data28384.zip (stored 0%)\n",
            "  adding: training_datas/train_data11288.zip (stored 0%)\n",
            "  adding: training_datas/train_data822.zip (stored 0%)\n",
            "  adding: training_datas/train_data19186.zip (stored 0%)\n",
            "  adding: training_datas/train_data5292.zip (stored 0%)\n",
            "  adding: training_datas/train_data11532.zip (stored 0%)\n",
            "  adding: training_datas/train_data22834.zip (stored 0%)\n",
            "  adding: training_datas/train_data16750.zip (stored 0%)\n",
            "  adding: training_datas/train_data5143.zip (stored 0%)\n",
            "  adding: training_datas/train_data11462.zip (stored 0%)\n",
            "  adding: training_datas/train_data803.zip (stored 0%)\n",
            "  adding: training_datas/train_data10042.zip (stored 0%)\n",
            "  adding: training_datas/train_data210.zip (stored 0%)\n",
            "  adding: training_datas/train_data22414.zip (stored 0%)\n",
            "  adding: training_datas/train_data3647.zip (stored 0%)\n",
            "  adding: training_datas/train_data21620.zip (stored 0%)\n",
            "  adding: training_datas/train_data22269.zip (stored 0%)\n",
            "  adding: training_datas/train_data22011.zip (stored 0%)\n",
            "  adding: training_datas/train_data7867.zip (stored 0%)\n",
            "  adding: training_datas/train_data4163.zip (stored 0%)\n",
            "  adding: training_datas/train_data6131.zip (stored 0%)\n",
            "  adding: training_datas/train_data5580.zip (stored 0%)\n",
            "  adding: training_datas/train_data24823.zip (stored 0%)\n",
            "  adding: training_datas/train_data6943.zip (stored 0%)\n",
            "  adding: training_datas/train_data12118.zip (stored 0%)\n",
            "  adding: training_datas/train_data29196.zip (stored 0%)\n",
            "  adding: training_datas/train_data13142.zip (stored 0%)\n",
            "  adding: training_datas/train_data8866.zip (stored 0%)\n",
            "  adding: training_datas/train_data10736.zip (stored 0%)\n",
            "  adding: training_datas/train_data25592.zip (stored 0%)\n",
            "  adding: training_datas/train_data13322.zip (stored 0%)\n",
            "  adding: training_datas/train_data9989.zip (stored 0%)\n",
            "  adding: training_datas/train_data27431.zip (stored 0%)\n",
            "  adding: training_datas/train_data18178.zip (stored 0%)\n",
            "  adding: training_datas/train_data13676.zip (stored 0%)\n",
            "  adding: training_datas/train_data25554.zip (stored 0%)\n",
            "  adding: training_datas/train_data23973.zip (stored 0%)\n",
            "  adding: training_datas/train_data21489.zip (stored 0%)\n",
            "  adding: training_datas/train_data30332.zip (stored 0%)\n",
            "  adding: training_datas/train_data4352.zip (stored 0%)\n",
            "  adding: training_datas/train_data116.zip (stored 0%)\n",
            "  adding: training_datas/train_data6804.zip (stored 0%)\n",
            "  adding: training_datas/train_data13463.zip (stored 0%)\n",
            "  adding: training_datas/train_data27253.zip (stored 0%)\n",
            "  adding: training_datas/train_data19921.zip (stored 0%)\n",
            "  adding: training_datas/train_data14821.zip (stored 0%)\n",
            "  adding: training_datas/train_data8280.zip (stored 0%)\n",
            "  adding: training_datas/train_data8957.zip (stored 0%)\n",
            "  adding: training_datas/train_data21071.zip (stored 0%)\n",
            "  adding: training_datas/train_data26724.zip (stored 0%)\n",
            "  adding: training_datas/train_data27087.zip (stored 0%)\n",
            "  adding: training_datas/train_data2348.zip (stored 0%)\n",
            "  adding: training_datas/train_data19171.zip (stored 0%)\n",
            "  adding: training_datas/train_data20230.zip (stored 0%)\n",
            "  adding: training_datas/train_data20408.zip (stored 0%)\n",
            "  adding: training_datas/train_data22106.zip (stored 0%)\n",
            "  adding: training_datas/train_data9823.zip (stored 0%)\n",
            "  adding: training_datas/train_data22054.zip (stored 0%)\n",
            "  adding: training_datas/train_data6283.zip (stored 0%)\n",
            "  adding: training_datas/train_data5606.zip (stored 0%)\n",
            "  adding: training_datas/train_data8721.zip (stored 0%)\n",
            "  adding: training_datas/train_data26432.zip (stored 0%)\n",
            "  adding: training_datas/train_data20524.zip (stored 0%)\n",
            "  adding: training_datas/train_data3980.zip (stored 0%)\n",
            "  adding: training_datas/train_data11383.zip (stored 0%)\n",
            "  adding: training_datas/train_data8469.zip (stored 0%)\n",
            "  adding: training_datas/train_data16851.zip (stored 0%)\n",
            "  adding: training_datas/train_data21899.zip (stored 0%)\n",
            "  adding: training_datas/train_data12295.zip (stored 0%)\n",
            "  adding: training_datas/train_data9188.zip (stored 0%)\n",
            "  adding: training_datas/train_data11150.zip (stored 0%)\n",
            "  adding: training_datas/train_data21421.zip (stored 0%)\n",
            "  adding: training_datas/train_data12294.zip (stored 0%)\n",
            "  adding: training_datas/train_data17426.zip (stored 0%)\n",
            "  adding: training_datas/train_data3603.zip (stored 0%)\n",
            "  adding: training_datas/train_data1857.zip (stored 0%)\n",
            "  adding: training_datas/train_data11236.zip (stored 0%)\n",
            "  adding: training_datas/train_data5079.zip (stored 0%)\n",
            "  adding: training_datas/train_data446.zip (stored 0%)\n",
            "  adding: training_datas/train_data19935.zip (stored 0%)\n",
            "  adding: training_datas/train_data4928.zip (stored 0%)\n",
            "  adding: training_datas/train_data22940.zip (stored 0%)\n",
            "  adding: training_datas/train_data9343.zip (stored 0%)\n",
            "  adding: training_datas/train_data18406.zip (stored 0%)\n",
            "  adding: training_datas/train_data2300.zip (stored 0%)\n",
            "  adding: training_datas/train_data29933.zip (stored 0%)\n",
            "  adding: training_datas/train_data13461.zip (stored 0%)\n",
            "  adding: training_datas/train_data2284.zip (stored 0%)\n",
            "  adding: training_datas/train_data4893.zip (stored 0%)\n",
            "  adding: training_datas/train_data16405.zip (stored 0%)\n",
            "  adding: training_datas/train_data13250.zip (stored 0%)\n",
            "  adding: training_datas/train_data14423.zip (stored 0%)\n",
            "  adding: training_datas/train_data10820.zip (stored 0%)\n",
            "  adding: training_datas/train_data10383.zip (stored 0%)\n",
            "  adding: training_datas/train_data3073.zip (stored 0%)\n",
            "  adding: training_datas/train_data27785.zip (stored 0%)\n",
            "  adding: training_datas/train_data674.zip (stored 0%)\n",
            "  adding: training_datas/train_data15836.zip (stored 0%)\n",
            "  adding: training_datas/train_data21302.zip (stored 0%)\n",
            "  adding: training_datas/train_data4889.zip (stored 0%)\n",
            "  adding: training_datas/train_data12255.zip (stored 0%)\n",
            "  adding: training_datas/train_data8339.zip (stored 0%)\n",
            "  adding: training_datas/train_data11897.zip (stored 0%)\n",
            "  adding: training_datas/train_data7405.zip (stored 0%)\n",
            "  adding: training_datas/train_data23948.zip (stored 0%)\n",
            "  adding: training_datas/train_data25406.zip (stored 0%)\n",
            "  adding: training_datas/train_data22580.zip (stored 0%)\n",
            "  adding: training_datas/train_data25165.zip (stored 0%)\n",
            "  adding: training_datas/train_data13619.zip (stored 0%)\n",
            "  adding: training_datas/train_data27063.zip (stored 0%)\n",
            "  adding: training_datas/train_data24175.zip (stored 0%)\n",
            "  adding: training_datas/train_data19152.zip (stored 0%)\n",
            "  adding: training_datas/train_data24789.zip (stored 0%)\n",
            "  adding: training_datas/train_data27132.zip (stored 0%)\n",
            "  adding: training_datas/train_data23758.zip (stored 0%)\n",
            "  adding: training_datas/train_data23346.zip (stored 0%)\n",
            "  adding: training_datas/train_data27229.zip (stored 0%)\n",
            "  adding: training_datas/train_data27653.zip (stored 0%)\n",
            "  adding: training_datas/train_data10892.zip (stored 0%)\n",
            "  adding: training_datas/train_data4300.zip (stored 0%)\n",
            "  adding: training_datas/train_data4980.zip (stored 0%)\n",
            "  adding: training_datas/train_data839.zip (stored 0%)\n",
            "  adding: training_datas/train_data29212.zip (stored 0%)\n",
            "  adding: training_datas/train_data21407.zip (stored 0%)\n",
            "  adding: training_datas/train_data3017.zip (stored 0%)\n",
            "  adding: training_datas/train_data27949.zip (stored 0%)\n",
            "  adding: training_datas/train_data12554.zip (stored 0%)\n",
            "  adding: training_datas/train_data27761.zip (stored 0%)\n",
            "  adding: training_datas/train_data5324.zip (stored 0%)\n",
            "  adding: training_datas/train_data20158.zip (stored 0%)\n",
            "  adding: training_datas/train_data13055.zip (stored 0%)\n",
            "  adding: training_datas/train_data25632.zip (stored 0%)\n",
            "  adding: training_datas/train_data14229.zip (stored 0%)\n",
            "  adding: training_datas/train_data27773.zip (stored 0%)\n",
            "  adding: training_datas/train_data21289.zip (stored 0%)\n",
            "  adding: training_datas/train_data20442.zip (stored 0%)\n",
            "  adding: training_datas/train_data12982.zip (stored 0%)\n",
            "  adding: training_datas/train_data1150.zip (stored 0%)\n",
            "  adding: training_datas/train_data14355.zip (stored 0%)\n",
            "  adding: training_datas/train_data27055.zip (stored 0%)\n",
            "  adding: training_datas/train_data19993.zip (stored 0%)\n",
            "  adding: training_datas/train_data28405.zip (stored 0%)\n",
            "  adding: training_datas/train_data21248.zip (stored 0%)\n",
            "  adding: training_datas/train_data10904.zip (stored 0%)\n",
            "  adding: training_datas/train_data25393.zip (stored 0%)\n",
            "  adding: training_datas/train_data760.zip (stored 0%)\n",
            "  adding: training_datas/train_data11189.zip (stored 0%)\n",
            "  adding: training_datas/train_data18982.zip (stored 0%)\n",
            "  adding: training_datas/train_data1650.zip (stored 0%)\n",
            "  adding: training_datas/train_data8667.zip (stored 0%)\n",
            "  adding: training_datas/train_data2757.zip (stored 0%)\n",
            "  adding: training_datas/train_data30433.zip (stored 0%)\n",
            "  adding: training_datas/train_data3224.zip (stored 0%)\n",
            "  adding: training_datas/train_data607.zip (stored 0%)\n",
            "  adding: training_datas/train_data621.zip (stored 0%)\n",
            "  adding: training_datas/train_data13656.zip (stored 0%)\n",
            "  adding: training_datas/train_data9350.zip (stored 0%)\n",
            "  adding: training_datas/train_data27415.zip (stored 0%)\n",
            "  adding: training_datas/train_data8775.zip (stored 0%)\n",
            "  adding: training_datas/train_data8710.zip (stored 0%)\n",
            "  adding: training_datas/train_data108.zip (stored 0%)\n",
            "  adding: training_datas/train_data6964.zip (stored 0%)\n",
            "  adding: training_datas/train_data5974.zip (stored 0%)\n",
            "  adding: training_datas/train_data14765.zip (stored 0%)\n",
            "  adding: training_datas/train_data14690.zip (stored 0%)\n",
            "  adding: training_datas/train_data12267.zip (stored 0%)\n",
            "  adding: training_datas/train_data24242.zip (stored 0%)\n",
            "  adding: training_datas/train_data28703.zip (stored 0%)\n",
            "  adding: training_datas/train_data2078.zip (stored 0%)\n",
            "  adding: training_datas/train_data19181.zip (stored 0%)\n",
            "  adding: training_datas/train_data28034.zip (stored 0%)\n",
            "  adding: training_datas/train_data1162.zip (stored 0%)\n",
            "  adding: training_datas/train_data18300.zip (stored 0%)\n",
            "  adding: training_datas/train_data19619.zip (stored 0%)\n",
            "  adding: training_datas/train_data27934.zip (stored 0%)\n",
            "  adding: training_datas/train_data24899.zip (stored 0%)\n",
            "  adding: training_datas/train_data11771.zip (stored 0%)\n",
            "  adding: training_datas/train_data24856.zip (stored 0%)\n",
            "  adding: training_datas/train_data7756.zip (stored 0%)\n",
            "  adding: training_datas/train_data17216.zip (stored 0%)\n",
            "  adding: training_datas/train_data15879.zip (stored 0%)\n",
            "  adding: training_datas/train_data21575.zip (stored 0%)\n",
            "  adding: training_datas/train_data7294.zip (stored 0%)\n",
            "  adding: training_datas/train_data27725.zip (stored 0%)\n",
            "  adding: training_datas/train_data23310.zip (stored 0%)\n",
            "  adding: training_datas/train_data16357.zip (stored 0%)\n",
            "  adding: training_datas/train_data5473.zip (stored 0%)\n",
            "  adding: training_datas/train_data8942.zip (stored 0%)\n",
            "  adding: training_datas/train_data27439.zip (stored 0%)\n",
            "  adding: training_datas/train_data5463.zip (stored 0%)\n",
            "  adding: training_datas/train_data26243.zip (stored 0%)\n",
            "  adding: training_datas/train_data20457.zip (stored 0%)\n",
            "  adding: training_datas/train_data11084.zip (stored 0%)\n",
            "  adding: training_datas/train_data13932.zip (stored 0%)\n",
            "  adding: training_datas/train_data2418.zip (stored 0%)\n",
            "  adding: training_datas/train_data27249.zip (stored 0%)\n",
            "  adding: training_datas/train_data4225.zip (stored 0%)\n",
            "  adding: training_datas/train_data15020.zip (stored 0%)\n",
            "  adding: training_datas/train_data10486.zip (stored 0%)\n",
            "  adding: training_datas/train_data20758.zip (stored 0%)\n",
            "  adding: training_datas/train_data27033.zip (stored 0%)\n",
            "  adding: training_datas/train_data20205.zip (stored 0%)\n",
            "  adding: training_datas/train_data22386.zip (stored 0%)\n",
            "  adding: training_datas/train_data6842.zip (stored 0%)\n",
            "  adding: training_datas/train_data21734.zip (stored 0%)\n",
            "  adding: training_datas/train_data30143.zip (stored 0%)\n",
            "  adding: training_datas/train_data9264.zip (stored 0%)\n",
            "  adding: training_datas/train_data19575.zip (stored 0%)\n",
            "  adding: training_datas/train_data27959.zip (stored 0%)\n",
            "  adding: training_datas/train_data29465.zip (stored 0%)\n",
            "  adding: training_datas/train_data21547.zip (stored 0%)\n",
            "  adding: training_datas/train_data28028.zip (stored 0%)\n",
            "  adding: training_datas/train_data1247.zip (stored 0%)\n",
            "  adding: training_datas/train_data5014.zip (stored 0%)\n",
            "  adding: training_datas/train_data20237.zip (stored 0%)\n",
            "  adding: training_datas/train_data26126.zip (stored 0%)\n",
            "  adding: training_datas/train_data4117.zip (stored 0%)\n",
            "  adding: training_datas/train_data7485.zip (stored 0%)\n",
            "  adding: training_datas/train_data15661.zip (stored 0%)\n",
            "  adding: training_datas/train_data12828.zip (stored 0%)\n",
            "  adding: training_datas/train_data7264.zip (stored 0%)\n",
            "  adding: training_datas/train_data21486.zip (stored 0%)\n",
            "  adding: training_datas/train_data5226.zip (stored 0%)\n",
            "  adding: training_datas/train_data10491.zip (stored 0%)\n",
            "  adding: training_datas/train_data4969.zip (stored 0%)\n",
            "  adding: training_datas/train_data20896.zip (stored 0%)\n",
            "  adding: training_datas/train_data9727.zip (stored 0%)\n",
            "  adding: training_datas/train_data23201.zip (stored 0%)\n",
            "  adding: training_datas/train_data11816.zip (stored 0%)\n",
            "  adding: training_datas/train_data28995.zip (stored 0%)\n",
            "  adding: training_datas/train_data14661.zip (stored 0%)\n",
            "  adding: training_datas/train_data6038.zip (stored 0%)\n",
            "  adding: training_datas/train_data9266.zip (stored 0%)\n",
            "  adding: training_datas/train_data24728.zip (stored 0%)\n",
            "  adding: training_datas/train_data1836.zip (stored 0%)\n",
            "  adding: training_datas/train_data24765.zip (stored 0%)\n",
            "  adding: training_datas/train_data4020.zip (stored 0%)\n",
            "  adding: training_datas/train_data11642.zip (stored 0%)\n",
            "  adding: training_datas/train_data8954.zip (stored 0%)\n",
            "  adding: training_datas/train_data10307.zip (stored 0%)\n",
            "  adding: training_datas/train_data29841.zip (stored 0%)\n",
            "  adding: training_datas/train_data25974.zip (stored 0%)\n",
            "  adding: training_datas/train_data18258.zip (stored 0%)\n",
            "  adding: training_datas/train_data17087.zip (stored 0%)\n",
            "  adding: training_datas/train_data7656.zip (stored 0%)\n",
            "  adding: training_datas/train_data17562.zip (stored 0%)\n",
            "  adding: training_datas/train_data27797.zip (stored 0%)\n",
            "  adding: training_datas/train_data9197.zip (stored 0%)\n",
            "  adding: training_datas/train_data11303.zip (stored 0%)\n",
            "  adding: training_datas/train_data20500.zip (stored 0%)\n",
            "  adding: training_datas/train_data30475.zip (stored 0%)\n",
            "  adding: training_datas/train_data13465.zip (stored 0%)\n",
            "  adding: training_datas/train_data21690.zip (stored 0%)\n",
            "  adding: training_datas/train_data21467.zip (stored 0%)\n",
            "  adding: training_datas/train_data10885.zip (stored 0%)\n",
            "  adding: training_datas/train_data30464.zip (stored 0%)\n",
            "  adding: training_datas/train_data6889.zip (stored 0%)\n",
            "  adding: training_datas/train_data14383.zip (stored 0%)\n",
            "  adding: training_datas/train_data10217.zip (stored 0%)\n",
            "  adding: training_datas/train_data5719.zip (stored 0%)\n",
            "  adding: training_datas/train_data7786.zip (stored 0%)\n",
            "  adding: training_datas/train_data22369.zip (stored 0%)\n",
            "  adding: training_datas/train_data10097.zip (stored 0%)\n",
            "  adding: training_datas/train_data14516.zip (stored 0%)\n",
            "  adding: training_datas/train_data20013.zip (stored 0%)\n",
            "  adding: training_datas/train_data19135.zip (stored 0%)\n",
            "  adding: training_datas/train_data2857.zip (stored 0%)\n",
            "  adding: training_datas/train_data17725.zip (stored 0%)\n",
            "  adding: training_datas/train_data10038.zip (stored 0%)\n",
            "  adding: training_datas/train_data24543.zip (stored 0%)\n",
            "  adding: training_datas/train_data28245.zip (stored 0%)\n",
            "  adding: training_datas/train_data21561.zip (stored 0%)\n",
            "  adding: training_datas/train_data13372.zip (stored 0%)\n",
            "  adding: training_datas/train_data30089.zip (stored 0%)\n",
            "  adding: training_datas/train_data14403.zip (stored 0%)\n",
            "  adding: training_datas/train_data20456.zip (stored 0%)\n",
            "  adding: training_datas/train_data26858.zip (stored 0%)\n",
            "  adding: training_datas/train_data28180.zip (stored 0%)\n",
            "  adding: training_datas/train_data23100.zip (stored 0%)\n",
            "  adding: training_datas/train_data20619.zip (stored 0%)\n",
            "  adding: training_datas/train_data29989.zip (stored 0%)\n",
            "  adding: training_datas/train_data20050.zip (stored 0%)\n",
            "  adding: training_datas/train_data5657.zip (stored 0%)\n",
            "  adding: training_datas/train_data11030.zip (stored 0%)\n",
            "  adding: training_datas/train_data6918.zip (stored 0%)\n",
            "  adding: training_datas/train_data10055.zip (stored 0%)\n",
            "  adding: training_datas/train_data7837.zip (stored 0%)\n",
            "  adding: training_datas/train_data22639.zip (stored 0%)\n",
            "  adding: training_datas/train_data14648.zip (stored 0%)\n",
            "  adding: training_datas/train_data4645.zip (stored 0%)\n",
            "  adding: training_datas/train_data21018.zip (stored 0%)\n",
            "  adding: training_datas/train_data27817.zip (stored 0%)\n",
            "  adding: training_datas/train_data4233.zip (stored 0%)\n",
            "  adding: training_datas/train_data5367.zip (stored 0%)\n",
            "  adding: training_datas/train_data18351.zip (stored 0%)\n",
            "  adding: training_datas/train_data13523.zip (stored 0%)\n",
            "  adding: training_datas/train_data4485.zip (stored 0%)\n",
            "  adding: training_datas/train_data19086.zip (stored 0%)\n",
            "  adding: training_datas/train_data22974.zip (stored 0%)\n",
            "  adding: training_datas/train_data8625.zip (stored 0%)\n",
            "  adding: training_datas/train_data10126.zip (stored 0%)\n",
            "  adding: training_datas/train_data9698.zip (stored 0%)\n",
            "  adding: training_datas/train_data11557.zip (stored 0%)\n",
            "  adding: training_datas/train_data29479.zip (stored 0%)\n",
            "  adding: training_datas/train_data7155.zip (stored 0%)\n",
            "  adding: training_datas/train_data7320.zip (stored 0%)\n",
            "  adding: training_datas/train_data21430.zip (stored 0%)\n",
            "  adding: training_datas/train_data7613.zip (stored 0%)\n",
            "  adding: training_datas/train_data2279.zip (stored 0%)\n",
            "  adding: training_datas/train_data1109.zip (stored 0%)\n",
            "  adding: training_datas/train_data18038.zip (stored 0%)\n",
            "  adding: training_datas/train_data8015.zip (stored 0%)\n",
            "  adding: training_datas/train_data16030.zip (stored 0%)\n",
            "  adding: training_datas/train_data4274.zip (stored 0%)\n",
            "  adding: training_datas/train_data12034.zip (stored 0%)\n",
            "  adding: training_datas/train_data7449.zip (stored 0%)\n",
            "  adding: training_datas/train_data28588.zip (stored 0%)\n",
            "  adding: training_datas/train_data8909.zip (stored 0%)\n",
            "  adding: training_datas/train_data11627.zip (stored 0%)\n",
            "  adding: training_datas/train_data4026.zip (stored 0%)\n",
            "  adding: training_datas/train_data23681.zip (stored 0%)\n",
            "  adding: training_datas/train_data20025.zip (stored 0%)\n",
            "  adding: training_datas/train_data4504.zip (stored 0%)\n",
            "  adding: training_datas/train_data21740.zip (stored 0%)\n",
            "  adding: training_datas/train_data26576.zip (stored 0%)\n",
            "  adding: training_datas/train_data2210.zip (stored 0%)\n",
            "  adding: training_datas/train_data7693.zip (stored 0%)\n",
            "  adding: training_datas/train_data2248.zip (stored 0%)\n",
            "  adding: training_datas/train_data4535.zip (stored 0%)\n",
            "  adding: training_datas/train_data25772.zip (stored 0%)\n",
            "  adding: training_datas/train_data18220.zip (stored 0%)\n",
            "  adding: training_datas/train_data2287.zip (stored 0%)\n",
            "  adding: training_datas/train_data13911.zip (stored 0%)\n",
            "  adding: training_datas/train_data6077.zip (stored 0%)\n",
            "  adding: training_datas/train_data25701.zip (stored 0%)\n",
            "  adding: training_datas/train_data16918.zip (stored 0%)\n",
            "  adding: training_datas/train_data19587.zip (stored 0%)\n",
            "  adding: training_datas/train_data2107.zip (stored 0%)\n",
            "  adding: training_datas/train_data12178.zip (stored 0%)\n",
            "  adding: training_datas/train_data21602.zip (stored 0%)\n",
            "  adding: training_datas/train_data14276.zip (stored 0%)\n",
            "  adding: training_datas/train_data10568.zip (stored 0%)\n",
            "  adding: training_datas/train_data20517.zip (stored 0%)\n",
            "  adding: training_datas/train_data2453.zip (stored 0%)\n",
            "  adding: training_datas/train_data10733.zip (stored 0%)\n",
            "  adding: training_datas/train_data13929.zip (stored 0%)\n",
            "  adding: training_datas/train_data11326.zip (stored 0%)\n",
            "  adding: training_datas/train_data20643.zip (stored 0%)\n",
            "  adding: training_datas/train_data9874.zip (stored 0%)\n",
            "  adding: training_datas/train_data17567.zip (stored 0%)\n",
            "  adding: training_datas/train_data1669.zip (stored 0%)\n",
            "  adding: training_datas/train_data22372.zip (stored 0%)\n",
            "  adding: training_datas/train_data19835.zip (stored 0%)\n",
            "  adding: training_datas/train_data6823.zip (stored 0%)\n",
            "  adding: training_datas/train_data29538.zip (stored 0%)\n",
            "  adding: training_datas/train_data18318.zip (stored 0%)\n",
            "  adding: training_datas/train_data14921.zip (stored 0%)\n",
            "  adding: training_datas/train_data13421.zip (stored 0%)\n",
            "  adding: training_datas/train_data20531.zip (stored 0%)\n",
            "  adding: training_datas/train_data5116.zip (stored 0%)\n",
            "  adding: training_datas/train_data17771.zip (stored 0%)\n",
            "  adding: training_datas/train_data12222.zip (stored 0%)\n",
            "  adding: training_datas/train_data14507.zip (stored 0%)\n",
            "  adding: training_datas/train_data5255.zip (stored 0%)\n",
            "  adding: training_datas/train_data5675.zip (stored 0%)\n",
            "  adding: training_datas/train_data564.zip (stored 0%)\n",
            "  adding: training_datas/train_data12356.zip (stored 0%)\n",
            "  adding: training_datas/train_data9386.zip (stored 0%)\n",
            "  adding: training_datas/train_data8325.zip (stored 0%)\n",
            "  adding: training_datas/train_data14356.zip (stored 0%)\n",
            "  adding: training_datas/train_data13788.zip (stored 0%)\n",
            "  adding: training_datas/train_data17934.zip (stored 0%)\n",
            "  adding: training_datas/train_data19289.zip (stored 0%)\n",
            "  adding: training_datas/train_data9422.zip (stored 0%)\n",
            "  adding: training_datas/train_data1623.zip (stored 0%)\n",
            "  adding: training_datas/train_data14093.zip (stored 0%)\n",
            "  adding: training_datas/train_data12234.zip (stored 0%)\n",
            "  adding: training_datas/train_data9050.zip (stored 0%)\n",
            "  adding: training_datas/train_data2422.zip (stored 0%)\n",
            "  adding: training_datas/train_data22739.zip (stored 0%)\n",
            "  adding: training_datas/train_data6307.zip (stored 0%)\n",
            "  adding: training_datas/train_data29268.zip (stored 0%)\n",
            "  adding: training_datas/train_data501.zip (stored 0%)\n",
            "  adding: training_datas/train_data21085.zip (stored 0%)\n",
            "  adding: training_datas/train_data26828.zip (stored 0%)\n",
            "  adding: training_datas/train_data30161.zip (stored 0%)\n",
            "  adding: training_datas/train_data29623.zip (stored 0%)\n",
            "  adding: training_datas/train_data14629.zip (stored 0%)\n",
            "  adding: training_datas/train_data11787.zip (stored 0%)\n",
            "  adding: training_datas/train_data19910.zip (stored 0%)\n",
            "  adding: training_datas/train_data21233.zip (stored 0%)\n",
            "  adding: training_datas/train_data17824.zip (stored 0%)\n",
            "  adding: training_datas/train_data12651.zip (stored 0%)\n",
            "  adding: training_datas/train_data8733.zip (stored 0%)\n",
            "  adding: training_datas/train_data15693.zip (stored 0%)\n",
            "  adding: training_datas/train_data29611.zip (stored 0%)\n",
            "  adding: training_datas/train_data4033.zip (stored 0%)\n",
            "  adding: training_datas/train_data27222.zip (stored 0%)\n",
            "  adding: training_datas/train_data7638.zip (stored 0%)\n",
            "  adding: training_datas/train_data8189.zip (stored 0%)\n",
            "  adding: training_datas/train_data13632.zip (stored 0%)\n",
            "  adding: training_datas/train_data1834.zip (stored 0%)\n",
            "  adding: training_datas/train_data27273.zip (stored 0%)\n",
            "  adding: training_datas/train_data4902.zip (stored 0%)\n",
            "  adding: training_datas/train_data2689.zip (stored 0%)\n",
            "  adding: training_datas/train_data24496.zip (stored 0%)\n",
            "  adding: training_datas/train_data5167.zip (stored 0%)\n",
            "  adding: training_datas/train_data19199.zip (stored 0%)\n",
            "  adding: training_datas/train_data7847.zip (stored 0%)\n",
            "  adding: training_datas/train_data12045.zip (stored 0%)\n",
            "  adding: training_datas/train_data178.zip (stored 0%)\n",
            "  adding: training_datas/train_data3624.zip (stored 0%)\n",
            "  adding: training_datas/train_data4390.zip (stored 0%)\n",
            "  adding: training_datas/train_data7215.zip (stored 0%)\n",
            "  adding: training_datas/train_data25932.zip (stored 0%)\n",
            "  adding: training_datas/train_data10759.zip (stored 0%)\n",
            "  adding: training_datas/train_data28258.zip (stored 0%)\n",
            "  adding: training_datas/train_data4511.zip (stored 0%)\n",
            "  adding: training_datas/train_data17017.zip (stored 0%)\n",
            "  adding: training_datas/train_data13529.zip (stored 0%)\n",
            "  adding: training_datas/train_data24723.zip (stored 0%)\n",
            "  adding: training_datas/train_data1429.zip (stored 0%)\n",
            "  adding: training_datas/train_data29817.zip (stored 0%)\n",
            "  adding: training_datas/train_data13890.zip (stored 0%)\n",
            "  adding: training_datas/train_data10489.zip (stored 0%)\n",
            "  adding: training_datas/train_data6280.zip (stored 0%)\n",
            "  adding: training_datas/train_data9413.zip (stored 0%)\n",
            "  adding: training_datas/train_data28847.zip (stored 0%)\n",
            "  adding: training_datas/train_data13493.zip (stored 0%)\n",
            "  adding: training_datas/train_data17040.zip (stored 0%)\n",
            "  adding: training_datas/train_data3841.zip (stored 0%)\n",
            "  adding: training_datas/train_data16428.zip (stored 0%)\n",
            "  adding: training_datas/train_data27335.zip (stored 0%)\n",
            "  adding: training_datas/train_data18213.zip (stored 0%)\n",
            "  adding: training_datas/train_data27552.zip (stored 0%)\n",
            "  adding: training_datas/train_data17085.zip (stored 0%)\n",
            "  adding: training_datas/train_data27708.zip (stored 0%)\n",
            "  adding: training_datas/train_data4729.zip (stored 0%)\n",
            "  adding: training_datas/train_data1324.zip (stored 0%)\n",
            "  adding: training_datas/train_data16640.zip (stored 0%)\n",
            "  adding: training_datas/train_data20611.zip (stored 0%)\n",
            "  adding: training_datas/train_data5570.zip (stored 0%)\n",
            "  adding: training_datas/train_data7052.zip (stored 0%)\n",
            "  adding: training_datas/train_data30033.zip (stored 0%)\n",
            "  adding: training_datas/train_data3822.zip (stored 0%)\n",
            "  adding: training_datas/train_data26064.zip (stored 0%)\n",
            "  adding: training_datas/train_data8630.zip (stored 0%)\n",
            "  adding: training_datas/train_data24453.zip (stored 0%)\n",
            "  adding: training_datas/train_data22794.zip (stored 0%)\n",
            "  adding: training_datas/train_data16169.zip (stored 0%)\n",
            "  adding: training_datas/train_data28304.zip (stored 0%)\n",
            "  adding: training_datas/train_data11067.zip (stored 0%)\n",
            "  adding: training_datas/train_data26657.zip (stored 0%)\n",
            "  adding: training_datas/train_data27779.zip (stored 0%)\n",
            "  adding: training_datas/train_data26956.zip (stored 0%)\n",
            "  adding: training_datas/train_data18127.zip (stored 0%)\n",
            "  adding: training_datas/train_data16509.zip (stored 0%)\n",
            "  adding: training_datas/train_data9868.zip (stored 0%)\n",
            "  adding: training_datas/train_data23208.zip (stored 0%)\n",
            "  adding: training_datas/train_data2129.zip (stored 0%)\n",
            "  adding: training_datas/train_data18037.zip (stored 0%)\n",
            "  adding: training_datas/train_data10205.zip (stored 0%)\n",
            "  adding: training_datas/train_data6078.zip (stored 0%)\n",
            "  adding: training_datas/train_data28661.zip (stored 0%)\n",
            "  adding: training_datas/train_data29661.zip (stored 0%)\n",
            "  adding: training_datas/train_data3121.zip (stored 0%)\n",
            "  adding: training_datas/train_data18699.zip (stored 0%)\n",
            "  adding: training_datas/train_data1043.zip (stored 0%)\n",
            "  adding: training_datas/train_data12929.zip (stored 0%)\n",
            "  adding: training_datas/train_data27814.zip (stored 0%)\n",
            "  adding: training_datas/train_data7255.zip (stored 0%)\n",
            "  adding: training_datas/train_data5046.zip (stored 0%)\n",
            "  adding: training_datas/train_data6061.zip (stored 0%)\n",
            "  adding: training_datas/train_data7919.zip (stored 0%)\n",
            "  adding: training_datas/train_data11672.zip (stored 0%)\n",
            "  adding: training_datas/train_data10369.zip (stored 0%)\n",
            "  adding: training_datas/train_data25787.zip (stored 0%)\n",
            "  adding: training_datas/train_data11276.zip (stored 0%)\n",
            "  adding: training_datas/train_data17001.zip (stored 0%)\n",
            "  adding: training_datas/train_data4502.zip (stored 0%)\n",
            "  adding: training_datas/train_data12343.zip (stored 0%)\n",
            "  adding: training_datas/train_data1861.zip (stored 0%)\n",
            "  adding: training_datas/train_data661.zip (stored 0%)\n",
            "  adding: training_datas/train_data25068.zip (stored 0%)\n",
            "  adding: training_datas/train_data22992.zip (stored 0%)\n",
            "  adding: training_datas/train_data1681.zip (stored 0%)\n",
            "  adding: training_datas/train_data8913.zip (stored 0%)\n",
            "  adding: training_datas/train_data19616.zip (stored 0%)\n",
            "  adding: training_datas/train_data13265.zip (stored 0%)\n",
            "  adding: training_datas/train_data15172.zip (stored 0%)\n",
            "  adding: training_datas/train_data3776.zip (stored 0%)\n",
            "  adding: training_datas/train_data14697.zip (stored 0%)\n",
            "  adding: training_datas/train_data1236.zip (stored 0%)\n",
            "  adding: training_datas/train_data15463.zip (stored 0%)\n",
            "  adding: training_datas/train_data2378.zip (stored 0%)\n",
            "  adding: training_datas/train_data5058.zip (stored 0%)\n",
            "  adding: training_datas/train_data4397.zip (stored 0%)\n",
            "  adding: training_datas/train_data3373.zip (stored 0%)\n",
            "  adding: training_datas/train_data26836.zip (stored 0%)\n",
            "  adding: training_datas/train_data28793.zip (stored 0%)\n",
            "  adding: training_datas/train_data4999.zip (stored 0%)\n",
            "  adding: training_datas/train_data6692.zip (stored 0%)\n",
            "  adding: training_datas/train_data8376.zip (stored 0%)\n",
            "  adding: training_datas/train_data4335.zip (stored 0%)\n",
            "  adding: training_datas/train_data3846.zip (stored 0%)\n",
            "  adding: training_datas/train_data11949.zip (stored 0%)\n",
            "  adding: training_datas/train_data22852.zip (stored 0%)\n",
            "  adding: training_datas/train_data9414.zip (stored 0%)\n",
            "  adding: training_datas/train_data7017.zip (stored 0%)\n",
            "  adding: training_datas/train_data23591.zip (stored 0%)\n",
            "  adding: training_datas/train_data4109.zip (stored 0%)\n",
            "  adding: training_datas/train_data15050.zip (stored 0%)\n",
            "  adding: training_datas/train_data28712.zip (stored 0%)\n",
            "  adding: training_datas/train_data19995.zip (stored 0%)\n",
            "  adding: training_datas/train_data7617.zip (stored 0%)\n",
            "  adding: training_datas/train_data9302.zip (stored 0%)\n",
            "  adding: training_datas/train_data11621.zip (stored 0%)\n",
            "  adding: training_datas/train_data22704.zip (stored 0%)\n",
            "  adding: training_datas/train_data5381.zip (stored 0%)\n",
            "  adding: training_datas/train_data25114.zip (stored 0%)\n",
            "  adding: training_datas/train_data25290.zip (stored 0%)\n",
            "  adding: training_datas/train_data24196.zip (stored 0%)\n",
            "  adding: training_datas/train_data16873.zip (stored 0%)\n",
            "  adding: training_datas/train_data4699.zip (stored 0%)\n",
            "  adding: training_datas/train_data3582.zip (stored 0%)\n",
            "  adding: training_datas/train_data22313.zip (stored 0%)\n",
            "  adding: training_datas/train_data3302.zip (stored 0%)\n",
            "  adding: training_datas/train_data18430.zip (stored 0%)\n",
            "  adding: training_datas/train_data26792.zip (stored 0%)\n",
            "  adding: training_datas/train_data21565.zip (stored 0%)\n",
            "  adding: training_datas/train_data12541.zip (stored 0%)\n",
            "  adding: training_datas/train_data30094.zip (stored 0%)\n",
            "  adding: training_datas/train_data20329.zip (stored 0%)\n",
            "  adding: training_datas/train_data9820.zip (stored 0%)\n",
            "  adding: training_datas/train_data20599.zip (stored 0%)\n",
            "  adding: training_datas/train_data19608.zip (stored 0%)\n",
            "  adding: training_datas/train_data26365.zip (stored 0%)\n",
            "  adding: training_datas/train_data24867.zip (stored 0%)\n",
            "  adding: training_datas/train_data5295.zip (stored 0%)\n",
            "  adding: training_datas/train_data10741.zip (stored 0%)\n",
            "  adding: training_datas/train_data23347.zip (stored 0%)\n",
            "  adding: training_datas/train_data3366.zip (stored 0%)\n",
            "  adding: training_datas/train_data11653.zip (stored 0%)\n",
            "  adding: training_datas/train_data8863.zip (stored 0%)\n",
            "  adding: training_datas/train_data8159.zip (stored 0%)\n",
            "  adding: training_datas/train_data3852.zip (stored 0%)\n",
            "  adding: training_datas/train_data19130.zip (stored 0%)\n",
            "  adding: training_datas/train_data28559.zip (stored 0%)\n",
            "  adding: training_datas/train_data9985.zip (stored 0%)\n",
            "  adding: training_datas/train_data8.zip (stored 0%)\n",
            "  adding: training_datas/train_data11965.zip (stored 0%)\n",
            "  adding: training_datas/train_data7694.zip (stored 0%)\n",
            "  adding: training_datas/train_data28909.zip (stored 0%)\n",
            "  adding: training_datas/train_data22458.zip (stored 0%)\n",
            "  adding: training_datas/train_data12297.zip (stored 0%)\n",
            "  adding: training_datas/train_data4447.zip (stored 0%)\n",
            "  adding: training_datas/train_data29550.zip (stored 0%)\n",
            "  adding: training_datas/train_data8445.zip (stored 0%)\n",
            "  adding: training_datas/train_data21542.zip (stored 0%)\n",
            "  adding: training_datas/train_data586.zip (stored 0%)\n",
            "  adding: training_datas/train_data2879.zip (stored 0%)\n",
            "  adding: training_datas/train_data17815.zip (stored 0%)\n",
            "  adding: training_datas/train_data17064.zip (stored 0%)\n",
            "  adding: training_datas/train_data14058.zip (stored 0%)\n",
            "  adding: training_datas/train_data16424.zip (stored 0%)\n",
            "  adding: training_datas/train_data28452.zip (stored 0%)\n",
            "  adding: training_datas/train_data8436.zip (stored 0%)\n",
            "  adding: training_datas/train_data19311.zip (stored 0%)\n",
            "  adding: training_datas/train_data2639.zip (stored 0%)\n",
            "  adding: training_datas/train_data5148.zip (stored 0%)\n",
            "  adding: training_datas/train_data4660.zip (stored 0%)\n",
            "  adding: training_datas/train_data16888.zip (stored 0%)\n",
            "  adding: training_datas/train_data4800.zip (stored 0%)\n",
            "  adding: training_datas/train_data15823.zip (stored 0%)\n",
            "  adding: training_datas/train_data29253.zip (stored 0%)\n",
            "  adding: training_datas/train_data29419.zip (stored 0%)\n",
            "  adding: training_datas/train_data24544.zip (stored 0%)\n",
            "  adding: training_datas/train_data11997.zip (stored 0%)\n",
            "  adding: training_datas/train_data16979.zip (stored 0%)\n",
            "  adding: training_datas/train_data25790.zip (stored 0%)\n",
            "  adding: training_datas/train_data1082.zip (stored 0%)\n",
            "  adding: training_datas/train_data12844.zip (stored 0%)\n",
            "  adding: training_datas/train_data20045.zip (stored 0%)\n",
            "  adding: training_datas/train_data25389.zip (stored 0%)\n",
            "  adding: training_datas/train_data11334.zip (stored 0%)\n",
            "  adding: training_datas/train_data9572.zip (stored 0%)\n",
            "  adding: training_datas/train_data24094.zip (stored 0%)\n",
            "  adding: training_datas/train_data28391.zip (stored 0%)\n",
            "  adding: training_datas/train_data6694.zip (stored 0%)\n",
            "  adding: training_datas/train_data22274.zip (stored 0%)\n",
            "  adding: training_datas/train_data13967.zip (stored 0%)\n",
            "  adding: training_datas/train_data1380.zip (stored 0%)\n",
            "  adding: training_datas/train_data10225.zip (stored 0%)\n",
            "  adding: training_datas/train_data23808.zip (stored 0%)\n",
            "  adding: training_datas/train_data16517.zip (stored 0%)\n",
            "  adding: training_datas/train_data9794.zip (stored 0%)\n",
            "  adding: training_datas/train_data6617.zip (stored 0%)\n",
            "  adding: training_datas/train_data5686.zip (stored 0%)\n",
            "  adding: training_datas/train_data9921.zip (stored 0%)\n",
            "  adding: training_datas/train_data1718.zip (stored 0%)\n",
            "  adding: training_datas/train_data7789.zip (stored 0%)\n",
            "  adding: training_datas/train_data18632.zip (stored 0%)\n",
            "  adding: training_datas/train_data11094.zip (stored 0%)\n",
            "  adding: training_datas/train_data26630.zip (stored 0%)\n",
            "  adding: training_datas/train_data18724.zip (stored 0%)\n",
            "  adding: training_datas/train_data28080.zip (stored 0%)\n",
            "  adding: training_datas/train_data23504.zip (stored 0%)\n",
            "  adding: training_datas/train_data15462.zip (stored 0%)\n",
            "  adding: training_datas/train_data27741.zip (stored 0%)\n",
            "  adding: training_datas/train_data29825.zip (stored 0%)\n",
            "  adding: training_datas/train_data7423.zip (stored 0%)\n",
            "  adding: training_datas/train_data17624.zip (stored 0%)\n",
            "  adding: training_datas/train_data26804.zip (stored 0%)\n",
            "  adding: training_datas/train_data11273.zip (stored 0%)\n",
            "  adding: training_datas/train_data904.zip (stored 0%)\n",
            "  adding: training_datas/train_data9971.zip (stored 0%)\n",
            "  adding: training_datas/train_data26962.zip (stored 0%)\n",
            "  adding: training_datas/train_data7242.zip (stored 0%)\n",
            "  adding: training_datas/train_data4445.zip (stored 0%)\n",
            "  adding: training_datas/train_data15569.zip (stored 0%)\n",
            "  adding: training_datas/train_data21896.zip (stored 0%)\n",
            "  adding: training_datas/train_data16478.zip (stored 0%)\n",
            "  adding: training_datas/train_data11286.zip (stored 0%)\n",
            "  adding: training_datas/train_data14949.zip (stored 0%)\n",
            "  adding: training_datas/train_data30035.zip (stored 0%)\n",
            "  adding: training_datas/train_data1354.zip (stored 0%)\n",
            "  adding: training_datas/train_data1164.zip (stored 0%)\n",
            "  adding: training_datas/train_data8806.zip (stored 0%)\n",
            "  adding: training_datas/train_data25558.zip (stored 0%)\n",
            "  adding: training_datas/train_data17392.zip (stored 0%)\n",
            "  adding: training_datas/train_data15715.zip (stored 0%)\n",
            "  adding: training_datas/train_data21901.zip (stored 0%)\n",
            "  adding: training_datas/train_data25504.zip (stored 0%)\n",
            "  adding: training_datas/train_data1022.zip (stored 0%)\n",
            "  adding: training_datas/train_data3372.zip (stored 0%)\n",
            "  adding: training_datas/train_data24685.zip (stored 0%)\n",
            "  adding: training_datas/train_data17398.zip (stored 0%)\n",
            "  adding: training_datas/train_data11985.zip (stored 0%)\n",
            "  adding: training_datas/train_data17947.zip (stored 0%)\n",
            "  adding: training_datas/train_data29162.zip (stored 0%)\n",
            "  adding: training_datas/train_data13330.zip (stored 0%)\n",
            "  adding: training_datas/train_data21632.zip (stored 0%)\n",
            "  adding: training_datas/train_data15476.zip (stored 0%)\n",
            "  adding: training_datas/train_data14870.zip (stored 0%)\n",
            "  adding: training_datas/train_data4885.zip (stored 0%)\n",
            "  adding: training_datas/train_data17621.zip (stored 0%)\n",
            "  adding: training_datas/train_data14120.zip (stored 0%)\n",
            "  adding: training_datas/train_data7923.zip (stored 0%)\n",
            "  adding: training_datas/train_data17498.zip (stored 0%)\n",
            "  adding: training_datas/train_data21000.zip (stored 0%)\n",
            "  adding: training_datas/train_data1786.zip (stored 0%)\n",
            "  adding: training_datas/train_data7090.zip (stored 0%)\n",
            "  adding: training_datas/train_data905.zip (stored 0%)\n",
            "  adding: training_datas/train_data13743.zip (stored 0%)\n",
            "  adding: training_datas/train_data12640.zip (stored 0%)\n",
            "  adding: training_datas/train_data295.zip (stored 0%)\n",
            "  adding: training_datas/train_data18788.zip (stored 0%)\n",
            "  adding: training_datas/train_data22159.zip (stored 0%)\n",
            "  adding: training_datas/train_data21594.zip (stored 0%)\n",
            "  adding: training_datas/train_data26359.zip (stored 0%)\n",
            "  adding: training_datas/train_data27735.zip (stored 0%)\n",
            "  adding: training_datas/train_data8612.zip (stored 0%)\n",
            "  adding: training_datas/train_data23978.zip (stored 0%)\n",
            "  adding: training_datas/train_data8487.zip (stored 0%)\n",
            "  adding: training_datas/train_data23829.zip (stored 0%)\n",
            "  adding: training_datas/train_data27513.zip (stored 0%)\n",
            "  adding: training_datas/train_data16950.zip (stored 0%)\n",
            "  adding: training_datas/train_data13180.zip (stored 0%)\n",
            "  adding: training_datas/train_data15995.zip (stored 0%)\n",
            "  adding: training_datas/train_data11153.zip (stored 0%)\n",
            "  adding: training_datas/train_data9539.zip (stored 0%)\n",
            "  adding: training_datas/train_data21118.zip (stored 0%)\n",
            "  adding: training_datas/train_data27679.zip (stored 0%)\n",
            "  adding: training_datas/train_data18986.zip (stored 0%)\n",
            "  adding: training_datas/train_data8113.zip (stored 0%)\n",
            "  adding: training_datas/train_data11923.zip (stored 0%)\n",
            "  adding: training_datas/train_data2420.zip (stored 0%)\n",
            "  adding: training_datas/train_data25335.zip (stored 0%)\n",
            "  adding: training_datas/train_data7413.zip (stored 0%)\n",
            "  adding: training_datas/train_data29972.zip (stored 0%)\n",
            "  adding: training_datas/train_data26619.zip (stored 0%)\n",
            "  adding: training_datas/train_data10337.zip (stored 0%)\n",
            "  adding: training_datas/train_data13426.zip (stored 0%)\n",
            "  adding: training_datas/train_data27532.zip (stored 0%)\n",
            "  adding: training_datas/train_data23422.zip (stored 0%)\n",
            "  adding: training_datas/train_data5662.zip (stored 0%)\n",
            "  adding: training_datas/train_data1403.zip (stored 0%)\n",
            "  adding: training_datas/train_data27094.zip (stored 0%)\n",
            "  adding: training_datas/train_data7284.zip (stored 0%)\n",
            "  adding: training_datas/train_data11847.zip (stored 0%)\n",
            "  adding: training_datas/train_data17942.zip (stored 0%)\n",
            "  adding: training_datas/train_data19813.zip (stored 0%)\n",
            "  adding: training_datas/train_data6730.zip (stored 0%)\n",
            "  adding: training_datas/train_data8204.zip (stored 0%)\n",
            "  adding: training_datas/train_data2507.zip (stored 0%)\n",
            "  adding: training_datas/train_data15601.zip (stored 0%)\n",
            "  adding: training_datas/train_data25136.zip (stored 0%)\n",
            "  adding: training_datas/train_data7792.zip (stored 0%)\n",
            "  adding: training_datas/train_data18358.zip (stored 0%)\n",
            "  adding: training_datas/train_data23381.zip (stored 0%)\n",
            "  adding: training_datas/train_data12008.zip (stored 0%)\n",
            "  adding: training_datas/train_data1783.zip (stored 0%)\n",
            "  adding: training_datas/train_data15455.zip (stored 0%)\n",
            "  adding: training_datas/train_data6317.zip (stored 0%)\n",
            "  adding: training_datas/train_data10934.zip (stored 0%)\n",
            "  adding: training_datas/train_data24970.zip (stored 0%)\n",
            "  adding: training_datas/train_data20603.zip (stored 0%)\n",
            "  adding: training_datas/train_data14018.zip (stored 0%)\n",
            "  adding: training_datas/train_data4780.zip (stored 0%)\n",
            "  adding: training_datas/train_data25035.zip (stored 0%)\n",
            "  adding: training_datas/train_data8718.zip (stored 0%)\n",
            "  adding: training_datas/train_data11352.zip (stored 0%)\n",
            "  adding: training_datas/train_data11434.zip (stored 0%)\n",
            "  adding: training_datas/train_data15047.zip (stored 0%)\n",
            "  adding: training_datas/train_data1225.zip (stored 0%)\n",
            "  adding: training_datas/train_data3643.zip (stored 0%)\n",
            "  adding: training_datas/train_data7173.zip (stored 0%)\n",
            "  adding: training_datas/train_data28073.zip (stored 0%)\n",
            "  adding: training_datas/train_data13280.zip (stored 0%)\n",
            "  adding: training_datas/train_data28980.zip (stored 0%)\n",
            "  adding: training_datas/train_data16625.zip (stored 0%)\n",
            "  adding: training_datas/train_data12761.zip (stored 0%)\n",
            "  adding: training_datas/train_data14441.zip (stored 0%)\n",
            "  adding: training_datas/train_data14195.zip (stored 0%)\n",
            "  adding: training_datas/train_data15594.zip (stored 0%)\n",
            "  adding: training_datas/train_data28417.zip (stored 0%)\n",
            "  adding: training_datas/train_data24053.zip (stored 0%)\n",
            "  adding: training_datas/train_data5538.zip (stored 0%)\n",
            "  adding: training_datas/train_data11069.zip (stored 0%)\n",
            "  adding: training_datas/train_data9855.zip (stored 0%)\n",
            "  adding: training_datas/train_data5401.zip (stored 0%)\n",
            "  adding: training_datas/train_data1212.zip (stored 0%)\n",
            "  adding: training_datas/train_data8802.zip (stored 0%)\n",
            "  adding: training_datas/train_data14681.zip (stored 0%)\n",
            "  adding: training_datas/train_data5252.zip (stored 0%)\n",
            "  adding: training_datas/train_data23059.zip (stored 0%)\n",
            "  adding: training_datas/train_data25150.zip (stored 0%)\n",
            "  adding: training_datas/train_data17290.zip (stored 0%)\n",
            "  adding: training_datas/train_data22065.zip (stored 0%)\n",
            "  adding: training_datas/train_data24066.zip (stored 0%)\n",
            "  adding: training_datas/train_data355.zip (stored 0%)\n",
            "  adding: training_datas/train_data24955.zip (stored 0%)\n",
            "  adding: training_datas/train_data23010.zip (stored 0%)\n",
            "  adding: training_datas/train_data5270.zip (stored 0%)\n",
            "  adding: training_datas/train_data26725.zip (stored 0%)\n",
            "  adding: training_datas/train_data20774.zip (stored 0%)\n",
            "  adding: training_datas/train_data2170.zip (stored 0%)\n",
            "  adding: training_datas/train_data28560.zip (stored 0%)\n",
            "  adding: training_datas/train_data9118.zip (stored 0%)\n",
            "  adding: training_datas/train_data16142.zip (stored 0%)\n",
            "  adding: training_datas/train_data29579.zip (stored 0%)\n",
            "  adding: training_datas/train_data9055.zip (stored 0%)\n",
            "  adding: training_datas/train_data21502.zip (stored 0%)\n",
            "  adding: training_datas/train_data26463.zip (stored 0%)\n",
            "  adding: training_datas/train_data23787.zip (stored 0%)\n",
            "  adding: training_datas/train_data7941.zip (stored 0%)\n",
            "  adding: training_datas/train_data6759.zip (stored 0%)\n",
            "  adding: training_datas/train_data4841.zip (stored 0%)\n",
            "  adding: training_datas/train_data20398.zip (stored 0%)\n",
            "  adding: training_datas/train_data556.zip (stored 0%)\n",
            "  adding: training_datas/train_data6472.zip (stored 0%)\n",
            "  adding: training_datas/train_data17170.zip (stored 0%)\n",
            "  adding: training_datas/train_data29969.zip (stored 0%)\n",
            "  adding: training_datas/train_data21256.zip (stored 0%)\n",
            "  adding: training_datas/train_data16694.zip (stored 0%)\n",
            "  adding: training_datas/train_data16628.zip (stored 0%)\n",
            "  adding: training_datas/train_data13183.zip (stored 0%)\n",
            "  adding: training_datas/train_data6308.zip (stored 0%)\n",
            "  adding: training_datas/train_data20798.zip (stored 0%)\n",
            "  adding: training_datas/train_data15360.zip (stored 0%)\n",
            "  adding: training_datas/train_data16994.zip (stored 0%)\n",
            "  adding: training_datas/train_data29673.zip (stored 0%)\n",
            "  adding: training_datas/train_data171.zip (stored 0%)\n",
            "  adding: training_datas/train_data26435.zip (stored 0%)\n",
            "  adding: training_datas/train_data25647.zip (stored 0%)\n",
            "  adding: training_datas/train_data25537.zip (stored 0%)\n",
            "  adding: training_datas/train_data23509.zip (stored 0%)\n",
            "  adding: training_datas/train_data7862.zip (stored 0%)\n",
            "  adding: training_datas/train_data22331.zip (stored 0%)\n",
            "  adding: training_datas/train_data28929.zip (stored 0%)\n",
            "  adding: training_datas/train_data13392.zip (stored 0%)\n",
            "  adding: training_datas/train_data9793.zip (stored 0%)\n",
            "  adding: training_datas/train_data28727.zip (stored 0%)\n",
            "  adding: training_datas/train_data6904.zip (stored 0%)\n",
            "  adding: training_datas/train_data1268.zip (stored 0%)\n",
            "  adding: training_datas/train_data5247.zip (stored 0%)\n",
            "  adding: training_datas/train_data9129.zip (stored 0%)\n",
            "  adding: training_datas/train_data21898.zip (stored 0%)\n",
            "  adding: training_datas/train_data25982.zip (stored 0%)\n",
            "  adding: training_datas/train_data13603.zip (stored 0%)\n",
            "  adding: training_datas/train_data13244.zip (stored 0%)\n",
            "  adding: training_datas/train_data20261.zip (stored 0%)\n",
            "  adding: training_datas/train_data24256.zip (stored 0%)\n",
            "  adding: training_datas/train_data6828.zip (stored 0%)\n",
            "  adding: training_datas/train_data18826.zip (stored 0%)\n",
            "  adding: training_datas/train_data18928.zip (stored 0%)\n",
            "  adding: training_datas/train_data12768.zip (stored 0%)\n",
            "  adding: training_datas/train_data9685.zip (stored 0%)\n",
            "  adding: training_datas/train_data13520.zip (stored 0%)\n",
            "  adding: training_datas/train_data8791.zip (stored 0%)\n",
            "  adding: training_datas/train_data11491.zip (stored 0%)\n",
            "  adding: training_datas/train_data8220.zip (stored 0%)\n",
            "  adding: training_datas/train_data27592.zip (stored 0%)\n",
            "  adding: training_datas/train_data23568.zip (stored 0%)\n",
            "  adding: training_datas/train_data28766.zip (stored 0%)\n",
            "  adding: training_datas/train_data13556.zip (stored 0%)\n",
            "  adding: training_datas/train_data5635.zip (stored 0%)\n",
            "  adding: training_datas/train_data18581.zip (stored 0%)\n",
            "  adding: training_datas/train_data10628.zip (stored 0%)\n",
            "  adding: training_datas/train_data5089.zip (stored 0%)\n",
            "  adding: training_datas/train_data3514.zip (stored 0%)\n",
            "  adding: training_datas/train_data15447.zip (stored 0%)\n",
            "  adding: training_datas/train_data15024.zip (stored 0%)\n",
            "  adding: training_datas/train_data10316.zip (stored 0%)\n",
            "  adding: training_datas/train_data20212.zip (stored 0%)\n",
            "  adding: training_datas/train_data21262.zip (stored 0%)\n",
            "  adding: training_datas/train_data28413.zip (stored 0%)\n",
            "  adding: training_datas/train_data1455.zip (stored 0%)\n",
            "  adding: training_datas/train_data17211.zip (stored 0%)\n",
            "  adding: training_datas/train_data25462.zip (stored 0%)\n",
            "  adding: training_datas/train_data7047.zip (stored 0%)\n",
            "  adding: training_datas/train_data10532.zip (stored 0%)\n",
            "  adding: training_datas/train_data23124.zip (stored 0%)\n",
            "  adding: training_datas/train_data12049.zip (stored 0%)\n",
            "  adding: training_datas/train_data9968.zip (stored 0%)\n",
            "  adding: training_datas/train_data22395.zip (stored 0%)\n",
            "  adding: training_datas/train_data7972.zip (stored 0%)\n",
            "  adding: training_datas/train_data16264.zip (stored 0%)\n",
            "  adding: training_datas/train_data1643.zip (stored 0%)\n",
            "  adding: training_datas/train_data6364.zip (stored 0%)\n",
            "  adding: training_datas/train_data15136.zip (stored 0%)\n",
            "  adding: training_datas/train_data16370.zip (stored 0%)\n",
            "  adding: training_datas/train_data12598.zip (stored 0%)\n",
            "  adding: training_datas/train_data852.zip (stored 0%)\n",
            "  adding: training_datas/train_data2677.zip (stored 0%)\n",
            "  adding: training_datas/train_data3399.zip (stored 0%)\n",
            "  adding: training_datas/train_data1355.zip (stored 0%)\n",
            "  adding: training_datas/train_data21506.zip (stored 0%)\n",
            "  adding: training_datas/train_data29301.zip (stored 0%)\n",
            "  adding: training_datas/train_data20719.zip (stored 0%)\n",
            "  adding: training_datas/train_data21880.zip (stored 0%)\n",
            "  adding: training_datas/train_data9959.zip (stored 0%)\n",
            "  adding: training_datas/train_data15309.zip (stored 0%)\n",
            "  adding: training_datas/train_data6066.zip (stored 0%)\n",
            "  adding: training_datas/train_data7167.zip (stored 0%)\n",
            "  adding: training_datas/train_data27362.zip (stored 0%)\n",
            "  adding: training_datas/train_data18068.zip (stored 0%)\n",
            "  adding: training_datas/train_data20234.zip (stored 0%)\n",
            "  adding: training_datas/train_data1985.zip (stored 0%)\n",
            "  adding: training_datas/train_data5839.zip (stored 0%)\n",
            "  adding: training_datas/train_data19547.zip (stored 0%)\n",
            "  adding: training_datas/train_data7905.zip (stored 0%)\n",
            "  adding: training_datas/train_data22955.zip (stored 0%)\n",
            "  adding: training_datas/train_data17285.zip (stored 0%)\n",
            "  adding: training_datas/train_data14382.zip (stored 0%)\n",
            "  adding: training_datas/train_data12394.zip (stored 0%)\n",
            "  adding: training_datas/train_data26089.zip (stored 0%)\n",
            "  adding: training_datas/train_data21946.zip (stored 0%)\n",
            "  adding: training_datas/train_data6253.zip (stored 0%)\n",
            "  adding: training_datas/train_data9932.zip (stored 0%)\n",
            "  adding: training_datas/train_data15108.zip (stored 0%)\n",
            "  adding: training_datas/train_data9624.zip (stored 0%)\n",
            "  adding: training_datas/train_data25586.zip (stored 0%)\n",
            "  adding: training_datas/train_data21607.zip (stored 0%)\n",
            "  adding: training_datas/train_data23789.zip (stored 0%)\n",
            "  adding: training_datas/train_data2049.zip (stored 0%)\n",
            "  adding: training_datas/train_data27082.zip (stored 0%)\n",
            "  adding: training_datas/train_data21960.zip (stored 0%)\n",
            "  adding: training_datas/train_data27041.zip (stored 0%)\n",
            "  adding: training_datas/train_data14625.zip (stored 0%)\n",
            "  adding: training_datas/train_data24203.zip (stored 0%)\n",
            "  adding: training_datas/train_data13061.zip (stored 0%)\n",
            "  adding: training_datas/train_data7920.zip (stored 0%)\n",
            "  adding: training_datas/train_data26931.zip (stored 0%)\n",
            "  adding: training_datas/train_data22796.zip (stored 0%)\n",
            "  adding: training_datas/train_data22050.zip (stored 0%)\n",
            "  adding: training_datas/train_data13599.zip (stored 0%)\n",
            "  adding: training_datas/train_data15765.zip (stored 0%)\n",
            "  adding: training_datas/train_data7201.zip (stored 0%)\n",
            "  adding: training_datas/train_data21588.zip (stored 0%)\n",
            "  adding: training_datas/train_data12030.zip (stored 0%)\n",
            "  adding: training_datas/train_data9211.zip (stored 0%)\n",
            "  adding: training_datas/train_data5332.zip (stored 0%)\n",
            "  adding: training_datas/train_data17271.zip (stored 0%)\n",
            "  adding: training_datas/train_data12938.zip (stored 0%)\n",
            "  adding: training_datas/train_data8111.zip (stored 0%)\n",
            "  adding: training_datas/train_data2251.zip (stored 0%)\n",
            "  adding: training_datas/train_data9711.zip (stored 0%)\n",
            "  adding: training_datas/train_data8375.zip (stored 0%)\n",
            "  adding: training_datas/train_data24987.zip (stored 0%)\n",
            "  adding: training_datas/train_data24211.zip (stored 0%)\n",
            "  adding: training_datas/train_data17768.zip (stored 0%)\n",
            "  adding: training_datas/train_data10570.zip (stored 0%)\n",
            "  adding: training_datas/train_data13293.zip (stored 0%)\n",
            "  adding: training_datas/train_data13159.zip (stored 0%)\n",
            "  adding: training_datas/train_data6354.zip (stored 0%)\n",
            "  adding: training_datas/train_data4083.zip (stored 0%)\n",
            "  adding: training_datas/train_data14411.zip (stored 0%)\n",
            "  adding: training_datas/train_data530.zip (stored 0%)\n",
            "  adding: training_datas/train_data26046.zip (stored 0%)\n",
            "  adding: training_datas/train_data13919.zip (stored 0%)\n",
            "  adding: training_datas/train_data29219.zip (stored 0%)\n",
            "  adding: training_datas/train_data23473.zip (stored 0%)\n",
            "  adding: training_datas/train_data25188.zip (stored 0%)\n",
            "  adding: training_datas/train_data27795.zip (stored 0%)\n",
            "  adding: training_datas/train_data28430.zip (stored 0%)\n",
            "  adding: training_datas/train_data8601.zip (stored 0%)\n",
            "  adding: training_datas/train_data27958.zip (stored 0%)\n",
            "  adding: training_datas/train_data23519.zip (stored 0%)\n",
            "  adding: training_datas/train_data6862.zip (stored 0%)\n",
            "  adding: training_datas/train_data21807.zip (stored 0%)\n",
            "  adding: training_datas/train_data26381.zip (stored 0%)\n",
            "  adding: training_datas/train_data18485.zip (stored 0%)\n",
            "  adding: training_datas/train_data18040.zip (stored 0%)\n",
            "  adding: training_datas/train_data21398.zip (stored 0%)\n",
            "  adding: training_datas/train_data14288.zip (stored 0%)\n",
            "  adding: training_datas/train_data7793.zip (stored 0%)\n",
            "  adding: training_datas/train_data5448.zip (stored 0%)\n",
            "  adding: training_datas/train_data16241.zip (stored 0%)\n",
            "  adding: training_datas/train_data29810.zip (stored 0%)\n",
            "  adding: training_datas/train_data25466.zip (stored 0%)\n",
            "  adding: training_datas/train_data21945.zip (stored 0%)\n",
            "  adding: training_datas/train_data30136.zip (stored 0%)\n",
            "  adding: training_datas/train_data9583.zip (stored 0%)\n",
            "  adding: training_datas/train_data13772.zip (stored 0%)\n",
            "  adding: training_datas/train_data5572.zip (stored 0%)\n",
            "  adding: training_datas/train_data20536.zip (stored 0%)\n",
            "  adding: training_datas/train_data5745.zip (stored 0%)\n",
            "  adding: training_datas/train_data11044.zip (stored 0%)\n",
            "  adding: training_datas/train_data25194.zip (stored 0%)\n",
            "  adding: training_datas/train_data28843.zip (stored 0%)\n",
            "  adding: training_datas/train_data9383.zip (stored 0%)\n",
            "  adding: training_datas/train_data14244.zip (stored 0%)\n",
            "  adding: training_datas/train_data1662.zip (stored 0%)\n",
            "  adding: training_datas/train_data25952.zip (stored 0%)\n",
            "  adding: training_datas/train_data25732.zip (stored 0%)\n",
            "  adding: training_datas/train_data12471.zip (stored 0%)\n",
            "  adding: training_datas/train_data23394.zip (stored 0%)\n",
            "  adding: training_datas/train_data6967.zip (stored 0%)\n",
            "  adding: training_datas/train_data23132.zip (stored 0%)\n",
            "  adding: training_datas/train_data17433.zip (stored 0%)\n",
            "  adding: training_datas/train_data8063.zip (stored 0%)\n",
            "  adding: training_datas/train_data24102.zip (stored 0%)\n",
            "  adding: training_datas/train_data23474.zip (stored 0%)\n",
            "  adding: training_datas/train_data11104.zip (stored 0%)\n",
            "  adding: training_datas/train_data4857.zip (stored 0%)\n",
            "  adding: training_datas/train_data29800.zip (stored 0%)\n",
            "  adding: training_datas/train_data12183.zip (stored 0%)\n",
            "  adding: training_datas/train_data22437.zip (stored 0%)\n",
            "  adding: training_datas/train_data24633.zip (stored 0%)\n",
            "  adding: training_datas/train_data26833.zip (stored 0%)\n",
            "  adding: training_datas/train_data10987.zip (stored 0%)\n",
            "  adding: training_datas/train_data8400.zip (stored 0%)\n",
            "  adding: training_datas/train_data2143.zip (stored 0%)\n",
            "  adding: training_datas/train_data2932.zip (stored 0%)\n",
            "  adding: training_datas/train_data24347.zip (stored 0%)\n",
            "  adding: training_datas/train_data1770.zip (stored 0%)\n",
            "  adding: training_datas/train_data23066.zip (stored 0%)\n",
            "  adding: training_datas/train_data14839.zip (stored 0%)\n",
            "  adding: training_datas/train_data15724.zip (stored 0%)\n",
            "  adding: training_datas/train_data18796.zip (stored 0%)\n",
            "  adding: training_datas/train_data18078.zip (stored 0%)\n",
            "  adding: training_datas/train_data7535.zip (stored 0%)\n",
            "  adding: training_datas/train_data2979.zip (stored 0%)\n",
            "  adding: training_datas/train_data22335.zip (stored 0%)\n",
            "  adding: training_datas/train_data24473.zip (stored 0%)\n",
            "  adding: training_datas/train_data16086.zip (stored 0%)\n",
            "  adding: training_datas/train_data6689.zip (stored 0%)\n",
            "  adding: training_datas/train_data5174.zip (stored 0%)\n",
            "  adding: training_datas/train_data30173.zip (stored 0%)\n",
            "  adding: training_datas/train_data4718.zip (stored 0%)\n",
            "  adding: training_datas/train_data9282.zip (stored 0%)\n",
            "  adding: training_datas/train_data492.zip (stored 0%)\n",
            "  adding: training_datas/train_data7655.zip (stored 0%)\n",
            "  adding: training_datas/train_data5624.zip (stored 0%)\n",
            "  adding: training_datas/train_data16946.zip (stored 0%)\n",
            "  adding: training_datas/train_data26951.zip (stored 0%)\n",
            "  adding: training_datas/train_data8053.zip (stored 0%)\n",
            "  adding: training_datas/train_data4989.zip (stored 0%)\n",
            "  adding: training_datas/train_data20513.zip (stored 0%)\n",
            "  adding: training_datas/train_data24150.zip (stored 0%)\n",
            "  adding: training_datas/train_data531.zip (stored 0%)\n",
            "  adding: training_datas/train_data11222.zip (stored 0%)\n",
            "  adding: training_datas/train_data29213.zip (stored 0%)\n",
            "  adding: training_datas/train_data17739.zip (stored 0%)\n",
            "  adding: training_datas/train_data11200.zip (stored 0%)\n",
            "  adding: training_datas/train_data23953.zip (stored 0%)\n",
            "  adding: training_datas/train_data23258.zip (stored 0%)\n",
            "  adding: training_datas/train_data18871.zip (stored 0%)\n",
            "  adding: training_datas/train_data16528.zip (stored 0%)\n",
            "  adding: training_datas/train_data15442.zip (stored 0%)\n",
            "  adding: training_datas/train_data22626.zip (stored 0%)\n",
            "  adding: training_datas/train_data16098.zip (stored 0%)\n",
            "  adding: training_datas/train_data19605.zip (stored 0%)\n",
            "  adding: training_datas/train_data20533.zip (stored 0%)\n",
            "  adding: training_datas/train_data1203.zip (stored 0%)\n",
            "  adding: training_datas/train_data25334.zip (stored 0%)\n",
            "  adding: training_datas/train_data23533.zip (stored 0%)\n",
            "  adding: training_datas/train_data2846.zip (stored 0%)\n",
            "  adding: training_datas/train_data9824.zip (stored 0%)\n",
            "  adding: training_datas/train_data2829.zip (stored 0%)\n",
            "  adding: training_datas/train_data9979.zip (stored 0%)\n",
            "  adding: training_datas/train_data3575.zip (stored 0%)\n",
            "  adding: training_datas/train_data4120.zip (stored 0%)\n",
            "  adding: training_datas/train_data16095.zip (stored 0%)\n",
            "  adding: training_datas/train_data1676.zip (stored 0%)\n",
            "  adding: training_datas/train_data20071.zip (stored 0%)\n",
            "  adding: training_datas/train_data1964.zip (stored 0%)\n",
            "  adding: training_datas/train_data2537.zip (stored 0%)\n",
            "  adding: training_datas/train_data16090.zip (stored 0%)\n",
            "  adding: training_datas/train_data72.zip (stored 0%)\n",
            "  adding: training_datas/train_data17872.zip (stored 0%)\n",
            "  adding: training_datas/train_data13125.zip (stored 0%)\n",
            "  adding: training_datas/train_data14444.zip (stored 0%)\n",
            "  adding: training_datas/train_data1221.zip (stored 0%)\n",
            "  adding: training_datas/train_data25236.zip (stored 0%)\n",
            "  adding: training_datas/train_data5900.zip (stored 0%)\n",
            "  adding: training_datas/train_data12280.zip (stored 0%)\n",
            "  adding: training_datas/train_data26372.zip (stored 0%)\n",
            "  adding: training_datas/train_data29942.zip (stored 0%)\n",
            "  adding: training_datas/train_data10813.zip (stored 0%)\n",
            "  adding: training_datas/train_data23955.zip (stored 0%)\n",
            "  adding: training_datas/train_data19356.zip (stored 0%)\n",
            "  adding: training_datas/train_data19482.zip (stored 0%)\n",
            "  adding: training_datas/train_data20444.zip (stored 0%)\n",
            "  adding: training_datas/train_data8423.zip (stored 0%)\n",
            "  adding: training_datas/train_data22655.zip (stored 0%)\n",
            "  adding: training_datas/train_data5592.zip (stored 0%)\n",
            "  adding: training_datas/train_data8240.zip (stored 0%)\n",
            "  adding: training_datas/train_data25943.zip (stored 0%)\n",
            "  adding: training_datas/train_data12139.zip (stored 0%)\n",
            "  adding: training_datas/train_data28819.zip (stored 0%)\n",
            "  adding: training_datas/train_data28001.zip (stored 0%)\n",
            "  adding: training_datas/train_data15493.zip (stored 0%)\n",
            "  adding: training_datas/train_data25223.zip (stored 0%)\n",
            "  adding: training_datas/train_data9277.zip (stored 0%)\n",
            "  adding: training_datas/train_data27588.zip (stored 0%)\n",
            "  adding: training_datas/train_data14180.zip (stored 0%)\n",
            "  adding: training_datas/train_data8097.zip (stored 0%)\n",
            "  adding: training_datas/train_data16879.zip (stored 0%)\n",
            "  adding: training_datas/train_data4910.zip (stored 0%)\n",
            "  adding: training_datas/train_data2536.zip (stored 0%)\n",
            "  adding: training_datas/train_data3684.zip (stored 0%)\n",
            "  adding: training_datas/train_data7435.zip (stored 0%)\n",
            "  adding: training_datas/train_data14770.zip (stored 0%)\n",
            "  adding: training_datas/train_data21646.zip (stored 0%)\n",
            "  adding: training_datas/train_data16229.zip (stored 0%)\n",
            "  adding: training_datas/train_data27545.zip (stored 0%)\n",
            "  adding: training_datas/train_data13168.zip (stored 0%)\n",
            "  adding: training_datas/train_data5614.zip (stored 0%)\n",
            "  adding: training_datas/train_data20031.zip (stored 0%)\n",
            "  adding: training_datas/train_data4079.zip (stored 0%)\n",
            "  adding: training_datas/train_data11644.zip (stored 0%)\n",
            "  adding: training_datas/train_data5406.zip (stored 0%)\n",
            "  adding: training_datas/train_data6949.zip (stored 0%)\n",
            "  adding: training_datas/train_data23801.zip (stored 0%)\n",
            "  adding: training_datas/train_data11232.zip (stored 0%)\n",
            "  adding: training_datas/train_data3076.zip (stored 0%)\n",
            "  adding: training_datas/train_data9403.zip (stored 0%)\n",
            "  adding: training_datas/train_data24913.zip (stored 0%)\n",
            "  adding: training_datas/train_data21103.zip (stored 0%)\n",
            "  adding: training_datas/train_data12470.zip (stored 0%)\n",
            "  adding: training_datas/train_data9900.zip (stored 0%)\n",
            "  adding: training_datas/train_data17220.zip (stored 0%)\n",
            "  adding: training_datas/train_data21611.zip (stored 0%)\n",
            "  adding: training_datas/train_data24261.zip (stored 0%)\n",
            "  adding: training_datas/train_data25016.zip (stored 0%)\n",
            "  adding: training_datas/train_data16699.zip (stored 0%)\n",
            "  adding: training_datas/train_data26044.zip (stored 0%)\n",
            "  adding: training_datas/train_data29223.zip (stored 0%)\n",
            "  adding: training_datas/train_data26379.zip (stored 0%)\n",
            "  adding: training_datas/train_data30186.zip (stored 0%)\n",
            "  adding: training_datas/train_data28850.zip (stored 0%)\n",
            "  adding: training_datas/train_data17767.zip (stored 0%)\n",
            "  adding: training_datas/train_data16985.zip (stored 0%)\n",
            "  adding: training_datas/train_data19247.zip (stored 0%)\n",
            "  adding: training_datas/train_data10986.zip (stored 0%)\n",
            "  adding: training_datas/train_data30092.zip (stored 0%)\n",
            "  adding: training_datas/train_data5505.zip (stored 0%)\n",
            "  adding: training_datas/train_data6998.zip (stored 0%)\n",
            "  adding: training_datas/train_data7074.zip (stored 0%)\n",
            "  adding: training_datas/train_data14576.zip (stored 0%)\n",
            "  adding: training_datas/train_data8743.zip (stored 0%)\n",
            "  adding: training_datas/train_data19385.zip (stored 0%)\n",
            "  adding: training_datas/train_data5688.zip (stored 0%)\n",
            "  adding: training_datas/train_data683.zip (stored 0%)\n",
            "  adding: training_datas/train_data6463.zip (stored 0%)\n",
            "  adding: training_datas/train_data1038.zip (stored 0%)\n",
            "  adding: training_datas/train_data7272.zip (stored 0%)\n",
            "  adding: training_datas/train_data5796.zip (stored 0%)\n",
            "  adding: training_datas/train_data10514.zip (stored 0%)\n",
            "  adding: training_datas/train_data7516.zip (stored 0%)\n",
            "  adding: training_datas/train_data5379.zip (stored 0%)\n",
            "  adding: training_datas/train_data22840.zip (stored 0%)\n",
            "  adding: training_datas/train_data4781.zip (stored 0%)\n",
            "  adding: training_datas/train_data30175.zip (stored 0%)\n",
            "  adding: training_datas/train_data19567.zip (stored 0%)\n",
            "  adding: training_datas/train_data27978.zip (stored 0%)\n",
            "  adding: training_datas/train_data27446.zip (stored 0%)\n",
            "  adding: training_datas/train_data14002.zip (stored 0%)\n",
            "  adding: training_datas/train_data5353.zip (stored 0%)\n",
            "  adding: training_datas/train_data6367.zip (stored 0%)\n",
            "  adding: training_datas/train_data4128.zip (stored 0%)\n",
            "  adding: training_datas/train_data17406.zip (stored 0%)\n",
            "  adding: training_datas/train_data24693.zip (stored 0%)\n",
            "  adding: training_datas/train_data29898.zip (stored 0%)\n",
            "  adding: training_datas/train_data11397.zip (stored 0%)\n",
            "  adding: training_datas/train_data23534.zip (stored 0%)\n",
            "  adding: training_datas/train_data10544.zip (stored 0%)\n",
            "  adding: training_datas/train_data4510.zip (stored 0%)\n",
            "  adding: training_datas/train_data1351.zip (stored 0%)\n",
            "  adding: training_datas/train_data21744.zip (stored 0%)\n",
            "  adding: training_datas/train_data17958.zip (stored 0%)\n",
            "  adding: training_datas/train_data8605.zip (stored 0%)\n",
            "  adding: training_datas/train_data8466.zip (stored 0%)\n",
            "  adding: training_datas/train_data12913.zip (stored 0%)\n",
            "  adding: training_datas/train_data15430.zip (stored 0%)\n",
            "  adding: training_datas/train_data26130.zip (stored 0%)\n",
            "  adding: training_datas/train_data17649.zip (stored 0%)\n",
            "  adding: training_datas/train_data15017.zip (stored 0%)\n",
            "  adding: training_datas/train_data11413.zip (stored 0%)\n",
            "  adding: training_datas/train_data17358.zip (stored 0%)\n",
            "  adding: training_datas/train_data11605.zip (stored 0%)\n",
            "  adding: training_datas/train_data5639.zip (stored 0%)\n",
            "  adding: training_datas/train_data1445.zip (stored 0%)\n",
            "  adding: training_datas/train_data5948.zip (stored 0%)\n",
            "  adding: training_datas/train_data1209.zip (stored 0%)\n",
            "  adding: training_datas/train_data27301.zip (stored 0%)\n",
            "  adding: training_datas/train_data16631.zip (stored 0%)\n",
            "  adding: training_datas/train_data23242.zip (stored 0%)\n",
            "  adding: training_datas/train_data11173.zip (stored 0%)\n",
            "  adding: training_datas/train_data12587.zip (stored 0%)\n",
            "  adding: training_datas/train_data8570.zip (stored 0%)\n",
            "  adding: training_datas/train_data10394.zip (stored 0%)\n",
            "  adding: training_datas/train_data17455.zip (stored 0%)\n",
            "  adding: training_datas/train_data766.zip (stored 0%)\n",
            "  adding: training_datas/train_data13309.zip (stored 0%)\n",
            "  adding: training_datas/train_data25797.zip (stored 0%)\n",
            "  adding: training_datas/train_data28144.zip (stored 0%)\n",
            "  adding: training_datas/train_data7379.zip (stored 0%)\n",
            "  adding: training_datas/train_data15656.zip (stored 0%)\n",
            "  adding: training_datas/train_data14070.zip (stored 0%)\n",
            "  adding: training_datas/train_data2222.zip (stored 0%)\n",
            "  adding: training_datas/train_data20118.zip (stored 0%)\n",
            "  adding: training_datas/train_data19716.zip (stored 0%)\n",
            "  adding: training_datas/train_data23359.zip (stored 0%)\n",
            "  adding: training_datas/train_data9398.zip (stored 0%)\n",
            "  adding: training_datas/train_data27931.zip (stored 0%)\n",
            "  adding: training_datas/train_data10333.zip (stored 0%)\n",
            "  adding: training_datas/train_data7426.zip (stored 0%)\n",
            "  adding: training_datas/train_data3966.zip (stored 0%)\n",
            "  adding: training_datas/train_data8995.zip (stored 0%)\n",
            "  adding: training_datas/train_data9977.zip (stored 0%)\n",
            "  adding: training_datas/train_data29064.zip (stored 0%)\n",
            "  adding: training_datas/train_data28111.zip (stored 0%)\n",
            "  adding: training_datas/train_data20273.zip (stored 0%)\n",
            "  adding: training_datas/train_data29472.zip (stored 0%)\n",
            "  adding: training_datas/train_data24417.zip (stored 0%)\n",
            "  adding: training_datas/train_data22306.zip (stored 0%)\n",
            "  adding: training_datas/train_data10200.zip (stored 0%)\n",
            "  adding: training_datas/train_data1348.zip (stored 0%)\n",
            "  adding: training_datas/train_data28039.zip (stored 0%)\n",
            "  adding: training_datas/train_data24658.zip (stored 0%)\n",
            "  adding: training_datas/train_data12275.zip (stored 0%)\n",
            "  adding: training_datas/train_data11799.zip (stored 0%)\n",
            "  adding: training_datas/train_data1789.zip (stored 0%)\n",
            "  adding: training_datas/train_data17534.zip (stored 0%)\n",
            "  adding: training_datas/train_data15347.zip (stored 0%)\n",
            "  adding: training_datas/train_data19449.zip (stored 0%)\n",
            "  adding: training_datas/train_data12718.zip (stored 0%)\n",
            "  adding: training_datas/train_data4092.zip (stored 0%)\n",
            "  adding: training_datas/train_data14277.zip (stored 0%)\n",
            "  adding: training_datas/train_data27447.zip (stored 0%)\n",
            "  adding: training_datas/train_data27576.zip (stored 0%)\n",
            "  adding: training_datas/train_data8922.zip (stored 0%)\n",
            "  adding: training_datas/train_data17716.zip (stored 0%)\n",
            "  adding: training_datas/train_data19692.zip (stored 0%)\n",
            "  adding: training_datas/train_data1210.zip (stored 0%)\n",
            "  adding: training_datas/train_data29712.zip (stored 0%)\n",
            "  adding: training_datas/train_data28586.zip (stored 0%)\n",
            "  adding: training_datas/train_data26192.zip (stored 0%)\n",
            "  adding: training_datas/train_data30421.zip (stored 0%)\n",
            "  adding: training_datas/train_data14521.zip (stored 0%)\n",
            "  adding: training_datas/train_data11126.zip (stored 0%)\n",
            "  adding: training_datas/train_data21802.zip (stored 0%)\n",
            "  adding: training_datas/train_data12715.zip (stored 0%)\n",
            "  adding: training_datas/train_data21183.zip (stored 0%)\n",
            "  adding: training_datas/train_data24704.zip (stored 0%)\n",
            "  adding: training_datas/train_data9692.zip (stored 0%)\n",
            "  adding: training_datas/train_data11612.zip (stored 0%)\n",
            "  adding: training_datas/train_data3710.zip (stored 0%)\n",
            "  adding: training_datas/train_data27308.zip (stored 0%)\n",
            "  adding: training_datas/train_data27848.zip (stored 0%)\n",
            "  adding: training_datas/train_data26690.zip (stored 0%)\n",
            "  adding: training_datas/train_data7232.zip (stored 0%)\n",
            "  adding: training_datas/train_data5384.zip (stored 0%)\n",
            "  adding: training_datas/train_data29622.zip (stored 0%)\n",
            "  adding: training_datas/train_data30040.zip (stored 0%)\n",
            "  adding: training_datas/train_data28360.zip (stored 0%)\n",
            "  adding: training_datas/train_data11043.zip (stored 0%)\n",
            "  adding: training_datas/train_data19218.zip (stored 0%)\n",
            "  adding: training_datas/train_data20738.zip (stored 0%)\n",
            "  adding: training_datas/train_data14412.zip (stored 0%)\n",
            "  adding: training_datas/train_data17843.zip (stored 0%)\n",
            "  adding: training_datas/train_data5138.zip (stored 0%)\n",
            "  adding: training_datas/train_data17547.zip (stored 0%)\n",
            "  adding: training_datas/train_data23158.zip (stored 0%)\n",
            "  adding: training_datas/train_data6574.zip (stored 0%)\n",
            "  adding: training_datas/train_data19939.zip (stored 0%)\n",
            "  adding: training_datas/train_data2680.zip (stored 0%)\n",
            "  adding: training_datas/train_data1745.zip (stored 0%)\n",
            "  adding: training_datas/train_data28635.zip (stored 0%)\n",
            "  adding: training_datas/train_data29146.zip (stored 0%)\n",
            "  adding: training_datas/train_data17488.zip (stored 0%)\n",
            "  adding: training_datas/train_data24535.zip (stored 0%)\n",
            "  adding: training_datas/train_data29077.zip (stored 0%)\n",
            "  adding: training_datas/train_data26817.zip (stored 0%)\n",
            "  adding: training_datas/train_data22931.zip (stored 0%)\n",
            "  adding: training_datas/train_data2972.zip (stored 0%)\n",
            "  adding: training_datas/train_data543.zip (stored 0%)\n",
            "  adding: training_datas/train_data29483.zip (stored 0%)\n",
            "  adding: training_datas/train_data17071.zip (stored 0%)\n",
            "  adding: training_datas/train_data7674.zip (stored 0%)\n",
            "  adding: training_datas/train_data14892.zip (stored 0%)\n",
            "  adding: training_datas/train_data18879.zip (stored 0%)\n",
            "  adding: training_datas/train_data4394.zip (stored 0%)\n",
            "  adding: training_datas/train_data16687.zip (stored 0%)\n",
            "  adding: training_datas/train_data4199.zip (stored 0%)\n",
            "  adding: training_datas/train_data2199.zip (stored 0%)\n",
            "  adding: training_datas/train_data24031.zip (stored 0%)\n",
            "  adding: training_datas/train_data11162.zip (stored 0%)\n",
            "  adding: training_datas/train_data9618.zip (stored 0%)\n",
            "  adding: training_datas/train_data24288.zip (stored 0%)\n",
            "  adding: training_datas/train_data12274.zip (stored 0%)\n",
            "  adding: training_datas/train_data14630.zip (stored 0%)\n",
            "  adding: training_datas/train_data5260.zip (stored 0%)\n",
            "  adding: training_datas/train_data19287.zip (stored 0%)\n",
            "  adding: training_datas/train_data11435.zip (stored 0%)\n",
            "  adding: training_datas/train_data4760.zip (stored 0%)\n",
            "  adding: training_datas/train_data16390.zip (stored 0%)\n",
            "  adding: training_datas/train_data14473.zip (stored 0%)\n",
            "  adding: training_datas/train_data3694.zip (stored 0%)\n",
            "  adding: training_datas/train_data11214.zip (stored 0%)\n",
            "  adding: training_datas/train_data23949.zip (stored 0%)\n",
            "  adding: training_datas/train_data13170.zip (stored 0%)\n",
            "  adding: training_datas/train_data12144.zip (stored 0%)\n",
            "  adding: training_datas/train_data8818.zip (stored 0%)\n",
            "  adding: training_datas/train_data26273.zip (stored 0%)\n",
            "  adding: training_datas/train_data22154.zip (stored 0%)\n",
            "  adding: training_datas/train_data4170.zip (stored 0%)\n",
            "  adding: training_datas/train_data29805.zip (stored 0%)\n",
            "  adding: training_datas/train_data2071.zip (stored 0%)\n",
            "  adding: training_datas/train_data14787.zip (stored 0%)\n",
            "  adding: training_datas/train_data9251.zip (stored 0%)\n",
            "  adding: training_datas/train_data8915.zip (stored 0%)\n",
            "  adding: training_datas/train_data22321.zip (stored 0%)\n",
            "  adding: training_datas/train_data18805.zip (stored 0%)\n",
            "  adding: training_datas/train_data3891.zip (stored 0%)\n",
            "  adding: training_datas/train_data19070.zip (stored 0%)\n",
            "  adding: training_datas/train_data7446.zip (stored 0%)\n",
            "  adding: training_datas/train_data14855.zip (stored 0%)\n",
            "  adding: training_datas/train_data198.zip (stored 0%)\n",
            "  adding: training_datas/train_data7120.zip (stored 0%)\n",
            "  adding: training_datas/train_data14698.zip (stored 0%)\n",
            "  adding: training_datas/train_data13939.zip (stored 0%)\n",
            "  adding: training_datas/train_data25282.zip (stored 0%)\n",
            "  adding: training_datas/train_data6125.zip (stored 0%)\n",
            "  adding: training_datas/train_data20843.zip (stored 0%)\n",
            "  adding: training_datas/train_data1794.zip (stored 0%)\n",
            "  adding: training_datas/train_data6590.zip (stored 0%)\n",
            "  adding: training_datas/train_data2203.zip (stored 0%)\n",
            "  adding: training_datas/train_data6417.zip (stored 0%)\n",
            "  adding: training_datas/train_data21603.zip (stored 0%)\n",
            "  adding: training_datas/train_data14230.zip (stored 0%)\n",
            "  adding: training_datas/train_data24533.zip (stored 0%)\n",
            "  adding: training_datas/train_data25649.zip (stored 0%)\n",
            "  adding: training_datas/train_data6994.zip (stored 0%)\n",
            "  adding: training_datas/train_data10031.zip (stored 0%)\n",
            "  adding: training_datas/train_data11828.zip (stored 0%)\n",
            "  adding: training_datas/train_data9789.zip (stored 0%)\n",
            "  adding: training_datas/train_data2488.zip (stored 0%)\n",
            "  adding: training_datas/train_data20694.zip (stored 0%)\n",
            "  adding: training_datas/train_data5611.zip (stored 0%)\n",
            "  adding: training_datas/train_data26302.zip (stored 0%)\n",
            "  adding: training_datas/train_data17370.zip (stored 0%)\n",
            "  adding: training_datas/train_data28924.zip (stored 0%)\n",
            "  adding: training_datas/train_data21324.zip (stored 0%)\n",
            "  adding: training_datas/train_data8967.zip (stored 0%)\n",
            "  adding: training_datas/train_data29398.zip (stored 0%)\n",
            "  adding: training_datas/train_data13185.zip (stored 0%)\n",
            "  adding: training_datas/train_data15520.zip (stored 0%)\n",
            "  adding: training_datas/train_data21051.zip (stored 0%)\n",
            "  adding: training_datas/train_data19442.zip (stored 0%)\n",
            "  adding: training_datas/train_data29762.zip (stored 0%)\n",
            "  adding: training_datas/train_data26047.zip (stored 0%)\n",
            "  adding: training_datas/train_data24398.zip (stored 0%)\n",
            "  adding: training_datas/train_data23191.zip (stored 0%)\n",
            "  adding: training_datas/train_data17519.zip (stored 0%)\n",
            "  adding: training_datas/train_data30337.zip (stored 0%)\n",
            "  adding: training_datas/train_data3257.zip (stored 0%)\n",
            "  adding: training_datas/train_data3052.zip (stored 0%)\n",
            "  adding: training_datas/train_data5999.zip (stored 0%)\n",
            "  adding: training_datas/train_data6326.zip (stored 0%)\n",
            "  adding: training_datas/train_data12925.zip (stored 0%)\n",
            "  adding: training_datas/train_data18540.zip (stored 0%)\n",
            "  adding: training_datas/train_data5845.zip (stored 0%)\n",
            "  adding: training_datas/train_data8677.zip (stored 0%)\n",
            "  adding: training_datas/train_data19439.zip (stored 0%)\n",
            "  adding: training_datas/train_data28557.zip (stored 0%)\n",
            "  adding: training_datas/train_data727.zip (stored 0%)\n",
            "  adding: training_datas/train_data23493.zip (stored 0%)\n",
            "  adding: training_datas/train_data26883.zip (stored 0%)\n",
            "  adding: training_datas/train_data8950.zip (stored 0%)\n",
            "  adding: training_datas/train_data6065.zip (stored 0%)\n",
            "  adding: training_datas/train_data15514.zip (stored 0%)\n",
            "  adding: training_datas/train_data18184.zip (stored 0%)\n",
            "  adding: training_datas/train_data18658.zip (stored 0%)\n",
            "  adding: training_datas/train_data16141.zip (stored 0%)\n",
            "  adding: training_datas/train_data28308.zip (stored 0%)\n",
            "  adding: training_datas/train_data21757.zip (stored 0%)\n",
            "  adding: training_datas/train_data29701.zip (stored 0%)\n",
            "  adding: training_datas/train_data5943.zip (stored 0%)\n",
            "  adding: training_datas/train_data23806.zip (stored 0%)\n",
            "  adding: training_datas/train_data98.zip (stored 0%)\n",
            "  adding: training_datas/train_data20108.zip (stored 0%)\n",
            "  adding: training_datas/train_data23696.zip (stored 0%)\n",
            "  adding: training_datas/train_data3254.zip (stored 0%)\n",
            "  adding: training_datas/train_data15771.zip (stored 0%)\n",
            "  adding: training_datas/train_data6309.zip (stored 0%)\n",
            "  adding: training_datas/train_data4600.zip (stored 0%)\n",
            "  adding: training_datas/train_data22793.zip (stored 0%)\n",
            "  adding: training_datas/train_data7234.zip (stored 0%)\n",
            "  adding: training_datas/train_data2452.zip (stored 0%)\n",
            "  adding: training_datas/train_data19182.zip (stored 0%)\n",
            "  adding: training_datas/train_data22396.zip (stored 0%)\n",
            "  adding: training_datas/train_data9116.zip (stored 0%)\n",
            "  adding: training_datas/train_data18336.zip (stored 0%)\n",
            "  adding: training_datas/train_data21566.zip (stored 0%)\n",
            "  adding: training_datas/train_data16469.zip (stored 0%)\n",
            "  adding: training_datas/train_data2029.zip (stored 0%)\n",
            "  adding: training_datas/train_data12386.zip (stored 0%)\n",
            "  adding: training_datas/train_data20468.zip (stored 0%)\n",
            "  adding: training_datas/train_data21627.zip (stored 0%)\n",
            "  adding: training_datas/train_data843.zip (stored 0%)\n",
            "  adding: training_datas/train_data30232.zip (stored 0%)\n",
            "  adding: training_datas/train_data22475.zip (stored 0%)\n",
            "  adding: training_datas/train_data22015.zip (stored 0%)\n",
            "  adding: training_datas/train_data23500.zip (stored 0%)\n",
            "  adding: training_datas/train_data11051.zip (stored 0%)\n",
            "  adding: training_datas/train_data14954.zip (stored 0%)\n",
            "  adding: training_datas/train_data17993.zip (stored 0%)\n",
            "  adding: training_datas/train_data2147.zip (stored 0%)\n",
            "  adding: training_datas/train_data2562.zip (stored 0%)\n",
            "  adding: training_datas/train_data20779.zip (stored 0%)\n",
            "  adding: training_datas/train_data204.zip (stored 0%)\n",
            "  adding: training_datas/train_data28866.zip (stored 0%)\n",
            "  adding: training_datas/train_data8026.zip (stored 0%)\n",
            "  adding: training_datas/train_data19346.zip (stored 0%)\n",
            "  adding: training_datas/train_data21014.zip (stored 0%)\n",
            "  adding: training_datas/train_data26814.zip (stored 0%)\n",
            "  adding: training_datas/train_data1132.zip (stored 0%)\n",
            "  adding: training_datas/train_data6501.zip (stored 0%)\n",
            "  adding: training_datas/train_data10015.zip (stored 0%)\n",
            "  adding: training_datas/train_data23959.zip (stored 0%)\n",
            "  adding: training_datas/train_data27965.zip (stored 0%)\n",
            "  adding: training_datas/train_data20084.zip (stored 0%)\n",
            "  adding: training_datas/train_data11704.zip (stored 0%)\n",
            "  adding: training_datas/train_data13700.zip (stored 0%)\n",
            "  adding: training_datas/train_data1631.zip (stored 0%)\n",
            "  adding: training_datas/train_data25844.zip (stored 0%)\n",
            "  adding: training_datas/train_data28495.zip (stored 0%)\n",
            "  adding: training_datas/train_data11055.zip (stored 0%)\n",
            "  adding: training_datas/train_data27985.zip (stored 0%)\n",
            "  adding: training_datas/train_data17730.zip (stored 0%)\n",
            "  adding: training_datas/train_data28679.zip (stored 0%)\n",
            "  adding: training_datas/train_data16559.zip (stored 0%)\n",
            "  adding: training_datas/train_data6183.zip (stored 0%)\n",
            "  adding: training_datas/train_data12931.zip (stored 0%)\n",
            "  adding: training_datas/train_data6336.zip (stored 0%)\n",
            "  adding: training_datas/train_data21140.zip (stored 0%)\n",
            "  adding: training_datas/train_data26034.zip (stored 0%)\n",
            "  adding: training_datas/train_data10575.zip (stored 0%)\n",
            "  adding: training_datas/train_data10530.zip (stored 0%)\n",
            "  adding: training_datas/train_data4451.zip (stored 0%)\n",
            "  adding: training_datas/train_data29957.zip (stored 0%)\n",
            "  adding: training_datas/train_data11025.zip (stored 0%)\n",
            "  adding: training_datas/train_data16936.zip (stored 0%)\n",
            "  adding: training_datas/train_data27633.zip (stored 0%)\n",
            "  adding: training_datas/train_data21260.zip (stored 0%)\n",
            "  adding: training_datas/train_data954.zip (stored 0%)\n",
            "  adding: training_datas/train_data12260.zip (stored 0%)\n",
            "  adding: training_datas/train_data8529.zip (stored 0%)\n",
            "  adding: training_datas/train_data28055.zip (stored 0%)\n",
            "  adding: training_datas/train_data9234.zip (stored 0%)\n",
            "  adding: training_datas/train_data1373.zip (stored 0%)\n",
            "  adding: training_datas/train_data23316.zip (stored 0%)\n",
            "  adding: training_datas/train_data2443.zip (stored 0%)\n",
            "  adding: training_datas/train_data24298.zip (stored 0%)\n",
            "  adding: training_datas/train_data18099.zip (stored 0%)\n",
            "  adding: training_datas/train_data7886.zip (stored 0%)\n",
            "  adding: training_datas/train_data19203.zip (stored 0%)\n",
            "  adding: training_datas/train_data28667.zip (stored 0%)\n",
            "  adding: training_datas/train_data6502.zip (stored 0%)\n",
            "  adding: training_datas/train_data8656.zip (stored 0%)\n",
            "  adding: training_datas/train_data9724.zip (stored 0%)\n",
            "  adding: training_datas/train_data23496.zip (stored 0%)\n",
            "  adding: training_datas/train_data15837.zip (stored 0%)\n",
            "  adding: training_datas/train_data20006.zip (stored 0%)\n",
            "  adding: training_datas/train_data20526.zip (stored 0%)\n",
            "  adding: training_datas/train_data4659.zip (stored 0%)\n",
            "  adding: training_datas/train_data16768.zip (stored 0%)\n",
            "  adding: training_datas/train_data30331.zip (stored 0%)\n",
            "  adding: training_datas/train_data22356.zip (stored 0%)\n",
            "  adding: training_datas/train_data20846.zip (stored 0%)\n",
            "  adding: training_datas/train_data20752.zip (stored 0%)\n",
            "  adding: training_datas/train_data15369.zip (stored 0%)\n",
            "  adding: training_datas/train_data27327.zip (stored 0%)\n",
            "  adding: training_datas/train_data11002.zip (stored 0%)\n",
            "  adding: training_datas/train_data4401.zip (stored 0%)\n",
            "  adding: training_datas/train_data17230.zip (stored 0%)\n",
            "  adding: training_datas/train_data6915.zip (stored 0%)\n",
            "  adding: training_datas/train_data27556.zip (stored 0%)\n",
            "  adding: training_datas/train_data1633.zip (stored 0%)\n",
            "  adding: training_datas/train_data19982.zip (stored 0%)\n",
            "  adding: training_datas/train_data12009.zip (stored 0%)\n",
            "  adding: training_datas/train_data27799.zip (stored 0%)\n",
            "  adding: training_datas/train_data17948.zip (stored 0%)\n",
            "  adding: training_datas/train_data9030.zip (stored 0%)\n",
            "  adding: training_datas/train_data6987.zip (stored 0%)\n",
            "  adding: training_datas/train_data3026.zip (stored 0%)\n",
            "  adding: training_datas/train_data13703.zip (stored 0%)\n",
            "  adding: training_datas/train_data936.zip (stored 0%)\n",
            "  adding: training_datas/train_data24700.zip (stored 0%)\n",
            "  adding: training_datas/train_data25811.zip (stored 0%)\n",
            "  adding: training_datas/train_data8407.zip (stored 0%)\n",
            "  adding: training_datas/train_data29986.zip (stored 0%)\n",
            "  adding: training_datas/train_data22972.zip (stored 0%)\n",
            "  adding: training_datas/train_data6049.zip (stored 0%)\n",
            "  adding: training_datas/train_data21674.zip (stored 0%)\n",
            "  adding: training_datas/train_data5695.zip (stored 0%)\n",
            "  adding: training_datas/train_data21994.zip (stored 0%)\n",
            "  adding: training_datas/train_data3745.zip (stored 0%)\n",
            "  adding: training_datas/train_data10151.zip (stored 0%)\n",
            "  adding: training_datas/train_data3398.zip (stored 0%)\n",
            "  adding: training_datas/train_data15044.zip (stored 0%)\n",
            "  adding: training_datas/train_data12869.zip (stored 0%)\n",
            "  adding: training_datas/train_data3775.zip (stored 0%)\n",
            "  adding: training_datas/train_data27597.zip (stored 0%)\n",
            "  adding: training_datas/train_data28307.zip (stored 0%)\n",
            "  adding: training_datas/train_data12513.zip (stored 0%)\n",
            "  adding: training_datas/train_data7703.zip (stored 0%)\n",
            "  adding: training_datas/train_data3946.zip (stored 0%)\n",
            "  adding: training_datas/train_data28004.zip (stored 0%)\n",
            "  adding: training_datas/train_data18313.zip (stored 0%)\n",
            "  adding: training_datas/train_data15586.zip (stored 0%)\n",
            "  adding: training_datas/train_data1545.zip (stored 0%)\n",
            "  adding: training_datas/train_data2100.zip (stored 0%)\n",
            "  adding: training_datas/train_data6264.zip (stored 0%)\n",
            "  adding: training_datas/train_data26204.zip (stored 0%)\n",
            "  adding: training_datas/train_data7070.zip (stored 0%)\n",
            "  adding: training_datas/train_data28235.zip (stored 0%)\n",
            "  adding: training_datas/train_data174.zip (stored 0%)\n",
            "  adding: training_datas/train_data495.zip (stored 0%)\n",
            "  adding: training_datas/train_data23142.zip (stored 0%)\n",
            "  adding: training_datas/train_data17655.zip (stored 0%)\n",
            "  adding: training_datas/train_data1731.zip (stored 0%)\n",
            "  adding: training_datas/train_data11548.zip (stored 0%)\n",
            "  adding: training_datas/train_data5810.zip (stored 0%)\n",
            "  adding: training_datas/train_data20002.zip (stored 0%)\n",
            "  adding: training_datas/train_data6311.zip (stored 0%)\n",
            "  adding: training_datas/train_data26818.zip (stored 0%)\n",
            "  adding: training_datas/train_data23554.zip (stored 0%)\n",
            "  adding: training_datas/train_data24352.zip (stored 0%)\n",
            "  adding: training_datas/train_data23832.zip (stored 0%)\n",
            "  adding: training_datas/train_data30056.zip (stored 0%)\n",
            "  adding: training_datas/train_data3577.zip (stored 0%)\n",
            "  adding: training_datas/train_data2904.zip (stored 0%)\n",
            "  adding: training_datas/train_data8017.zip (stored 0%)\n",
            "  adding: training_datas/train_data2325.zip (stored 0%)\n",
            "  adding: training_datas/train_data7127.zip (stored 0%)\n",
            "  adding: training_datas/train_data26112.zip (stored 0%)\n",
            "  adding: training_datas/train_data8234.zip (stored 0%)\n",
            "  adding: training_datas/train_data8892.zip (stored 0%)\n",
            "  adding: training_datas/train_data26173.zip (stored 0%)\n",
            "  adding: training_datas/train_data7192.zip (stored 0%)\n",
            "  adding: training_datas/train_data19801.zip (stored 0%)\n",
            "  adding: training_datas/train_data18434.zip (stored 0%)\n",
            "  adding: training_datas/train_data6951.zip (stored 0%)\n",
            "  adding: training_datas/train_data4255.zip (stored 0%)\n",
            "  adding: training_datas/train_data9567.zip (stored 0%)\n",
            "  adding: training_datas/train_data13145.zip (stored 0%)\n",
            "  adding: training_datas/train_data4080.zip (stored 0%)\n",
            "  adding: training_datas/train_data12916.zip (stored 0%)\n",
            "  adding: training_datas/train_data8195.zip (stored 0%)\n",
            "  adding: training_datas/train_data8160.zip (stored 0%)\n",
            "  adding: training_datas/train_data4432.zip (stored 0%)\n",
            "  adding: training_datas/train_data4423.zip (stored 0%)\n",
            "  adding: training_datas/train_data27108.zip (stored 0%)\n",
            "  adding: training_datas/train_data28331.zip (stored 0%)\n",
            "  adding: training_datas/train_data13521.zip (stored 0%)\n",
            "  adding: training_datas/train_data20900.zip (stored 0%)\n",
            "  adding: training_datas/train_data5791.zip (stored 0%)\n",
            "  adding: training_datas/train_data6993.zip (stored 0%)\n",
            "  adding: training_datas/train_data5413.zip (stored 0%)\n",
            "  adding: training_datas/train_data6825.zip (stored 0%)\n",
            "  adding: training_datas/train_data23452.zip (stored 0%)\n",
            "  adding: training_datas/train_data10186.zip (stored 0%)\n",
            "  adding: training_datas/train_data15707.zip (stored 0%)\n",
            "  adding: training_datas/train_data27397.zip (stored 0%)\n",
            "  adding: training_datas/train_data21124.zip (stored 0%)\n",
            "  adding: training_datas/train_data24745.zip (stored 0%)\n",
            "  adding: training_datas/train_data7445.zip (stored 0%)\n",
            "  adding: training_datas/train_data14289.zip (stored 0%)\n",
            "  adding: training_datas/train_data11460.zip (stored 0%)\n",
            "  adding: training_datas/train_data19535.zip (stored 0%)\n",
            "  adding: training_datas/train_data5806.zip (stored 0%)\n",
            "  adding: training_datas/train_data5001.zip (stored 0%)\n",
            "  adding: training_datas/train_data16533.zip (stored 0%)\n",
            "  adding: training_datas/train_data5800.zip (stored 0%)\n",
            "  adding: training_datas/train_data26826.zip (stored 0%)\n",
            "  adding: training_datas/train_data20149.zip (stored 0%)\n",
            "  adding: training_datas/train_data10625.zip (stored 0%)\n",
            "  adding: training_datas/train_data13666.zip (stored 0%)\n",
            "  adding: training_datas/train_data27344.zip (stored 0%)\n",
            "  adding: training_datas/train_data13252.zip (stored 0%)\n",
            "  adding: training_datas/train_data484.zip (stored 0%)\n",
            "  adding: training_datas/train_data27925.zip (stored 0%)\n",
            "  adding: training_datas/train_data8686.zip (stored 0%)\n",
            "  adding: training_datas/train_data23362.zip (stored 0%)\n",
            "  adding: training_datas/train_data5673.zip (stored 0%)\n",
            "  adding: training_datas/train_data3144.zip (stored 0%)\n",
            "  adding: training_datas/train_data26577.zip (stored 0%)\n",
            "  adding: training_datas/train_data8291.zip (stored 0%)\n",
            "  adding: training_datas/train_data5171.zip (stored 0%)\n",
            "  adding: training_datas/train_data5637.zip (stored 0%)\n",
            "  adding: training_datas/train_data23678.zip (stored 0%)\n",
            "  adding: training_datas/train_data28658.zip (stored 0%)\n",
            "  adding: training_datas/train_data10767.zip (stored 0%)\n",
            "  adding: training_datas/train_data28656.zip (stored 0%)\n",
            "  adding: training_datas/train_data9098.zip (stored 0%)\n",
            "  adding: training_datas/train_data29934.zip (stored 0%)\n",
            "  adding: training_datas/train_data14717.zip (stored 0%)\n",
            "  adding: training_datas/train_data17569.zip (stored 0%)\n",
            "  adding: training_datas/train_data6031.zip (stored 0%)\n",
            "  adding: training_datas/train_data29296.zip (stored 0%)\n",
            "  adding: training_datas/train_data4585.zip (stored 0%)\n",
            "  adding: training_datas/train_data17136.zip (stored 0%)\n",
            "  adding: training_datas/train_data2768.zip (stored 0%)\n",
            "  adding: training_datas/train_data25152.zip (stored 0%)\n",
            "  adding: training_datas/train_data3860.zip (stored 0%)\n",
            "  adding: training_datas/train_data5314.zip (stored 0%)\n",
            "  adding: training_datas/train_data14000.zip (stored 0%)\n",
            "  adding: training_datas/train_data24687.zip (stored 0%)\n",
            "  adding: training_datas/train_data28801.zip (stored 0%)\n",
            "  adding: training_datas/train_data3455.zip (stored 0%)\n",
            "  adding: training_datas/train_data12029.zip (stored 0%)\n",
            "  adding: training_datas/train_data26190.zip (stored 0%)\n",
            "  adding: training_datas/train_data5717.zip (stored 0%)\n",
            "  adding: training_datas/train_data19920.zip (stored 0%)\n",
            "  adding: training_datas/train_data259.zip (stored 0%)\n",
            "  adding: training_datas/train_data7969.zip (stored 0%)\n",
            "  adding: training_datas/train_data19106.zip (stored 0%)\n",
            "  adding: training_datas/train_data17883.zip (stored 0%)\n",
            "  adding: training_datas/train_data568.zip (stored 0%)\n",
            "  adding: training_datas/train_data8178.zip (stored 0%)\n",
            "  adding: training_datas/train_data3041.zip (stored 0%)\n",
            "  adding: training_datas/train_data19051.zip (stored 0%)\n",
            "  adding: training_datas/train_data23350.zip (stored 0%)\n",
            "  adding: training_datas/train_data2856.zip (stored 0%)\n",
            "  adding: training_datas/train_data22268.zip (stored 0%)\n",
            "  adding: training_datas/train_data25680.zip (stored 0%)\n",
            "  adding: training_datas/train_data23521.zip (stored 0%)\n",
            "  adding: training_datas/train_data29314.zip (stored 0%)\n",
            "  adding: training_datas/train_data26144.zip (stored 0%)\n",
            "  adding: training_datas/train_data6710.zip (stored 0%)\n",
            "  adding: training_datas/train_data1562.zip (stored 0%)\n",
            "  adding: training_datas/train_data5091.zip (stored 0%)\n",
            "  adding: training_datas/train_data25973.zip (stored 0%)\n",
            "  adding: training_datas/train_data20097.zip (stored 0%)\n",
            "  adding: training_datas/train_data11622.zip (stored 0%)\n",
            "  adding: training_datas/train_data2938.zip (stored 0%)\n",
            "  adding: training_datas/train_data28469.zip (stored 0%)\n",
            "  adding: training_datas/train_data29361.zip (stored 0%)\n",
            "  adding: training_datas/train_data6830.zip (stored 0%)\n",
            "  adding: training_datas/train_data18704.zip (stored 0%)\n",
            "  adding: training_datas/train_data29532.zip (stored 0%)\n",
            "  adding: training_datas/train_data8076.zip (stored 0%)\n",
            "  adding: training_datas/train_data2601.zip (stored 0%)\n",
            "  adding: training_datas/train_data17189.zip (stored 0%)\n",
            "  adding: training_datas/train_data18731.zip (stored 0%)\n",
            "  adding: training_datas/train_data2656.zip (stored 0%)\n",
            "  adding: training_datas/train_data23686.zip (stored 0%)\n",
            "  adding: training_datas/train_data25606.zip (stored 0%)\n",
            "  adding: training_datas/train_data12474.zip (stored 0%)\n",
            "  adding: training_datas/train_data22139.zip (stored 0%)\n",
            "  adding: training_datas/train_data15933.zip (stored 0%)\n",
            "  adding: training_datas/train_data21254.zip (stored 0%)\n",
            "  adding: training_datas/train_data5479.zip (stored 0%)\n",
            "  adding: training_datas/train_data14100.zip (stored 0%)\n",
            "  adding: training_datas/train_data23881.zip (stored 0%)\n",
            "  adding: training_datas/train_data2523.zip (stored 0%)\n",
            "  adding: training_datas/train_data4673.zip (stored 0%)\n",
            "  adding: training_datas/train_data1413.zip (stored 0%)\n",
            "  adding: training_datas/train_data7058.zip (stored 0%)\n",
            "  adding: training_datas/train_data12251.zip (stored 0%)\n",
            "  adding: training_datas/train_data5550.zip (stored 0%)\n",
            "  adding: training_datas/train_data10165.zip (stored 0%)\n",
            "  adding: training_datas/train_data22009.zip (stored 0%)\n",
            "  adding: training_datas/train_data15184.zip (stored 0%)\n",
            "  adding: training_datas/train_data185.zip (stored 0%)\n",
            "  adding: training_datas/train_data25284.zip (stored 0%)\n",
            "  adding: training_datas/train_data4306.zip (stored 0%)\n",
            "  adding: training_datas/train_data19552.zip (stored 0%)\n",
            "  adding: training_datas/train_data14357.zip (stored 0%)\n",
            "  adding: training_datas/train_data20821.zip (stored 0%)\n",
            "  adding: training_datas/train_data3074.zip (stored 0%)\n",
            "  adding: training_datas/train_data25163.zip (stored 0%)\n",
            "  adding: training_datas/train_data6316.zip (stored 0%)\n",
            "  adding: training_datas/train_data18158.zip (stored 0%)\n",
            "  adding: training_datas/train_data27389.zip (stored 0%)\n",
            "  adding: training_datas/train_data29741.zip (stored 0%)\n",
            "  adding: training_datas/train_data20782.zip (stored 0%)\n",
            "  adding: training_datas/train_data16377.zip (stored 0%)\n",
            "  adding: training_datas/train_data1295.zip (stored 0%)\n",
            "  adding: training_datas/train_data29809.zip (stored 0%)\n",
            "  adding: training_datas/train_data1761.zip (stored 0%)\n",
            "  adding: training_datas/train_data27254.zip (stored 0%)\n",
            "  adding: training_datas/train_data6213.zip (stored 0%)\n",
            "  adding: training_datas/train_data25330.zip (stored 0%)\n",
            "  adding: training_datas/train_data13823.zip (stored 0%)\n",
            "  adding: training_datas/train_data17330.zip (stored 0%)\n",
            "  adding: training_datas/train_data28354.zip (stored 0%)\n",
            "  adding: training_datas/train_data28373.zip (stored 0%)\n",
            "  adding: training_datas/train_data16644.zip (stored 0%)\n",
            "  adding: training_datas/train_data27150.zip (stored 0%)\n",
            "  adding: training_datas/train_data21917.zip (stored 0%)\n",
            "  adding: training_datas/train_data3189.zip (stored 0%)\n",
            "  adding: training_datas/train_data30124.zip (stored 0%)\n",
            "  adding: training_datas/train_data17491.zip (stored 0%)\n",
            "  adding: training_datas/train_data2495.zip (stored 0%)\n",
            "  adding: training_datas/train_data9362.zip (stored 0%)\n",
            "  adding: training_datas/train_data27214.zip (stored 0%)\n",
            "  adding: training_datas/train_data810.zip (stored 0%)\n",
            "  adding: training_datas/train_data7029.zip (stored 0%)\n",
            "  adding: training_datas/train_data5003.zip (stored 0%)\n",
            "  adding: training_datas/train_data16703.zip (stored 0%)\n",
            "  adding: training_datas/train_data4513.zip (stored 0%)\n",
            "  adding: training_datas/train_data14290.zip (stored 0%)\n",
            "  adding: training_datas/train_data28742.zip (stored 0%)\n",
            "  adding: training_datas/train_data20803.zip (stored 0%)\n",
            "  adding: training_datas/train_data19386.zip (stored 0%)\n",
            "  adding: training_datas/train_data22597.zip (stored 0%)\n",
            "  adding: training_datas/train_data6302.zip (stored 0%)\n",
            "  adding: training_datas/train_data942.zip (stored 0%)\n",
            "  adding: training_datas/train_data21593.zip (stored 0%)\n",
            "  adding: training_datas/train_data14730.zip (stored 0%)\n",
            "  adding: training_datas/train_data26890.zip (stored 0%)\n",
            "  adding: training_datas/train_data13365.zip (stored 0%)\n",
            "  adding: training_datas/train_data11161.zip (stored 0%)\n",
            "  adding: training_datas/train_data25563.zip (stored 0%)\n",
            "  adding: training_datas/train_data8705.zip (stored 0%)\n",
            "  adding: training_datas/train_data22415.zip (stored 0%)\n",
            "  adding: training_datas/train_data27131.zip (stored 0%)\n",
            "  adding: training_datas/train_data348.zip (stored 0%)\n",
            "  adding: training_datas/train_data29979.zip (stored 0%)\n",
            "  adding: training_datas/train_data25579.zip (stored 0%)\n",
            "  adding: training_datas/train_data17159.zip (stored 0%)\n",
            "  adding: training_datas/train_data23172.zip (stored 0%)\n",
            "  adding: training_datas/train_data549.zip (stored 0%)\n",
            "  adding: training_datas/train_data14816.zip (stored 0%)\n",
            "  adding: training_datas/train_data22539.zip (stored 0%)\n",
            "  adding: training_datas/train_data12811.zip (stored 0%)\n",
            "  adding: training_datas/train_data5567.zip (stored 0%)\n",
            "  adding: training_datas/train_data30299.zip (stored 0%)\n",
            "  adding: training_datas/train_data967.zip (stored 0%)\n",
            "  adding: training_datas/train_data29326.zip (stored 0%)\n",
            "  adding: training_datas/train_data25341.zip (stored 0%)\n",
            "  adding: training_datas/train_data30289.zip (stored 0%)\n",
            "  adding: training_datas/train_data21505.zip (stored 0%)\n",
            "  adding: training_datas/train_data24696.zip (stored 0%)\n",
            "  adding: training_datas/train_data29474.zip (stored 0%)\n",
            "  adding: training_datas/train_data27514.zip (stored 0%)\n",
            "  adding: training_datas/train_data17975.zip (stored 0%)\n",
            "  adding: training_datas/train_data23994.zip (stored 0%)\n",
            "  adding: training_datas/train_data30459.zip (stored 0%)\n",
            "  adding: training_datas/train_data24510.zip (stored 0%)\n",
            "  adding: training_datas/train_data26660.zip (stored 0%)\n",
            "  adding: training_datas/train_data16204.zip (stored 0%)\n",
            "  adding: training_datas/train_data5025.zip (stored 0%)\n",
            "  adding: training_datas/train_data258.zip (stored 0%)\n",
            "  adding: training_datas/train_data21828.zip (stored 0%)\n",
            "  adding: training_datas/train_data7719.zip (stored 0%)\n",
            "  adding: training_datas/train_data25716.zip (stored 0%)\n",
            "  adding: training_datas/train_data2558.zip (stored 0%)\n",
            "  adding: training_datas/train_data11614.zip (stored 0%)\n",
            "  adding: training_datas/train_data12641.zip (stored 0%)\n",
            "  adding: training_datas/train_data20558.zip (stored 0%)\n",
            "  adding: training_datas/train_data17373.zip (stored 0%)\n",
            "  adding: training_datas/train_data16829.zip (stored 0%)\n",
            "  adding: training_datas/train_data17857.zip (stored 0%)\n",
            "  adding: training_datas/train_data28569.zip (stored 0%)\n",
            "  adding: training_datas/train_data25286.zip (stored 0%)\n",
            "  adding: training_datas/train_data4206.zip (stored 0%)\n",
            "  adding: training_datas/train_data8035.zip (stored 0%)\n",
            "  adding: training_datas/train_data25168.zip (stored 0%)\n",
            "  adding: training_datas/train_data23451.zip (stored 0%)\n",
            "  adding: training_datas/train_data21016.zip (stored 0%)\n",
            "  adding: training_datas/train_data11473.zip (stored 0%)\n",
            "  adding: training_datas/train_data10747.zip (stored 0%)\n",
            "  adding: training_datas/train_data6657.zip (stored 0%)\n",
            "  adding: training_datas/train_data24664.zip (stored 0%)\n",
            "  adding: training_datas/train_data20662.zip (stored 0%)\n",
            "  adding: training_datas/train_data22565.zip (stored 0%)\n",
            "  adding: training_datas/train_data11278.zip (stored 0%)\n",
            "  adding: training_datas/train_data4259.zip (stored 0%)\n",
            "  adding: training_datas/train_data2623.zip (stored 0%)\n",
            "  adding: training_datas/train_data8916.zip (stored 0%)\n",
            "  adding: training_datas/train_data20210.zip (stored 0%)\n",
            "  adding: training_datas/train_data22727.zip (stored 0%)\n",
            "  adding: training_datas/train_data29667.zip (stored 0%)\n",
            "  adding: training_datas/train_data22999.zip (stored 0%)\n",
            "  adding: training_datas/train_data22760.zip (stored 0%)\n",
            "  adding: training_datas/train_data20963.zip (stored 0%)\n",
            "  adding: training_datas/train_data6241.zip (stored 0%)\n",
            "  adding: training_datas/train_data14973.zip (stored 0%)\n",
            "  adding: training_datas/train_data23713.zip (stored 0%)\n",
            "  adding: training_datas/train_data13274.zip (stored 0%)\n",
            "  adding: training_datas/train_data30395.zip (stored 0%)\n",
            "  adding: training_datas/train_data16338.zip (stored 0%)\n",
            "  adding: training_datas/train_data14190.zip (stored 0%)\n",
            "  adding: training_datas/train_data19885.zip (stored 0%)\n",
            "  adding: training_datas/train_data8312.zip (stored 0%)\n",
            "  adding: training_datas/train_data736.zip (stored 0%)\n",
            "  adding: training_datas/train_data28633.zip (stored 0%)\n",
            "  adding: training_datas/train_data11639.zip (stored 0%)\n",
            "  adding: training_datas/train_data963.zip (stored 0%)\n",
            "  adding: training_datas/train_data9879.zip (stored 0%)\n",
            "  adding: training_datas/train_data30487.zip (stored 0%)\n",
            "  adding: training_datas/train_data10178.zip (stored 0%)\n",
            "  adding: training_datas/train_data14875.zip (stored 0%)\n",
            "  adding: training_datas/train_data27913.zip (stored 0%)\n",
            "  adding: training_datas/train_data2020.zip (stored 0%)\n",
            "  adding: training_datas/train_data3734.zip (stored 0%)\n",
            "  adding: training_datas/train_data15714.zip (stored 0%)\n",
            "  adding: training_datas/train_data13887.zip (stored 0%)\n",
            "  adding: training_datas/train_data4280.zip (stored 0%)\n",
            "  adding: training_datas/train_data18310.zip (stored 0%)\n",
            "  adding: training_datas/train_data17777.zip (stored 0%)\n",
            "  adding: training_datas/train_data29983.zip (stored 0%)\n",
            "  adding: training_datas/train_data4248.zip (stored 0%)\n",
            "  adding: training_datas/train_data19004.zip (stored 0%)\n",
            "  adding: training_datas/train_data9726.zip (stored 0%)\n",
            "  adding: training_datas/train_data7745.zip (stored 0%)\n",
            "  adding: training_datas/train_data8907.zip (stored 0%)\n",
            "  adding: training_datas/train_data782.zip (stored 0%)\n",
            "  adding: training_datas/train_data3642.zip (stored 0%)\n",
            "  adding: training_datas/train_data22384.zip (stored 0%)\n",
            "  adding: training_datas/train_data7494.zip (stored 0%)\n",
            "  adding: training_datas/train_data7093.zip (stored 0%)\n",
            "  adding: training_datas/train_data23867.zip (stored 0%)\n",
            "  adding: training_datas/train_data11289.zip (stored 0%)\n",
            "  adding: training_datas/train_data14928.zip (stored 0%)\n",
            "  adding: training_datas/train_data18502.zip (stored 0%)\n",
            "  adding: training_datas/train_data19002.zip (stored 0%)\n",
            "  adding: training_datas/train_data18716.zip (stored 0%)\n",
            "  adding: training_datas/train_data18678.zip (stored 0%)\n",
            "  adding: training_datas/train_data26756.zip (stored 0%)\n",
            "  adding: training_datas/train_data17008.zip (stored 0%)\n",
            "  adding: training_datas/train_data22008.zip (stored 0%)\n",
            "  adding: training_datas/train_data11597.zip (stored 0%)\n",
            "  adding: training_datas/train_data7295.zip (stored 0%)\n",
            "  adding: training_datas/train_data28493.zip (stored 0%)\n",
            "  adding: training_datas/train_data17867.zip (stored 0%)\n",
            "  adding: training_datas/train_data15876.zip (stored 0%)\n",
            "  adding: training_datas/train_data15498.zip (stored 0%)\n",
            "  adding: training_datas/train_data3682.zip (stored 0%)\n",
            "  adding: training_datas/train_data9951.zip (stored 0%)\n",
            "  adding: training_datas/train_data26070.zip (stored 0%)\n",
            "  adding: training_datas/train_data21924.zip (stored 0%)\n",
            "  adding: training_datas/train_data19141.zip (stored 0%)\n",
            "  adding: training_datas/train_data13533.zip (stored 0%)\n",
            "  adding: training_datas/train_data16863.zip (stored 0%)\n",
            "  adding: training_datas/train_data15996.zip (stored 0%)\n",
            "  adding: training_datas/train_data24938.zip (stored 0%)\n",
            "  adding: training_datas/train_data6416.zip (stored 0%)\n",
            "  adding: training_datas/train_data11432.zip (stored 0%)\n",
            "  adding: training_datas/train_data5533.zip (stored 0%)\n",
            "  adding: training_datas/train_data9696.zip (stored 0%)\n",
            "  adding: training_datas/train_data12418.zip (stored 0%)\n",
            "  adding: training_datas/train_data26879.zip (stored 0%)\n",
            "  adding: training_datas/train_data6454.zip (stored 0%)\n",
            "  adding: training_datas/train_data19626.zip (stored 0%)\n",
            "  adding: training_datas/train_data7761.zip (stored 0%)\n",
            "  adding: training_datas/train_data8422.zip (stored 0%)\n",
            "  adding: training_datas/train_data16017.zip (stored 0%)\n",
            "  adding: training_datas/train_data10715.zip (stored 0%)\n",
            "  adding: training_datas/train_data2447.zip (stored 0%)\n",
            "  adding: training_datas/train_data13494.zip (stored 0%)\n",
            "  adding: training_datas/train_data4623.zip (stored 0%)\n",
            "  adding: training_datas/train_data24481.zip (stored 0%)\n",
            "  adding: training_datas/train_data3446.zip (stored 0%)\n",
            "  adding: training_datas/train_data20138.zip (stored 0%)\n",
            "  adding: training_datas/train_data25816.zip (stored 0%)\n",
            "  adding: training_datas/train_data4715.zip (stored 0%)\n",
            "  adding: training_datas/train_data28385.zip (stored 0%)\n",
            "  adding: training_datas/train_data12428.zip (stored 0%)\n",
            "  adding: training_datas/train_data18734.zip (stored 0%)\n",
            "  adding: training_datas/train_data13688.zip (stored 0%)\n",
            "  adding: training_datas/train_data16216.zip (stored 0%)\n",
            "  adding: training_datas/train_data26520.zip (stored 0%)\n",
            "  adding: training_datas/train_data12993.zip (stored 0%)\n",
            "  adding: training_datas/train_data25714.zip (stored 0%)\n",
            "  adding: training_datas/train_data13643.zip (stored 0%)\n",
            "  adding: training_datas/train_data1726.zip (stored 0%)\n",
            "  adding: training_datas/train_data12676.zip (stored 0%)\n",
            "  adding: training_datas/train_data18102.zip (stored 0%)\n",
            "  adding: training_datas/train_data5242.zip (stored 0%)\n",
            "  adding: training_datas/train_data30282.zip (stored 0%)\n",
            "  adding: training_datas/train_data18169.zip (stored 0%)\n",
            "  adding: training_datas/train_data22568.zip (stored 0%)\n",
            "  adding: training_datas/train_data22630.zip (stored 0%)\n",
            "  adding: training_datas/train_data9193.zip (stored 0%)\n",
            "  adding: training_datas/train_data4918.zip (stored 0%)\n",
            "  adding: training_datas/train_data24100.zip (stored 0%)\n",
            "  adding: training_datas/train_data11615.zip (stored 0%)\n",
            "  adding: training_datas/train_data28671.zip (stored 0%)\n",
            "  adding: training_datas/train_data22382.zip (stored 0%)\n",
            "  adding: training_datas/train_data7658.zip (stored 0%)\n",
            "  adding: training_datas/train_data29581.zip (stored 0%)\n",
            "  adding: training_datas/train_data15061.zip (stored 0%)\n",
            "  adding: training_datas/train_data1614.zip (stored 0%)\n",
            "  adding: training_datas/train_data5221.zip (stored 0%)\n",
            "  adding: training_datas/train_data16793.zip (stored 0%)\n",
            "  adding: training_datas/train_data15098.zip (stored 0%)\n",
            "  adding: training_datas/train_data12575.zip (stored 0%)\n",
            "  adding: training_datas/train_data2385.zip (stored 0%)\n",
            "  adding: training_datas/train_data13933.zip (stored 0%)\n",
            "  adding: training_datas/train_data8606.zip (stored 0%)\n",
            "  adding: training_datas/train_data12465.zip (stored 0%)\n",
            "  adding: training_datas/train_data11191.zip (stored 0%)\n",
            "  adding: training_datas/train_data5638.zip (stored 0%)\n",
            "  adding: training_datas/train_data27497.zip (stored 0%)\n",
            "  adding: training_datas/train_data12692.zip (stored 0%)\n",
            "  adding: training_datas/train_data5761.zip (stored 0%)\n",
            "  adding: training_datas/train_data12011.zip (stored 0%)\n",
            "  adding: training_datas/train_data23972.zip (stored 0%)\n",
            "  adding: training_datas/train_data26590.zip (stored 0%)\n",
            "  adding: training_datas/train_data23851.zip (stored 0%)\n",
            "  adding: training_datas/train_data25800.zip (stored 0%)\n",
            "  adding: training_datas/train_data5150.zip (stored 0%)\n",
            "  adding: training_datas/train_data6079.zip (stored 0%)\n",
            "  adding: training_datas/train_data8934.zip (stored 0%)\n",
            "  adding: training_datas/train_data27478.zip (stored 0%)\n",
            "  adding: training_datas/train_data16162.zip (stored 0%)\n",
            "  adding: training_datas/train_data1765.zip (stored 0%)\n",
            "  adding: training_datas/train_data9832.zip (stored 0%)\n",
            "  adding: training_datas/train_data27941.zip (stored 0%)\n",
            "  adding: training_datas/train_data23704.zip (stored 0%)\n",
            "  adding: training_datas/train_data9496.zip (stored 0%)\n",
            "  adding: training_datas/train_data27448.zip (stored 0%)\n",
            "  adding: training_datas/train_data9842.zip (stored 0%)\n",
            "  adding: training_datas/train_data8142.zip (stored 0%)\n",
            "  adding: training_datas/train_data27201.zip (stored 0%)\n",
            "  adding: training_datas/train_data17607.zip (stored 0%)\n",
            "  adding: training_datas/train_data16609.zip (stored 0%)\n",
            "  adding: training_datas/train_data3355.zip (stored 0%)\n",
            "  adding: training_datas/train_data24876.zip (stored 0%)\n",
            "  adding: training_datas/train_data29096.zip (stored 0%)\n",
            "  adding: training_datas/train_data19853.zip (stored 0%)\n",
            "  adding: training_datas/train_data8657.zip (stored 0%)\n",
            "  adding: training_datas/train_data9389.zip (stored 0%)\n",
            "  adding: training_datas/train_data463.zip (stored 0%)\n",
            "  adding: training_datas/train_data16000.zip (stored 0%)\n",
            "  adding: training_datas/train_data28606.zip (stored 0%)\n",
            "  adding: training_datas/train_data17344.zip (stored 0%)\n",
            "  adding: training_datas/train_data21678.zip (stored 0%)\n",
            "  adding: training_datas/train_data20583.zip (stored 0%)\n",
            "  adding: training_datas/train_data2541.zip (stored 0%)\n",
            "  adding: training_datas/train_data5386.zip (stored 0%)\n",
            "  adding: training_datas/train_data4399.zip (stored 0%)\n",
            "  adding: training_datas/train_data24077.zip (stored 0%)\n",
            "  adding: training_datas/train_data16865.zip (stored 0%)\n",
            "  adding: training_datas/train_data22137.zip (stored 0%)\n",
            "  adding: training_datas/train_data24627.zip (stored 0%)\n",
            "  adding: training_datas/train_data9975.zip (stored 0%)\n",
            "  adding: training_datas/train_data23454.zip (stored 0%)\n",
            "  adding: training_datas/train_data5076.zip (stored 0%)\n",
            "  adding: training_datas/train_data9821.zip (stored 0%)\n",
            "  adding: training_datas/train_data18350.zip (stored 0%)\n",
            "  adding: training_datas/train_data24436.zip (stored 0%)\n",
            "  adding: training_datas/train_data9365.zip (stored 0%)\n",
            "  adding: training_datas/train_data21947.zip (stored 0%)\n",
            "  adding: training_datas/train_data12622.zip (stored 0%)\n",
            "  adding: training_datas/train_data18206.zip (stored 0%)\n",
            "  adding: training_datas/train_data18556.zip (stored 0%)\n",
            "  adding: training_datas/train_data20304.zip (stored 0%)\n",
            "  adding: training_datas/train_data22557.zip (stored 0%)\n",
            "  adding: training_datas/train_data247.zip (stored 0%)\n",
            "  adding: training_datas/train_data14268.zip (stored 0%)\n",
            "  adding: training_datas/train_data12366.zip (stored 0%)\n",
            "  adding: training_datas/train_data20820.zip (stored 0%)\n",
            "  adding: training_datas/train_data24280.zip (stored 0%)\n",
            "  adding: training_datas/train_data21625.zip (stored 0%)\n",
            "  adding: training_datas/train_data245.zip (stored 0%)\n",
            "  adding: training_datas/train_data11906.zip (stored 0%)\n",
            "  adding: training_datas/train_data15560.zip (stored 0%)\n",
            "  adding: training_datas/train_data21117.zip (stored 0%)\n",
            "  adding: training_datas/train_data20559.zip (stored 0%)\n",
            "  adding: training_datas/train_data17115.zip (stored 0%)\n",
            "  adding: training_datas/train_data4310.zip (stored 0%)\n",
            "  adding: training_datas/train_data4022.zip (stored 0%)\n",
            "  adding: training_datas/train_data3909.zip (stored 0%)\n",
            "  adding: training_datas/train_data20866.zip (stored 0%)\n",
            "  adding: training_datas/train_data29963.zip (stored 0%)\n",
            "  adding: training_datas/train_data16068.zip (stored 0%)\n",
            "  adding: training_datas/train_data12974.zip (stored 0%)\n",
            "  adding: training_datas/train_data4126.zip (stored 0%)\n",
            "  adding: training_datas/train_data553.zip (stored 0%)\n",
            "  adding: training_datas/train_data9319.zip (stored 0%)\n",
            "  adding: training_datas/train_data17456.zip (stored 0%)\n",
            "  adding: training_datas/train_data6060.zip (stored 0%)\n",
            "  adding: training_datas/train_data21288.zip (stored 0%)\n",
            "  adding: training_datas/train_data1584.zip (stored 0%)\n",
            "  adding: training_datas/train_data24919.zip (stored 0%)\n",
            "  adding: training_datas/train_data12551.zip (stored 0%)\n",
            "  adding: training_datas/train_data5069.zip (stored 0%)\n",
            "  adding: training_datas/train_data28576.zip (stored 0%)\n",
            "  adding: training_datas/train_data10712.zip (stored 0%)\n",
            "  adding: training_datas/train_data434.zip (stored 0%)\n",
            "  adding: training_datas/train_data30479.zip (stored 0%)\n",
            "  adding: training_datas/train_data1148.zip (stored 0%)\n",
            "  adding: training_datas/train_data12924.zip (stored 0%)\n",
            "  adding: training_datas/train_data17881.zip (stored 0%)\n",
            "  adding: training_datas/train_data7112.zip (stored 0%)\n",
            "  adding: training_datas/train_data5362.zip (stored 0%)\n",
            "  adding: training_datas/train_data19704.zip (stored 0%)\n",
            "  adding: training_datas/train_data9881.zip (stored 0%)\n",
            "  adding: training_datas/train_data3617.zip (stored 0%)\n",
            "  adding: training_datas/train_data23911.zip (stored 0%)\n",
            "  adding: training_datas/train_data5751.zip (stored 0%)\n",
            "  adding: training_datas/train_data9608.zip (stored 0%)\n",
            "  adding: training_datas/train_data9703.zip (stored 0%)\n",
            "  adding: training_datas/train_data21969.zip (stored 0%)\n",
            "  adding: training_datas/train_data8511.zip (stored 0%)\n",
            "  adding: training_datas/train_data3876.zip (stored 0%)\n",
            "  adding: training_datas/train_data27987.zip (stored 0%)\n",
            "  adding: training_datas/train_data15041.zip (stored 0%)\n",
            "  adding: training_datas/train_data7600.zip (stored 0%)\n",
            "  adding: training_datas/train_data1126.zip (stored 0%)\n",
            "  adding: training_datas/train_data20048.zip (stored 0%)\n",
            "  adding: training_datas/train_data5147.zip (stored 0%)\n",
            "  adding: training_datas/train_data28248.zip (stored 0%)\n",
            "  adding: training_datas/train_data22051.zip (stored 0%)\n",
            "  adding: training_datas/train_data28087.zip (stored 0%)\n",
            "  adding: training_datas/train_data28531.zip (stored 0%)\n",
            "  adding: training_datas/train_data814.zip (stored 0%)\n",
            "  adding: training_datas/train_data19201.zip (stored 0%)\n",
            "  adding: training_datas/train_data8906.zip (stored 0%)\n",
            "  adding: training_datas/train_data15621.zip (stored 0%)\n",
            "  adding: training_datas/train_data3201.zip (stored 0%)\n",
            "  adding: training_datas/train_data16884.zip (stored 0%)\n",
            "  adding: training_datas/train_data25425.zip (stored 0%)\n",
            "  adding: training_datas/train_data24145.zip (stored 0%)\n",
            "  adding: training_datas/train_data2773.zip (stored 0%)\n",
            "  adding: training_datas/train_data26244.zip (stored 0%)\n",
            "  adding: training_datas/train_data24785.zip (stored 0%)\n",
            "  adding: training_datas/train_data23235.zip (stored 0%)\n",
            "  adding: training_datas/train_data10908.zip (stored 0%)\n",
            "  adding: training_datas/train_data9869.zip (stored 0%)\n",
            "  adding: training_datas/train_data14212.zip (stored 0%)\n",
            "  adding: training_datas/train_data12025.zip (stored 0%)\n",
            "  adding: training_datas/train_data1728.zip (stored 0%)\n",
            "  adding: training_datas/train_data25589.zip (stored 0%)\n",
            "  adding: training_datas/train_data19260.zip (stored 0%)\n",
            "  adding: training_datas/train_data8361.zip (stored 0%)\n",
            "  adding: training_datas/train_data26824.zip (stored 0%)\n",
            "  adding: training_datas/train_data4913.zip (stored 0%)\n",
            "  adding: training_datas/train_data4725.zip (stored 0%)\n",
            "  adding: training_datas/train_data28737.zip (stored 0%)\n",
            "  adding: training_datas/train_data16189.zip (stored 0%)\n",
            "  adding: training_datas/train_data11027.zip (stored 0%)\n",
            "  adding: training_datas/train_data3313.zip (stored 0%)\n",
            "  adding: training_datas/train_data28264.zip (stored 0%)\n",
            "  adding: training_datas/train_data13720.zip (stored 0%)\n",
            "  adding: training_datas/train_data24676.zip (stored 0%)\n",
            "  adding: training_datas/train_data29382.zip (stored 0%)\n",
            "  adding: training_datas/train_data12271.zip (stored 0%)\n",
            "  adding: training_datas/train_data24091.zip (stored 0%)\n",
            "  adding: training_datas/train_data20813.zip (stored 0%)\n",
            "  adding: training_datas/train_data12421.zip (stored 0%)\n",
            "  adding: training_datas/train_data14830.zip (stored 0%)\n",
            "  adding: training_datas/train_data20063.zip (stored 0%)\n",
            "  adding: training_datas/train_data8302.zip (stored 0%)\n",
            "  adding: training_datas/train_data3818.zip (stored 0%)\n",
            "  adding: training_datas/train_data6072.zip (stored 0%)\n",
            "  adding: training_datas/train_data3583.zip (stored 0%)\n",
            "  adding: training_datas/train_data29642.zip (stored 0%)\n",
            "  adding: training_datas/train_data27895.zip (stored 0%)\n",
            "  adding: training_datas/train_data10851.zip (stored 0%)\n",
            "  adding: training_datas/train_data2658.zip (stored 0%)\n",
            "  adding: training_datas/train_data7565.zip (stored 0%)\n",
            "  adding: training_datas/train_data1299.zip (stored 0%)\n",
            "  adding: training_datas/train_data1258.zip (stored 0%)\n",
            "  adding: training_datas/train_data23518.zip (stored 0%)\n",
            "  adding: training_datas/train_data14085.zip (stored 0%)\n",
            "  adding: training_datas/train_data24871.zip (stored 0%)\n",
            "  adding: training_datas/train_data22062.zip (stored 0%)\n",
            "  adding: training_datas/train_data14987.zip (stored 0%)\n",
            "  adding: training_datas/train_data17070.zip (stored 0%)\n",
            "  adding: training_datas/train_data23324.zip (stored 0%)\n",
            "  adding: training_datas/train_data5774.zip (stored 0%)\n",
            "  adding: training_datas/train_data20973.zip (stored 0%)\n",
            "  adding: training_datas/train_data840.zip (stored 0%)\n",
            "  adding: training_datas/train_data21091.zip (stored 0%)\n",
            "  adding: training_datas/train_data23935.zip (stored 0%)\n",
            "  adding: training_datas/train_data17949.zip (stored 0%)\n",
            "  adding: training_datas/train_data26703.zip (stored 0%)\n",
            "  adding: training_datas/train_data19637.zip (stored 0%)\n",
            "  adding: training_datas/train_data469.zip (stored 0%)\n",
            "  adding: training_datas/train_data22862.zip (stored 0%)\n",
            "  adding: training_datas/train_data5219.zip (stored 0%)\n",
            "  adding: training_datas/train_data1041.zip (stored 0%)\n",
            "  adding: training_datas/train_data30178.zip (stored 0%)\n",
            "  adding: training_datas/train_data4758.zip (stored 0%)\n",
            "  adding: training_datas/train_data16164.zip (stored 0%)\n",
            "  adding: training_datas/train_data14488.zip (stored 0%)\n",
            "  adding: training_datas/train_data28543.zip (stored 0%)\n",
            "  adding: training_datas/train_data5404.zip (stored 0%)\n",
            "  adding: training_datas/train_data13992.zip (stored 0%)\n",
            "  adding: training_datas/train_data15086.zip (stored 0%)\n",
            "  adding: training_datas/train_data15358.zip (stored 0%)\n",
            "  adding: training_datas/train_data15209.zip (stored 0%)\n",
            "  adding: training_datas/train_data10761.zip (stored 0%)\n",
            "  adding: training_datas/train_data28603.zip (stored 0%)\n",
            "  adding: training_datas/train_data20909.zip (stored 0%)\n",
            "  adding: training_datas/train_data19958.zip (stored 0%)\n",
            "  adding: training_datas/train_data9330.zip (stored 0%)\n",
            "  adding: training_datas/train_data16445.zip (stored 0%)\n",
            "  adding: training_datas/train_data17348.zip (stored 0%)\n",
            "  adding: training_datas/train_data4506.zip (stored 0%)\n",
            "  adding: training_datas/train_data17719.zip (stored 0%)\n",
            "  adding: training_datas/train_data25328.zip (stored 0%)\n",
            "  adding: training_datas/train_data25782.zip (stored 0%)\n",
            "  adding: training_datas/train_data17512.zip (stored 0%)\n",
            "  adding: training_datas/train_data602.zip (stored 0%)\n",
            "  adding: training_datas/train_data9854.zip (stored 0%)\n",
            "  adding: training_datas/train_data2740.zip (stored 0%)\n",
            "  adding: training_datas/train_data15680.zip (stored 0%)\n",
            "  adding: training_datas/train_data14443.zip (stored 0%)\n",
            "  adding: training_datas/train_data20167.zip (stored 0%)\n",
            "  adding: training_datas/train_data16682.zip (stored 0%)\n",
            "  adding: training_datas/train_data16760.zip (stored 0%)\n",
            "  adding: training_datas/train_data15412.zip (stored 0%)\n",
            "  adding: training_datas/train_data18576.zip (stored 0%)\n",
            "  adding: training_datas/train_data5044.zip (stored 0%)\n",
            "  adding: training_datas/train_data16779.zip (stored 0%)\n",
            "  adding: training_datas/train_data15068.zip (stored 0%)\n",
            "  adding: training_datas/train_data13850.zip (stored 0%)\n",
            "  adding: training_datas/train_data4396.zip (stored 0%)\n",
            "  adding: training_datas/train_data23468.zip (stored 0%)\n",
            "  adding: training_datas/train_data13797.zip (stored 0%)\n",
            "  adding: training_datas/train_data6199.zip (stored 0%)\n",
            "  adding: training_datas/train_data5469.zip (stored 0%)\n",
            "  adding: training_datas/train_data18623.zip (stored 0%)\n",
            "  adding: training_datas/train_data8615.zip (stored 0%)\n",
            "  adding: training_datas/train_data23624.zip (stored 0%)\n",
            "  adding: training_datas/train_data22037.zip (stored 0%)\n",
            "  adding: training_datas/train_data23546.zip (stored 0%)\n",
            "  adding: training_datas/train_data18671.zip (stored 0%)\n",
            "  adding: training_datas/train_data27546.zip (stored 0%)\n",
            "  adding: training_datas/train_data25945.zip (stored 0%)\n",
            "  adding: training_datas/train_data26300.zip (stored 0%)\n",
            "  adding: training_datas/train_data8264.zip (stored 0%)\n",
            "  adding: training_datas/train_data10719.zip (stored 0%)\n",
            "  adding: training_datas/train_data13941.zip (stored 0%)\n",
            "  adding: training_datas/train_data28644.zip (stored 0%)\n",
            "  adding: training_datas/train_data3602.zip (stored 0%)\n",
            "  adding: training_datas/train_data11078.zip (stored 0%)\n",
            "  adding: training_datas/train_data23849.zip (stored 0%)\n",
            "  adding: training_datas/train_data23348.zip (stored 0%)\n",
            "  adding: training_datas/train_data15598.zip (stored 0%)\n",
            "  adding: training_datas/train_data9999.zip (stored 0%)\n",
            "  adding: training_datas/train_data26798.zip (stored 0%)\n",
            "  adding: training_datas/train_data14873.zip (stored 0%)\n",
            "  adding: training_datas/train_data28252.zip (stored 0%)\n",
            "  adding: training_datas/train_data9517.zip (stored 0%)\n",
            "  adding: training_datas/train_data18250.zip (stored 0%)\n",
            "  adding: training_datas/train_data14527.zip (stored 0%)\n",
            "  adding: training_datas/train_data28227.zip (stored 0%)\n",
            "  adding: training_datas/train_data2913.zip (stored 0%)\n",
            "  adding: training_datas/train_data20484.zip (stored 0%)\n",
            "  adding: training_datas/train_data27660.zip (stored 0%)\n",
            "  adding: training_datas/train_data11155.zip (stored 0%)\n",
            "  adding: training_datas/train_data1261.zip (stored 0%)\n",
            "  adding: training_datas/train_data22279.zip (stored 0%)\n",
            "  adding: training_datas/train_data29820.zip (stored 0%)\n",
            "  adding: training_datas/train_data3100.zip (stored 0%)\n",
            "  adding: training_datas/train_data11781.zip (stored 0%)\n",
            "  adding: training_datas/train_data2786.zip (stored 0%)\n",
            "  adding: training_datas/train_data4710.zip (stored 0%)\n",
            "  adding: training_datas/train_data19075.zip (stored 0%)\n",
            "  adding: training_datas/train_data19745.zip (stored 0%)\n",
            "  adding: training_datas/train_data15312.zip (stored 0%)\n",
            "  adding: training_datas/train_data24721.zip (stored 0%)\n",
            "  adding: training_datas/train_data14192.zip (stored 0%)\n",
            "  adding: training_datas/train_data27977.zip (stored 0%)\n",
            "  adding: training_datas/train_data27889.zip (stored 0%)\n",
            "  adding: training_datas/train_data13117.zip (stored 0%)\n",
            "  adding: training_datas/train_data12668.zip (stored 0%)\n",
            "  adding: training_datas/train_data7848.zip (stored 0%)\n",
            "  adding: training_datas/train_data14144.zip (stored 0%)\n",
            "  adding: training_datas/train_data13595.zip (stored 0%)\n",
            "  adding: training_datas/train_data21195.zip (stored 0%)\n",
            "  adding: training_datas/train_data10957.zip (stored 0%)\n",
            "  adding: training_datas/train_data21869.zip (stored 0%)\n",
            "  adding: training_datas/train_data20098.zip (stored 0%)\n",
            "  adding: training_datas/train_data16940.zip (stored 0%)\n",
            "  adding: training_datas/train_data16875.zip (stored 0%)\n",
            "  adding: training_datas/train_data29966.zip (stored 0%)\n",
            "  adding: training_datas/train_data10313.zip (stored 0%)\n",
            "  adding: training_datas/train_data27438.zip (stored 0%)\n",
            "  adding: training_datas/train_data27561.zip (stored 0%)\n",
            "  adding: training_datas/train_data11134.zip (stored 0%)\n",
            "  adding: training_datas/train_data26324.zip (stored 0%)\n",
            "  adding: training_datas/train_data10312.zip (stored 0%)\n",
            "  adding: training_datas/train_data3186.zip (stored 0%)\n",
            "  adding: training_datas/train_data29684.zip (stored 0%)\n",
            "  adding: training_datas/train_data14108.zip (stored 0%)\n",
            "  adding: training_datas/train_data9090.zip (stored 0%)\n",
            "  adding: training_datas/train_data1670.zip (stored 0%)\n",
            "  adding: training_datas/train_data17080.zip (stored 0%)\n",
            "  adding: training_datas/train_data6159.zip (stored 0%)\n",
            "  adding: training_datas/train_data27062.zip (stored 0%)\n",
            "  adding: training_datas/train_data28545.zip (stored 0%)\n",
            "  adding: training_datas/train_data627.zip (stored 0%)\n",
            "  adding: training_datas/train_data27102.zip (stored 0%)\n",
            "  adding: training_datas/train_data25023.zip (stored 0%)\n",
            "  adding: training_datas/train_data24928.zip (stored 0%)\n",
            "  adding: training_datas/train_data7687.zip (stored 0%)\n",
            "  adding: training_datas/train_data4905.zip (stored 0%)\n",
            "  adding: training_datas/train_data8206.zip (stored 0%)\n",
            "  adding: training_datas/train_data11862.zip (stored 0%)\n",
            "  adding: training_datas/train_data737.zip (stored 0%)\n",
            "  adding: training_datas/train_data29700.zip (stored 0%)\n",
            "  adding: training_datas/train_data10020.zip (stored 0%)\n",
            "  adding: training_datas/train_data24342.zip (stored 0%)\n",
            "  adding: training_datas/train_data5100.zip (stored 0%)\n",
            "  adding: training_datas/train_data21883.zip (stored 0%)\n",
            "  adding: training_datas/train_data24005.zip (stored 0%)\n",
            "  adding: training_datas/train_data22782.zip (stored 0%)\n",
            "  adding: training_datas/train_data20415.zip (stored 0%)\n",
            "  adding: training_datas/train_data593.zip (stored 0%)\n",
            "  adding: training_datas/train_data22554.zip (stored 0%)\n",
            "  adding: training_datas/train_data11888.zip (stored 0%)\n",
            "  adding: training_datas/train_data16610.zip (stored 0%)\n",
            "  adding: training_datas/train_data7398.zip (stored 0%)\n",
            "  adding: training_datas/train_data28297.zip (stored 0%)\n",
            "  adding: training_datas/train_data23575.zip (stored 0%)\n",
            "  adding: training_datas/train_data22368.zip (stored 0%)\n",
            "  adding: training_datas/train_data13725.zip (stored 0%)\n",
            "  adding: training_datas/train_data7588.zip (stored 0%)\n",
            "  adding: training_datas/train_data16920.zip (stored 0%)\n",
            "  adding: training_datas/train_data20975.zip (stored 0%)\n",
            "  adding: training_datas/train_data25894.zip (stored 0%)\n",
            "  adding: training_datas/train_data28928.zip (stored 0%)\n",
            "  adding: training_datas/train_data12220.zip (stored 0%)\n",
            "  adding: training_datas/train_data24733.zip (stored 0%)\n",
            "  adding: training_datas/train_data26341.zip (stored 0%)\n",
            "  adding: training_datas/train_data9076.zip (stored 0%)\n",
            "  adding: training_datas/train_data10076.zip (stored 0%)\n",
            "  adding: training_datas/train_data25423.zip (stored 0%)\n",
            "  adding: training_datas/train_data29394.zip (stored 0%)\n",
            "  adding: training_datas/train_data22239.zip (stored 0%)\n",
            "  adding: training_datas/train_data15852.zip (stored 0%)\n",
            "  adding: training_datas/train_data24255.zip (stored 0%)\n",
            "  adding: training_datas/train_data300.zip (stored 0%)\n",
            "  adding: training_datas/train_data14399.zip (stored 0%)\n",
            "  adding: training_datas/train_data13358.zip (stored 0%)\n",
            "  adding: training_datas/train_data18117.zip (stored 0%)\n",
            "  adding: training_datas/train_data23412.zip (stored 0%)\n",
            "  adding: training_datas/train_data22659.zip (stored 0%)\n",
            "  adding: training_datas/train_data18877.zip (stored 0%)\n",
            "  adding: training_datas/train_data11837.zip (stored 0%)\n",
            "  adding: training_datas/train_data19406.zip (stored 0%)\n",
            "  adding: training_datas/train_data17195.zip (stored 0%)\n",
            "  adding: training_datas/train_data1310.zip (stored 0%)\n",
            "  adding: training_datas/train_data29646.zip (stored 0%)\n",
            "  adding: training_datas/train_data22822.zip (stored 0%)\n",
            "  adding: training_datas/train_data8860.zip (stored 0%)\n",
            "  adding: training_datas/train_data21404.zip (stored 0%)\n",
            "  adding: training_datas/train_data11635.zip (stored 0%)\n",
            "  adding: training_datas/train_data5202.zip (stored 0%)\n",
            "  adding: training_datas/train_data27020.zip (stored 0%)\n",
            "  adding: training_datas/train_data3708.zip (stored 0%)\n",
            "  adding: training_datas/train_data15282.zip (stored 0%)\n",
            "  adding: training_datas/train_data22587.zip (stored 0%)\n",
            "  adding: training_datas/train_data29903.zip (stored 0%)\n",
            "  adding: training_datas/train_data16274.zip (stored 0%)\n",
            "  adding: training_datas/train_data20088.zip (stored 0%)\n",
            "  adding: training_datas/train_data11964.zip (stored 0%)\n",
            "  adding: training_datas/train_data21703.zip (stored 0%)\n",
            "  adding: training_datas/train_data28243.zip (stored 0%)\n",
            "  adding: training_datas/train_data29243.zip (stored 0%)\n",
            "  adding: training_datas/train_data1471.zip (stored 0%)\n",
            "  adding: training_datas/train_data4069.zip (stored 0%)\n",
            "  adding: training_datas/train_data14645.zip (stored 0%)\n",
            "  adding: training_datas/train_data19401.zip (stored 0%)\n",
            "  adding: training_datas/train_data1412.zip (stored 0%)\n",
            "  adding: training_datas/train_data733.zip (stored 0%)\n",
            "  adding: training_datas/train_data8216.zip (stored 0%)\n",
            "  adding: training_datas/train_data9441.zip (stored 0%)\n",
            "  adding: training_datas/train_data24112.zip (stored 0%)\n",
            "  adding: training_datas/train_data9243.zip (stored 0%)\n",
            "  adding: training_datas/train_data23679.zip (stored 0%)\n",
            "  adding: training_datas/train_data6886.zip (stored 0%)\n",
            "  adding: training_datas/train_data1736.zip (stored 0%)\n",
            "  adding: training_datas/train_data23512.zip (stored 0%)\n",
            "  adding: training_datas/train_data28681.zip (stored 0%)\n",
            "  adding: training_datas/train_data9153.zip (stored 0%)\n",
            "  adding: training_datas/train_data19318.zip (stored 0%)\n",
            "  adding: training_datas/train_data10398.zip (stored 0%)\n",
            "  adding: training_datas/train_data4236.zip (stored 0%)\n",
            "  adding: training_datas/train_data17155.zip (stored 0%)\n",
            "  adding: training_datas/train_data12872.zip (stored 0%)\n",
            "  adding: training_datas/train_data20628.zip (stored 0%)\n",
            "  adding: training_datas/train_data2880.zip (stored 0%)\n",
            "  adding: training_datas/train_data26625.zip (stored 0%)\n",
            "  adding: training_datas/train_data17163.zip (stored 0%)\n",
            "  adding: training_datas/train_data18586.zip (stored 0%)\n",
            "  adding: training_datas/train_data24060.zip (stored 0%)\n",
            "  adding: training_datas/train_data24420.zip (stored 0%)\n",
            "  adding: training_datas/train_data795.zip (stored 0%)\n",
            "  adding: training_datas/train_data20608.zip (stored 0%)\n",
            "  adding: training_datas/train_data20112.zip (stored 0%)\n",
            "  adding: training_datas/train_data13856.zip (stored 0%)\n",
            "  adding: training_datas/train_data10662.zip (stored 0%)\n",
            "  adding: training_datas/train_data19737.zip (stored 0%)\n",
            "  adding: training_datas/train_data28400.zip (stored 0%)\n",
            "  adding: training_datas/train_data3539.zip (stored 0%)\n",
            "  adding: training_datas/train_data10680.zip (stored 0%)\n",
            "  adding: training_datas/train_data24519.zip (stored 0%)\n",
            "  adding: training_datas/train_data18424.zip (stored 0%)\n",
            "  adding: training_datas/train_data457.zip (stored 0%)\n",
            "  adding: training_datas/train_data5959.zip (stored 0%)\n",
            "  adding: training_datas/train_data3024.zip (stored 0%)\n",
            "  adding: training_datas/train_data10364.zip (stored 0%)\n",
            "  adding: training_datas/train_data20491.zip (stored 0%)\n",
            "  adding: training_datas/train_data18545.zip (stored 0%)\n",
            "  adding: training_datas/train_data5511.zip (stored 0%)\n",
            "  adding: training_datas/train_data26514.zip (stored 0%)\n",
            "  adding: training_datas/train_data19534.zip (stored 0%)\n",
            "  adding: training_datas/train_data27184.zip (stored 0%)\n",
            "  adding: training_datas/train_data29318.zip (stored 0%)\n",
            "  adding: training_datas/train_data28506.zip (stored 0%)\n",
            "  adding: training_datas/train_data14553.zip (stored 0%)\n",
            "  adding: training_datas/train_data13580.zip (stored 0%)\n",
            "  adding: training_datas/train_data2009.zip (stored 0%)\n",
            "  adding: training_datas/train_data27602.zip (stored 0%)\n",
            "  adding: training_datas/train_data9701.zip (stored 0%)\n",
            "  adding: training_datas/train_data23697.zip (stored 0%)\n",
            "  adding: training_datas/train_data20878.zip (stored 0%)\n",
            "  adding: training_datas/train_data25464.zip (stored 0%)\n",
            "  adding: training_datas/train_data8566.zip (stored 0%)\n",
            "  adding: training_datas/train_data24754.zip (stored 0%)\n",
            "  adding: training_datas/train_data13211.zip (stored 0%)\n",
            "  adding: training_datas/train_data17605.zip (stored 0%)\n",
            "  adding: training_datas/train_data3920.zip (stored 0%)\n",
            "  adding: training_datas/train_data1883.zip (stored 0%)\n",
            "  adding: training_datas/train_data28833.zip (stored 0%)\n",
            "  adding: training_datas/train_data20421.zip (stored 0%)\n",
            "  adding: training_datas/train_data490.zip (stored 0%)\n",
            "  adding: training_datas/train_data9494.zip (stored 0%)\n",
            "  adding: training_datas/train_data3947.zip (stored 0%)\n",
            "  adding: training_datas/train_data8759.zip (stored 0%)\n",
            "  adding: training_datas/train_data10917.zip (stored 0%)\n",
            "  adding: training_datas/train_data11712.zip (stored 0%)\n",
            "  adding: training_datas/train_data22600.zip (stored 0%)\n",
            "  adding: training_datas/train_data11691.zip (stored 0%)\n",
            "  adding: training_datas/train_data20606.zip (stored 0%)\n",
            "  adding: training_datas/train_data28066.zip (stored 0%)\n",
            "  adding: training_datas/train_data30169.zip (stored 0%)\n",
            "  adding: training_datas/train_data14262.zip (stored 0%)\n",
            "  adding: training_datas/train_data4347.zip (stored 0%)\n",
            "  adding: training_datas/train_data6285.zip (stored 0%)\n",
            "  adding: training_datas/train_data15350.zip (stored 0%)\n",
            "  adding: training_datas/train_data25528.zip (stored 0%)\n",
            "  adding: training_datas/train_data17000.zip (stored 0%)\n",
            "  adding: training_datas/train_data22219.zip (stored 0%)\n",
            "  adding: training_datas/train_data2596.zip (stored 0%)\n",
            "  adding: training_datas/train_data29170.zip (stored 0%)\n",
            "  adding: training_datas/train_data26069.zip (stored 0%)\n",
            "  adding: training_datas/train_data1625.zip (stored 0%)\n",
            "  adding: training_datas/train_data1078.zip (stored 0%)\n",
            "  adding: training_datas/train_data15985.zip (stored 0%)\n",
            "  adding: training_datas/train_data24960.zip (stored 0%)\n",
            "  adding: training_datas/train_data20014.zip (stored 0%)\n",
            "  adding: training_datas/train_data20861.zip (stored 0%)\n",
            "  adding: training_datas/train_data3904.zip (stored 0%)\n",
            "  adding: training_datas/train_data17546.zip (stored 0%)\n",
            "  adding: training_datas/train_data2780.zip (stored 0%)\n",
            "  adding: training_datas/train_data6157.zip (stored 0%)\n",
            "  adding: training_datas/train_data2197.zip (stored 0%)\n",
            "  adding: training_datas/train_data2465.zip (stored 0%)\n",
            "  adding: training_datas/train_data28698.zip (stored 0%)\n",
            "  adding: training_datas/train_data18268.zip (stored 0%)\n",
            "  adding: training_datas/train_data25497.zip (stored 0%)\n",
            "  adding: training_datas/train_data17995.zip (stored 0%)\n",
            "  adding: training_datas/train_data17489.zip (stored 0%)\n",
            "  adding: training_datas/train_data3630.zip (stored 0%)\n",
            "  adding: training_datas/train_data28353.zip (stored 0%)\n",
            "  adding: training_datas/train_data2908.zip (stored 0%)\n",
            "  adding: training_datas/train_data5981.zip (stored 0%)\n",
            "  adding: training_datas/train_data5370.zip (stored 0%)\n",
            "  adding: training_datas/train_data13092.zip (stored 0%)\n",
            "  adding: training_datas/train_data28732.zip (stored 0%)\n",
            "  adding: training_datas/train_data3715.zip (stored 0%)\n",
            "  adding: training_datas/train_data3462.zip (stored 0%)\n",
            "  adding: training_datas/train_data20232.zip (stored 0%)\n",
            "  adding: training_datas/train_data17825.zip (stored 0%)\n",
            "  adding: training_datas/train_data21370.zip (stored 0%)\n",
            "  adding: training_datas/train_data19984.zip (stored 0%)\n",
            "  adding: training_datas/train_data11994.zip (stored 0%)\n",
            "  adding: training_datas/train_data11546.zip (stored 0%)\n",
            "  adding: training_datas/train_data22516.zip (stored 0%)\n",
            "  adding: training_datas/train_data24293.zip (stored 0%)\n",
            "  adding: training_datas/train_data1143.zip (stored 0%)\n",
            "  adding: training_datas/train_data20069.zip (stored 0%)\n",
            "  adding: training_datas/train_data6598.zip (stored 0%)\n",
            "  adding: training_datas/train_data17811.zip (stored 0%)\n",
            "  adding: training_datas/train_data12690.zip (stored 0%)\n",
            "  adding: training_datas/train_data6489.zip (stored 0%)\n",
            "  adding: training_datas/train_data6272.zip (stored 0%)\n",
            "  adding: training_datas/train_data19031.zip (stored 0%)\n",
            "  adding: training_datas/train_data18872.zip (stored 0%)\n",
            "  adding: training_datas/train_data27657.zip (stored 0%)\n",
            "  adding: training_datas/train_data6513.zip (stored 0%)\n",
            "  adding: training_datas/train_data28617.zip (stored 0%)\n",
            "  adding: training_datas/train_data20344.zip (stored 0%)\n",
            "  adding: training_datas/train_data23057.zip (stored 0%)\n",
            "  adding: training_datas/train_data24912.zip (stored 0%)\n",
            "  adding: training_datas/train_data28233.zip (stored 0%)\n",
            "  adding: training_datas/train_data5880.zip (stored 0%)\n",
            "  adding: training_datas/train_data1243.zip (stored 0%)\n",
            "  adding: training_datas/train_data9190.zip (stored 0%)\n",
            "  adding: training_datas/train_data9966.zip (stored 0%)\n",
            "  adding: training_datas/train_data18075.zip (stored 0%)\n",
            "  adding: training_datas/train_data15702.zip (stored 0%)\n",
            "  adding: training_datas/train_data23730.zip (stored 0%)\n",
            "  adding: training_datas/train_data25859.zip (stored 0%)\n",
            "  adding: training_datas/train_data13946.zip (stored 0%)\n",
            "  adding: training_datas/train_data21679.zip (stored 0%)\n",
            "  adding: training_datas/train_data25656.zip (stored 0%)\n",
            "  adding: training_datas/train_data21180.zip (stored 0%)\n",
            "  adding: training_datas/train_data30176.zip (stored 0%)\n",
            "  adding: training_datas/train_data3202.zip (stored 0%)\n",
            "  adding: training_datas/train_data4414.zip (stored 0%)\n",
            "  adding: training_datas/train_data11031.zip (stored 0%)\n",
            "  adding: training_datas/train_data30389.zip (stored 0%)\n",
            "  adding: training_datas/train_data4104.zip (stored 0%)\n",
            "  adding: training_datas/train_data24521.zip (stored 0%)\n",
            "  adding: training_datas/train_data24045.zip (stored 0%)\n",
            "  adding: training_datas/train_data6366.zip (stored 0%)\n",
            "  adding: training_datas/train_data16972.zip (stored 0%)\n",
            "  adding: training_datas/train_data8071.zip (stored 0%)\n",
            "  adding: training_datas/train_data10370.zip (stored 0%)\n",
            "  adding: training_datas/train_data25552.zip (stored 0%)\n",
            "  adding: training_datas/train_data16762.zip (stored 0%)\n",
            "  adding: training_datas/train_data16899.zip (stored 0%)\n",
            "  adding: training_datas/train_data1502.zip (stored 0%)\n",
            "  adding: training_datas/train_data22330.zip (stored 0%)\n",
            "  adding: training_datas/train_data17873.zip (stored 0%)\n",
            "  adding: training_datas/train_data4739.zip (stored 0%)\n",
            "  adding: training_datas/train_data18463.zip (stored 0%)\n",
            "  adding: training_datas/train_data6946.zip (stored 0%)\n",
            "  adding: training_datas/train_data8614.zip (stored 0%)\n",
            "  adding: training_datas/train_data1682.zip (stored 0%)\n",
            "  adding: training_datas/train_data16244.zip (stored 0%)\n",
            "  adding: training_datas/train_data19381.zip (stored 0%)\n",
            "  adding: training_datas/train_data964.zip (stored 0%)\n",
            "  adding: training_datas/train_data23112.zip (stored 0%)\n",
            "  adding: training_datas/train_data8879.zip (stored 0%)\n",
            "  adding: training_datas/train_data12879.zip (stored 0%)\n",
            "  adding: training_datas/train_data12591.zip (stored 0%)\n",
            "  adding: training_datas/train_data15990.zip (stored 0%)\n",
            "  adding: training_datas/train_data7002.zip (stored 0%)\n",
            "  adding: training_datas/train_data10552.zip (stored 0%)\n",
            "  adding: training_datas/train_data27496.zip (stored 0%)\n",
            "  adding: training_datas/train_data1784.zip (stored 0%)\n",
            "  adding: training_datas/train_data7385.zip (stored 0%)\n",
            "  adding: training_datas/train_data27322.zip (stored 0%)\n",
            "  adding: training_datas/train_data4368.zip (stored 0%)\n",
            "  adding: training_datas/train_data2309.zip (stored 0%)\n",
            "  adding: training_datas/train_data28303.zip (stored 0%)\n",
            "  adding: training_datas/train_data28957.zip (stored 0%)\n",
            "  adding: training_datas/train_data19681.zip (stored 0%)\n",
            "  adding: training_datas/train_data13156.zip (stored 0%)\n",
            "  adding: training_datas/train_data18709.zip (stored 0%)\n",
            "  adding: training_datas/train_data11835.zip (stored 0%)\n",
            "  adding: training_datas/train_data14941.zip (stored 0%)\n",
            "  adding: training_datas/train_data11241.zip (stored 0%)\n",
            "  adding: training_datas/train_data23076.zip (stored 0%)\n",
            "  adding: training_datas/train_data14164.zip (stored 0%)\n",
            "  adding: training_datas/train_data15140.zip (stored 0%)\n",
            "  adding: training_datas/train_data11970.zip (stored 0%)\n",
            "  adding: training_datas/train_data21416.zip (stored 0%)\n",
            "  adding: training_datas/train_data747.zip (stored 0%)\n",
            "  adding: training_datas/train_data27157.zip (stored 0%)\n",
            "  adding: training_datas/train_data25640.zip (stored 0%)\n",
            "  adding: training_datas/train_data29813.zip (stored 0%)\n",
            "  adding: training_datas/train_data18592.zip (stored 0%)\n",
            "  adding: training_datas/train_data3777.zip (stored 0%)\n",
            "  adding: training_datas/train_data21175.zip (stored 0%)\n",
            "  adding: training_datas/train_data5521.zip (stored 0%)\n",
            "  adding: training_datas/train_data15441.zip (stored 0%)\n",
            "  adding: training_datas/train_data6295.zip (stored 0%)\n",
            "  adding: training_datas/train_data30434.zip (stored 0%)\n",
            "  adding: training_datas/train_data4323.zip (stored 0%)\n",
            "  adding: training_datas/train_data15589.zip (stored 0%)\n",
            "  adding: training_datas/train_data8742.zip (stored 0%)\n",
            "  adding: training_datas/train_data6476.zip (stored 0%)\n",
            "  adding: training_datas/train_data816.zip (stored 0%)\n",
            "  adding: training_datas/train_data29176.zip (stored 0%)\n",
            "  adding: training_datas/train_data21971.zip (stored 0%)\n",
            "  adding: training_datas/train_data6919.zip (stored 0%)\n",
            "  adding: training_datas/train_data13844.zip (stored 0%)\n",
            "  adding: training_datas/train_data10642.zip (stored 0%)\n",
            "  adding: training_datas/train_data17585.zip (stored 0%)\n",
            "  adding: training_datas/train_data4544.zip (stored 0%)\n",
            "  adding: training_datas/train_data6517.zip (stored 0%)\n",
            "  adding: training_datas/train_data19272.zip (stored 0%)\n",
            "  adding: training_datas/train_data14978.zip (stored 0%)\n",
            "  adding: training_datas/train_data6663.zip (stored 0%)\n",
            "  adding: training_datas/train_data1882.zip (stored 0%)\n",
            "  adding: training_datas/train_data23778.zip (stored 0%)\n",
            "  adding: training_datas/train_data18242.zip (stored 0%)\n",
            "  adding: training_datas/train_data17856.zip (stored 0%)\n",
            "  adding: training_datas/train_data19249.zip (stored 0%)\n",
            "  adding: training_datas/train_data22629.zip (stored 0%)\n",
            "  adding: training_datas/train_data29037.zip (stored 0%)\n",
            "  adding: training_datas/train_data13485.zip (stored 0%)\n",
            "  adding: training_datas/train_data22874.zip (stored 0%)\n",
            "  adding: training_datas/train_data10386.zip (stored 0%)\n",
            "  adding: training_datas/train_data22887.zip (stored 0%)\n",
            "  adding: training_datas/train_data21348.zip (stored 0%)\n",
            "  adding: training_datas/train_data226.zip (stored 0%)\n",
            "  adding: training_datas/train_data22477.zip (stored 0%)\n",
            "  adding: training_datas/train_data16996.zip (stored 0%)\n",
            "  adding: training_datas/train_data1970.zip (stored 0%)\n",
            "  adding: training_datas/train_data16655.zip (stored 0%)\n",
            "  adding: training_datas/train_data6667.zip (stored 0%)\n",
            "  adding: training_datas/train_data26306.zip (stored 0%)\n",
            "  adding: training_datas/train_data20759.zip (stored 0%)\n",
            "  adding: training_datas/train_data9208.zip (stored 0%)\n",
            "  adding: training_datas/train_data29373.zip (stored 0%)\n",
            "  adding: training_datas/train_data6711.zip (stored 0%)\n",
            "  adding: training_datas/train_data21518.zip (stored 0%)\n",
            "  adding: training_datas/train_data18792.zip (stored 0%)\n",
            "  adding: training_datas/train_data18938.zip (stored 0%)\n",
            "  adding: training_datas/train_data1206.zip (stored 0%)\n",
            "  adding: training_datas/train_data10012.zip (stored 0%)\n",
            "  adding: training_datas/train_data22085.zip (stored 0%)\n",
            "  adding: training_datas/train_data9762.zip (stored 0%)\n",
            "  adding: training_datas/train_data18837.zip (stored 0%)\n",
            "  adding: training_datas/train_data3746.zip (stored 0%)\n",
            "  adding: training_datas/train_data27051.zip (stored 0%)\n",
            "  adding: training_datas/train_data7196.zip (stored 0%)\n",
            "  adding: training_datas/train_data8984.zip (stored 0%)\n",
            "  adding: training_datas/train_data23498.zip (stored 0%)\n",
            "  adding: training_datas/train_data380.zip (stored 0%)\n",
            "  adding: training_datas/train_data23041.zip (stored 0%)\n",
            "  adding: training_datas/train_data28978.zip (stored 0%)\n",
            "  adding: training_datas/train_data22333.zip (stored 0%)\n",
            "  adding: training_datas/train_data1163.zip (stored 0%)\n",
            "  adding: training_datas/train_data8702.zip (stored 0%)\n",
            "  adding: training_datas/train_data11151.zip (stored 0%)\n",
            "  adding: training_datas/train_data11792.zip (stored 0%)\n",
            "  adding: training_datas/train_data28760.zip (stored 0%)\n",
            "  adding: training_datas/train_data21617.zip (stored 0%)\n",
            "  adding: training_datas/train_data22029.zip (stored 0%)\n",
            "  adding: training_datas/train_data27839.zip (stored 0%)\n",
            "  adding: training_datas/train_data9549.zip (stored 0%)\n",
            "  adding: training_datas/train_data19846.zip (stored 0%)\n",
            "  adding: training_datas/train_data20814.zip (stored 0%)\n",
            "  adding: training_datas/train_data21600.zip (stored 0%)\n",
            "  adding: training_datas/train_data7668.zip (stored 0%)\n",
            "  adding: training_datas/train_data19812.zip (stored 0%)\n",
            "  adding: training_datas/train_data14278.zip (stored 0%)\n",
            "  adding: training_datas/train_data1841.zip (stored 0%)\n",
            "  adding: training_datas/train_data3307.zip (stored 0%)\n",
            "  adding: training_datas/train_data21024.zip (stored 0%)\n",
            "  adding: training_datas/train_data26468.zip (stored 0%)\n",
            "  adding: training_datas/train_data19862.zip (stored 0%)\n",
            "  adding: training_datas/train_data10783.zip (stored 0%)\n",
            "  adding: training_datas/train_data13271.zip (stored 0%)\n",
            "  adding: training_datas/train_data20481.zip (stored 0%)\n",
            "  adding: training_datas/train_data22469.zip (stored 0%)\n",
            "  adding: training_datas/train_data12174.zip (stored 0%)\n",
            "  adding: training_datas/train_data14956.zip (stored 0%)\n",
            "  adding: training_datas/train_data2556.zip (stored 0%)\n",
            "  adding: training_datas/train_data18668.zip (stored 0%)\n",
            "  adding: training_datas/train_data14800.zip (stored 0%)\n",
            "  adding: training_datas/train_data15742.zip (stored 0%)\n",
            "  adding: training_datas/train_data9806.zip (stored 0%)\n",
            "  adding: training_datas/train_data12975.zip (stored 0%)\n",
            "  adding: training_datas/train_data21612.zip (stored 0%)\n",
            "  adding: training_datas/train_data11910.zip (stored 0%)\n",
            "  adding: training_datas/train_data24454.zip (stored 0%)\n",
            "  adding: training_datas/train_data6997.zip (stored 0%)\n",
            "  adding: training_datas/train_data19595.zip (stored 0%)\n",
            "  adding: training_datas/train_data6925.zip (stored 0%)\n",
            "  adding: training_datas/train_data10452.zip (stored 0%)\n",
            "  adding: training_datas/train_data15787.zip (stored 0%)\n",
            "  adding: training_datas/train_data23588.zip (stored 0%)\n",
            "  adding: training_datas/train_data16384.zip (stored 0%)\n",
            "  adding: training_datas/train_data6660.zip (stored 0%)\n",
            "  adding: training_datas/train_data24806.zip (stored 0%)\n",
            "  adding: training_datas/train_data18904.zip (stored 0%)\n",
            "  adding: training_datas/train_data3912.zip (stored 0%)\n",
            "  adding: training_datas/train_data14385.zip (stored 0%)\n",
            "  adding: training_datas/train_data21466.zip (stored 0%)\n",
            "  adding: training_datas/train_data13883.zip (stored 0%)\n",
            "  adding: training_datas/train_data20775.zip (stored 0%)\n",
            "  adding: training_datas/train_data20582.zip (stored 0%)\n",
            "  adding: training_datas/train_data27125.zip (stored 0%)\n",
            "  adding: training_datas/train_data10118.zip (stored 0%)\n",
            "  adding: training_datas/train_data4207.zip (stored 0%)\n",
            "  adding: training_datas/train_data24434.zip (stored 0%)\n",
            "  adding: training_datas/train_data7938.zip (stored 0%)\n",
            "  adding: training_datas/train_data11492.zip (stored 0%)\n",
            "  adding: training_datas/train_data28721.zip (stored 0%)\n",
            "  adding: training_datas/train_data24006.zip (stored 0%)\n",
            "  adding: training_datas/train_data12447.zip (stored 0%)\n",
            "  adding: training_datas/train_data29653.zip (stored 0%)\n",
            "  adding: training_datas/train_data27854.zip (stored 0%)\n",
            "  adding: training_datas/train_data6242.zip (stored 0%)\n",
            "  adding: training_datas/train_data15825.zip (stored 0%)\n",
            "  adding: training_datas/train_data18500.zip (stored 0%)\n",
            "  adding: training_datas/train_data3774.zip (stored 0%)\n",
            "  adding: training_datas/train_data14742.zip (stored 0%)\n",
            "  adding: training_datas/train_data10598.zip (stored 0%)\n",
            "  adding: training_datas/train_data25910.zip (stored 0%)\n",
            "  adding: training_datas/train_data27508.zip (stored 0%)\n",
            "  adding: training_datas/train_data28083.zip (stored 0%)\n",
            "  adding: training_datas/train_data27241.zip (stored 0%)\n",
            "  adding: training_datas/train_data9241.zip (stored 0%)\n",
            "  adding: training_datas/train_data22902.zip (stored 0%)\n",
            "  adding: training_datas/train_data433.zip (stored 0%)\n",
            "  adding: training_datas/train_data4071.zip (stored 0%)\n",
            "  adding: training_datas/train_data23538.zip (stored 0%)\n",
            "  adding: training_datas/train_data10766.zip (stored 0%)\n",
            "  adding: training_datas/train_data8041.zip (stored 0%)\n",
            "  adding: training_datas/train_data20294.zip (stored 0%)\n",
            "  adding: training_datas/train_data20734.zip (stored 0%)\n",
            "  adding: training_datas/train_data21133.zip (stored 0%)\n",
            "  adding: training_datas/train_data25766.zip (stored 0%)\n",
            "  adding: training_datas/train_data1735.zip (stored 0%)\n",
            "  adding: training_datas/train_data1339.zip (stored 0%)\n",
            "  adding: training_datas/train_data20841.zip (stored 0%)\n",
            "  adding: training_datas/train_data9380.zip (stored 0%)\n",
            "  adding: training_datas/train_data14860.zip (stored 0%)\n",
            "  adding: training_datas/train_data12390.zip (stored 0%)\n",
            "  adding: training_datas/train_data28584.zip (stored 0%)\n",
            "  adding: training_datas/train_data13671.zip (stored 0%)\n",
            "  adding: training_datas/train_data22354.zip (stored 0%)\n",
            "  adding: training_datas/train_data26580.zip (stored 0%)\n",
            "  adding: training_datas/train_data5994.zip (stored 0%)\n",
            "  adding: training_datas/train_data5763.zip (stored 0%)\n",
            "  adding: training_datas/train_data15488.zip (stored 0%)\n",
            "  adding: training_datas/train_data2522.zip (stored 0%)\n",
            "  adding: training_datas/train_data11038.zip (stored 0%)\n",
            "  adding: training_datas/train_data29770.zip (stored 0%)\n",
            "  adding: training_datas/train_data2299.zip (stored 0%)\n",
            "  adding: training_datas/train_data24304.zip (stored 0%)\n",
            "  adding: training_datas/train_data17152.zip (stored 0%)\n",
            "  adding: training_datas/train_data16376.zip (stored 0%)\n",
            "  adding: training_datas/train_data6385.zip (stored 0%)\n",
            "  adding: training_datas/train_data20347.zip (stored 0%)\n",
            "  adding: training_datas/train_data25333.zip (stored 0%)\n",
            "  adding: training_datas/train_data16808.zip (stored 0%)\n",
            "  adding: training_datas/train_data28497.zip (stored 0%)\n",
            "  adding: training_datas/train_data17154.zip (stored 0%)\n",
            "  adding: training_datas/train_data12396.zip (stored 0%)\n",
            "  adding: training_datas/train_data28214.zip (stored 0%)\n",
            "  adding: training_datas/train_data9656.zip (stored 0%)\n",
            "  adding: training_datas/train_data3481.zip (stored 0%)\n",
            "  adding: training_datas/train_data4868.zip (stored 0%)\n",
            "  adding: training_datas/train_data16121.zip (stored 0%)\n",
            "  adding: training_datas/train_data10615.zip (stored 0%)\n",
            "  adding: training_datas/train_data10053.zip (stored 0%)\n",
            "  adding: training_datas/train_data30303.zip (stored 0%)\n",
            "  adding: training_datas/train_data9798.zip (stored 0%)\n",
            "  adding: training_datas/train_data5935.zip (stored 0%)\n",
            "  adding: training_datas/train_data14996.zip (stored 0%)\n",
            "  adding: training_datas/train_data26800.zip (stored 0%)\n",
            "  adding: training_datas/train_data10036.zip (stored 0%)\n",
            "  adding: training_datas/train_data10969.zip (stored 0%)\n",
            "  adding: training_datas/train_data30432.zip (stored 0%)\n",
            "  adding: training_datas/train_data11119.zip (stored 0%)\n",
            "  adding: training_datas/train_data27477.zip (stored 0%)\n",
            "  adding: training_datas/train_data1961.zip (stored 0%)\n",
            "  adding: training_datas/train_data15121.zip (stored 0%)\n",
            "  adding: training_datas/train_data5578.zip (stored 0%)\n",
            "  adding: training_datas/train_data27791.zip (stored 0%)\n",
            "  adding: training_datas/train_data20795.zip (stored 0%)\n",
            "  adding: training_datas/train_data22895.zip (stored 0%)\n",
            "  adding: training_datas/train_data22729.zip (stored 0%)\n",
            "  adding: training_datas/train_data8091.zip (stored 0%)\n",
            "  adding: training_datas/train_data8303.zip (stored 0%)\n",
            "  adding: training_datas/train_data14072.zip (stored 0%)\n",
            "  adding: training_datas/train_data28507.zip (stored 0%)\n",
            "  adding: training_datas/train_data28791.zip (stored 0%)\n",
            "  adding: training_datas/train_data17542.zip (stored 0%)\n",
            "  adding: training_datas/train_data30192.zip (stored 0%)\n",
            "  adding: training_datas/train_data5610.zip (stored 0%)\n",
            "  adding: training_datas/train_data11367.zip (stored 0%)\n",
            "  adding: training_datas/train_data13130.zip (stored 0%)\n",
            "  adding: training_datas/train_data26407.zip (stored 0%)\n",
            "  adding: training_datas/train_data17441.zip (stored 0%)\n",
            "  adding: training_datas/train_data25176.zip (stored 0%)\n",
            "  adding: training_datas/train_data20359.zip (stored 0%)\n",
            "  adding: training_datas/train_data13587.zip (stored 0%)\n",
            "  adding: training_datas/train_data29225.zip (stored 0%)\n",
            "  adding: training_datas/train_data965.zip (stored 0%)\n",
            "  adding: training_datas/train_data19195.zip (stored 0%)\n",
            "  adding: training_datas/train_data16680.zip (stored 0%)\n",
            "  adding: training_datas/train_data14716.zip (stored 0%)\n",
            "  adding: training_datas/train_data14500.zip (stored 0%)\n",
            "  adding: training_datas/train_data11945.zip (stored 0%)\n",
            "  adding: training_datas/train_data11185.zip (stored 0%)\n",
            "  adding: training_datas/train_data15801.zip (stored 0%)\n",
            "  adding: training_datas/train_data20106.zip (stored 0%)\n",
            "  adding: training_datas/train_data4191.zip (stored 0%)\n",
            "  adding: training_datas/train_data17190.zip (stored 0%)\n",
            "  adding: training_datas/train_data3541.zip (stored 0%)\n",
            "  adding: training_datas/train_data16096.zip (stored 0%)\n",
            "  adding: training_datas/train_data10509.zip (stored 0%)\n",
            "  adding: training_datas/train_data24881.zip (stored 0%)\n",
            "  adding: training_datas/train_data15762.zip (stored 0%)\n",
            "  adding: training_datas/train_data291.zip (stored 0%)\n",
            "  adding: training_datas/train_data24998.zip (stored 0%)\n",
            "  adding: training_datas/train_data11823.zip (stored 0%)\n",
            "  adding: training_datas/train_data8267.zip (stored 0%)\n",
            "  adding: training_datas/train_data18932.zip (stored 0%)\n",
            "  adding: training_datas/train_data18573.zip (stored 0%)\n",
            "  adding: training_datas/train_data13311.zip (stored 0%)\n",
            "  adding: training_datas/train_data19581.zip (stored 0%)\n",
            "  adding: training_datas/train_data3163.zip (stored 0%)\n",
            "  adding: training_datas/train_data7790.zip (stored 0%)\n",
            "  adding: training_datas/train_data8364.zip (stored 0%)\n",
            "  adding: training_datas/train_data27372.zip (stored 0%)\n",
            "  adding: training_datas/train_data19438.zip (stored 0%)\n",
            "  adding: training_datas/train_data11071.zip (stored 0%)\n",
            "  adding: training_datas/train_data28919.zip (stored 0%)\n",
            "  adding: training_datas/train_data19513.zip (stored 0%)\n",
            "  adding: training_datas/train_data13076.zip (stored 0%)\n",
            "  adding: training_datas/train_data22574.zip (stored 0%)\n",
            "  adding: training_datas/train_data10893.zip (stored 0%)\n",
            "  adding: training_datas/train_data1701.zip (stored 0%)\n",
            "  adding: training_datas/train_data25975.zip (stored 0%)\n",
            "  adding: training_datas/train_data1072.zip (stored 0%)\n",
            "  adding: training_datas/train_data28947.zip (stored 0%)\n",
            "  adding: training_datas/train_data22442.zip (stored 0%)\n",
            "  adding: training_datas/train_data28366.zip (stored 0%)\n",
            "  adding: training_datas/train_data10595.zip (stored 0%)\n",
            "  adding: training_datas/train_data27445.zip (stored 0%)\n",
            "  adding: training_datas/train_data12773.zip (stored 0%)\n",
            "  adding: training_datas/train_data9369.zip (stored 0%)\n",
            "  adding: training_datas/train_data11143.zip (stored 0%)\n",
            "  adding: training_datas/train_data871.zip (stored 0%)\n",
            "  adding: training_datas/train_data2164.zip (stored 0%)\n",
            "  adding: training_datas/train_data25517.zip (stored 0%)\n",
            "  adding: training_datas/train_data25034.zip (stored 0%)\n",
            "  adding: training_datas/train_data3683.zip (stored 0%)\n",
            "  adding: training_datas/train_data1211.zip (stored 0%)\n",
            "  adding: training_datas/train_data21776.zip (stored 0%)\n",
            "  adding: training_datas/train_data13473.zip (stored 0%)\n",
            "  adding: training_datas/train_data28920.zip (stored 0%)\n",
            "  adding: training_datas/train_data1111.zip (stored 0%)\n",
            "  adding: training_datas/train_data15179.zip (stored 0%)\n",
            "  adding: training_datas/train_data27505.zip (stored 0%)\n",
            "  adding: training_datas/train_data2679.zip (stored 0%)\n",
            "  adding: training_datas/train_data3325.zip (stored 0%)\n",
            "  adding: training_datas/train_data13060.zip (stored 0%)\n",
            "  adding: training_datas/train_data26905.zip (stored 0%)\n",
            "  adding: training_datas/train_data9316.zip (stored 0%)\n",
            "  adding: training_datas/train_data14350.zip (stored 0%)\n",
            "  adding: training_datas/train_data29856.zip (stored 0%)\n",
            "  adding: training_datas/train_data26916.zip (stored 0%)\n",
            "  adding: training_datas/train_data18655.zip (stored 0%)\n",
            "  adding: training_datas/train_data17322.zip (stored 0%)\n",
            "  adding: training_datas/train_data11509.zip (stored 0%)\n",
            "  adding: training_datas/train_data1540.zip (stored 0%)\n",
            "  adding: training_datas/train_data25792.zip (stored 0%)\n",
            "  adding: training_datas/train_data16755.zip (stored 0%)\n",
            "  adding: training_datas/train_data19542.zip (stored 0%)\n",
            "  adding: training_datas/train_data24156.zip (stored 0%)\n",
            "  adding: training_datas/train_data2057.zip (stored 0%)\n",
            "  adding: training_datas/train_data2774.zip (stored 0%)\n",
            "  adding: training_datas/train_data26412.zip (stored 0%)\n",
            "  adding: training_datas/train_data28368.zip (stored 0%)\n",
            "  adding: training_datas/train_data13453.zip (stored 0%)\n",
            "  adding: training_datas/train_data18714.zip (stored 0%)\n",
            "  adding: training_datas/train_data23477.zip (stored 0%)\n",
            "  adding: training_datas/train_data14489.zip (stored 0%)\n",
            "  adding: training_datas/train_data24039.zip (stored 0%)\n",
            "  adding: training_datas/train_data812.zip (stored 0%)\n",
            "  adding: training_datas/train_data18686.zip (stored 0%)\n",
            "  adding: training_datas/train_data25298.zip (stored 0%)\n",
            "  adding: training_datas/train_data29266.zip (stored 0%)\n",
            "  adding: training_datas/train_data13543.zip (stored 0%)\n",
            "  adding: training_datas/train_data20414.zip (stored 0%)\n",
            "  adding: training_datas/train_data3702.zip (stored 0%)\n",
            "  adding: training_datas/train_data4459.zip (stored 0%)\n",
            "  adding: training_datas/train_data22151.zip (stored 0%)\n",
            "  adding: training_datas/train_data14224.zip (stored 0%)\n",
            "  adding: training_datas/train_data11486.zip (stored 0%)\n",
            "  adding: training_datas/train_data1787.zip (stored 0%)\n",
            "  adding: training_datas/train_data11391.zip (stored 0%)\n",
            "  adding: training_datas/train_data23914.zip (stored 0%)\n",
            "  adding: training_datas/train_data4385.zip (stored 0%)\n",
            "  adding: training_datas/train_data10472.zip (stored 0%)\n",
            "  adding: training_datas/train_data10434.zip (stored 0%)\n",
            "  adding: training_datas/train_data10454.zip (stored 0%)\n",
            "  adding: training_datas/train_data19285.zip (stored 0%)\n",
            "  adding: training_datas/train_data26702.zip (stored 0%)\n",
            "  adding: training_datas/train_data17606.zip (stored 0%)\n",
            "  adding: training_datas/train_data27957.zip (stored 0%)\n",
            "  adding: training_datas/train_data353.zip (stored 0%)\n",
            "  adding: training_datas/train_data17302.zip (stored 0%)\n",
            "  adding: training_datas/train_data6725.zip (stored 0%)\n",
            "  adding: training_datas/train_data25499.zip (stored 0%)\n",
            "  adding: training_datas/train_data12320.zip (stored 0%)\n",
            "  adding: training_datas/train_data14727.zip (stored 0%)\n",
            "  adding: training_datas/train_data5984.zip (stored 0%)\n",
            "  adding: training_datas/train_data10901.zip (stored 0%)\n",
            "  adding: training_datas/train_data22325.zip (stored 0%)\n",
            "  adding: training_datas/train_data2000.zip (stored 0%)\n",
            "  adding: training_datas/train_data21264.zip (stored 0%)\n",
            "  adding: training_datas/train_data1830.zip (stored 0%)\n",
            "  adding: training_datas/train_data1809.zip (stored 0%)\n",
            "  adding: training_datas/train_data29135.zip (stored 0%)\n",
            "  adding: training_datas/train_data7765.zip (stored 0%)\n",
            "  adding: training_datas/train_data13032.zip (stored 0%)\n",
            "  adding: training_datas/train_data19625.zip (stored 0%)\n",
            "  adding: training_datas/train_data17627.zip (stored 0%)\n",
            "  adding: training_datas/train_data20220.zip (stored 0%)\n",
            "  adding: training_datas/train_data24661.zip (stored 0%)\n",
            "  adding: training_datas/train_data23437.zip (stored 0%)\n",
            "  adding: training_datas/train_data12102.zip (stored 0%)\n",
            "  adding: training_datas/train_data4256.zip (stored 0%)\n",
            "  adding: training_datas/train_data488.zip (stored 0%)\n",
            "  adding: training_datas/train_data12063.zip (stored 0%)\n",
            "  adding: training_datas/train_data18469.zip (stored 0%)\n",
            "  adding: training_datas/train_data26466.zip (stored 0%)\n",
            "  adding: training_datas/train_data18472.zip (stored 0%)\n",
            "  adding: training_datas/train_data10609.zip (stored 0%)\n",
            "  adding: training_datas/train_data23928.zip (stored 0%)\n",
            "  adding: training_datas/train_data28595.zip (stored 0%)\n",
            "  adding: training_datas/train_data6134.zip (stored 0%)\n",
            "  adding: training_datas/train_data29553.zip (stored 0%)\n",
            "  adding: training_datas/train_data10007.zip (stored 0%)\n",
            "  adding: training_datas/train_data24943.zip (stored 0%)\n",
            "  adding: training_datas/train_data7218.zip (stored 0%)\n",
            "  adding: training_datas/train_data4012.zip (stored 0%)\n",
            "  adding: training_datas/train_data9402.zip (stored 0%)\n",
            "  adding: training_datas/train_data21464.zip (stored 0%)\n",
            "  adding: training_datas/train_data12010.zip (stored 0%)\n",
            "  adding: training_datas/train_data14139.zip (stored 0%)\n",
            "  adding: training_datas/train_data20976.zip (stored 0%)\n",
            "  adding: training_datas/train_data5365.zip (stored 0%)\n",
            "  adding: training_datas/train_data11536.zip (stored 0%)\n",
            "  adding: training_datas/train_data7944.zip (stored 0%)\n",
            "  adding: training_datas/train_data28287.zip (stored 0%)\n",
            "  adding: training_datas/train_data9284.zip (stored 0%)\n",
            "  adding: training_datas/train_data14097.zip (stored 0%)\n",
            "  adding: training_datas/train_data13849.zip (stored 0%)\n",
            "  adding: training_datas/train_data3806.zip (stored 0%)\n",
            "  adding: training_datas/train_data18328.zip (stored 0%)\n",
            "  adding: training_datas/train_data6127.zip (stored 0%)\n",
            "  adding: training_datas/train_data12302.zip (stored 0%)\n",
            "  adding: training_datas/train_data24407.zip (stored 0%)\n",
            "  adding: training_datas/train_data29826.zip (stored 0%)\n",
            "  adding: training_datas/train_data20739.zip (stored 0%)\n",
            "  adding: training_datas/train_data9694.zip (stored 0%)\n",
            "  adding: training_datas/train_data1410.zip (stored 0%)\n",
            "  adding: training_datas/train_data16814.zip (stored 0%)\n",
            "  adding: training_datas/train_data17262.zip (stored 0%)\n",
            "  adding: training_datas/train_data28890.zip (stored 0%)\n",
            "  adding: training_datas/train_data1835.zip (stored 0%)\n",
            "  adding: training_datas/train_data20629.zip (stored 0%)\n",
            "  adding: training_datas/train_data10929.zip (stored 0%)\n",
            "  adding: training_datas/train_data7597.zip (stored 0%)\n",
            "  adding: training_datas/train_data23525.zip (stored 0%)\n",
            "  adding: training_datas/train_data24021.zip (stored 0%)\n",
            "  adding: training_datas/train_data13492.zip (stored 0%)\n",
            "  adding: training_datas/train_data2115.zip (stored 0%)\n",
            "  adding: training_datas/train_data9182.zip (stored 0%)\n",
            "  adding: training_datas/train_data24804.zip (stored 0%)\n",
            "  adding: training_datas/train_data9085.zip (stored 0%)\n",
            "  adding: training_datas/train_data22438.zip (stored 0%)\n",
            "  adding: training_datas/train_data29627.zip (stored 0%)\n",
            "  adding: training_datas/train_data2976.zip (stored 0%)\n",
            "  adding: training_datas/train_data9475.zip (stored 0%)\n",
            "  adding: training_datas/train_data7219.zip (stored 0%)\n",
            "  adding: training_datas/train_data16334.zip (stored 0%)\n",
            "  adding: training_datas/train_data13023.zip (stored 0%)\n",
            "  adding: training_datas/train_data26632.zip (stored 0%)\n",
            "  adding: training_datas/train_data28012.zip (stored 0%)\n",
            "  adding: training_datas/train_data1306.zip (stored 0%)\n",
            "  adding: training_datas/train_data28522.zip (stored 0%)\n",
            "  adding: training_datas/train_data8238.zip (stored 0%)\n",
            "  adding: training_datas/train_data16008.zip (stored 0%)\n",
            "  adding: training_datas/train_data2413.zip (stored 0%)\n",
            "  adding: training_datas/train_data16667.zip (stored 0%)\n",
            "  adding: training_datas/train_data12886.zip (stored 0%)\n",
            "  adding: training_datas/train_data13210.zip (stored 0%)\n",
            "  adding: training_datas/train_data9265.zip (stored 0%)\n",
            "  adding: training_datas/train_data8885.zip (stored 0%)\n",
            "  adding: training_datas/train_data13134.zip (stored 0%)\n",
            "  adding: training_datas/train_data8715.zip (stored 0%)\n",
            "  adding: training_datas/train_data19717.zip (stored 0%)\n",
            "  adding: training_datas/train_data28051.zip (stored 0%)\n",
            "  adding: training_datas/train_data2237.zip (stored 0%)\n",
            "  adding: training_datas/train_data21741.zip (stored 0%)\n",
            "  adding: training_datas/train_data9112.zip (stored 0%)\n",
            "  adding: training_datas/train_data9016.zip (stored 0%)\n",
            "  adding: training_datas/train_data21110.zip (stored 0%)\n",
            "  adding: training_datas/train_data28622.zip (stored 0%)\n",
            "  adding: training_datas/train_data17328.zip (stored 0%)\n",
            "  adding: training_datas/train_data5267.zip (stored 0%)\n",
            "  adding: training_datas/train_data9488.zip (stored 0%)\n",
            "  adding: training_datas/train_data8314.zip (stored 0%)\n",
            "  adding: training_datas/train_data17287.zip (stored 0%)\n",
            "  adding: training_datas/train_data23393.zip (stored 0%)\n",
            "  adding: training_datas/train_data4685.zip (stored 0%)\n",
            "  adding: training_datas/train_data16210.zip (stored 0%)\n",
            "  adding: training_datas/train_data21665.zip (stored 0%)\n",
            "  adding: training_datas/train_data6627.zip (stored 0%)\n",
            "  adding: training_datas/train_data9132.zip (stored 0%)\n",
            "  adding: training_datas/train_data8919.zip (stored 0%)\n",
            "  adding: training_datas/train_data51.zip (stored 0%)\n",
            "  adding: training_datas/train_data7353.zip (stored 0%)\n",
            "  adding: training_datas/train_data27753.zip (stored 0%)\n",
            "  adding: training_datas/train_data14255.zip (stored 0%)\n",
            "  adding: training_datas/train_data3837.zip (stored 0%)\n",
            "  adding: training_datas/train_data25302.zip (stored 0%)\n",
            "  adding: training_datas/train_data3862.zip (stored 0%)\n",
            "  adding: training_datas/train_data24570.zip (stored 0%)\n",
            "  adding: training_datas/train_data27914.zip (stored 0%)\n",
            "  adding: training_datas/train_data13895.zip (stored 0%)\n",
            "  adding: training_datas/train_data22311.zip (stored 0%)\n",
            "  adding: training_datas/train_data28321.zip (stored 0%)\n",
            "  adding: training_datas/train_data19526.zip (stored 0%)\n",
            "  adding: training_datas/train_data12266.zip (stored 0%)\n",
            "  adding: training_datas/train_data18359.zip (stored 0%)\n",
            "  adding: training_datas/train_data1495.zip (stored 0%)\n",
            "  adding: training_datas/train_data3431.zip (stored 0%)\n",
            "  adding: training_datas/train_data17737.zip (stored 0%)\n",
            "  adding: training_datas/train_data19782.zip (stored 0%)\n",
            "  adding: training_datas/train_data25742.zip (stored 0%)\n",
            "  adding: training_datas/train_data29074.zip (stored 0%)\n",
            "  adding: training_datas/train_data28136.zip (stored 0%)\n",
            "  adding: training_datas/train_data19945.zip (stored 0%)\n",
            "  adding: training_datas/train_data26060.zip (stored 0%)\n",
            "  adding: training_datas/train_data28891.zip (stored 0%)\n",
            "  adding: training_datas/train_data29802.zip (stored 0%)\n",
            "  adding: training_datas/train_data29539.zip (stored 0%)\n",
            "  adding: training_datas/train_data5665.zip (stored 0%)\n",
            "  adding: training_datas/train_data26771.zip (stored 0%)\n",
            "  adding: training_datas/train_data26614.zip (stored 0%)\n",
            "  adding: training_datas/train_data14539.zip (stored 0%)\n",
            "  adding: training_datas/train_data326.zip (stored 0%)\n",
            "  adding: training_datas/train_data1873.zip (stored 0%)\n",
            "  adding: training_datas/train_data27179.zip (stored 0%)\n",
            "  adding: training_datas/train_data25514.zip (stored 0%)\n",
            "  adding: training_datas/train_data678.zip (stored 0%)\n",
            "  adding: training_datas/train_data10760.zip (stored 0%)\n",
            "  adding: training_datas/train_data2022.zip (stored 0%)\n",
            "  adding: training_datas/train_data2616.zip (stored 0%)\n",
            "  adding: training_datas/train_data24328.zip (stored 0%)\n",
            "  adding: training_datas/train_data5920.zip (stored 0%)\n",
            "  adding: training_datas/train_data13682.zip (stored 0%)\n",
            "  adding: training_datas/train_data13490.zip (stored 0%)\n",
            "  adding: training_datas/train_data6251.zip (stored 0%)\n",
            "  adding: training_datas/train_data3342.zip (stored 0%)\n",
            "  adding: training_datas/train_data17471.zip (stored 0%)\n",
            "  adding: training_datas/train_data19228.zip (stored 0%)\n",
            "  adding: training_datas/train_data5102.zip (stored 0%)\n",
            "  adding: training_datas/train_data10541.zip (stored 0%)\n",
            "  adding: training_datas/train_data15299.zip (stored 0%)\n",
            "  adding: training_datas/train_data17643.zip (stored 0%)\n",
            "  adding: training_datas/train_data29097.zip (stored 0%)\n",
            "  adding: training_datas/train_data20036.zip (stored 0%)\n",
            "  adding: training_datas/train_data2877.zip (stored 0%)\n",
            "  adding: training_datas/train_data2312.zip (stored 0%)\n",
            "  adding: training_datas/train_data153.zip (stored 0%)\n",
            "  adding: training_datas/train_data6397.zip (stored 0%)\n",
            "  adding: training_datas/train_data19266.zip (stored 0%)\n",
            "  adding: training_datas/train_data5632.zip (stored 0%)\n",
            "  adding: training_datas/train_data21075.zip (stored 0%)\n",
            "  adding: training_datas/train_data19773.zip (stored 0%)\n",
            "  adding: training_datas/train_data26380.zip (stored 0%)\n",
            "  adding: training_datas/train_data3111.zip (stored 0%)\n",
            "  adding: training_datas/train_data30037.zip (stored 0%)\n",
            "  adding: training_datas/train_data16205.zip (stored 0%)\n",
            "  adding: training_datas/train_data13982.zip (stored 0%)\n",
            "  adding: training_datas/train_data4767.zip (stored 0%)\n",
            "  adding: training_datas/train_data27575.zip (stored 0%)\n",
            "  adding: training_datas/train_data27408.zip (stored 0%)\n",
            "  adding: training_datas/train_data23964.zip (stored 0%)\n",
            "  adding: training_datas/train_data14776.zip (stored 0%)\n",
            "  adding: training_datas/train_data14061.zip (stored 0%)\n",
            "  adding: training_datas/train_data20243.zip (stored 0%)\n",
            "  adding: training_datas/train_data15676.zip (stored 0%)\n",
            "  adding: training_datas/train_data8383.zip (stored 0%)\n",
            "  adding: training_datas/train_data20962.zip (stored 0%)\n",
            "  adding: training_datas/train_data26459.zip (stored 0%)\n",
            "  adding: training_datas/train_data17340.zip (stored 0%)\n",
            "  adding: training_datas/train_data16013.zip (stored 0%)\n",
            "  adding: training_datas/train_data1905.zip (stored 0%)\n",
            "  adding: training_datas/train_data27208.zip (stored 0%)\n",
            "  adding: training_datas/train_data15110.zip (stored 0%)\n",
            "  adding: training_datas/train_data3811.zip (stored 0%)\n",
            "  adding: training_datas/train_data12235.zip (stored 0%)\n",
            "  adding: training_datas/train_data16280.zip (stored 0%)\n",
            "  adding: training_datas/train_data23238.zip (stored 0%)\n",
            "  adding: training_datas/train_data4294.zip (stored 0%)\n",
            "  adding: training_datas/train_data28231.zip (stored 0%)\n",
            "  adding: training_datas/train_data20907.zip (stored 0%)\n",
            "  adding: training_datas/train_data14475.zip (stored 0%)\n",
            "  adding: training_datas/train_data27951.zip (stored 0%)\n",
            "  adding: training_datas/train_data3113.zip (stored 0%)\n",
            "  adding: training_datas/train_data20078.zip (stored 0%)\n",
            "  adding: training_datas/train_data24278.zip (stored 0%)\n",
            "  adding: training_datas/train_data10646.zip (stored 0%)\n",
            "  adding: training_datas/train_data10331.zip (stored 0%)\n",
            "  adding: training_datas/train_data106.zip (stored 0%)\n",
            "  adding: training_datas/train_data23694.zip (stored 0%)\n",
            "  adding: training_datas/train_data24179.zip (stored 0%)\n",
            "  adding: training_datas/train_data8505.zip (stored 0%)\n",
            "  adding: training_datas/train_data20709.zip (stored 0%)\n",
            "  adding: training_datas/train_data1060.zip (stored 0%)\n",
            "  adding: training_datas/train_data25685.zip (stored 0%)\n",
            "  adding: training_datas/train_data24613.zip (stored 0%)\n",
            "  adding: training_datas/train_data20141.zip (stored 0%)\n",
            "  adding: training_datas/train_data25130.zip (stored 0%)\n",
            "  adding: training_datas/train_data8474.zip (stored 0%)\n",
            "  adding: training_datas/train_data1357.zip (stored 0%)\n",
            "  adding: training_datas/train_data6648.zip (stored 0%)\n",
            "  adding: training_datas/train_data26274.zip (stored 0%)\n",
            "  adding: training_datas/train_data8960.zip (stored 0%)\n",
            "  adding: training_datas/train_data26688.zip (stored 0%)\n",
            "  adding: training_datas/train_data18600.zip (stored 0%)\n",
            "  adding: training_datas/train_data18670.zip (stored 0%)\n",
            "  adding: training_datas/train_data13927.zip (stored 0%)\n",
            "  adding: training_datas/train_data8835.zip (stored 0%)\n",
            "  adding: training_datas/train_data21606.zip (stored 0%)\n",
            "  adding: training_datas/train_data28631.zip (stored 0%)\n",
            "  adding: training_datas/train_data16995.zip (stored 0%)\n",
            "  adding: training_datas/train_data20638.zip (stored 0%)\n",
            "  adding: training_datas/train_data7879.zip (stored 0%)\n",
            "  adding: training_datas/train_data9485.zip (stored 0%)\n",
            "  adding: training_datas/train_data24628.zip (stored 0%)\n",
            "  adding: training_datas/train_data25541.zip (stored 0%)\n",
            "  adding: training_datas/train_data27728.zip (stored 0%)\n",
            "  adding: training_datas/train_data29469.zip (stored 0%)\n",
            "  adding: training_datas/train_data12497.zip (stored 0%)\n",
            "  adding: training_datas/train_data21509.zip (stored 0%)\n",
            "  adding: training_datas/train_data13760.zip (stored 0%)\n",
            "  adding: training_datas/train_data24411.zip (stored 0%)\n",
            "  adding: training_datas/train_data4925.zip (stored 0%)\n",
            "  adding: training_datas/train_data11023.zip (stored 0%)\n",
            "  adding: training_datas/train_data22672.zip (stored 0%)\n",
            "  adding: training_datas/train_data7465.zip (stored 0%)\n",
            "  adding: training_datas/train_data11580.zip (stored 0%)\n",
            "  adding: training_datas/train_data3897.zip (stored 0%)\n",
            "  adding: training_datas/train_data1734.zip (stored 0%)\n",
            "  adding: training_datas/train_data25344.zip (stored 0%)\n",
            "  adding: training_datas/train_data29209.zip (stored 0%)\n",
            "  adding: training_datas/train_data16648.zip (stored 0%)\n",
            "  adding: training_datas/train_data22496.zip (stored 0%)\n",
            "  adding: training_datas/train_data17198.zip (stored 0%)\n",
            "  adding: training_datas/train_data22776.zip (stored 0%)\n",
            "  adding: training_datas/train_data21291.zip (stored 0%)\n",
            "  adding: training_datas/train_data7893.zip (stored 0%)\n",
            "  adding: training_datas/train_data13043.zip (stored 0%)\n",
            "  adding: training_datas/train_data7700.zip (stored 0%)\n",
            "  adding: training_datas/train_data11858.zip (stored 0%)\n",
            "  adding: training_datas/train_data6027.zip (stored 0%)\n",
            "  adding: training_datas/train_data25429.zip (stored 0%)\n",
            "  adding: training_datas/train_data739.zip (stored 0%)\n",
            "  adding: training_datas/train_data14962.zip (stored 0%)\n",
            "  adding: training_datas/train_data24358.zip (stored 0%)\n",
            "  adding: training_datas/train_data18100.zip (stored 0%)\n",
            "  adding: training_datas/train_data16139.zip (stored 0%)\n",
            "  adding: training_datas/train_data20348.zip (stored 0%)\n",
            "  adding: training_datas/train_data6553.zip (stored 0%)\n",
            "  adding: training_datas/train_data16927.zip (stored 0%)\n",
            "  adding: training_datas/train_data30151.zip (stored 0%)\n",
            "  adding: training_datas/train_data23753.zip (stored 0%)\n",
            "  adding: training_datas/train_data16663.zip (stored 0%)\n",
            "  adding: training_datas/train_data16502.zip (stored 0%)\n",
            "  adding: training_datas/train_data22588.zip (stored 0%)\n",
            "  adding: training_datas/train_data19425.zip (stored 0%)\n",
            "  adding: training_datas/train_data6957.zip (stored 0%)\n",
            "  adding: training_datas/train_data26591.zip (stored 0%)\n",
            "  adding: training_datas/train_data13677.zip (stored 0%)\n",
            "  adding: training_datas/train_data8070.zip (stored 0%)\n",
            "  adding: training_datas/train_data552.zip (stored 0%)\n",
            "  adding: training_datas/train_data29281.zip (stored 0%)\n",
            "  adding: training_datas/train_data27197.zip (stored 0%)\n",
            "  adding: training_datas/train_data18692.zip (stored 0%)\n",
            "  adding: training_datas/train_data1375.zip (stored 0%)\n",
            "  adding: training_datas/train_data17599.zip (stored 0%)\n",
            "  adding: training_datas/train_data10808.zip (stored 0%)\n",
            "  adding: training_datas/train_data8061.zip (stored 0%)\n",
            "  adding: training_datas/train_data13001.zip (stored 0%)\n",
            "  adding: training_datas/train_data24340.zip (stored 0%)\n",
            "  adding: training_datas/train_data18759.zip (stored 0%)\n",
            "  adding: training_datas/train_data4706.zip (stored 0%)\n",
            "  adding: training_datas/train_data23486.zip (stored 0%)\n",
            "  adding: training_datas/train_data17623.zip (stored 0%)\n",
            "  adding: training_datas/train_data9347.zip (stored 0%)\n",
            "  adding: training_datas/train_data336.zip (stored 0%)\n",
            "  adding: training_datas/train_data14124.zip (stored 0%)\n",
            "  adding: training_datas/train_data18260.zip (stored 0%)\n",
            "  adding: training_datas/train_data14581.zip (stored 0%)\n",
            "  adding: training_datas/train_data16992.zip (stored 0%)\n",
            "  adding: training_datas/train_data6534.zip (stored 0%)\n",
            "  adding: training_datas/train_data24424.zip (stored 0%)\n",
            "  adding: training_datas/train_data28209.zip (stored 0%)\n",
            "  adding: training_datas/train_data15221.zip (stored 0%)\n",
            "  adding: training_datas/train_data1918.zip (stored 0%)\n",
            "  adding: training_datas/train_data16708.zip (stored 0%)\n",
            "  adding: training_datas/train_data25970.zip (stored 0%)\n",
            "  adding: training_datas/train_data22674.zip (stored 0%)\n",
            "  adding: training_datas/train_data25345.zip (stored 0%)\n",
            "  adding: training_datas/train_data880.zip (stored 0%)\n",
            "  adding: training_datas/train_data20018.zip (stored 0%)\n",
            "  adding: training_datas/train_data17610.zip (stored 0%)\n",
            "  adding: training_datas/train_data19332.zip (stored 0%)\n",
            "  adding: training_datas/train_data15030.zip (stored 0%)\n",
            "  adding: training_datas/train_data30036.zip (stored 0%)\n",
            "  adding: training_datas/train_data9072.zip (stored 0%)\n",
            "  adding: training_datas/train_data13734.zip (stored 0%)\n",
            "  adding: training_datas/train_data16906.zip (stored 0%)\n",
            "  adding: training_datas/train_data25492.zip (stored 0%)\n",
            "  adding: training_datas/train_data2318.zip (stored 0%)\n",
            "  adding: training_datas/train_data3578.zip (stored 0%)\n",
            "  adding: training_datas/train_data5936.zip (stored 0%)\n",
            "  adding: training_datas/train_data10423.zip (stored 0%)\n",
            "  adding: training_datas/train_data23685.zip (stored 0%)\n",
            "  adding: training_datas/train_data8371.zip (stored 0%)\n",
            "  adding: training_datas/train_data15989.zip (stored 0%)\n",
            "  adding: training_datas/train_data1693.zip (stored 0%)\n",
            "  adding: training_datas/train_data4129.zip (stored 0%)\n",
            "  adding: training_datas/train_data1780.zip (stored 0%)\n",
            "  adding: training_datas/train_data23506.zip (stored 0%)\n",
            "  adding: training_datas/train_data11058.zip (stored 0%)\n",
            "  adding: training_datas/train_data3309.zip (stored 0%)\n",
            "  adding: training_datas/train_data29850.zip (stored 0%)\n",
            "  adding: training_datas/train_data17274.zip (stored 0%)\n",
            "  adding: training_datas/train_data3081.zip (stored 0%)\n",
            "  adding: training_datas/train_data7545.zip (stored 0%)\n",
            "  adding: training_datas/train_data7050.zip (stored 0%)\n",
            "  adding: training_datas/train_data16586.zip (stored 0%)\n",
            "  adding: training_datas/train_data23391.zip (stored 0%)\n",
            "  adding: training_datas/train_data22526.zip (stored 0%)\n",
            "  adding: training_datas/train_data13562.zip (stored 0%)\n",
            "  adding: training_datas/train_data27454.zip (stored 0%)\n",
            "  adding: training_datas/train_data3799.zip (stored 0%)\n",
            "  adding: training_datas/train_data17603.zip (stored 0%)\n",
            "  adding: training_datas/train_data19140.zip (stored 0%)\n",
            "  adding: training_datas/train_data15389.zip (stored 0%)\n",
            "  adding: training_datas/train_data19519.zip (stored 0%)\n",
            "  adding: training_datas/train_data21934.zip (stored 0%)\n",
            "  adding: training_datas/train_data22596.zip (stored 0%)\n",
            "  adding: training_datas/train_data8801.zip (stored 0%)\n",
            "  adding: training_datas/train_data25134.zip (stored 0%)\n",
            "  adding: training_datas/train_data20154.zip (stored 0%)\n",
            "  adding: training_datas/train_data16674.zip (stored 0%)\n",
            "  adding: training_datas/train_data3217.zip (stored 0%)\n",
            "  adding: training_datas/train_data24618.zip (stored 0%)\n",
            "  adding: training_datas/train_data7783.zip (stored 0%)\n",
            "  adding: training_datas/train_data5885.zip (stored 0%)\n",
            "  adding: training_datas/train_data17647.zip (stored 0%)\n",
            "  adding: training_datas/train_data12438.zip (stored 0%)\n",
            "  adding: training_datas/train_data11034.zip (stored 0%)\n",
            "  adding: training_datas/train_data5640.zip (stored 0%)\n",
            "  adding: training_datas/train_data8692.zip (stored 0%)\n",
            "  adding: training_datas/train_data18343.zip (stored 0%)\n",
            "  adding: training_datas/train_data18942.zip (stored 0%)\n",
            "  adding: training_datas/train_data25088.zip (stored 0%)\n",
            "  adding: training_datas/train_data2485.zip (stored 0%)\n",
            "  adding: training_datas/train_data3048.zip (stored 0%)\n",
            "  adding: training_datas/train_data11399.zip (stored 0%)\n",
            "  adding: training_datas/train_data6464.zip (stored 0%)\n",
            "  adding: training_datas/train_data9258.zip (stored 0%)\n",
            "  adding: training_datas/train_data14270.zip (stored 0%)\n",
            "  adding: training_datas/train_data26485.zip (stored 0%)\n",
            "  adding: training_datas/train_data12496.zip (stored 0%)\n",
            "  adding: training_datas/train_data11570.zip (stored 0%)\n",
            "  adding: training_datas/train_data8068.zip (stored 0%)\n",
            "  adding: training_datas/train_data5057.zip (stored 0%)\n",
            "  adding: training_datas/train_data12806.zip (stored 0%)\n",
            "  adding: training_datas/train_data1839.zip (stored 0%)\n",
            "  adding: training_datas/train_data4915.zip (stored 0%)\n",
            "  adding: training_datas/train_data16671.zip (stored 0%)\n",
            "  adding: training_datas/train_data17894.zip (stored 0%)\n",
            "  adding: training_datas/train_data4168.zip (stored 0%)\n",
            "  adding: training_datas/train_data12782.zip (stored 0%)\n",
            "  adding: training_datas/train_data18333.zip (stored 0%)\n",
            "  adding: training_datas/train_data26297.zip (stored 0%)\n",
            "  adding: training_datas/train_data15190.zip (stored 0%)\n",
            "  adding: training_datas/train_data17538.zip (stored 0%)\n",
            "  adding: training_datas/train_data6857.zip (stored 0%)\n",
            "  adding: training_datas/train_data13382.zip (stored 0%)\n",
            "  adding: training_datas/train_data22431.zip (stored 0%)\n",
            "  adding: training_datas/train_data16574.zip (stored 0%)\n",
            "  adding: training_datas/train_data30070.zip (stored 0%)\n",
            "  adding: training_datas/train_data25629.zip (stored 0%)\n",
            "  adding: training_datas/train_data29930.zip (stored 0%)\n",
            "  adding: training_datas/train_data1388.zip (stored 0%)\n",
            "  adding: training_datas/train_data5840.zip (stored 0%)\n",
            "  adding: training_datas/train_data13264.zip (stored 0%)\n",
            "  adding: training_datas/train_data12556.zip (stored 0%)\n",
            "  adding: training_datas/train_data26260.zip (stored 0%)\n",
            "  adding: training_datas/train_data19985.zip (stored 0%)\n",
            "  adding: training_datas/train_data5659.zip (stored 0%)\n",
            "  adding: training_datas/train_data20295.zip (stored 0%)\n",
            "  adding: training_datas/train_data2871.zip (stored 0%)\n",
            "  adding: training_datas/train_data16560.zip (stored 0%)\n",
            "  adding: training_datas/train_data16482.zip (stored 0%)\n",
            "  adding: training_datas/train_data26596.zip (stored 0%)\n",
            "  adding: training_datas/train_data18451.zip (stored 0%)\n",
            "  adding: training_datas/train_data1002.zip (stored 0%)\n",
            "  adding: training_datas/train_data4970.zip (stored 0%)\n",
            "  adding: training_datas/train_data21126.zip (stored 0%)\n",
            "  adding: training_datas/train_data11105.zip (stored 0%)\n",
            "  adding: training_datas/train_data3371.zip (stored 0%)\n",
            "  adding: training_datas/train_data14493.zip (stored 0%)\n",
            "  adding: training_datas/train_data28239.zip (stored 0%)\n",
            "  adding: training_datas/train_data30258.zip (stored 0%)\n",
            "  adding: training_datas/train_data18433.zip (stored 0%)\n",
            "  adding: training_datas/train_data3560.zip (stored 0%)\n",
            "  adding: training_datas/train_data19718.zip (stored 0%)\n",
            "  adding: training_datas/train_data14968.zip (stored 0%)\n",
            "  adding: training_datas/train_data30065.zip (stored 0%)\n",
            "  adding: training_datas/train_data250.zip (stored 0%)\n",
            "  adding: training_datas/train_data20502.zip (stored 0%)\n",
            "  adding: training_datas/train_data1290.zip (stored 0%)\n",
            "  adding: training_datas/train_data16513.zip (stored 0%)\n",
            "  adding: training_datas/train_data3677.zip (stored 0%)\n",
            "  adding: training_datas/train_data20641.zip (stored 0%)\n",
            "  adding: training_datas/train_data14526.zip (stored 0%)\n",
            "  adding: training_datas/train_data23243.zip (stored 0%)\n",
            "  adding: training_datas/train_data5231.zip (stored 0%)\n",
            "  adding: training_datas/train_data17540.zip (stored 0%)\n",
            "  adding: training_datas/train_data14644.zip (stored 0%)\n",
            "  adding: training_datas/train_data335.zip (stored 0%)\n",
            "  adding: training_datas/train_data17988.zip (stored 0%)\n",
            "  adding: training_datas/train_data5412.zip (stored 0%)\n",
            "  adding: training_datas/train_data29372.zip (stored 0%)\n",
            "  adding: training_datas/train_data20989.zip (stored 0%)\n",
            "  adding: training_datas/train_data11600.zip (stored 0%)\n",
            "  adding: training_datas/train_data11793.zip (stored 0%)\n",
            "  adding: training_datas/train_data3260.zip (stored 0%)\n",
            "  adding: training_datas/train_data10801.zip (stored 0%)\n",
            "  adding: training_datas/train_data22889.zip (stored 0%)\n",
            "  adding: training_datas/train_data13715.zip (stored 0%)\n",
            "  adding: training_datas/train_data9521.zip (stored 0%)\n",
            "  adding: training_datas/train_data2755.zip (stored 0%)\n",
            "  adding: training_datas/train_data29790.zip (stored 0%)\n",
            "  adding: training_datas/train_data14310.zip (stored 0%)\n",
            "  adding: training_datas/train_data5507.zip (stored 0%)\n",
            "  adding: training_datas/train_data22018.zip (stored 0%)\n",
            "  adding: training_datas/train_data7343.zip (stored 0%)\n",
            "  adding: training_datas/train_data22791.zip (stored 0%)\n",
            "  adding: training_datas/train_data19484.zip (stored 0%)\n",
            "  adding: training_datas/train_data18027.zip (stored 0%)\n",
            "  adding: training_datas/train_data14556.zip (stored 0%)\n",
            "  adding: training_datas/train_data16843.zip (stored 0%)\n",
            "  adding: training_datas/train_data19170.zip (stored 0%)\n",
            "  adding: training_datas/train_data29906.zip (stored 0%)\n",
            "  adding: training_datas/train_data26554.zip (stored 0%)\n",
            "  adding: training_datas/train_data13033.zip (stored 0%)\n",
            "  adding: training_datas/train_data1395.zip (stored 0%)\n",
            "  adding: training_datas/train_data12833.zip (stored 0%)\n",
            "  adding: training_datas/train_data69.zip (stored 0%)\n",
            "  adding: training_datas/train_data13670.zip (stored 0%)\n",
            "  adding: training_datas/train_data13373.zip (stored 0%)\n",
            "  adding: training_datas/train_data9286.zip (stored 0%)\n",
            "  adding: training_datas/train_data17141.zip (stored 0%)\n",
            "  adding: training_datas/train_data20773.zip (stored 0%)\n",
            "  adding: training_datas/train_data22350.zip (stored 0%)\n",
            "  adding: training_datas/train_data27209.zip (stored 0%)\n",
            "  adding: training_datas/train_data28575.zip (stored 0%)\n",
            "  adding: training_datas/train_data30128.zip (stored 0%)\n",
            "  adding: training_datas/train_data17789.zip (stored 0%)\n",
            "  adding: training_datas/train_data6937.zip (stored 0%)\n",
            "  adding: training_datas/train_data25121.zip (stored 0%)\n",
            "  adding: training_datas/train_data939.zip (stored 0%)\n",
            "  adding: training_datas/train_data16801.zip (stored 0%)\n",
            "  adding: training_datas/train_data27231.zip (stored 0%)\n",
            "  adding: training_datas/train_data23426.zip (stored 0%)\n",
            "  adding: training_datas/train_data24553.zip (stored 0%)\n",
            "  adding: training_datas/train_data1077.zip (stored 0%)\n",
            "  adding: training_datas/train_data2715.zip (stored 0%)\n",
            "  adding: training_datas/train_data12071.zip (stored 0%)\n",
            "  adding: training_datas/train_data8138.zip (stored 0%)\n",
            "  adding: training_datas/train_data11170.zip (stored 0%)\n",
            "  adding: training_datas/train_data4834.zip (stored 0%)\n",
            "  adding: training_datas/train_data24849.zip (stored 0%)\n",
            "  adding: training_datas/train_data24182.zip (stored 0%)\n",
            "  adding: training_datas/train_data17609.zip (stored 0%)\n",
            "  adding: training_datas/train_data2296.zip (stored 0%)\n",
            "  adding: training_datas/train_data4293.zip (stored 0%)\n",
            "  adding: training_datas/train_data14937.zip (stored 0%)\n",
            "  adding: training_datas/train_data11080.zip (stored 0%)\n",
            "  adding: training_datas/train_data807.zip (stored 0%)\n",
            "  adding: training_datas/train_data2383.zip (stored 0%)\n",
            "  adding: training_datas/train_data22983.zip (stored 0%)\n",
            "  adding: training_datas/train_data19079.zip (stored 0%)\n",
            "  adding: training_datas/train_data28955.zip (stored 0%)\n",
            "  adding: training_datas/train_data16145.zip (stored 0%)\n",
            "  adding: training_datas/train_data3443.zip (stored 0%)\n",
            "  adding: training_datas/train_data14549.zip (stored 0%)\n",
            "  adding: training_datas/train_data2603.zip (stored 0%)\n",
            "  adding: training_datas/train_data15155.zip (stored 0%)\n",
            "  adding: training_datas/train_data28489.zip (stored 0%)\n",
            "  adding: training_datas/train_data4783.zip (stored 0%)\n",
            "  adding: training_datas/train_data3251.zip (stored 0%)\n",
            "  adding: training_datas/train_data27061.zip (stored 0%)\n",
            "  adding: training_datas/train_data17707.zip (stored 0%)\n",
            "  adding: training_datas/train_data2403.zip (stored 0%)\n",
            "  adding: training_datas/train_data26588.zip (stored 0%)\n",
            "  adding: training_datas/train_data13903.zip (stored 0%)\n",
            "  adding: training_datas/train_data21952.zip (stored 0%)\n",
            "  adding: training_datas/train_data8590.zip (stored 0%)\n",
            "  adding: training_datas/train_data4689.zip (stored 0%)\n",
            "  adding: training_datas/train_data5674.zip (stored 0%)\n",
            "  adding: training_datas/train_data29857.zip (stored 0%)\n",
            "  adding: training_datas/train_data8519.zip (stored 0%)\n",
            "  adding: training_datas/train_data10621.zip (stored 0%)\n",
            "  adding: training_datas/train_data10640.zip (stored 0%)\n",
            "  adding: training_datas/train_data9913.zip (stored 0%)\n",
            "  adding: training_datas/train_data691.zip (stored 0%)\n",
            "  adding: training_datas/train_data20397.zip (stored 0%)\n",
            "  adding: training_datas/train_data17435.zip (stored 0%)\n",
            "  adding: training_datas/train_data165.zip (stored 0%)\n",
            "  adding: training_datas/train_data15087.zip (stored 0%)\n",
            "  adding: training_datas/train_data20797.zip (stored 0%)\n",
            "  adding: training_datas/train_data25376.zip (stored 0%)\n",
            "  adding: training_datas/train_data15361.zip (stored 0%)\n",
            "  adding: training_datas/train_data7310.zip (stored 0%)\n",
            "  adding: training_datas/train_data6064.zip (stored 0%)\n",
            "  adding: training_datas/train_data21891.zip (stored 0%)\n",
            "  adding: training_datas/train_data20541.zip (stored 0%)\n",
            "  adding: training_datas/train_data22810.zip (stored 0%)\n",
            "  adding: training_datas/train_data16676.zip (stored 0%)\n",
            "  adding: training_datas/train_data7854.zip (stored 0%)\n",
            "  adding: training_datas/train_data4730.zip (stored 0%)\n",
            "  adding: training_datas/train_data18817.zip (stored 0%)\n",
            "  adding: training_datas/train_data16410.zip (stored 0%)\n",
            "  adding: training_datas/train_data27979.zip (stored 0%)\n",
            "  adding: training_datas/train_data15521.zip (stored 0%)\n",
            "  adding: training_datas/train_data29713.zip (stored 0%)\n",
            "  adding: training_datas/train_data15138.zip (stored 0%)\n",
            "  adding: training_datas/train_data10231.zip (stored 0%)\n",
            "  adding: training_datas/train_data21066.zip (stored 0%)\n",
            "  adding: training_datas/train_data26357.zip (stored 0%)\n",
            "  adding: training_datas/train_data28702.zip (stored 0%)\n",
            "  adding: training_datas/train_data16403.zip (stored 0%)\n",
            "  adding: training_datas/train_data20318.zip (stored 0%)\n",
            "  adding: training_datas/train_data5878.zip (stored 0%)\n",
            "  adding: training_datas/train_data14955.zip (stored 0%)\n",
            "  adding: training_datas/train_data29662.zip (stored 0%)\n",
            "  adding: training_datas/train_data26437.zip (stored 0%)\n",
            "  adding: training_datas/train_data8330.zip (stored 0%)\n",
            "  adding: training_datas/train_data7103.zip (stored 0%)\n",
            "  adding: training_datas/train_data30453.zip (stored 0%)\n",
            "  adding: training_datas/train_data10753.zip (stored 0%)\n",
            "  adding: training_datas/train_data10106.zip (stored 0%)\n",
            "  adding: training_datas/train_data20429.zip (stored 0%)\n",
            "  adding: training_datas/train_data12070.zip (stored 0%)\n",
            "  adding: training_datas/train_data23211.zip (stored 0%)\n",
            "  adding: training_datas/train_data6602.zip (stored 0%)\n",
            "  adding: training_datas/train_data28.zip (stored 0%)\n",
            "  adding: training_datas/train_data10347.zip (stored 0%)\n",
            "  adding: training_datas/train_data22351.zip (stored 0%)\n",
            "  adding: training_datas/train_data20037.zip (stored 0%)\n",
            "  adding: training_datas/train_data22070.zip (stored 0%)\n",
            "  adding: training_datas/train_data6179.zip (stored 0%)\n",
            "  adding: training_datas/train_data3134.zip (stored 0%)\n",
            "  adding: training_datas/train_data21720.zip (stored 0%)\n",
            "  adding: training_datas/train_data22196.zip (stored 0%)\n",
            "  adding: training_datas/train_data2429.zip (stored 0%)\n",
            "  adding: training_datas/train_data23553.zip (stored 0%)\n",
            "  adding: training_datas/train_data28666.zip (stored 0%)\n",
            "  adding: training_datas/train_data27867.zip (stored 0%)\n",
            "  adding: training_datas/train_data468.zip (stored 0%)\n",
            "  adding: training_datas/train_data9987.zip (stored 0%)\n",
            "  adding: training_datas/train_data6164.zip (stored 0%)\n",
            "  adding: training_datas/train_data13253.zip (stored 0%)\n",
            "  adding: training_datas/train_data25615.zip (stored 0%)\n",
            "  adding: training_datas/train_data25055.zip (stored 0%)\n",
            "  adding: training_datas/train_data14141.zip (stored 0%)\n",
            "  adding: training_datas/train_data11295.zip (stored 0%)\n",
            "  adding: training_datas/train_data2550.zip (stored 0%)\n",
            "  adding: training_datas/train_data8069.zip (stored 0%)\n",
            "  adding: training_datas/train_data25377.zip (stored 0%)\n",
            "  adding: training_datas/train_data5993.zip (stored 0%)\n",
            "  adding: training_datas/train_data8477.zip (stored 0%)\n",
            "  adding: training_datas/train_data27059.zip (stored 0%)\n",
            "  adding: training_datas/train_data3471.zip (stored 0%)\n",
            "  adding: training_datas/train_data1347.zip (stored 0%)\n",
            "  adding: training_datas/train_data4933.zip (stored 0%)\n",
            "  adding: training_datas/train_data9560.zip (stored 0%)\n",
            "  adding: training_datas/train_data5094.zip (stored 0%)\n",
            "  adding: training_datas/train_data5135.zip (stored 0%)\n",
            "  adding: training_datas/train_data30172.zip (stored 0%)\n",
            "  adding: training_datas/train_data1479.zip (stored 0%)\n",
            "  adding: training_datas/train_data13947.zip (stored 0%)\n",
            "  adding: training_datas/train_data22416.zip (stored 0%)\n",
            "  adding: training_datas/train_data28113.zip (stored 0%)\n",
            "  adding: training_datas/train_data17299.zip (stored 0%)\n",
            "  adding: training_datas/train_data243.zip (stored 0%)\n",
            "  adding: training_datas/train_data9068.zip (stored 0%)\n",
            "  adding: training_datas/train_data2228.zip (stored 0%)\n",
            "  adding: training_datas/train_data30311.zip (stored 0%)\n",
            "  adding: training_datas/train_data3787.zip (stored 0%)\n",
            "  adding: training_datas/train_data26195.zip (stored 0%)\n",
            "  adding: training_datas/train_data12361.zip (stored 0%)\n",
            "  adding: training_datas/train_data9500.zip (stored 0%)\n",
            "  adding: training_datas/train_data16639.zip (stored 0%)\n",
            "  adding: training_datas/train_data5039.zip (stored 0%)\n",
            "  adding: training_datas/train_data14813.zip (stored 0%)\n",
            "  adding: training_datas/train_data22133.zip (stored 0%)\n",
            "  adding: training_datas/train_data4709.zip (stored 0%)\n",
            "  adding: training_datas/train_data19698.zip (stored 0%)\n",
            "  adding: training_datas/train_data4137.zip (stored 0%)\n",
            "  adding: training_datas/train_data17900.zip (stored 0%)\n",
            "  adding: training_datas/train_data17681.zip (stored 0%)\n",
            "  adding: training_datas/train_data20416.zip (stored 0%)\n",
            "  adding: training_datas/train_data20291.zip (stored 0%)\n",
            "  adding: training_datas/train_data14967.zip (stored 0%)\n",
            "  adding: training_datas/train_data28680.zip (stored 0%)\n",
            "  adding: training_datas/train_data18609.zip (stored 0%)\n",
            "  adding: training_datas/train_data18291.zip (stored 0%)\n",
            "  adding: training_datas/train_data17930.zip (stored 0%)\n",
            "  adding: training_datas/train_data17386.zip (stored 0%)\n",
            "  adding: training_datas/train_data25962.zip (stored 0%)\n",
            "  adding: training_datas/train_data15420.zip (stored 0%)\n",
            "  adding: training_datas/train_data13588.zip (stored 0%)\n",
            "  adding: training_datas/train_data9761.zip (stored 0%)\n",
            "  adding: training_datas/train_data19024.zip (stored 0%)\n",
            "  adding: training_datas/train_data21514.zip (stored 0%)\n",
            "  adding: training_datas/train_data4634.zip (stored 0%)\n",
            "  adding: training_datas/train_data20761.zip (stored 0%)\n",
            "  adding: training_datas/train_data2849.zip (stored 0%)\n",
            "  adding: training_datas/train_data9049.zip (stored 0%)\n",
            "  adding: training_datas/train_data13422.zip (stored 0%)\n",
            "  adding: training_datas/train_data26976.zip (stored 0%)\n",
            "  adding: training_datas/train_data30217.zip (stored 0%)\n",
            "  adding: training_datas/train_data18829.zip (stored 0%)\n",
            "  adding: training_datas/train_data1194.zip (stored 0%)\n",
            "  adding: training_datas/train_data22253.zip (stored 0%)\n",
            "  adding: training_datas/train_data2462.zip (stored 0%)\n",
            "  adding: training_datas/train_data6344.zip (stored 0%)\n",
            "  adding: training_datas/train_data759.zip (stored 0%)\n",
            "  adding: training_datas/train_data23377.zip (stored 0%)\n",
            "  adding: training_datas/train_data16016.zip (stored 0%)\n",
            "  adding: training_datas/train_data20000.zip (stored 0%)\n",
            "  adding: training_datas/train_data14017.zip (stored 0%)\n",
            "  adding: training_datas/train_data18145.zip (stored 0%)\n",
            "  adding: training_datas/train_data27018.zip (stored 0%)\n",
            "  adding: training_datas/train_data111.zip (stored 0%)\n",
            "  adding: training_datas/train_data5772.zip (stored 0%)\n",
            "  adding: training_datas/train_data1475.zip (stored 0%)\n",
            "  adding: training_datas/train_data953.zip (stored 0%)\n",
            "  adding: training_datas/train_data21892.zip (stored 0%)\n",
            "  adding: training_datas/train_data6774.zip (stored 0%)\n",
            "  adding: training_datas/train_data4790.zip (stored 0%)\n",
            "  adding: training_datas/train_data24646.zip (stored 0%)\n",
            "  adding: training_datas/train_data16626.zip (stored 0%)\n",
            "  adding: training_datas/train_data4475.zip (stored 0%)\n",
            "  adding: training_datas/train_data24525.zip (stored 0%)\n",
            "  adding: training_datas/train_data28803.zip (stored 0%)\n",
            "  adding: training_datas/train_data14171.zip (stored 0%)\n",
            "  adding: training_datas/train_data15883.zip (stored 0%)\n",
            "  adding: training_datas/train_data22181.zip (stored 0%)\n",
            "  adding: training_datas/train_data28020.zip (stored 0%)\n",
            "  adding: training_datas/train_data12995.zip (stored 0%)\n",
            "  adding: training_datas/train_data4628.zip (stored 0%)\n",
            "  adding: training_datas/train_data28387.zip (stored 0%)\n",
            "  adding: training_datas/train_data310.zip (stored 0%)\n",
            "  adding: training_datas/train_data30004.zip (stored 0%)\n",
            "  adding: training_datas/train_data1238.zip (stored 0%)\n",
            "  adding: training_datas/train_data8811.zip (stored 0%)\n",
            "  adding: training_datas/train_data15975.zip (stored 0%)\n",
            "  adding: training_datas/train_data370.zip (stored 0%)\n",
            "  adding: training_datas/train_data12325.zip (stored 0%)\n",
            "  adding: training_datas/train_data5305.zip (stored 0%)\n",
            "  adding: training_datas/train_data13796.zip (stored 0%)\n",
            "  adding: training_datas/train_data14938.zip (stored 0%)\n",
            "  adding: training_datas/train_data18256.zip (stored 0%)\n",
            "  adding: training_datas/train_data29239.zip (stored 0%)\n",
            "  adding: training_datas/train_data30480.zip (stored 0%)\n",
            "  adding: training_datas/train_data13213.zip (stored 0%)\n",
            "  adding: training_datas/train_data7114.zip (stored 0%)\n",
            "  adding: training_datas/train_data20663.zip (stored 0%)\n",
            "  adding: training_datas/train_data4751.zip (stored 0%)\n",
            "  adding: training_datas/train_data26781.zip (stored 0%)\n",
            "  adding: training_datas/train_data25620.zip (stored 0%)\n",
            "  adding: training_datas/train_data20677.zip (stored 0%)\n",
            "  adding: training_datas/train_data25170.zip (stored 0%)\n",
            "  adding: training_datas/train_data2765.zip (stored 0%)\n",
            "  adding: training_datas/train_data17451.zip (stored 0%)\n",
            "  adding: training_datas/train_data23764.zip (stored 0%)\n",
            "  adding: training_datas/train_data29269.zip (stored 0%)\n",
            "  adding: training_datas/train_data25043.zip (stored 0%)\n",
            "  adding: training_datas/train_data18230.zip (stored 0%)\n",
            "  adding: training_datas/train_data16041.zip (stored 0%)\n",
            "  adding: training_datas/train_data8358.zip (stored 0%)\n",
            "  adding: training_datas/train_data4565.zip (stored 0%)\n",
            "  adding: training_datas/train_data4230.zip (stored 0%)\n",
            "  adding: training_datas/train_data28751.zip (stored 0%)\n",
            "  adding: training_datas/train_data13990.zip (stored 0%)\n",
            "  adding: training_datas/train_data20783.zip (stored 0%)\n",
            "  adding: training_datas/train_data24388.zip (stored 0%)\n",
            "  adding: training_datas/train_data27190.zip (stored 0%)\n",
            "  adding: training_datas/train_data30179.zip (stored 0%)\n",
            "  adding: training_datas/train_data10255.zip (stored 0%)\n",
            "  adding: training_datas/train_data2637.zip (stored 0%)\n",
            "  adding: training_datas/train_data5070.zip (stored 0%)\n",
            "  adding: training_datas/train_data30182.zip (stored 0%)\n",
            "  adding: training_datas/train_data11239.zip (stored 0%)\n",
            "  adding: training_datas/train_data22046.zip (stored 0%)\n",
            "  adding: training_datas/train_data8621.zip (stored 0%)\n",
            "  adding: training_datas/train_data28578.zip (stored 0%)\n",
            "  adding: training_datas/train_data16191.zip (stored 0%)\n",
            "  adding: training_datas/train_data29639.zip (stored 0%)\n",
            "  adding: training_datas/train_data26908.zip (stored 0%)\n",
            "  adding: training_datas/train_data8541.zip (stored 0%)\n",
            "  adding: training_datas/train_data11463.zip (stored 0%)\n",
            "  adding: training_datas/train_data196.zip (stored 0%)\n",
            "  adding: training_datas/train_data17652.zip (stored 0%)\n",
            "  adding: training_datas/train_data8496.zip (stored 0%)\n",
            "  adding: training_datas/train_data9856.zip (stored 0%)\n",
            "  adding: training_datas/train_data26444.zip (stored 0%)\n",
            "  adding: training_datas/train_data8917.zip (stored 0%)\n",
            "  adding: training_datas/train_data11350.zip (stored 0%)\n",
            "  adding: training_datas/train_data8119.zip (stored 0%)\n",
            "  adding: training_datas/train_data27577.zip (stored 0%)\n",
            "  adding: training_datas/train_data28280.zip (stored 0%)\n",
            "  adding: training_datas/train_data24956.zip (stored 0%)\n",
            "  adding: training_datas/train_data1419.zip (stored 0%)\n",
            "  adding: training_datas/train_data22559.zip (stored 0%)\n",
            "  adding: training_datas/train_data28206.zip (stored 0%)\n",
            "  adding: training_datas/train_data14502.zip (stored 0%)\n",
            "  adding: training_datas/train_data12638.zip (stored 0%)\n",
            "  adding: training_datas/train_data6656.zip (stored 0%)\n",
            "  adding: training_datas/train_data7542.zip (stored 0%)\n",
            "  adding: training_datas/train_data9829.zip (stored 0%)\n",
            "  adding: training_datas/train_data11511.zip (stored 0%)\n",
            "  adding: training_datas/train_data23292.zip (stored 0%)\n",
            "  adding: training_datas/train_data18691.zip (stored 0%)\n",
            "  adding: training_datas/train_data28389.zip (stored 0%)\n",
            "  adding: training_datas/train_data3933.zip (stored 0%)\n",
            "  adding: training_datas/train_data8482.zip (stored 0%)\n",
            "  adding: training_datas/train_data22248.zip (stored 0%)\n",
            "  adding: training_datas/train_data17162.zip (stored 0%)\n",
            "  adding: training_datas/train_data10453.zip (stored 0%)\n",
            "  adding: training_datas/train_data28518.zip (stored 0%)\n",
            "  adding: training_datas/train_data24848.zip (stored 0%)\n",
            "  adding: training_datas/train_data2875.zip (stored 0%)\n",
            "  adding: training_datas/train_data21084.zip (stored 0%)\n",
            "  adding: training_datas/train_data8031.zip (stored 0%)\n",
            "  adding: training_datas/train_data28177.zip (stored 0%)\n",
            "  adding: training_datas/train_data10592.zip (stored 0%)\n",
            "  adding: training_datas/train_data20021.zip (stored 0%)\n",
            "  adding: training_datas/train_data16617.zip (stored 0%)\n",
            "  adding: training_datas/train_data18154.zip (stored 0%)\n",
            "  adding: training_datas/train_data1550.zip (stored 0%)\n",
            "  adding: training_datas/train_data900.zip (stored 0%)\n",
            "  adding: training_datas/train_data8074.zip (stored 0%)\n",
            "  adding: training_datas/train_data20706.zip (stored 0%)\n",
            "  adding: training_datas/train_data6203.zip (stored 0%)\n",
            "  adding: training_datas/train_data17898.zip (stored 0%)\n",
            "  adding: training_datas/train_data28775.zip (stored 0%)\n",
            "  adding: training_datas/train_data17099.zip (stored 0%)\n",
            "  adding: training_datas/train_data28084.zip (stored 0%)\n",
            "  adding: training_datas/train_data7749.zip (stored 0%)\n",
            "  adding: training_datas/train_data3690.zip (stored 0%)\n",
            "  adding: training_datas/train_data11634.zip (stored 0%)\n",
            "  adding: training_datas/train_data17572.zip (stored 0%)\n",
            "  adding: training_datas/train_data27767.zip (stored 0%)\n",
            "  adding: training_datas/train_data22671.zip (stored 0%)\n",
            "  adding: training_datas/train_data18162.zip (stored 0%)\n",
            "  adding: training_datas/train_data29654.zip (stored 0%)\n",
            "  adding: training_datas/train_data11886.zip (stored 0%)\n",
            "  adding: training_datas/train_data1084.zip (stored 0%)\n",
            "  adding: training_datas/train_data8587.zip (stored 0%)\n",
            "  adding: training_datas/train_data3286.zip (stored 0%)\n",
            "  adding: training_datas/train_data23736.zip (stored 0%)\n",
            "  adding: training_datas/train_data12194.zip (stored 0%)\n",
            "  adding: training_datas/train_data9817.zip (stored 0%)\n",
            "  adding: training_datas/train_data3766.zip (stored 0%)\n",
            "  adding: training_datas/train_data1953.zip (stored 0%)\n",
            "  adding: training_datas/train_data27563.zip (stored 0%)\n",
            "  adding: training_datas/train_data12198.zip (stored 0%)\n",
            "  adding: training_datas/train_data26362.zip (stored 0%)\n",
            "  adding: training_datas/train_data29982.zip (stored 0%)\n",
            "  adding: training_datas/train_data29643.zip (stored 0%)\n",
            "  adding: training_datas/train_data21135.zip (stored 0%)\n",
            "  adding: training_datas/train_data15214.zip (stored 0%)\n",
            "  adding: training_datas/train_data11100.zip (stored 0%)\n",
            "  adding: training_datas/train_data16387.zip (stored 0%)\n",
            "  adding: training_datas/train_data14334.zip (stored 0%)\n",
            "  adding: training_datas/train_data23662.zip (stored 0%)\n",
            "  adding: training_datas/train_data30387.zip (stored 0%)\n",
            "  adding: training_datas/train_data7511.zip (stored 0%)\n",
            "  adding: training_datas/train_data19023.zip (stored 0%)\n",
            "  adding: training_datas/train_data12617.zip (stored 0%)\n",
            "  adding: training_datas/train_data4617.zip (stored 0%)\n",
            "  adding: training_datas/train_data5714.zip (stored 0%)\n",
            "  adding: training_datas/train_data16152.zip (stored 0%)\n",
            "  adding: training_datas/train_data796.zip (stored 0%)\n",
            "  adding: training_datas/train_data25764.zip (stored 0%)\n",
            "  adding: training_datas/train_data12164.zip (stored 0%)\n",
            "  adding: training_datas/train_data28225.zip (stored 0%)\n",
            "  adding: training_datas/train_data12482.zip (stored 0%)\n",
            "  adding: training_datas/train_data20248.zip (stored 0%)\n",
            "  adding: training_datas/train_data12268.zip (stored 0%)\n",
            "  adding: training_datas/train_data22703.zip (stored 0%)\n",
            "  adding: training_datas/train_data16223.zip (stored 0%)\n",
            "  adding: training_datas/train_data27139.zip (stored 0%)\n",
            "  adding: training_datas/train_data6746.zip (stored 0%)\n",
            "  adding: training_datas/train_data22642.zip (stored 0%)\n",
            "  adding: training_datas/train_data14387.zip (stored 0%)\n",
            "  adding: training_datas/train_data13726.zip (stored 0%)\n",
            "  adding: training_datas/train_data24048.zip (stored 0%)\n",
            "  adding: training_datas/train_data16052.zip (stored 0%)\n",
            "  adding: training_datas/train_data14733.zip (stored 0%)\n",
            "  adding: training_datas/train_data27319.zip (stored 0%)\n",
            "  adding: training_datas/train_data770.zip (stored 0%)\n",
            "  adding: training_datas/train_data30329.zip (stored 0%)\n",
            "  adding: training_datas/train_data22960.zip (stored 0%)\n",
            "  adding: training_datas/train_data13803.zip (stored 0%)\n",
            "  adding: training_datas/train_data13882.zip (stored 0%)\n",
            "  adding: training_datas/train_data18046.zip (stored 0%)\n",
            "  adding: training_datas/train_data7077.zip (stored 0%)\n",
            "  adding: training_datas/train_data21648.zip (stored 0%)\n",
            "  adding: training_datas/train_data27035.zip (stored 0%)\n",
            "  adding: training_datas/train_data29255.zip (stored 0%)\n",
            "  adding: training_datas/train_data30424.zip (stored 0%)\n",
            "  adding: training_datas/train_data5860.zip (stored 0%)\n",
            "  adding: training_datas/train_data13197.zip (stored 0%)\n",
            "  adding: training_datas/train_data6958.zip (stored 0%)\n",
            "  adding: training_datas/train_data11867.zip (stored 0%)\n",
            "  adding: training_datas/train_data1331.zip (stored 0%)\n",
            "  adding: training_datas/train_data12126.zip (stored 0%)\n",
            "  adding: training_datas/train_data7198.zip (stored 0%)\n",
            "  adding: training_datas/train_data11723.zip (stored 0%)\n",
            "  adding: training_datas/train_data24140.zip (stored 0%)\n",
            "  adding: training_datas/train_data20285.zip (stored 0%)\n",
            "  adding: training_datas/train_data13051.zip (stored 0%)\n",
            "  adding: training_datas/train_data26972.zip (stored 0%)\n",
            "  adding: training_datas/train_data9924.zip (stored 0%)\n",
            "  adding: training_datas/train_data12684.zip (stored 0%)\n",
            "  adding: training_datas/train_data1294.zip (stored 0%)\n",
            "  adding: training_datas/train_data27303.zip (stored 0%)\n",
            "  adding: training_datas/train_data9480.zip (stored 0%)\n",
            "  adding: training_datas/train_data24359.zip (stored 0%)\n",
            "  adding: training_datas/train_data24577.zip (stored 0%)\n",
            "  adding: training_datas/train_data18279.zip (stored 0%)\n",
            "  adding: training_datas/train_data10172.zip (stored 0%)\n",
            "  adding: training_datas/train_data11220.zip (stored 0%)\n",
            "  adding: training_datas/train_data6200.zip (stored 0%)\n",
            "  adding: training_datas/train_data20288.zip (stored 0%)\n",
            "  adding: training_datas/train_data17616.zip (stored 0%)\n",
            "  adding: training_datas/train_data9670.zip (stored 0%)\n",
            "  adding: training_datas/train_data9750.zip (stored 0%)\n",
            "  adding: training_datas/train_data9803.zip (stored 0%)\n",
            "  adding: training_datas/train_data6543.zip (stored 0%)\n",
            "  adding: training_datas/train_data12342.zip (stored 0%)\n",
            "  adding: training_datas/train_data22635.zip (stored 0%)\n",
            "  adding: training_datas/train_data29349.zip (stored 0%)\n",
            "  adding: training_datas/train_data14565.zip (stored 0%)\n",
            "  adding: training_datas/train_data67.zip (stored 0%)\n",
            "  adding: training_datas/train_data26006.zip (stored 0%)\n",
            "  adding: training_datas/train_data3907.zip (stored 0%)\n",
            "  adding: training_datas/train_data25024.zip (stored 0%)\n",
            "  adding: training_datas/train_data2038.zip (stored 0%)\n",
            "  adding: training_datas/train_data23487.zip (stored 0%)\n",
            "  adding: training_datas/train_data22096.zip (stored 0%)\n",
            "  adding: training_datas/train_data20323.zip (stored 0%)\n",
            "  adding: training_datas/train_data1094.zip (stored 0%)\n",
            "  adding: training_datas/train_data14997.zip (stored 0%)\n",
            "  adding: training_datas/train_data9722.zip (stored 0%)\n",
            "  adding: training_datas/train_data28079.zip (stored 0%)\n",
            "  adding: training_datas/train_data1777.zip (stored 0%)\n",
            "  adding: training_datas/train_data653.zip (stored 0%)\n",
            "  adding: training_datas/train_data14434.zip (stored 0%)\n",
            "  adding: training_datas/train_data13683.zip (stored 0%)\n",
            "  adding: training_datas/train_data12272.zip (stored 0%)\n",
            "  adding: training_datas/train_data12603.zip (stored 0%)\n",
            "  adding: training_datas/train_data18504.zip (stored 0%)\n",
            "  adding: training_datas/train_data29214.zip (stored 0%)\n",
            "  adding: training_datas/train_data5211.zip (stored 0%)\n",
            "  adding: training_datas/train_data14321.zip (stored 0%)\n",
            "  adding: training_datas/train_data789.zip (stored 0%)\n",
            "  adding: training_datas/train_data25743.zip (stored 0%)\n",
            "  adding: training_datas/train_data6873.zip (stored 0%)\n",
            "  adding: training_datas/train_data27341.zip (stored 0%)\n",
            "  adding: training_datas/train_data10554.zip (stored 0%)\n",
            "  adding: training_datas/train_data30054.zip (stored 0%)\n",
            "  adding: training_datas/train_data12955.zip (stored 0%)\n",
            "  adding: training_datas/train_data15884.zip (stored 0%)\n",
            "  adding: training_datas/train_data14095.zip (stored 0%)\n",
            "  adding: training_datas/train_data17067.zip (stored 0%)\n",
            "  adding: training_datas/train_data1504.zip (stored 0%)\n",
            "  adding: training_datas/train_data8357.zip (stored 0%)\n",
            "  adding: training_datas/train_data28530.zip (stored 0%)\n",
            "  adding: training_datas/train_data29367.zip (stored 0%)\n",
            "  adding: training_datas/train_data6418.zip (stored 0%)\n",
            "  adding: training_datas/train_data24161.zip (stored 0%)\n",
            "  adding: training_datas/train_data3301.zip (stored 0%)\n",
            "  adding: training_datas/train_data27873.zip (stored 0%)\n",
            "  adding: training_datas/train_data29744.zip (stored 0%)\n",
            "  adding: training_datas/train_data13088.zip (stored 0%)\n",
            "  adding: training_datas/train_data27947.zip (stored 0%)\n",
            "  adding: training_datas/train_data21595.zip (stored 0%)\n",
            "  adding: training_datas/train_data19222.zip (stored 0%)\n",
            "  adding: training_datas/train_data2988.zip (stored 0%)\n",
            "  adding: training_datas/train_data4108.zip (stored 0%)\n",
            "  adding: training_datas/train_data23993.zip (stored 0%)\n",
            "  adding: training_datas/train_data19845.zip (stored 0%)\n",
            "  adding: training_datas/train_data2283.zip (stored 0%)\n",
            "  adding: training_datas/train_data10558.zip (stored 0%)\n",
            "  adding: training_datas/train_data9795.zip (stored 0%)\n",
            "  adding: training_datas/train_data25818.zip (stored 0%)\n",
            "  adding: training_datas/train_data26811.zip (stored 0%)\n",
            "  adding: training_datas/train_data8352.zip (stored 0%)\n",
            "  adding: training_datas/train_data4952.zip (stored 0%)\n",
            "  adding: training_datas/train_data22873.zip (stored 0%)\n",
            "  adding: training_datas/train_data12605.zip (stored 0%)\n",
            "  adding: training_datas/train_data21876.zip (stored 0%)\n",
            "  adding: training_datas/train_data19036.zip (stored 0%)\n",
            "  adding: training_datas/train_data26586.zip (stored 0%)\n",
            "  adding: training_datas/train_data28123.zip (stored 0%)\n",
            "  adding: training_datas/train_data14609.zip (stored 0%)\n",
            "  adding: training_datas/train_data11408.zip (stored 0%)\n",
            "  adding: training_datas/train_data30251.zip (stored 0%)\n",
            "  adding: training_datas/train_data25611.zip (stored 0%)\n",
            "  adding: training_datas/train_data24227.zip (stored 0%)\n",
            "  adding: training_datas/train_data10393.zip (stored 0%)\n",
            "  adding: training_datas/train_data2654.zip (stored 0%)\n",
            "  adding: training_datas/train_data22199.zip (stored 0%)\n",
            "  adding: training_datas/train_data26681.zip (stored 0%)\n",
            "  adding: training_datas/train_data26974.zip (stored 0%)\n",
            "  adding: training_datas/train_data20586.zip (stored 0%)\n",
            "  adding: training_datas/train_data11623.zip (stored 0%)\n",
            "  adding: training_datas/train_data16127.zip (stored 0%)\n",
            "  adding: training_datas/train_data23378.zip (stored 0%)\n",
            "  adding: training_datas/train_data29291.zip (stored 0%)\n",
            "  adding: training_datas/train_data16966.zip (stored 0%)\n",
            "  adding: training_datas/train_data27304.zip (stored 0%)\n",
            "  adding: training_datas/train_data9228.zip (stored 0%)\n",
            "  adding: training_datas/train_data16382.zip (stored 0%)\n",
            "  adding: training_datas/train_data21197.zip (stored 0%)\n",
            "  adding: training_datas/train_data2234.zip (stored 0%)\n",
            "  adding: training_datas/train_data16172.zip (stored 0%)\n",
            "  adding: training_datas/train_data4222.zip (stored 0%)\n",
            "  adding: training_datas/train_data21786.zip (stored 0%)\n",
            "  adding: training_datas/train_data7526.zip (stored 0%)\n",
            "  adding: training_datas/train_data12957.zip (stored 0%)\n",
            "  adding: training_datas/train_data10422.zip (stored 0%)\n",
            "  adding: training_datas/train_data14312.zip (stored 0%)\n",
            "  adding: training_datas/train_data15618.zip (stored 0%)\n",
            "  adding: training_datas/train_data9723.zip (stored 0%)\n",
            "  adding: training_datas/train_data1655.zip (stored 0%)\n",
            "  adding: training_datas/train_data6485.zip (stored 0%)\n",
            "  adding: training_datas/train_data2394.zip (stored 0%)\n",
            "  adding: training_datas/train_data2572.zip (stored 0%)\n",
            "  adding: training_datas/train_data21250.zip (stored 0%)\n",
            "  adding: training_datas/train_data16882.zip (stored 0%)\n",
            "  adding: training_datas/train_data23609.zip (stored 0%)\n",
            "  adding: training_datas/train_data10546.zip (stored 0%)\n",
            "  adding: training_datas/train_data16539.zip (stored 0%)\n",
            "  adding: training_datas/train_data2133.zip (stored 0%)\n",
            "  adding: training_datas/train_data24152.zip (stored 0%)\n",
            "  adding: training_datas/train_data3713.zip (stored 0%)\n",
            "  adding: training_datas/train_data1712.zip (stored 0%)\n",
            "  adding: training_datas/train_data30322.zip (stored 0%)\n",
            "  adding: training_datas/train_data19530.zip (stored 0%)\n",
            "  adding: training_datas/train_data9484.zip (stored 0%)\n",
            "  adding: training_datas/train_data4097.zip (stored 0%)\n",
            "  adding: training_datas/train_data4744.zip (stored 0%)\n",
            "  adding: training_datas/train_data9599.zip (stored 0%)\n",
            "  adding: training_datas/train_data16222.zip (stored 0%)\n",
            "  adding: training_datas/train_data21292.zip (stored 0%)\n",
            "  adding: training_datas/train_data22187.zip (stored 0%)\n",
            "  adding: training_datas/train_data16218.zip (stored 0%)\n",
            "  adding: training_datas/train_data28254.zip (stored 0%)\n",
            "  adding: training_datas/train_data14107.zip (stored 0%)\n",
            "  adding: training_datas/train_data28393.zip (stored 0%)\n",
            "  adding: training_datas/train_data13412.zip (stored 0%)\n",
            "  adding: training_datas/train_data26121.zip (stored 0%)\n",
            "  adding: training_datas/train_data18756.zip (stored 0%)\n",
            "  adding: training_datas/train_data26330.zip (stored 0%)\n",
            "  adding: training_datas/train_data13103.zip (stored 0%)\n",
            "  adding: training_datas/train_data14343.zip (stored 0%)\n",
            "  adding: training_datas/train_data24081.zip (stored 0%)\n",
            "  adding: training_datas/train_data28599.zip (stored 0%)\n",
            "  adding: training_datas/train_data11362.zip (stored 0%)\n",
            "  adding: training_datas/train_data15859.zip (stored 0%)\n",
            "  adding: training_datas/train_data6032.zip (stored 0%)\n",
            "  adding: training_datas/train_data27919.zip (stored 0%)\n",
            "  adding: training_datas/train_data26877.zip (stored 0%)\n",
            "  adding: training_datas/train_data7742.zip (stored 0%)\n",
            "  adding: training_datas/train_data18909.zip (stored 0%)\n",
            "  adding: training_datas/train_data29224.zip (stored 0%)\n",
            "  adding: training_datas/train_data9149.zip (stored 0%)\n",
            "  adding: training_datas/train_data14620.zip (stored 0%)\n",
            "  adding: training_datas/train_data20023.zip (stored 0%)\n",
            "  adding: training_datas/train_data3472.zip (stored 0%)\n",
            "  adding: training_datas/train_data3932.zip (stored 0%)\n",
            "  adding: training_datas/train_data18082.zip (stored 0%)\n",
            "  adding: training_datas/train_data20375.zip (stored 0%)\n",
            "  adding: training_datas/train_data30045.zip (stored 0%)\n",
            "  adding: training_datas/train_data6145.zip (stored 0%)\n",
            "  adding: training_datas/train_data15128.zip (stored 0%)\n",
            "  adding: training_datas/train_data10427.zip (stored 0%)\n",
            "  adding: training_datas/train_data19889.zip (stored 0%)\n",
            "  adding: training_datas/train_data22290.zip (stored 0%)\n",
            "  adding: training_datas/train_data1703.zip (stored 0%)\n",
            "  adding: training_datas/train_data23018.zip (stored 0%)\n",
            "  adding: training_datas/train_data2763.zip (stored 0%)\n",
            "  adding: training_datas/train_data20102.zip (stored 0%)\n",
            "  adding: training_datas/train_data956.zip (stored 0%)\n",
            "  adding: training_datas/train_data19580.zip (stored 0%)\n",
            "  adding: training_datas/train_data5177.zip (stored 0%)\n",
            "  adding: training_datas/train_data20153.zip (stored 0%)\n",
            "  adding: training_datas/train_data13825.zip (stored 0%)\n",
            "  adding: training_datas/train_data21222.zip (stored 0%)\n",
            "  adding: training_datas/train_data15538.zip (stored 0%)\n",
            "  adding: training_datas/train_data4909.zip (stored 0%)\n",
            "  adding: training_datas/train_data13907.zip (stored 0%)\n",
            "  adding: training_datas/train_data27862.zip (stored 0%)\n",
            "  adding: training_datas/train_data21675.zip (stored 0%)\n",
            "  adding: training_datas/train_data1732.zip (stored 0%)\n",
            "  adding: training_datas/train_data23539.zip (stored 0%)\n",
            "  adding: training_datas/train_data18497.zip (stored 0%)\n",
            "  adding: training_datas/train_data16209.zip (stored 0%)\n",
            "  adding: training_datas/train_data15527.zip (stored 0%)\n",
            "  adding: training_datas/train_data18431.zip (stored 0%)\n",
            "  adding: training_datas/train_data14471.zip (stored 0%)\n",
            "  adding: training_datas/train_data7640.zip (stored 0%)\n",
            "  adding: training_datas/train_data1365.zip (stored 0%)\n",
            "  adding: training_datas/train_data23122.zip (stored 0%)\n",
            "  adding: training_datas/train_data13784.zip (stored 0%)\n",
            "  adding: training_datas/train_data20801.zip (stored 0%)\n",
            "  adding: training_datas/train_data14985.zip (stored 0%)\n",
            "  adding: training_datas/train_data10323.zip (stored 0%)\n",
            "  adding: training_datas/train_data20355.zip (stored 0%)\n",
            "  adding: training_datas/train_data2663.zip (stored 0%)\n",
            "  adding: training_datas/train_data6492.zip (stored 0%)\n",
            "  adding: training_datas/train_data15444.zip (stored 0%)\n",
            "  adding: training_datas/train_data11376.zip (stored 0%)\n",
            "  adding: training_datas/train_data14708.zip (stored 0%)\n",
            "  adding: training_datas/train_data12885.zip (stored 0%)\n",
            "  adding: training_datas/train_data8793.zip (stored 0%)\n",
            "  adding: training_datas/train_data18987.zip (stored 0%)\n",
            "  adding: training_datas/train_data18870.zip (stored 0%)\n",
            "  adding: training_datas/train_data13385.zip (stored 0%)\n",
            "  adding: training_datas/train_data24629.zip (stored 0%)\n",
            "  adding: training_datas/train_data1120.zip (stored 0%)\n",
            "  adding: training_datas/train_data3979.zip (stored 0%)\n",
            "  adding: training_datas/train_data21847.zip (stored 0%)\n",
            "  adding: training_datas/train_data24051.zip (stored 0%)\n",
            "  adding: training_datas/train_data4039.zip (stored 0%)\n",
            "  adding: training_datas/train_data27006.zip (stored 0%)\n",
            "  adding: training_datas/train_data18610.zip (stored 0%)\n",
            "  adding: training_datas/train_data10584.zip (stored 0%)\n",
            "  adding: training_datas/train_data21737.zip (stored 0%)\n",
            "  adding: training_datas/train_data20610.zip (stored 0%)\n",
            "  adding: training_datas/train_data3870.zip (stored 0%)\n",
            "  adding: training_datas/train_data8098.zip (stored 0%)\n",
            "  adding: training_datas/train_data18720.zip (stored 0%)\n",
            "  adding: training_datas/train_data16497.zip (stored 0%)\n",
            "  adding: training_datas/train_data21412.zip (stored 0%)\n",
            "  adding: training_datas/train_data3296.zip (stored 0%)\n",
            "  adding: training_datas/train_data1957.zip (stored 0%)\n",
            "  adding: training_datas/train_data3101.zip (stored 0%)\n",
            "  adding: training_datas/train_data6310.zip (stored 0%)\n",
            "  adding: training_datas/train_data24109.zip (stored 0%)\n",
            "  adding: training_datas/train_data537.zip (stored 0%)\n",
            "  adding: training_datas/train_data3105.zip (stored 0%)\n",
            "  adding: training_datas/train_data8678.zip (stored 0%)\n",
            "  adding: training_datas/train_data1362.zip (stored 0%)\n",
            "  adding: training_datas/train_data24589.zip (stored 0%)\n",
            "  adding: training_datas/train_data6868.zip (stored 0%)\n",
            "  adding: training_datas/train_data25877.zip (stored 0%)\n",
            "  adding: training_datas/train_data10271.zip (stored 0%)\n",
            "  adding: training_datas/train_data9013.zip (stored 0%)\n",
            "  adding: training_datas/train_data30328.zip (stored 0%)\n",
            "  adding: training_datas/train_data18666.zip (stored 0%)\n",
            "  adding: training_datas/train_data7935.zip (stored 0%)\n",
            "  adding: training_datas/train_data11555.zip (stored 0%)\n",
            "  adding: training_datas/train_data2065.zip (stored 0%)\n",
            "  adding: training_datas/train_data16647.zip (stored 0%)\n",
            "  adding: training_datas/train_data15949.zip (stored 0%)\n",
            "  adding: training_datas/train_data27691.zip (stored 0%)\n",
            "  adding: training_datas/train_data23927.zip (stored 0%)\n",
            "  adding: training_datas/train_data28756.zip (stored 0%)\n",
            "  adding: training_datas/train_data29102.zip (stored 0%)\n",
            "  adding: training_datas/train_data24248.zip (stored 0%)\n",
            "  adding: training_datas/train_data25899.zip (stored 0%)\n",
            "  adding: training_datas/train_data20658.zip (stored 0%)\n",
            "  adding: training_datas/train_data9682.zip (stored 0%)\n",
            "  adding: training_datas/train_data23541.zip (stored 0%)\n",
            "  adding: training_datas/train_data17110.zip (stored 0%)\n",
            "  adding: training_datas/train_data218.zip (stored 0%)\n",
            "  adding: training_datas/train_data17595.zip (stored 0%)\n",
            "  adding: training_datas/train_data18510.zip (stored 0%)\n",
            "  adding: training_datas/train_data1417.zip (stored 0%)\n",
            "  adding: training_datas/train_data714.zip (stored 0%)\n",
            "  adding: training_datas/train_data18185.zip (stored 0%)\n",
            "  adding: training_datas/train_data27536.zip (stored 0%)\n",
            "  adding: training_datas/train_data12459.zip (stored 0%)\n",
            "  adding: training_datas/train_data14617.zip (stored 0%)\n",
            "  adding: training_datas/train_data15654.zip (stored 0%)\n",
            "  adding: training_datas/train_data1997.zip (stored 0%)\n",
            "  adding: training_datas/train_data19240.zip (stored 0%)\n",
            "  adding: training_datas/train_data23628.zip (stored 0%)\n",
            "  adding: training_datas/train_data16987.zip (stored 0%)\n",
            "  adding: training_datas/train_data8898.zip (stored 0%)\n",
            "  adding: training_datas/train_data5650.zip (stored 0%)\n",
            "  adding: training_datas/train_data12584.zip (stored 0%)\n",
            "  adding: training_datas/train_data10070.zip (stored 0%)\n",
            "  adding: training_datas/train_data8516.zip (stored 0%)\n",
            "  adding: training_datas/train_data24026.zip (stored 0%)\n",
            "  adding: training_datas/train_data26662.zip (stored 0%)\n",
            "  adding: training_datas/train_data16131.zip (stored 0%)\n",
            "  adding: training_datas/train_data7388.zip (stored 0%)\n",
            "  adding: training_datas/train_data21516.zip (stored 0%)\n",
            "  adding: training_datas/train_data17477.zip (stored 0%)\n",
            "  adding: training_datas/train_data30131.zip (stored 0%)\n",
            "  adding: training_datas/train_data3306.zip (stored 0%)\n",
            "  adding: training_datas/train_data24399.zip (stored 0%)\n",
            "  adding: training_datas/train_data18981.zip (stored 0%)\n",
            "  adding: training_datas/train_data11346.zip (stored 0%)\n",
            "  adding: training_datas/train_data5293.zip (stored 0%)\n",
            "  adding: training_datas/train_data22803.zip (stored 0%)\n",
            "  adding: training_datas/train_data7369.zip (stored 0%)\n",
            "  adding: training_datas/train_data17325.zip (stored 0%)\n",
            "  adding: training_datas/train_data25810.zip (stored 0%)\n",
            "  adding: training_datas/train_data10043.zip (stored 0%)\n",
            "  adding: training_datas/train_data2883.zip (stored 0%)\n",
            "  adding: training_datas/train_data28326.zip (stored 0%)\n",
            "  adding: training_datas/train_data8577.zip (stored 0%)\n",
            "  adding: training_datas/train_data30064.zip (stored 0%)\n",
            "  adding: training_datas/train_data9830.zip (stored 0%)\n",
            "  adding: training_datas/train_data21688.zip (stored 0%)\n",
            "  adding: training_datas/train_data22057.zip (stored 0%)\n",
            "  adding: training_datas/train_data8072.zip (stored 0%)\n",
            "  adding: training_datas/train_data27396.zip (stored 0%)\n",
            "  adding: training_datas/train_data8701.zip (stored 0%)\n",
            "  adding: training_datas/train_data3232.zip (stored 0%)\n",
            "  adding: training_datas/train_data28932.zip (stored 0%)\n",
            "  adding: training_datas/train_data3633.zip (stored 0%)\n",
            "  adding: training_datas/train_data15440.zip (stored 0%)\n",
            "  adding: training_datas/train_data637.zip (stored 0%)\n",
            "  adding: training_datas/train_data2775.zip (stored 0%)\n",
            "  adding: training_datas/train_data11012.zip (stored 0%)\n",
            "  adding: training_datas/train_data21766.zip (stored 0%)\n",
            "  adding: training_datas/train_data5690.zip (stored 0%)\n",
            "  adding: training_datas/train_data96.zip (stored 0%)\n",
            "  adding: training_datas/train_data4290.zip (stored 0%)\n",
            "  adding: training_datas/train_data392.zip (stored 0%)\n",
            "  adding: training_datas/train_data12134.zip (stored 0%)\n",
            "  adding: training_datas/train_data6477.zip (stored 0%)\n",
            "  adding: training_datas/train_data3295.zip (stored 0%)\n",
            "  adding: training_datas/train_data6717.zip (stored 0%)\n",
            "  adding: training_datas/train_data28457.zip (stored 0%)\n",
            "  adding: training_datas/train_data25108.zip (stored 0%)\n",
            "  adding: training_datas/train_data29668.zip (stored 0%)\n",
            "  adding: training_datas/train_data26095.zip (stored 0%)\n",
            "  adding: training_datas/train_data19687.zip (stored 0%)\n",
            "  adding: training_datas/train_data22566.zip (stored 0%)\n",
            "  adding: training_datas/train_data19113.zip (stored 0%)\n",
            "  adding: training_datas/train_data5826.zip (stored 0%)\n",
            "  adding: training_datas/train_data5409.zip (stored 0%)\n",
            "  adding: training_datas/train_data9396.zip (stored 0%)\n",
            "  adding: training_datas/train_data15900.zip (stored 0%)\n",
            "  adding: training_datas/train_data7621.zip (stored 0%)\n",
            "  adding: training_datas/train_data16374.zip (stored 0%)\n",
            "  adding: training_datas/train_data21715.zip (stored 0%)\n",
            "  adding: training_datas/train_data17918.zip (stored 0%)\n",
            "  adding: training_datas/train_data1421.zip (stored 0%)\n",
            "  adding: training_datas/train_data22930.zip (stored 0%)\n",
            "  adding: training_datas/train_data6142.zip (stored 0%)\n",
            "  adding: training_datas/train_data22153.zip (stored 0%)\n",
            "  adding: training_datas/train_data10750.zip (stored 0%)\n",
            "  adding: training_datas/train_data7550.zip (stored 0%)\n",
            "  adding: training_datas/train_data15866.zip (stored 0%)\n",
            "  adding: training_datas/train_data3950.zip (stored 0%)\n",
            "  adding: training_datas/train_data22941.zip (stored 0%)\n",
            "  adding: training_datas/train_data13434.zip (stored 0%)\n",
            "  adding: training_datas/train_data15581.zip (stored 0%)\n",
            "  adding: training_datas/train_data23726.zip (stored 0%)\n",
            "  adding: training_datas/train_data7728.zip (stored 0%)\n",
            "  adding: training_datas/train_data5736.zip (stored 0%)\n",
            "  adding: training_datas/train_data10562.zip (stored 0%)\n",
            "  adding: training_datas/train_data19122.zip (stored 0%)\n",
            "  adding: training_datas/train_data19811.zip (stored 0%)\n",
            "  adding: training_datas/train_data19243.zip (stored 0%)\n",
            "  adding: training_datas/train_data6126.zip (stored 0%)\n",
            "  adding: training_datas/train_data23840.zip (stored 0%)\n",
            "  adding: training_datas/train_data29852.zip (stored 0%)\n",
            "  adding: training_datas/train_data21159.zip (stored 0%)\n",
            "  adding: training_datas/train_data4605.zip (stored 0%)\n",
            "  adding: training_datas/train_data26979.zip (stored 0%)\n",
            "  adding: training_datas/train_data9499.zip (stored 0%)\n",
            "  adding: training_datas/train_data2303.zip (stored 0%)\n",
            "  adding: training_datas/train_data20585.zip (stored 0%)\n",
            "  adding: training_datas/train_data23875.zip (stored 0%)\n",
            "  adding: training_datas/train_data29786.zip (stored 0%)\n",
            "  adding: training_datas/train_data992.zip (stored 0%)\n",
            "  adding: training_datas/train_data24274.zip (stored 0%)\n",
            "  adding: training_datas/train_data21177.zip (stored 0%)\n",
            "  adding: training_datas/train_data1104.zip (stored 0%)\n",
            "  adding: training_datas/train_data8927.zip (stored 0%)\n",
            "  adding: training_datas/train_data27516.zip (stored 0%)\n",
            "  adding: training_datas/train_data18958.zip (stored 0%)\n",
            "  adding: training_datas/train_data17612.zip (stored 0%)\n",
            "  adding: training_datas/train_data5706.zip (stored 0%)\n",
            "  adding: training_datas/train_data30256.zip (stored 0%)\n",
            "  adding: training_datas/train_data4920.zip (stored 0%)\n",
            "  adding: training_datas/train_data26902.zip (stored 0%)\n",
            "  adding: training_datas/train_data8176.zip (stored 0%)\n",
            "  adding: training_datas/train_data11107.zip (stored 0%)\n",
            "  adding: training_datas/train_data27830.zip (stored 0%)\n",
            "  adding: training_datas/train_data11583.zip (stored 0%)\n",
            "  adding: training_datas/train_data2067.zip (stored 0%)\n",
            "  adding: training_datas/train_data142.zip (stored 0%)\n",
            "  adding: training_datas/train_data20635.zip (stored 0%)\n",
            "  adding: training_datas/train_data19198.zip (stored 0%)\n",
            "  adding: training_datas/train_data1615.zip (stored 0%)\n",
            "  adding: training_datas/train_data5266.zip (stored 0%)\n",
            "  adding: training_datas/train_data3665.zip (stored 0%)\n",
            "  adding: training_datas/train_data8807.zip (stored 0%)\n",
            "  adding: training_datas/train_data5020.zip (stored 0%)\n",
            "  adding: training_datas/train_data3559.zip (stored 0%)\n",
            "  adding: training_datas/train_data4152.zip (stored 0%)\n",
            "  adding: training_datas/train_data24332.zip (stored 0%)\n",
            "  adding: training_datas/train_data29527.zip (stored 0%)\n",
            "  adding: training_datas/train_data10326.zip (stored 0%)\n",
            "  adding: training_datas/train_data3981.zip (stored 0%)\n",
            "  adding: training_datas/train_data24334.zip (stored 0%)\n",
            "  adding: training_datas/train_data22692.zip (stored 0%)\n",
            "  adding: training_datas/train_data26709.zip (stored 0%)\n",
            "  adding: training_datas/train_data24996.zip (stored 0%)\n",
            "  adding: training_datas/train_data9083.zip (stored 0%)\n",
            "  adding: training_datas/train_data20128.zip (stored 0%)\n",
            "  adding: training_datas/train_data14494.zip (stored 0%)\n",
            "  adding: training_datas/train_data19022.zip (stored 0%)\n",
            "  adding: training_datas/train_data1538.zip (stored 0%)\n",
            "  adding: training_datas/train_data19912.zip (stored 0%)\n",
            "  adding: training_datas/train_data23920.zip (stored 0%)\n",
            "  adding: training_datas/train_data13986.zip (stored 0%)\n",
            "  adding: training_datas/train_data26452.zip (stored 0%)\n",
            "  adding: training_datas/train_data26927.zip (stored 0%)\n",
            "  adding: training_datas/train_data16654.zip (stored 0%)\n",
            "  adding: training_datas/train_data24276.zip (stored 0%)\n",
            "  adding: training_datas/train_data4587.zip (stored 0%)\n",
            "  adding: training_datas/train_data10246.zip (stored 0%)\n",
            "  adding: training_datas/train_data8549.zip (stored 0%)\n",
            "  adding: training_datas/train_data26763.zip (stored 0%)\n",
            "  adding: training_datas/train_data3808.zip (stored 0%)\n",
            "  adding: training_datas/train_data3018.zip (stored 0%)\n",
            "  adding: training_datas/train_data30079.zip (stored 0%)\n",
            "  adding: training_datas/train_data24056.zip (stored 0%)\n",
            "  adding: training_datas/train_data11567.zip (stored 0%)\n",
            "  adding: training_datas/train_data3968.zip (stored 0%)\n",
            "  adding: training_datas/train_data16830.zip (stored 0%)\n",
            "  adding: training_datas/train_data15267.zip (stored 0%)\n",
            "  adding: training_datas/train_data18732.zip (stored 0%)\n",
            "  adding: training_datas/train_data26096.zip (stored 0%)\n",
            "  adding: training_datas/train_data29054.zip (stored 0%)\n",
            "  adding: training_datas/train_data9689.zip (stored 0%)\n",
            "  adding: training_datas/train_data23939.zip (stored 0%)\n",
            "  adding: training_datas/train_data10622.zip (stored 0%)\n",
            "  adding: training_datas/train_data6007.zip (stored 0%)\n",
            "  adding: training_datas/train_data27350.zip (stored 0%)\n",
            "  adding: training_datas/train_data3951.zip (stored 0%)\n",
            "  adding: training_datas/train_data1442.zip (stored 0%)\n",
            "  adding: training_datas/train_data15348.zip (stored 0%)\n",
            "  adding: training_datas/train_data12675.zip (stored 0%)\n",
            "  adding: training_datas/train_data23259.zip (stored 0%)\n",
            "  adding: training_datas/train_data850.zip (stored 0%)\n",
            "  adding: training_datas/train_data20129.zip (stored 0%)\n",
            "  adding: training_datas/train_data20120.zip (stored 0%)\n",
            "  adding: training_datas/train_data7532.zip (stored 0%)\n",
            "  adding: training_datas/train_data3242.zip (stored 0%)\n",
            "  adding: training_datas/train_data28320.zip (stored 0%)\n",
            "  adding: training_datas/train_data17556.zip (stored 0%)\n",
            "  adding: training_datas/train_data2432.zip (stored 0%)\n",
            "  adding: training_datas/train_data26708.zip (stored 0%)\n",
            "  adding: training_datas/train_data4043.zip (stored 0%)\n",
            "  adding: training_datas/train_data20728.zip (stored 0%)\n",
            "  adding: training_datas/train_data17147.zip (stored 0%)\n",
            "  adding: training_datas/train_data17237.zip (stored 0%)\n",
            "  adding: training_datas/train_data2983.zip (stored 0%)\n",
            "  adding: training_datas/train_data2162.zip (stored 0%)\n",
            "  adding: training_datas/train_data1503.zip (stored 0%)\n",
            "  adding: training_datas/train_data14649.zip (stored 0%)\n",
            "  adding: training_datas/train_data11188.zip (stored 0%)\n",
            "  adding: training_datas/train_data24083.zip (stored 0%)\n",
            "  adding: training_datas/train_data18827.zip (stored 0%)\n",
            "  adding: training_datas/train_data8010.zip (stored 0%)\n",
            "  adding: training_datas/train_data26001.zip (stored 0%)\n",
            "  adding: training_datas/train_data2194.zip (stored 0%)\n",
            "  adding: training_datas/train_data10025.zip (stored 0%)\n",
            "  adding: training_datas/train_data9119.zip (stored 0%)\n",
            "  adding: training_datas/train_data14695.zip (stored 0%)\n",
            "  adding: training_datas/train_data4945.zip (stored 0%)\n",
            "  adding: training_datas/train_data29138.zip (stored 0%)\n",
            "  adding: training_datas/train_data25888.zip (stored 0%)\n",
            "  adding: training_datas/train_data17668.zip (stored 0%)\n",
            "  adding: training_datas/train_data28910.zip (stored 0%)\n",
            "  adding: training_datas/train_data11011.zip (stored 0%)\n",
            "  adding: training_datas/train_data18098.zip (stored 0%)\n",
            "  adding: training_datas/train_data14804.zip (stored 0%)\n",
            "  adding: training_datas/train_data29624.zip (stored 0%)\n",
            "  adding: training_datas/train_data27966.zip (stored 0%)\n",
            "  adding: training_datas/train_data7451.zip (stored 0%)\n",
            "  adding: training_datas/train_data7864.zip (stored 0%)\n",
            "  adding: training_datas/train_data3384.zip (stored 0%)\n",
            "  adding: training_datas/train_data23102.zip (stored 0%)\n",
            "  adding: training_datas/train_data16153.zip (stored 0%)\n",
            "  adding: training_datas/train_data6787.zip (stored 0%)\n",
            "  adding: training_datas/train_data17721.zip (stored 0%)\n",
            "  adding: training_datas/train_data21025.zip (stored 0%)\n",
            "  adding: training_datas/train_data26202.zip (stored 0%)\n",
            "  adding: training_datas/train_data10927.zip (stored 0%)\n",
            "  adding: training_datas/train_data613.zip (stored 0%)\n",
            "  adding: training_datas/train_data29528.zip (stored 0%)\n",
            "  adding: training_datas/train_data3899.zip (stored 0%)\n",
            "  adding: training_datas/train_data190.zip (stored 0%)\n",
            "  adding: training_datas/train_data20189.zip (stored 0%)\n",
            "  adding: training_datas/train_data23630.zip (stored 0%)\n",
            "  adding: training_datas/train_data15984.zip (stored 0%)\n",
            "  adding: training_datas/train_data22397.zip (stored 0%)\n",
            "  adding: training_datas/train_data14754.zip (stored 0%)\n",
            "  adding: training_datas/train_data17573.zip (stored 0%)\n",
            "  adding: training_datas/train_data4856.zip (stored 0%)\n",
            "  adding: training_datas/train_data18241.zip (stored 0%)\n",
            "  adding: training_datas/train_data14405.zip (stored 0%)\n",
            "  adding: training_datas/train_data15240.zip (stored 0%)\n",
            "  adding: training_datas/train_data29729.zip (stored 0%)\n",
            "  adding: training_datas/train_data13591.zip (stored 0%)\n",
            "  adding: training_datas/train_data2493.zip (stored 0%)\n",
            "  adding: training_datas/train_data1112.zip (stored 0%)\n",
            "  adding: training_datas/train_data9771.zip (stored 0%)\n",
            "  adding: training_datas/train_data11617.zip (stored 0%)\n",
            "  adding: training_datas/train_data25941.zip (stored 0%)\n",
            "  adding: training_datas/train_data18197.zip (stored 0%)\n",
            "  adding: training_datas/train_data11225.zip (stored 0%)\n",
            "  adding: training_datas/train_data28151.zip (stored 0%)\n",
            "  adding: training_datas/train_data14331.zip (stored 0%)\n",
            "  adding: training_datas/train_data3237.zip (stored 0%)\n",
            "  adding: training_datas/train_data2095.zip (stored 0%)\n",
            "  adding: training_datas/train_data18311.zip (stored 0%)\n",
            "  adding: training_datas/train_data22953.zip (stored 0%)\n",
            "  adding: training_datas/train_data14974.zip (stored 0%)\n",
            "  adding: training_datas/train_data29640.zip (stored 0%)\n",
            "  adding: training_datas/train_data12948.zip (stored 0%)\n",
            "  adding: training_datas/train_data26556.zip (stored 0%)\n",
            "  adding: training_datas/train_data18151.zip (stored 0%)\n",
            "  adding: training_datas/train_data26161.zip (stored 0%)\n",
            "  adding: training_datas/train_data359.zip (stored 0%)\n",
            "  adding: training_datas/train_data27834.zip (stored 0%)\n",
            "  adding: training_datas/train_data4608.zip (stored 0%)\n",
            "  adding: training_datas/train_data14388.zip (stored 0%)\n",
            "  adding: training_datas/train_data20417.zip (stored 0%)\n",
            "  adding: training_datas/train_data9963.zip (stored 0%)\n",
            "  adding: training_datas/train_data3524.zip (stored 0%)\n",
            "  adding: training_datas/train_data9988.zip (stored 0%)\n",
            "  adding: training_datas/train_data29931.zip (stored 0%)\n",
            "  adding: training_datas/train_data17617.zip (stored 0%)\n",
            "  adding: training_datas/train_data5418.zip (stored 0%)\n",
            "  adding: training_datas/train_data30100.zip (stored 0%)\n",
            "  adding: training_datas/train_data1095.zip (stored 0%)\n",
            "  adding: training_datas/train_data26532.zip (stored 0%)\n",
            "  adding: training_datas/train_data14602.zip (stored 0%)\n",
            "  adding: training_datas/train_data26501.zip (stored 0%)\n",
            "  adding: training_datas/train_data6618.zip (stored 0%)\n",
            "  adding: training_datas/train_data2511.zip (stored 0%)\n",
            "  adding: training_datas/train_data8184.zip (stored 0%)\n",
            "  adding: training_datas/train_data18273.zip (stored 0%)\n",
            "  adding: training_datas/train_data9935.zip (stored 0%)\n",
            "  adding: training_datas/train_data21435.zip (stored 0%)\n",
            "  adding: training_datas/train_data10169.zip (stored 0%)\n",
            "  adding: training_datas/train_data29289.zip (stored 0%)\n",
            "  adding: training_datas/train_data12149.zip (stored 0%)\n",
            "  adding: training_datas/train_data23449.zip (stored 0%)\n",
            "  adding: training_datas/train_data10936.zip (stored 0%)\n",
            "  adding: training_datas/train_data23502.zip (stored 0%)\n",
            "  adding: training_datas/train_data3961.zip (stored 0%)\n",
            "  adding: training_datas/train_data12824.zip (stored 0%)\n",
            "  adding: training_datas/train_data14156.zip (stored 0%)\n",
            "  adding: training_datas/train_data29208.zip (stored 0%)\n",
            "  adding: training_datas/train_data26228.zip (stored 0%)\n",
            "  adding: training_datas/train_data17910.zip (stored 0%)\n",
            "  adding: training_datas/train_data4032.zip (stored 0%)\n",
            "  adding: training_datas/train_data21484.zip (stored 0%)\n",
            "  adding: training_datas/train_data19524.zip (stored 0%)\n",
            "  adding: training_datas/train_data24186.zip (stored 0%)\n",
            "  adding: training_datas/train_data19553.zip (stored 0%)\n",
            "  adding: training_datas/train_data17187.zip (stored 0%)\n",
            "  adding: training_datas/train_data547.zip (stored 0%)\n",
            "  adding: training_datas/train_data27961.zip (stored 0%)\n",
            "  adding: training_datas/train_data8756.zip (stored 0%)\n",
            "  adding: training_datas/train_data5928.zip (stored 0%)\n",
            "  adding: training_datas/train_data17473.zip (stored 0%)\n",
            "  adding: training_datas/train_data12858.zip (stored 0%)\n",
            "  adding: training_datas/train_data5607.zip (stored 0%)\n",
            "  adding: training_datas/train_data16563.zip (stored 0%)\n",
            "  adding: training_datas/train_data4003.zip (stored 0%)\n",
            "  adding: training_datas/train_data885.zip (stored 0%)\n",
            "  adding: training_datas/train_data21546.zip (stored 0%)\n",
            "  adding: training_datas/train_data454.zip (stored 0%)\n",
            "  adding: training_datas/train_data11826.zip (stored 0%)\n",
            "  adding: training_datas/train_data7555.zip (stored 0%)\n",
            "  adding: training_datas/train_data17596.zip (stored 0%)\n",
            "  adding: training_datas/train_data29547.zip (stored 0%)\n",
            "  adding: training_datas/train_data2732.zip (stored 0%)\n",
            "  adding: training_datas/train_data13609.zip (stored 0%)\n",
            "  adding: training_datas/train_data7493.zip (stored 0%)\n",
            "  adding: training_datas/train_data3122.zip (stored 0%)\n",
            "  adding: training_datas/train_data20670.zip (stored 0%)\n",
            "  adding: training_datas/train_data26075.zip (stored 0%)\n",
            "  adding: training_datas/train_data8353.zip (stored 0%)\n",
            "  adding: training_datas/train_data10586.zip (stored 0%)\n",
            "  adding: training_datas/train_data15359.zip (stored 0%)\n",
            "  adding: training_datas/train_data17410.zip (stored 0%)\n",
            "  adding: training_datas/train_data3497.zip (stored 0%)\n",
            "  adding: training_datas/train_data1270.zip (stored 0%)\n",
            "  adding: training_datas/train_data29331.zip (stored 0%)\n",
            "  adding: training_datas/train_data7122.zip (stored 0%)\n",
            "  adding: training_datas/train_data25900.zip (stored 0%)\n",
            "  adding: training_datas/train_data3380.zip (stored 0%)\n",
            "  adding: training_datas/train_data2873.zip (stored 0%)\n",
            "  adding: training_datas/train_data24231.zip (stored 0%)\n",
            "  adding: training_datas/train_data25320.zip (stored 0%)\n",
            "  adding: training_datas/train_data18755.zip (stored 0%)\n",
            "  adding: training_datas/train_data22289.zip (stored 0%)\n",
            "  adding: training_datas/train_data5891.zip (stored 0%)\n",
            "  adding: training_datas/train_data7082.zip (stored 0%)\n",
            "  adding: training_datas/train_data2546.zip (stored 0%)\n",
            "  adding: training_datas/train_data22242.zip (stored 0%)\n",
            "  adding: training_datas/train_data16600.zip (stored 0%)\n",
            "  adding: training_datas/train_data4831.zip (stored 0%)\n",
            "  adding: training_datas/train_data1400.zip (stored 0%)\n",
            "  adding: training_datas/train_data6082.zip (stored 0%)\n",
            "  adding: training_datas/train_data24262.zip (stored 0%)\n",
            "  adding: training_datas/train_data16282.zip (stored 0%)\n",
            "  adding: training_datas/train_data29923.zip (stored 0%)\n",
            "  adding: training_datas/train_data4452.zip (stored 0%)\n",
            "  adding: training_datas/train_data6806.zip (stored 0%)\n",
            "  adding: training_datas/train_data24702.zip (stored 0%)\n",
            "  adding: training_datas/train_data16251.zip (stored 0%)\n",
            "  adding: training_datas/train_data28963.zip (stored 0%)\n",
            "  adding: training_datas/train_data25431.zip (stored 0%)\n",
            "  adding: training_datas/train_data20597.zip (stored 0%)\n",
            "  adding: training_datas/train_data7869.zip (stored 0%)\n",
            "  adding: training_datas/train_data25682.zip (stored 0%)\n",
            "  adding: training_datas/train_data19701.zip (stored 0%)\n",
            "  adding: training_datas/train_data7736.zip (stored 0%)\n",
            "  adding: training_datas/train_data14143.zip (stored 0%)\n",
            "  adding: training_datas/train_data28645.zip (stored 0%)\n",
            "  adding: training_datas/train_data16335.zip (stored 0%)\n",
            "  adding: training_datas/train_data6555.zip (stored 0%)\n",
            "  adding: training_datas/train_data740.zip (stored 0%)\n",
            "  adding: training_datas/train_data20335.zip (stored 0%)\n",
            "  adding: training_datas/train_data21986.zip (stored 0%)\n",
            "  adding: training_datas/train_data29711.zip (stored 0%)\n",
            "  adding: training_datas/train_data4533.zip (stored 0%)\n",
            "  adding: training_datas/train_data24247.zip (stored 0%)\n",
            "  adding: training_datas/train_data8891.zip (stored 0%)\n",
            "  adding: training_datas/train_data3844.zip (stored 0%)\n",
            "  adding: training_datas/train_data27584.zip (stored 0%)\n",
            "  adding: training_datas/train_data25187.zip (stored 0%)\n",
            "  adding: training_datas/train_data2632.zip (stored 0%)\n",
            "  adding: training_datas/train_data15875.zip (stored 0%)\n",
            "  adding: training_datas/train_data15357.zip (stored 0%)\n",
            "  adding: training_datas/train_data19497.zip (stored 0%)\n",
            "  adding: training_datas/train_data28807.zip (stored 0%)\n",
            "  adding: training_datas/train_data9758.zip (stored 0%)\n",
            "  adding: training_datas/train_data10829.zip (stored 0%)\n",
            "  adding: training_datas/train_data16193.zip (stored 0%)\n",
            "  adding: training_datas/train_data28965.zip (stored 0%)\n",
            "  adding: training_datas/train_data11794.zip (stored 0%)\n",
            "  adding: training_datas/train_data27560.zip (stored 0%)\n",
            "  adding: training_datas/train_data23399.zip (stored 0%)\n",
            "  adding: training_datas/train_data22180.zip (stored 0%)\n",
            "  adding: training_datas/train_data11082.zip (stored 0%)\n",
            "  adding: training_datas/train_data26052.zip (stored 0%)\n",
            "  adding: training_datas/train_data2398.zip (stored 0%)\n",
            "  adding: training_datas/train_data28700.zip (stored 0%)\n",
            "  adding: training_datas/train_data3970.zip (stored 0%)\n",
            "  adding: training_datas/train_data4713.zip (stored 0%)\n",
            "  adding: training_datas/train_data25924.zip (stored 0%)\n",
            "  adding: training_datas/train_data19233.zip (stored 0%)\n",
            "  adding: training_datas/train_data9591.zip (stored 0%)\n",
            "  adding: training_datas/train_data14451.zip (stored 0%)\n",
            "  adding: training_datas/train_data9890.zip (stored 0%)\n",
            "  adding: training_datas/train_data18804.zip (stored 0%)\n",
            "  adding: training_datas/train_data27620.zip (stored 0%)\n",
            "  adding: training_datas/train_data19413.zip (stored 0%)\n",
            "  adding: training_datas/train_data2966.zip (stored 0%)\n",
            "  adding: training_datas/train_data3362.zip (stored 0%)\n",
            "  adding: training_datas/train_data23140.zip (stored 0%)\n",
            "  adding: training_datas/train_data7414.zip (stored 0%)\n",
            "  adding: training_datas/train_data18741.zip (stored 0%)\n",
            "  adding: training_datas/train_data15339.zip (stored 0%)\n",
            "  adding: training_datas/train_data9974.zip (stored 0%)\n",
            "  adding: training_datas/train_data15956.zip (stored 0%)\n",
            "  adding: training_datas/train_data12318.zip (stored 0%)\n",
            "  adding: training_datas/train_data4316.zip (stored 0%)\n",
            "  adding: training_datas/train_data15224.zip (stored 0%)\n",
            "  adding: training_datas/train_data17044.zip (stored 0%)\n",
            "  adding: training_datas/train_data10102.zip (stored 0%)\n",
            "  adding: training_datas/train_data28191.zip (stored 0%)\n",
            "  adding: training_datas/train_data10912.zip (stored 0%)\n",
            "  adding: training_datas/train_data3347.zip (stored 0%)\n",
            "  adding: training_datas/train_data6757.zip (stored 0%)\n",
            "  adding: training_datas/train_data20434.zip (stored 0%)\n",
            "  adding: training_datas/train_data23087.zip (stored 0%)\n",
            "  adding: training_datas/train_data18386.zip (stored 0%)\n",
            "  adding: training_datas/train_data13894.zip (stored 0%)\n",
            "  adding: training_datas/train_data16473.zip (stored 0%)\n",
            "  adding: training_datas/train_data27598.zip (stored 0%)\n",
            "  adding: training_datas/train_data6592.zip (stored 0%)\n",
            "  adding: training_datas/train_data20745.zip (stored 0%)\n",
            "  adding: training_datas/train_data14702.zip (stored 0%)\n",
            "  adding: training_datas/train_data9009.zip (stored 0%)\n",
            "  adding: training_datas/train_data28439.zip (stored 0%)\n",
            "  adding: training_datas/train_data28446.zip (stored 0%)\n",
            "  adding: training_datas/train_data6682.zip (stored 0%)\n",
            "  adding: training_datas/train_data22298.zip (stored 0%)\n",
            "  adding: training_datas/train_data8191.zip (stored 0%)\n",
            "  adding: training_datas/train_data14031.zip (stored 0%)\n",
            "  adding: training_datas/train_data10098.zip (stored 0%)\n",
            "  adding: training_datas/train_data16110.zip (stored 0%)\n",
            "  adding: training_datas/train_data5698.zip (stored 0%)\n",
            "  adding: training_datas/train_data14007.zip (stored 0%)\n",
            "  adding: training_datas/train_data25359.zip (stored 0%)\n",
            "  adding: training_datas/train_data13777.zip (stored 0%)\n",
            "  adding: training_datas/train_data24279.zip (stored 0%)\n",
            "  adding: training_datas/train_data3572.zip (stored 0%)\n",
            "  adding: training_datas/train_data2993.zip (stored 0%)\n",
            "  adding: training_datas/train_data13304.zip (stored 0%)\n",
            "  adding: training_datas/train_data16201.zip (stored 0%)\n",
            "  adding: training_datas/train_data14258.zip (stored 0%)\n",
            "  adding: training_datas/train_data14501.zip (stored 0%)\n",
            "  adding: training_datas/train_data12876.zip (stored 0%)\n",
            "  adding: training_datas/train_data27748.zip (stored 0%)\n",
            "  adding: training_datas/train_data2737.zip (stored 0%)\n",
            "  adding: training_datas/train_data6674.zip (stored 0%)\n",
            "  adding: training_datas/train_data18789.zip (stored 0%)\n",
            "  adding: training_datas/train_data14829.zip (stored 0%)\n",
            "  adding: training_datas/train_data9379.zip (stored 0%)\n",
            "  adding: training_datas/train_data27787.zip (stored 0%)\n",
            "  adding: training_datas/train_data10163.zip (stored 0%)\n",
            "  adding: training_datas/train_data2345.zip (stored 0%)\n",
            "  adding: training_datas/train_data21957.zip (stored 0%)\n",
            "  adding: training_datas/train_data23874.zip (stored 0%)\n",
            "  adding: training_datas/train_data1711.zip (stored 0%)\n",
            "  adding: training_datas/train_data23187.zip (stored 0%)\n",
            "  adding: training_datas/train_data13764.zip (stored 0%)\n",
            "  adding: training_datas/train_data24061.zip (stored 0%)\n",
            "  adding: training_datas/train_data9655.zip (stored 0%)\n",
            "  adding: training_datas/train_data10718.zip (stored 0%)\n",
            "  adding: training_datas/train_data21900.zip (stored 0%)\n",
            "  adding: training_datas/train_data20182.zip (stored 0%)\n",
            "  adding: training_datas/train_data7273.zip (stored 0%)\n",
            "  adding: training_datas/train_data8457.zip (stored 0%)\n",
            "  adding: training_datas/train_data25403.zip (stored 0%)\n",
            "  adding: training_datas/train_data7048.zip (stored 0%)\n",
            "  adding: training_datas/train_data14185.zip (stored 0%)\n",
            "  adding: training_datas/train_data25142.zip (stored 0%)\n",
            "  adding: training_datas/train_data27587.zip (stored 0%)\n",
            "  adding: training_datas/train_data5939.zip (stored 0%)\n",
            "  adding: training_datas/train_data25113.zip (stored 0%)\n",
            "  adding: training_datas/train_data26721.zip (stored 0%)\n",
            "  adding: training_datas/train_data13739.zip (stored 0%)\n",
            "  adding: training_datas/train_data22280.zip (stored 0%)\n",
            "  adding: training_datas/train_data27643.zip (stored 0%)\n",
            "  adding: training_datas/train_data29747.zip (stored 0%)\n",
            "  adding: training_datas/train_data16185.zip (stored 0%)\n",
            "  adding: training_datas/train_data19799.zip (stored 0%)\n",
            "  adding: training_datas/train_data24498.zip (stored 0%)\n",
            "  adding: training_datas/train_data8910.zip (stored 0%)\n",
            "  adding: training_datas/train_data15824.zip (stored 0%)\n",
            "  adding: training_datas/train_data23226.zip (stored 0%)\n",
            "  adding: training_datas/train_data9788.zip (stored 0%)\n",
            "  adding: training_datas/train_data25227.zip (stored 0%)\n",
            "  adding: training_datas/train_data14148.zip (stored 0%)\n",
            "  adding: training_datas/train_data27143.zip (stored 0%)\n",
            "  adding: training_datas/train_data1561.zip (stored 0%)\n",
            "  adding: training_datas/train_data15994.zip (stored 0%)\n",
            "  adding: training_datas/train_data19414.zip (stored 0%)\n",
            "  adding: training_datas/train_data25060.zip (stored 0%)\n",
            "  adding: training_datas/train_data12729.zip (stored 0%)\n",
            "  adding: training_datas/train_data5827.zip (stored 0%)\n",
            "  adding: training_datas/train_data4224.zip (stored 0%)\n",
            "  adding: training_datas/train_data19780.zip (stored 0%)\n",
            "  adding: training_datas/train_data12112.zip (stored 0%)\n",
            "  adding: training_datas/train_data6306.zip (stored 0%)\n",
            "  adding: training_datas/train_data29733.zip (stored 0%)\n",
            "  adding: training_datas/train_data29240.zip (stored 0%)\n",
            "  adding: training_datas/train_data28991.zip (stored 0%)\n",
            "  adding: training_datas/train_data24245.zip (stored 0%)\n",
            "  adding: training_datas/train_data10100.zip (stored 0%)\n",
            "  adding: training_datas/train_data16059.zip (stored 0%)\n",
            "  adding: training_datas/train_data12060.zip (stored 0%)\n",
            "  adding: training_datas/train_data2442.zip (stored 0%)\n",
            "  adding: training_datas/train_data17251.zip (stored 0%)\n",
            "  adding: training_datas/train_data29454.zip (stored 0%)\n",
            "  adding: training_datas/train_data4609.zip (stored 0%)\n",
            "  adding: training_datas/train_data25869.zip (stored 0%)\n",
            "  adding: training_datas/train_data19937.zip (stored 0%)\n",
            "  adding: training_datas/train_data27971.zip (stored 0%)\n",
            "  adding: training_datas/train_data10116.zip (stored 0%)\n",
            "  adding: training_datas/train_data12374.zip (stored 0%)\n",
            "  adding: training_datas/train_data3809.zip (stored 0%)\n",
            "  adding: training_datas/train_data15281.zip (stored 0%)\n",
            "  adding: training_datas/train_data18323.zip (stored 0%)\n",
            "  adding: training_datas/train_data16661.zip (stored 0%)\n",
            "  adding: training_datas/train_data1725.zip (stored 0%)\n",
            "  adding: training_datas/train_data25048.zip (stored 0%)\n",
            "  adding: training_datas/train_data622.zip (stored 0%)\n",
            "  adding: training_datas/train_data14606.zip (stored 0%)\n",
            "  adding: training_datas/train_data19641.zip (stored 0%)\n",
            "  adding: training_datas/train_data10511.zip (stored 0%)\n",
            "  adding: training_datas/train_data12422.zip (stored 0%)\n",
            "  adding: training_datas/train_data9381.zip (stored 0%)\n",
            "  adding: training_datas/train_data18168.zip (stored 0%)\n",
            "  adding: training_datas/train_data17874.zip (stored 0%)\n",
            "  adding: training_datas/train_data19364.zip (stored 0%)\n",
            "  adding: training_datas/train_data12750.zip (stored 0%)\n",
            "  adding: training_datas/train_data20307.zip (stored 0%)\n",
            "  adding: training_datas/train_data6561.zip (stored 0%)\n",
            "  adding: training_datas/train_data20364.zip (stored 0%)\n",
            "  adding: training_datas/train_data20887.zip (stored 0%)\n",
            "  adding: training_datas/train_data30356.zip (stored 0%)\n",
            "  adding: training_datas/train_data26502.zip (stored 0%)\n",
            "  adding: training_datas/train_data27804.zip (stored 0%)\n",
            "  adding: training_datas/train_data17980.zip (stored 0%)\n",
            "  adding: training_datas/train_data1653.zip (stored 0%)\n",
            "  adding: training_datas/train_data8903.zip (stored 0%)\n",
            "  adding: training_datas/train_data20271.zip (stored 0%)\n",
            "  adding: training_datas/train_data21725.zip (stored 0%)\n",
            "  adding: training_datas/train_data6233.zip (stored 0%)\n",
            "  adding: training_datas/train_data28277.zip (stored 0%)\n",
            "  adding: training_datas/train_data12930.zip (stored 0%)\n",
            "  adding: training_datas/train_data17341.zip (stored 0%)\n",
            "  adding: training_datas/train_data10359.zip (stored 0%)\n",
            "  adding: training_datas/train_data1629.zip (stored 0%)\n",
            "  adding: training_datas/train_data21667.zip (stored 0%)\n",
            "  adding: training_datas/train_data29739.zip (stored 0%)\n",
            "  adding: training_datas/train_data1636.zip (stored 0%)\n",
            "  adding: training_datas/train_data15962.zip (stored 0%)\n",
            "  adding: training_datas/train_data2087.zip (stored 0%)\n",
            "  adding: training_datas/train_data28033.zip (stored 0%)\n",
            "  adding: training_datas/train_data9061.zip (stored 0%)\n",
            "  adding: training_datas/train_data9593.zip (stored 0%)\n",
            "  adding: training_datas/train_data8550.zip (stored 0%)\n",
            "  adding: training_datas/train_data24584.zip (stored 0%)\n",
            "  adding: training_datas/train_data11966.zip (stored 0%)\n",
            "  adding: training_datas/train_data6735.zip (stored 0%)\n",
            "  adding: training_datas/train_data3225.zip (stored 0%)\n",
            "  adding: training_datas/train_data7943.zip (stored 0%)\n",
            "  adding: training_datas/train_data25349.zip (stored 0%)\n",
            "  adding: training_datas/train_data4363.zip (stored 0%)\n",
            "  adding: training_datas/train_data22876.zip (stored 0%)\n",
            "  adding: training_datas/train_data26654.zip (stored 0%)\n",
            "  adding: training_datas/train_data363.zip (stored 0%)\n",
            "  adding: training_datas/train_data13219.zip (stored 0%)\n",
            "  adding: training_datas/train_data26543.zip (stored 0%)\n",
            "  adding: training_datas/train_data1195.zip (stored 0%)\n",
            "  adding: training_datas/train_data13892.zip (stored 0%)\n",
            "  adding: training_datas/train_data13162.zip (stored 0%)\n",
            "  adding: training_datas/train_data12875.zip (stored 0%)\n",
            "  adding: training_datas/train_data12404.zip (stored 0%)\n",
            "  adding: training_datas/train_data12213.zip (stored 0%)\n",
            "  adding: training_datas/train_data2882.zip (stored 0%)\n",
            "  adding: training_datas/train_data29434.zip (stored 0%)\n",
            "  adding: training_datas/train_data19098.zip (stored 0%)\n",
            "  adding: training_datas/train_data22087.zip (stored 0%)\n",
            "  adding: training_datas/train_data2132.zip (stored 0%)\n",
            "  adding: training_datas/train_data20560.zip (stored 0%)\n",
            "  adding: training_datas/train_data3454.zip (stored 0%)\n",
            "  adding: training_datas/train_data11183.zip (stored 0%)\n",
            "  adding: training_datas/train_data10091.zip (stored 0%)\n",
            "  adding: training_datas/train_data21062.zip (stored 0%)\n",
            "  adding: training_datas/train_data17718.zip (stored 0%)\n",
            "  adding: training_datas/train_data27411.zip (stored 0%)\n",
            "  adding: training_datas/train_data22880.zip (stored 0%)\n",
            "  adding: training_datas/train_data5875.zip (stored 0%)\n",
            "  adding: training_datas/train_data9144.zip (stored 0%)\n",
            "  adding: training_datas/train_data3858.zip (stored 0%)\n",
            "  adding: training_datas/train_data18810.zip (stored 0%)\n",
            "  adding: training_datas/train_data12322.zip (stored 0%)\n",
            "  adding: training_datas/train_data13345.zip (stored 0%)\n",
            "  adding: training_datas/train_data25623.zip (stored 0%)\n",
            "  adding: training_datas/train_data14890.zip (stored 0%)\n",
            "  adding: training_datas/train_data24958.zip (stored 0%)\n",
            "  adding: training_datas/train_data12419.zip (stored 0%)\n",
            "  adding: training_datas/train_data11423.zip (stored 0%)\n",
            "  adding: training_datas/train_data15292.zip (stored 0%)\n",
            "  adding: training_datas/train_data24576.zip (stored 0%)\n",
            "  adding: training_datas/train_data8755.zip (stored 0%)\n",
            "  adding: training_datas/train_data5158.zip (stored 0%)\n",
            "  adding: training_datas/train_data18455.zip (stored 0%)\n",
            "  adding: training_datas/train_data5534.zip (stored 0%)\n",
            "  adding: training_datas/train_data4762.zip (stored 0%)\n",
            "  adding: training_datas/train_data28341.zip (stored 0%)\n",
            "  adding: training_datas/train_data8223.zip (stored 0%)\n",
            "  adding: training_datas/train_data11092.zip (stored 0%)\n",
            "  adding: training_datas/train_data20093.zip (stored 0%)\n",
            "  adding: training_datas/train_data23823.zip (stored 0%)\n",
            "  adding: training_datas/train_data17458.zip (stored 0%)\n",
            "  adding: training_datas/train_data12809.zip (stored 0%)\n",
            "  adding: training_datas/train_data4620.zip (stored 0%)\n",
            "  adding: training_datas/train_data22146.zip (stored 0%)\n",
            "  adding: training_datas/train_data18563.zip (stored 0%)\n",
            "  adding: training_datas/train_data3840.zip (stored 0%)\n",
            "  adding: training_datas/train_data26732.zip (stored 0%)\n",
            "  adding: training_datas/train_data21800.zip (stored 0%)\n",
            "  adding: training_datas/train_data16468.zip (stored 0%)\n",
            "  adding: training_datas/train_data18352.zip (stored 0%)\n",
            "  adding: training_datas/train_data328.zip (stored 0%)\n",
            "  adding: training_datas/train_data24442.zip (stored 0%)\n",
            "  adding: training_datas/train_data24224.zip (stored 0%)\n",
            "  adding: training_datas/train_data17452.zip (stored 0%)\n",
            "  adding: training_datas/train_data7628.zip (stored 0%)\n",
            "  adding: training_datas/train_data2141.zip (stored 0%)\n",
            "  adding: training_datas/train_data10254.zip (stored 0%)\n",
            "  adding: training_datas/train_data11157.zip (stored 0%)\n",
            "  adding: training_datas/train_data18066.zip (stored 0%)\n",
            "  adding: training_datas/train_data20707.zip (stored 0%)\n",
            "  adding: training_datas/train_data9191.zip (stored 0%)\n",
            "  adding: training_datas/train_data6124.zip (stored 0%)\n",
            "  adding: training_datas/train_data11586.zip (stored 0%)\n",
            "  adding: training_datas/train_data18289.zip (stored 0%)\n",
            "  adding: training_datas/train_data22293.zip (stored 0%)\n",
            "  adding: training_datas/train_data19045.zip (stored 0%)\n",
            "  adding: training_datas/train_data11205.zip (stored 0%)\n",
            "  adding: training_datas/train_data22000.zip (stored 0%)\n",
            "  adding: training_datas/train_data18404.zip (stored 0%)\n",
            "  adding: training_datas/train_data23961.zip (stored 0%)\n",
            "  adding: training_datas/train_data9278.zip (stored 0%)\n",
            "  adding: training_datas/train_data23352.zip (stored 0%)\n",
            "  adding: training_datas/train_data24049.zip (stored 0%)\n",
            "  adding: training_datas/train_data13747.zip (stored 0%)\n",
            "  adding: training_datas/train_data23015.zip (stored 0%)\n",
            "  adding: training_datas/train_data14993.zip (stored 0%)\n",
            "  adding: training_datas/train_data15845.zip (stored 0%)\n",
            "  adding: training_datas/train_data518.zip (stored 0%)\n",
            "  adding: training_datas/train_data315.zip (stored 0%)\n",
            "  adding: training_datas/train_data11814.zip (stored 0%)\n",
            "  adding: training_datas/train_data877.zip (stored 0%)\n",
            "  adding: training_datas/train_data5897.zip (stored 0%)\n",
            "  adding: training_datas/train_data27722.zip (stored 0%)\n",
            "  adding: training_datas/train_data25171.zip (stored 0%)\n",
            "  adding: training_datas/train_data8905.zip (stored 0%)\n",
            "  adding: training_datas/train_data30385.zip (stored 0%)\n",
            "  adding: training_datas/train_data9155.zip (stored 0%)\n",
            "  adding: training_datas/train_data8969.zip (stored 0%)\n",
            "  adding: training_datas/train_data6695.zip (stored 0%)\n",
            "  adding: training_datas/train_data25281.zip (stored 0%)\n",
            "  adding: training_datas/train_data25584.zip (stored 0%)\n",
            "  adding: training_datas/train_data29905.zip (stored 0%)\n",
            "  adding: training_datas/train_data19409.zip (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCarWPWpS30T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c768d2a6-46d4-46cb-c3a7-70ad1e2a1e0b"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3z1Z5VNTRbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7955fc0-ce83-4394-f779-987352463ced"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data  training_datas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "225AxoYKTYNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r training_datas/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWlkTACev0zH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "26a925cd-059f-43de-d2f9-77fbc67c2e8d"
      },
      "source": [
        "with zipfile.ZipFile(\"./training_datas.zip\") as myzip:\n",
        "    filelist = myzip.namelist()\n",
        "    df = pd.read_csv(myzip.extract(filelist[10]))\n",
        "\n",
        "print(df.shape)\n",
        "print(len(filelist))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-711233816816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./training_datas.zip\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfilelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xbb in position 0: invalid start byte"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi-eyaAHrj5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79d3c7db-1899-4b60-9686-63c2dad6dabd"
      },
      "source": [
        "for i in range(len(listdir[10])):\n",
        "    with zipfile.ZipFile(\"./training_datas/\" + listdir[i]) as zip:\n",
        "        filelist = zip.namelist()\n",
        "        print(filelist)\n",
        "        data = pickle.loads(zip.read(filelist[0]))\n",
        "        print(data.shape)\n",
        "        print(data)\n",
        "        # for info in zip.infolist():\n",
        "        #     if info.is_dir():\n",
        "        #         continue\n",
        "        #     data = pickle.loads(zip.read(info.filename))\n",
        "        #     print(\"\\n\", data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['./training_datas/train_data0.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  8.382812   0.0\n",
            "1965        0        0        0  ...   0  8.382812   0.0\n",
            "1966        0        0        0  ...   0  8.382812   0.0\n",
            "1967        0        0        0  ...   0  8.382812   0.0\n",
            "1968        0        0        0  ...   0  8.382812   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data1.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  3.970703   0.0\n",
            "1965        0        0        0  ...   0  3.970703   0.0\n",
            "1966        0        0        0  ...   0  3.970703   0.0\n",
            "1967        0        0        0  ...   0  3.970703   0.0\n",
            "1968        0        0        0  ...   0  3.970703   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  4.878906   0.0\n",
            "1965        0        0        0  ...   0  4.878906   0.0\n",
            "1966        0        0        0  ...   0  4.878906   0.0\n",
            "1967        0        0        0  ...   0  4.878906   0.0\n",
            "1968        0        0        0  ...   0  4.878906   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data100.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  3.480469   0.0\n",
            "1965        0        0        0  ...   0  3.480469   0.0\n",
            "1966        0        0        0  ...   0  3.480469   0.0\n",
            "1967        0        0        0  ...   0  3.480469   0.0\n",
            "1968        0        0        0  ...   0  3.480469   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data1000.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  event_name_1_Chanukah End  ...  21  22  price  sale\n",
            "0           0        0        0                          0  ...   0   0    0.0   0.0\n",
            "1           0        0        0                          0  ...   0   0    0.0   0.0\n",
            "2           0        0        0                          0  ...   0   0    0.0   0.0\n",
            "3           1        1        0                          0  ...   0   0    0.0   0.0\n",
            "4           1        0        1                          0  ...   0   0    0.0   0.0\n",
            "...       ...      ...      ...                        ...  ...  ..  ..    ...   ...\n",
            "1964        0        1        1                          0  ...   0   0    1.5   0.0\n",
            "1965        0        0        0                          0  ...   0   0    1.5   0.0\n",
            "1966        0        0        0                          0  ...   0   0    1.5   0.0\n",
            "1967        0        0        0                          0  ...   0   0    1.5   0.0\n",
            "1968        0        0        0                          0  ...   0   0    1.5   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10000.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  1.980469   1.0\n",
            "1           0        0        0  ...   0  1.980469   5.0\n",
            "2           0        0        0  ...   0  1.980469   0.0\n",
            "3           1        1        0  ...   0  1.980469   5.0\n",
            "4           1        0        1  ...   0  1.980469   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  2.240234   0.0\n",
            "1965        0        0        0  ...   0  2.240234   0.0\n",
            "1966        0        0        0  ...   0  2.240234   0.0\n",
            "1967        0        0        0  ...   0  2.240234   0.0\n",
            "1968        0        0        0  ...   0  2.240234   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10001.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22      price  sale\n",
            "0           0        0        0  ...   0   0.000000   0.0\n",
            "1           0        0        0  ...   0   0.000000   0.0\n",
            "2           0        0        0  ...   0   0.000000   0.0\n",
            "3           1        1        0  ...   0   0.000000   0.0\n",
            "4           1        0        1  ...   0   0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..        ...   ...\n",
            "1964        0        1        1  ...   0  12.679688   0.0\n",
            "1965        0        0        0  ...   0  12.679688   0.0\n",
            "1966        0        0        0  ...   0  12.679688   0.0\n",
            "1967        0        0        0  ...   0  12.679688   0.0\n",
            "1968        0        0        0  ...   0  12.679688   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10002.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0   0.00000   0.0\n",
            "1           0        0        0  ...   0   0.00000   0.0\n",
            "2           0        0        0  ...   0   0.00000   0.0\n",
            "3           1        1        0  ...   0   0.00000   0.0\n",
            "4           1        0        1  ...   0   0.00000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  12.84375   0.0\n",
            "1965        0        0        0  ...   0  12.84375   0.0\n",
            "1966        0        0        0  ...   0  12.84375   0.0\n",
            "1967        0        0        0  ...   0  12.84375   0.0\n",
            "1968        0        0        0  ...   0  12.84375   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10003.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  5.980469   0.0\n",
            "1965        0        0        0  ...   0  5.980469   0.0\n",
            "1966        0        0        0  ...   0  5.980469   0.0\n",
            "1967        0        0        0  ...   0  5.980469   0.0\n",
            "1968        0        0        0  ...   0  5.980469   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10004.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  5.890625   1.0\n",
            "1           0        0        0  ...   0  5.890625   3.0\n",
            "2           0        0        0  ...   0  5.890625   1.0\n",
            "3           1        1        0  ...   0  5.890625   3.0\n",
            "4           1        0        1  ...   0  5.890625   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  5.980469   0.0\n",
            "1965        0        0        0  ...   0  5.980469   0.0\n",
            "1966        0        0        0  ...   0  5.980469   0.0\n",
            "1967        0        0        0  ...   0  5.980469   0.0\n",
            "1968        0        0        0  ...   0  5.980469   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10005.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  1.570312   1.0\n",
            "1           0        0        0  ...   0  1.570312   3.0\n",
            "2           0        0        0  ...   0  1.570312   1.0\n",
            "3           1        1        0  ...   0  1.570312   1.0\n",
            "4           1        0        1  ...   0  1.570312   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  0.959961   0.0\n",
            "1965        0        0        0  ...   0  0.959961   0.0\n",
            "1966        0        0        0  ...   0  0.959961   0.0\n",
            "1967        0        0        0  ...   0  0.959961   0.0\n",
            "1968        0        0        0  ...   0  0.959961   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10006.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  5.921875   0.0\n",
            "1965        0        0        0  ...   0  5.921875   0.0\n",
            "1966        0        0        0  ...   0  5.921875   0.0\n",
            "1967        0        0        0  ...   0  5.921875   0.0\n",
            "1968        0        0        0  ...   0  5.921875   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10007.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.979980   4.0\n",
            "1           0        0        0  ...   0  0.979980   6.0\n",
            "2           0        0        0  ...   0  0.979980   5.0\n",
            "3           1        1        0  ...   0  0.979980   1.0\n",
            "4           1        0        1  ...   0  0.979980   3.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  0.970215   0.0\n",
            "1965        0        0        0  ...   0  0.970215   0.0\n",
            "1966        0        0        0  ...   0  0.970215   0.0\n",
            "1967        0        0        0  ...   0  0.970215   0.0\n",
            "1968        0        0        0  ...   0  0.970215   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10008.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22      price  sale\n",
            "0           0        0        0  ...   0   0.000000   0.0\n",
            "1           0        0        0  ...   0   0.000000   0.0\n",
            "2           0        0        0  ...   0   0.000000   0.0\n",
            "3           1        1        0  ...   0   0.000000   0.0\n",
            "4           1        0        1  ...   0   0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..        ...   ...\n",
            "1964        0        1        1  ...   0  12.476562   0.0\n",
            "1965        0        0        0  ...   0  12.476562   0.0\n",
            "1966        0        0        0  ...   0  12.476562   0.0\n",
            "1967        0        0        0  ...   0  12.476562   0.0\n",
            "1968        0        0        0  ...   0  12.476562   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10009.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  0.879883   0.0\n",
            "1965        0        0        0  ...   0  0.879883   0.0\n",
            "1966        0        0        0  ...   0  0.879883   0.0\n",
            "1967        0        0        0  ...   0  0.879883   0.0\n",
            "1968        0        0        0  ...   0  0.879883   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data1001.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  1.969727   4.0\n",
            "1           0        0        0  ...   0  1.969727   3.0\n",
            "2           0        0        0  ...   0  1.969727   1.0\n",
            "3           1        1        0  ...   0  1.969727   0.0\n",
            "4           1        0        1  ...   0  1.969727   1.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  2.000000   0.0\n",
            "1965        0        0        0  ...   0  2.000000   0.0\n",
            "1966        0        0        0  ...   0  2.000000   0.0\n",
            "1967        0        0        0  ...   0  2.000000   0.0\n",
            "1968        0        0        0  ...   0  2.000000   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10010.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  9.976562   0.0\n",
            "1965        0        0        0  ...   0  9.976562   0.0\n",
            "1966        0        0        0  ...   0  9.976562   0.0\n",
            "1967        0        0        0  ...   0  9.976562   0.0\n",
            "1968        0        0        0  ...   0  9.976562   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10011.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  0.000000   0.0\n",
            "1           0        0        0  ...   0  0.000000   0.0\n",
            "2           0        0        0  ...   0  0.000000   0.0\n",
            "3           1        1        0  ...   0  0.000000   0.0\n",
            "4           1        0        1  ...   0  0.000000   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  1.969727   0.0\n",
            "1965        0        0        0  ...   0  1.969727   0.0\n",
            "1966        0        0        0  ...   0  1.969727   0.0\n",
            "1967        0        0        0  ...   0  1.969727   0.0\n",
            "1968        0        0        0  ...   0  1.969727   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n",
            "['./training_datas/train_data10012.zip']\n",
            "(1969, 68)\n",
            "      snap_CA  snap_TX  snap_WI  ...  22     price  sale\n",
            "0           0        0        0  ...   0  3.279297   2.0\n",
            "1           0        0        0  ...   0  3.279297   1.0\n",
            "2           0        0        0  ...   0  3.279297   2.0\n",
            "3           1        1        0  ...   0  3.279297   1.0\n",
            "4           1        0        1  ...   0  3.279297   0.0\n",
            "...       ...      ...      ...  ...  ..       ...   ...\n",
            "1964        0        1        1  ...   0  2.960938   0.0\n",
            "1965        0        0        0  ...   0  2.960938   0.0\n",
            "1966        0        0        0  ...   0  2.960938   0.0\n",
            "1967        0        0        0  ...   0  2.960938   0.0\n",
            "1968        0        0        0  ...   0  2.960938   0.0\n",
            "\n",
            "[1969 rows x 68 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tdNWWq9C_2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "715a4694-2117-4219-8701-00b150a56ebb"
      },
      "source": [
        "    listdir = os.listdir(\"./training_datas\")\n",
        "    listdir.sort()\n",
        "    listdir[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_data0.zip',\n",
              " 'train_data1.zip',\n",
              " 'train_data10.zip',\n",
              " 'train_data100.zip',\n",
              " 'train_data1000.zip',\n",
              " 'train_data10000.zip',\n",
              " 'train_data10001.zip',\n",
              " 'train_data10002.zip',\n",
              " 'train_data10003.zip',\n",
              " 'train_data10004.zip']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RexdF3drcA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "listdir = os.listdir(DATA_PATH)\n",
        "listdir[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWffdQ5pKmOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd70e1b8-56ef-4e63-de85-b294e9300b20"
      },
      "source": [
        "os.path.isdir(\"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas_onehot/training_datas\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfC-F4l3LQVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cb82e65-843d-4dda-d63a-14f6196ad643"
      },
      "source": [
        "os.path.isdir(DATA_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNtlklycOPUw",
        "colab_type": "text"
      },
      "source": [
        "# データ生成後は以下を実行するだけでOK\n",
        "→ .py にして一部はライブラリ化する？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoAdpHY1OXwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import os \n",
        "from itertools import cycle\n",
        "color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
        "\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    \"\"\"\n",
        "    目的：メモリサイズの削減\n",
        "    df: メモリを削減したい DataFrame (pandas.DataFrame)\n",
        "    verbose: 実行時に、メモリ削減の情報を出力するかどうかを指定(bool)\n",
        "\n",
        "    ■ 基本思想\n",
        "    【前提知識】\n",
        "    pandas で作成したデータフレームのうち数値データは、特に dtype を指定しない場合\n",
        "    int64 または float64 でデータを作成するので、\n",
        "    実際のデータよりもこの型が大きいと余計なメモリサイズを確保してしまう。\n",
        "\n",
        "    【処理内容】\n",
        "    (1) 入力された DataFrame の column の型を全てチェック(for loop)\n",
        "    (2) その型が大きい数値データ(int16~int64, float16~float64)ならば、\n",
        "        そのデータフレームの最大値・最小値をチェック。\n",
        "        現在処理中のカラムを、上記の最大値・最小値を表せる必要最低限の型に変換する。\n",
        "        int と floatに分けて処理。\n",
        "\n",
        "    ────────────────────────────────────────────────────────────────────────\n",
        "    【変更履歴】\n",
        "    2020/06/06:\n",
        "    ■ 35行目\n",
        "    ifのネストが深かったので、リファクタ。\n",
        "    Early Continueを入れたので可読性が向上(したはず)。\n",
        "\n",
        "    ■ 46行目・71行目(置き換え・追加)\n",
        "    説明変数(関数?)で置き換え。\n",
        "    columnのtypeがintであるか否かを判定する関数を噛ませている。\n",
        "    (返り値はbool値)\n",
        "    \"\"\"\n",
        "\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    # main loop    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "\n",
        "        if col_type not in numerics: \n",
        "            continue # Early continue if column type is not numeric\n",
        "        \n",
        "        c_min = df[col].min()\n",
        "        c_max = df[col].max()\n",
        "\n",
        "        if IsInt(col_type):\n",
        "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                df[col] = df[col].astype(np.int8)\n",
        "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                df[col] = df[col].astype(np.int16)\n",
        "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                df[col] = df[col].astype(np.int32)\n",
        "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                df[col] = df[col].astype(np.int64)  \n",
        "        else:\n",
        "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                df[col] = df[col].astype(np.float16)\n",
        "            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                df[col] = df[col].astype(np.float32)\n",
        "            else:\n",
        "                df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    if verbose: \n",
        "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def IsInt(col_type):\n",
        "    return str(col_type)[:3] == 'int'"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgMQu6yHza8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "zipからデータ読み出し。\n",
        "展開しないのでディスク容量も圧迫せず済む\n",
        "6/17: 追記\n",
        "\n",
        "myzip.extract(f_name) が、カレントディレクトリに圧縮ファイルを展開してしまう。\n",
        "→ バグにつながっていた。\n",
        "\n",
        "【対処法】\n",
        "ファイル展開用のフォルダを作成し、そこへ展開した後、生成されたcsvは削除するコードを追加。\n",
        "\n",
        "※ このコードの考え方を、ReccurentTrainGeneratorへ応用\n",
        "\n",
        "\"\"\"\n",
        "import pickle\n",
        "import zipfile\n",
        "NUM_ITEMS = 30490\n",
        "DATA_PATH = \"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas_onehot/training_datas\"\n",
        "\n",
        "def train_data_from_pickle_generator(num=NUM_ITEMS, datapath=DATA_PATH):\n",
        "    listdir = os.listdir(datapath)\n",
        "    #listdir.sort()\n",
        "\n",
        "    for i in range(len(listdir)):\n",
        "\n",
        "        if i > num:\n",
        "            break\n",
        "\n",
        "        with zipfile.ZipFile(datapath + \"/\" + listdir[i]) as tmpzip:\n",
        "            filelist = tmpzip.namelist()\n",
        "\n",
        "            df = pickle.loads(tmpzip.read(filelist[0]))\n",
        "            #df = reduce_mem_usage(df, verbose=False)\n",
        "            df = df.fillna(0)\n",
        "            array = df.values\n",
        "        \n",
        "            yield array"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yFZU7X6BltK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpg = train_data_from_pickle_generator(datapath=\"./training_datas\")"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNcqdMkPBt1y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "026faa76-48a2-42ac-a6f9-daa06aeb8313"
      },
      "source": [
        "next(tpg)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.13333333, 3.9609375 ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.2       , 3.9609375 ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.2       , 3.9609375 ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48lrS5YrwJG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import Sequence\n",
        "from keras.models import Sequential\n",
        "\n",
        "\"\"\"\n",
        "model.fit_generatorを使うためのユーザ定義関数\n",
        "※ generator を使わないとメモリが死ぬ\n",
        "\"\"\"\n",
        "class ReccurentTrainGenerator(Sequence):\n",
        "    def _resetindices(self):\n",
        "        \"\"\"\n",
        "        バッチ生成用のインデックスをランダムに出力\n",
        "        \"\"\"\n",
        "        self.num_called = 0\n",
        "\n",
        "        all_idx = np.random.permutation(np.arange(self.num_batches))\n",
        "        remain_idx = np.random.choice(np.arange(self.num_batches),\n",
        "                                      size=(self.steps_per_epoch*self.batch_size-len(all_idx)),\n",
        "                                      replace=False)\n",
        "        \n",
        "        self.indices = np.hstack([all_idx, remain_idx]).reshape(self.steps_per_epoch, self.batch_size)\n",
        "\n",
        "    def __init__(self, DataPath, batch_size, InputSteps=28, OutputSteps=28, delay=1, normalize_factor=None, sample_indices=np.arange(0, 30490)):\n",
        "        \"\"\"\n",
        "        【入力】\n",
        "        InputTensor: 入力データ(説明変数) データ数(\"HOBBIES_1_...\"などに対応) × データ点数(時系列方向のデータ数) × 特徴量数 のndarray\n",
        "                     ※ 正解ラベルも、この時系列データからとるのでこれだけ入力すればOK\n",
        "                     ※ 今回は、引数 DataPathの先に圧縮してあるファイル(pickle)を都度解凍して利用する \n",
        "        batch_size: バッチサイズ(例えば、timestepが5として、時刻0~4までのデータ、1~5までのデータ、...、10~14までのデータ、\n",
        "                                をひとまとめにして1データとみなすとする。RNNの場合はこのサイズがバッチサイズに対応する。)\n",
        "        InputSteps: リカレント層に食わせるデータを、何ステップ前までのデータにするか\n",
        "        OutputSteps: リカレント層からの出力(予測ステップ数)の設定値\n",
        "        delay: 目的変数をどの程度遅らせるか？(予測ステップのスタート位置をどの程度後ろにずらすか)\n",
        "        normalize_factor: 正規化する際のスケーリングをどの程度にするか\n",
        "\n",
        "        6/16: 正解ラベル作成について、ラベルが間違っている可能性あり。\n",
        "        6/17: 要素数を選択できるようにする (引数 num_samplesでも作る？)\n",
        "        【構成案】\n",
        "        sklearn.model_selection.KFold などで得たインデックスを流用できる形にする。\n",
        "        ⇒ インデックスの配列をself.sample_indicesに突っ込み、その組を並び替える形で使用\n",
        "        → _resetindicesなども修正対象\n",
        "        \"\"\"\n",
        "        # データファイル名リストの取得\n",
        "        self.datapath = DataPath\n",
        "        self.listdir = os.listdir(DataPath)\n",
        "        self.sample_indices = sample_indices\n",
        "\n",
        "        with zipfile.ZipFile(self.datapath + \"/\" + self.listdir[sample_indices[0]]) as tmpzip:\n",
        "            filelist = tmpzip.namelist()\n",
        "\n",
        "            df = pickle.loads(tmpzip.read(filelist[0]))\n",
        "            #df = reduce_mem_usage(df, verbose=False)\n",
        "            df = df.fillna(0)\n",
        "\n",
        "        # 現在のエポックでバッチ生成の対象となっているデータ系列\n",
        "        self.now_data = df.values\n",
        "\n",
        "        # 各種パラメータ\n",
        "        self.num_datas = len(self.sample_indices)\n",
        "        self.len_sequence = df.shape[0]\n",
        "        self.num_features = df.shape[1]\n",
        "        self.batch_size = batch_size\n",
        "        self.input_steps = InputSteps\n",
        "        self.output_steps = OutputSteps\n",
        "        self.delay = delay \n",
        "\n",
        "        # 各データ系列に対し、バッチサイズいくつ作れるか計算するのに必要な値\n",
        "        self.len_requied_per_batch = InputSteps + (batch_size-1) + (delay-1) + OutputSteps # 訓練データと正解データを作るために必要なサイズ \n",
        "        self.num_batches = self.len_sequence - self.len_requied_per_batch + 1              # 作れるバッチの数\n",
        "\n",
        "        # 1エポック当たりのステップ数\n",
        "        self.steps_per_epoch = int(np.ceil(self.len_sequence / float(batch_size)))\n",
        "        \n",
        "        # バッチ生成用の乱数初期化\n",
        "        self._resetindices()\n",
        "\n",
        "        # データ取得用インデックス生成\n",
        "        self.data_idx = self._reset_dataset_indices(self.num_datas)\n",
        "        self.num_epoch = 0\n",
        "\n",
        "        self.normalize_factor = normalize_factor\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        1エポックあたりのステップ数をリターン\n",
        "        \"\"\"\n",
        "        return self.steps_per_epoch\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        データをバッチにまとめて出力\n",
        "        \"\"\"\n",
        "        indices_temp = self.indices[idx] # indices は (steps_per_epoch, batchsize)の array\n",
        "\n",
        "        batch_x = np.array([self.now_data[i:i+self.input_steps] for i in indices_temp])\n",
        "        batch_y = np.array([self.now_data[i+self.input_steps+(self.delay-1):i+self.input_steps+(self.delay-1)+self.output_steps, -1] for i in indices_temp]).reshape(self.batch_size, self.output_steps, 1)\n",
        "\n",
        "        if self.num_called == (self.steps_per_epoch-1):\n",
        "            self._resetindices()\n",
        "        else:\n",
        "            self.num_called += 1\n",
        "\n",
        "        if self.normalize_factor:\n",
        "            batch_x = batch_x / self.normalize_factor\n",
        "            batch_y = batch_y / self.normalize_factor\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"\n",
        "        Epoch 終了ごとにデータセットを入れ替える\n",
        "        (データセット：\"HOBBIES_1_...\"などに対応)\n",
        "        \"\"\"\n",
        "        if self.num_epoch == self.num_datas:\n",
        "            self.num_epoch = 0\n",
        "            self.data_idx = self._reset_dataset_indices(self.num_datas)\n",
        "        else:\n",
        "            self.num_epoch += 1\n",
        "        \n",
        "        next_data_idx = self.data_idx[self.num_epoch]\n",
        "\n",
        "        with zipfile.ZipFile(self.datapath + \"/\" + self.listdir[self.sample_indices[next_data_idx]]) as tmpzip:\n",
        "            filelist = tmpzip.namelist()\n",
        "            print(filelist)\n",
        "\n",
        "            tmp_df = pickle.loads(tmpzip.read(filelist[0]))\n",
        "            #tmp_df = reduce_mem_usage(tmp_df, verbose=False)\n",
        "            #tmp_df = tmp_df.fillna(0)\n",
        "            self.now_data = tmp_df.values\n",
        "\n",
        "    def _reset_dataset_indices(self, num_datas):\n",
        "        \"\"\"\n",
        "        Epoch毎に入れ替えるデータのインデックスをランダムにするためのメソッド\n",
        "        \"\"\"\n",
        "        return np.random.permutation(np.arange(num_datas))"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9Q5eflf0Oq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 動作未チェック\n",
        "\n",
        "from sklearn import preprocessing, metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM,Dropout\n",
        "from keras.layers import RepeatVector,TimeDistributed, BatchNormalization\n",
        "from numpy import array\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "\"\"\"\n",
        "仮のモデル\n",
        "ハイパーパラメータを引数にとれるよう改造すべき？\n",
        "※ チューニングができるように\n",
        "\"\"\"\n",
        "def build_model():\n",
        "    timesteps = 28\n",
        "    delay = 1\n",
        "\n",
        "    n_out_seq_length = 28\n",
        "    num_y = 1\n",
        "\n",
        "#    train_generator = train_data_from_pickle_generator(num=1)\n",
        "    train_generator = train_data_from_pickle_generator(num=1, datapath=\"./training_datas\") \n",
        "    x_shape = next(train_generator).shape\n",
        "    print(x_shape)\n",
        "\n",
        "    len_sequence, num_features = x_shape\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(LSTM(128, activation='relu', batch_input_shape=(None, timesteps, num_features), return_sequences=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(RepeatVector(28))\n",
        "    model.add(LSTM(32, activation='relu', return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.1))  \n",
        "    model.add(TimeDistributed(Dense(delay, activation=\"relu\")))   # num_y means the shape of y,in some problem(like translate), it can be many.\n",
        "                                                #In that case, you should set the  activation= 'softmax'\n",
        "    \n",
        "    #RMSpropOptimizer = RMSprop(lr=0.001, clipvalue=0.5)\n",
        "    #model.compile(optimizer=RMSpropOptimizer, loss='mean_squared_error', metrics=[\"accuracy\"])\n",
        "    model.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "    return model"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV6jnj130VQB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "f01a6e82-4973-4080-fe81-99d534d23c4c"
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1941, 70)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128)               101888    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 28, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 28, 32)            20608     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 32)            128       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 28, 32)            0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 28, 1)             33        \n",
            "=================================================================\n",
            "Total params: 123,169\n",
            "Trainable params: 122,849\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rg9ueCc0XdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DATA_PATH = \"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas_onehot/training_datas\"\n",
        "#DATA_PATH = \"./training_datas.zip\"\n",
        "DATA_PATH = \"./training_datas\"\n",
        "RTG = ReccurentTrainGenerator(DataPath=DATA_PATH, batch_size=128, InputSteps=28, sample_indices=np.arange(0,1000))\n",
        "Validation_RTG = ReccurentTrainGenerator(DataPath=DATA_PATH, batch_size=128, InputSteps=28, sample_indices=np.arange(9000,10000))"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlgibjZm1Vw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "3a2c60c9-d339-4f58-e431-0ff78a1a87b3"
      },
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        " \n",
        "# Early-stopping: patienceはもう少し大きくとる？\n",
        "early_stopping = EarlyStopping(patience=5, verbose=1) \n",
        "\n",
        "history = model.fit_generator(RTG, epochs=500, verbose=1, validation_data=Validation_RTG,callbacks=[early_stopping])"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 0.2293 - accuracy: 0.7949 - val_loss: 1.7267 - val_accuracy: 0.5248\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.1115 - accuracy: 0.8811 - val_loss: 1.8423 - val_accuracy: 0.5297\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.0751 - accuracy: 0.9238 - val_loss: 2.0181 - val_accuracy: 0.5275\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0625 - accuracy: 0.9381 - val_loss: 1.8661 - val_accuracy: 0.5284\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.0549 - accuracy: 0.9477 - val_loss: 2.0078 - val_accuracy: 0.5283\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0505 - accuracy: 0.9525 - val_loss: 1.8680 - val_accuracy: 0.5289\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17mFjb0G1yCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "743c5f33-73b8-4344-90fe-558fbac26223"
      },
      "source": [
        "RTG.__getitem__(1)[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 28, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfjvx8Wtk-6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f2324dd-408a-4ed4-8c74-c86b2543aae9"
      },
      "source": [
        "RTG.now_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1969, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INLwaZW5lMdD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8abcf98-8a20-4be5-9db4-8b43b8859e69"
      },
      "source": [
        "RTG.on_epoch_end()"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['./training_datas/train_data2314.zip']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvqSKPSViPUq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21f5eb17-dfdc-4d07-c3bd-3b2e95b5c576"
      },
      "source": [
        "RTG.num_epoch"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psMJFyEei8Kw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "497a09df-f2a9-4302-908a-ba3f6d429e5a"
      },
      "source": [
        "RTG.data_idx[RTG.num_epoch]"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "928"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWY2YUFlho_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "8442a9eb-8c5f-46a1-c2e5-0d69f5e1e579"
      },
      "source": [
        "RTG.now_data"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ..., 59.93333333,\n",
              "         3.97070312,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ..., 60.4       ,\n",
              "         3.97070312,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ..., 59.63333333,\n",
              "         3.97070312,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDX3roHFk17n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "6d682116-a2bd-41d5-c828-0ac6ec6cb25b"
      },
      "source": [
        "RTG.tmp_df"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_name_1_Chanukah End</th>\n",
              "      <th>event_name_1_Christmas</th>\n",
              "      <th>event_name_1_Cinco De Mayo</th>\n",
              "      <th>event_name_1_ColumbusDay</th>\n",
              "      <th>event_name_1_Easter</th>\n",
              "      <th>event_name_1_Eid al-Fitr</th>\n",
              "      <th>event_name_1_EidAlAdha</th>\n",
              "      <th>event_name_1_Father's day</th>\n",
              "      <th>event_name_1_Halloween</th>\n",
              "      <th>event_name_1_IndependenceDay</th>\n",
              "      <th>event_name_1_LaborDay</th>\n",
              "      <th>event_name_1_LentStart</th>\n",
              "      <th>event_name_1_LentWeek2</th>\n",
              "      <th>event_name_1_MartinLutherKingDay</th>\n",
              "      <th>event_name_1_MemorialDay</th>\n",
              "      <th>event_name_1_Mother's day</th>\n",
              "      <th>event_name_1_NBAFinalsEnd</th>\n",
              "      <th>event_name_1_NBAFinalsStart</th>\n",
              "      <th>event_name_1_NewYear</th>\n",
              "      <th>event_name_1_OrthodoxChristmas</th>\n",
              "      <th>event_name_1_OrthodoxEaster</th>\n",
              "      <th>event_name_1_Pesach End</th>\n",
              "      <th>event_name_1_PresidentsDay</th>\n",
              "      <th>event_name_1_Purim End</th>\n",
              "      <th>event_name_1_Ramadan starts</th>\n",
              "      <th>event_name_1_StPatricksDay</th>\n",
              "      <th>event_name_1_SuperBowl</th>\n",
              "      <th>event_name_1_Thanksgiving</th>\n",
              "      <th>event_name_1_ValentinesDay</th>\n",
              "      <th>event_name_1_VeteransDay</th>\n",
              "      <th>event_type_1_Cultural</th>\n",
              "      <th>event_type_1_National</th>\n",
              "      <th>event_type_1_Religious</th>\n",
              "      <th>event_type_1_Sporting</th>\n",
              "      <th>event_name_2_Cinco De Mayo</th>\n",
              "      <th>event_name_2_Easter</th>\n",
              "      <th>event_name_2_Father's day</th>\n",
              "      <th>event_name_2_OrthodoxEaster</th>\n",
              "      <th>event_type_2_Cultural</th>\n",
              "      <th>event_type_2_Religious</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>2314</th>\n",
              "      <th>2314</th>\n",
              "      <th>price</th>\n",
              "      <th>sale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1936</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50.285714</td>\n",
              "      <td>58.400000</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1937</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52.571429</td>\n",
              "      <td>58.600000</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1938</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.428571</td>\n",
              "      <td>59.933333</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1939</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54.285714</td>\n",
              "      <td>60.400000</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1940</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52.857143</td>\n",
              "      <td>59.633333</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1941 rows × 70 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      snap_CA  snap_TX  snap_WI  ...       2314     price  sale\n",
              "0           0        0        0  ...   0.000000  0.000000   0.0\n",
              "1           0        0        0  ...   0.000000  0.000000   0.0\n",
              "2           0        0        0  ...   0.000000  0.000000   0.0\n",
              "3           1        1        0  ...   0.000000  0.000000   0.0\n",
              "4           1        0        1  ...   0.000000  0.000000   0.0\n",
              "...       ...      ...      ...  ...        ...       ...   ...\n",
              "1936        0        0        0  ...  58.400000  3.970703   0.0\n",
              "1937        0        0        0  ...  58.600000  3.970703   0.0\n",
              "1938        0        0        0  ...  59.933333  3.970703   0.0\n",
              "1939        0        0        0  ...  60.400000  3.970703   0.0\n",
              "1940        0        0        0  ...  59.633333  3.970703   0.0\n",
              "\n",
              "[1941 rows x 70 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JritQ5N3NLSD",
        "colab_type": "text"
      },
      "source": [
        "# クロスバリデーションのテスト"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nsWsJzpNNcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=5)\n",
        "CV_gen = kfold.split(np.arange(0,1000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ipw_35qNUJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2c79e40-2ec2-4bd4-cc3d-758dd8022208"
      },
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        "\n",
        "History = []\n",
        "\n",
        "# 1000サンプルでクロスバリデーションテスト(kfold.splitの引数に、0～999が順に入った配列を代入)\n",
        "for train_cv_idx, valid_cv_idx in kfold.split(np.arange(0,30490)):\n",
        "    X_CV_train_gen = ReccurentTrainGenerator(DataPath=DATA_PATH, batch_size=128, InputSteps=28, sample_indices=train_cv_idx)\n",
        "    X_CV_valid_gen = ReccurentTrainGenerator(DataPath=DATA_PATH, batch_size=128, InputSteps=28, sample_indices=valid_cv_idx)\n",
        "\n",
        "    model = build_model() #カテゴリごとのモデルを作る時も、同様にfor文内で再度モデルをビルドすればよいかもしれない。\n",
        " \n",
        "    # Early-stopping: patienceはもう少し大きくとる？\n",
        "    early_stopping = EarlyStopping(patience=100, verbose=1) \n",
        "\n",
        "    history = model.fit_generator(X_CV_train_gen, epochs=500, verbose=1, validation_data=X_CV_valid_gen, callbacks=[early_stopping])\n",
        "    History.append(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 244ms/step - loss: 17.2825 - accuracy: 0.2291 - val_loss: 1.3013 - val_accuracy: 0.8715\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 13.6302 - accuracy: 0.2324 - val_loss: 1.4011 - val_accuracy: 0.8711\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 12.0956 - accuracy: 0.2365 - val_loss: 1.1496 - val_accuracy: 0.8713\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 11.4883 - accuracy: 0.2367 - val_loss: 1.1198 - val_accuracy: 0.8724\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 4s 245ms/step - loss: 10.9414 - accuracy: 0.2408 - val_loss: 1.0533 - val_accuracy: 0.8606\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 10.4521 - accuracy: 0.2435 - val_loss: 0.9319 - val_accuracy: 0.8591\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 10.0977 - accuracy: 0.2452 - val_loss: 1.1564 - val_accuracy: 0.8585\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 10.0879 - accuracy: 0.2375 - val_loss: 1.1472 - val_accuracy: 0.8504\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 9.5648 - accuracy: 0.2406 - val_loss: 1.1506 - val_accuracy: 0.8594\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 9.1539 - accuracy: 0.2380 - val_loss: 1.1574 - val_accuracy: 0.8571\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 9.0564 - accuracy: 0.2403 - val_loss: 1.0387 - val_accuracy: 0.8499\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 8.8615 - accuracy: 0.2392 - val_loss: 1.2565 - val_accuracy: 0.6139\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 8.5265 - accuracy: 0.2397 - val_loss: 1.3856 - val_accuracy: 0.5691\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 8.2772 - accuracy: 0.2426 - val_loss: 1.4379 - val_accuracy: 0.5848\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 8.3341 - accuracy: 0.2398 - val_loss: 1.5436 - val_accuracy: 0.5172\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 8.2143 - accuracy: 0.2449 - val_loss: 1.3965 - val_accuracy: 0.5629\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 8.2624 - accuracy: 0.2355 - val_loss: 1.5067 - val_accuracy: 0.5440\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 7.8717 - accuracy: 0.2427 - val_loss: 1.8043 - val_accuracy: 0.5289\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 7.6556 - accuracy: 0.2421 - val_loss: 1.7611 - val_accuracy: 0.4716\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 7.4762 - accuracy: 0.2444 - val_loss: 2.2863 - val_accuracy: 0.4632\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 7.5649 - accuracy: 0.2439 - val_loss: 1.9211 - val_accuracy: 0.5182\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 7.6276 - accuracy: 0.2415 - val_loss: 1.7552 - val_accuracy: 0.5155\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 7.4885 - accuracy: 0.2429 - val_loss: 1.9105 - val_accuracy: 0.3854\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 7.2383 - accuracy: 0.2380 - val_loss: 2.1839 - val_accuracy: 0.3487\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 7.1730 - accuracy: 0.2416 - val_loss: 2.4589 - val_accuracy: 0.2915\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 7.3612 - accuracy: 0.2406 - val_loss: 2.4505 - val_accuracy: 0.2016\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 7.4461 - accuracy: 0.2391 - val_loss: 2.7253 - val_accuracy: 0.2075\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 7.1556 - accuracy: 0.2383 - val_loss: 2.3077 - val_accuracy: 0.3802\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 7.2469 - accuracy: 0.2325 - val_loss: 2.6132 - val_accuracy: 0.1385\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 7.0173 - accuracy: 0.2369 - val_loss: 2.6501 - val_accuracy: 0.1628\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 7.0684 - accuracy: 0.2317 - val_loss: 2.5855 - val_accuracy: 0.2885\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 7.2058 - accuracy: 0.2361 - val_loss: 4.0024 - val_accuracy: 0.0303\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.7723 - accuracy: 0.2411 - val_loss: 4.9827 - val_accuracy: 0.0334\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 6.7494 - accuracy: 0.2365 - val_loss: 6.4905 - val_accuracy: 0.0286\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.5130 - accuracy: 0.2384 - val_loss: 5.8744 - val_accuracy: 0.0319\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 6.9803 - accuracy: 0.2407 - val_loss: 4.9324 - val_accuracy: 0.0269\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 7.0294 - accuracy: 0.2302 - val_loss: 4.8612 - val_accuracy: 0.0301\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 6.9358 - accuracy: 0.2348 - val_loss: 5.6175 - val_accuracy: 0.0240\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.6857 - accuracy: 0.2397 - val_loss: 5.1656 - val_accuracy: 0.0269\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 6.6425 - accuracy: 0.2330 - val_loss: 5.7248 - val_accuracy: 0.0215\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 6.8426 - accuracy: 0.2395 - val_loss: 9.4778 - val_accuracy: 0.0164\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.5871 - accuracy: 0.2324 - val_loss: 10.7517 - val_accuracy: 0.0141\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.5650 - accuracy: 0.2369 - val_loss: 11.6749 - val_accuracy: 0.0152\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 6.4563 - accuracy: 0.2346 - val_loss: 11.7512 - val_accuracy: 0.0171\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.3935 - accuracy: 0.2333 - val_loss: 11.5627 - val_accuracy: 0.0172\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.5028 - accuracy: 0.2372 - val_loss: 12.8066 - val_accuracy: 0.0150\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.3842 - accuracy: 0.2358 - val_loss: 13.3381 - val_accuracy: 0.0150\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 6.4125 - accuracy: 0.2363 - val_loss: 12.9154 - val_accuracy: 0.0163\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.3912 - accuracy: 0.2320 - val_loss: 13.7246 - val_accuracy: 0.0164\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.2946 - accuracy: 0.2423 - val_loss: 14.0844 - val_accuracy: 0.0144\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 6.2605 - accuracy: 0.2323 - val_loss: 13.6607 - val_accuracy: 0.0150\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.1326 - accuracy: 0.2380 - val_loss: 12.0295 - val_accuracy: 0.0164\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.1442 - accuracy: 0.2336 - val_loss: 12.2782 - val_accuracy: 0.0168\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 6.1985 - accuracy: 0.2316 - val_loss: 12.1573 - val_accuracy: 0.0176\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.9964 - accuracy: 0.2397 - val_loss: 13.2219 - val_accuracy: 0.0151\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 5.9760 - accuracy: 0.2346 - val_loss: 14.7929 - val_accuracy: 0.0137\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 6.1019 - accuracy: 0.2407 - val_loss: 10.4486 - val_accuracy: 0.0171\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.0800 - accuracy: 0.2371 - val_loss: 12.6034 - val_accuracy: 0.0163\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.0348 - accuracy: 0.2327 - val_loss: 9.6338 - val_accuracy: 0.0170\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.9434 - accuracy: 0.2354 - val_loss: 11.4239 - val_accuracy: 0.0134\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 5.8592 - accuracy: 0.2390 - val_loss: 13.0565 - val_accuracy: 0.0133\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.8542 - accuracy: 0.2390 - val_loss: 12.4094 - val_accuracy: 0.0138\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.9203 - accuracy: 0.2383 - val_loss: 10.6643 - val_accuracy: 0.0160\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.2547 - accuracy: 0.2318 - val_loss: 17.4921 - val_accuracy: 0.0084\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 8.4550 - accuracy: 0.2337 - val_loss: 6.6778 - val_accuracy: 0.0956\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 7.1189 - accuracy: 0.2355 - val_loss: 5.8219 - val_accuracy: 0.0451\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.6458 - accuracy: 0.2361 - val_loss: 6.5984 - val_accuracy: 0.0259\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.4193 - accuracy: 0.2375 - val_loss: 7.0059 - val_accuracy: 0.0290\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 6.2054 - accuracy: 0.2360 - val_loss: 7.2807 - val_accuracy: 0.0469\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 6.1373 - accuracy: 0.2360 - val_loss: 6.5990 - val_accuracy: 0.1454\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.2648 - accuracy: 0.2346 - val_loss: 5.2129 - val_accuracy: 0.2070\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 6.0853 - accuracy: 0.2377 - val_loss: 5.6345 - val_accuracy: 0.1742\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 6.0539 - accuracy: 0.2390 - val_loss: 5.0124 - val_accuracy: 0.1903\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 6.0337 - accuracy: 0.2384 - val_loss: 6.2739 - val_accuracy: 0.1749\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.9218 - accuracy: 0.2425 - val_loss: 4.8881 - val_accuracy: 0.2388\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 5.9757 - accuracy: 0.2407 - val_loss: 3.9600 - val_accuracy: 0.3267\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 5.8934 - accuracy: 0.2426 - val_loss: 5.2834 - val_accuracy: 0.2836\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 5.9470 - accuracy: 0.2451 - val_loss: 5.0557 - val_accuracy: 0.2173\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 6.0689 - accuracy: 0.2429 - val_loss: 5.8633 - val_accuracy: 0.1723\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.9117 - accuracy: 0.2405 - val_loss: 6.1238 - val_accuracy: 0.1628\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 5.8194 - accuracy: 0.2459 - val_loss: 5.8895 - val_accuracy: 0.2253\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 5.8431 - accuracy: 0.2457 - val_loss: 6.8770 - val_accuracy: 0.1743\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 5.8399 - accuracy: 0.2488 - val_loss: 5.7034 - val_accuracy: 0.1579\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 5.7489 - accuracy: 0.2428 - val_loss: 5.6250 - val_accuracy: 0.1541\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 5.7429 - accuracy: 0.2456 - val_loss: 4.4958 - val_accuracy: 0.1981\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 5.7261 - accuracy: 0.2517 - val_loss: 4.5921 - val_accuracy: 0.1845\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.6549 - accuracy: 0.2466 - val_loss: 6.0801 - val_accuracy: 0.1608\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 5.7216 - accuracy: 0.2487 - val_loss: 5.7437 - val_accuracy: 0.1546\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.8121 - accuracy: 0.2424 - val_loss: 5.2092 - val_accuracy: 0.1659\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.7304 - accuracy: 0.2437 - val_loss: 6.7228 - val_accuracy: 0.1589\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.5323 - accuracy: 0.2463 - val_loss: 5.0470 - val_accuracy: 0.2129\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.6300 - accuracy: 0.2445 - val_loss: 5.9910 - val_accuracy: 0.1727\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 5.6470 - accuracy: 0.2482 - val_loss: 6.6666 - val_accuracy: 0.1770\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 5.5380 - accuracy: 0.2454 - val_loss: 5.0938 - val_accuracy: 0.2148\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.6621 - accuracy: 0.2436 - val_loss: 6.2067 - val_accuracy: 0.2017\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 5.6287 - accuracy: 0.2471 - val_loss: 5.3311 - val_accuracy: 0.2489\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.5019 - accuracy: 0.2446 - val_loss: 5.9195 - val_accuracy: 0.1844\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 5.4526 - accuracy: 0.2467 - val_loss: 5.2629 - val_accuracy: 0.2275\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.4178 - accuracy: 0.2449 - val_loss: 5.5054 - val_accuracy: 0.2100\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 5.5342 - accuracy: 0.2483 - val_loss: 4.9100 - val_accuracy: 0.2705\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 5.5181 - accuracy: 0.2454 - val_loss: 4.5761 - val_accuracy: 0.2613\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.2947 - accuracy: 0.2468 - val_loss: 4.5897 - val_accuracy: 0.2698\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 5.3545 - accuracy: 0.2495 - val_loss: 5.0596 - val_accuracy: 0.2612\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 5.3298 - accuracy: 0.2504 - val_loss: 4.9783 - val_accuracy: 0.2562\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.3440 - accuracy: 0.2506 - val_loss: 5.8229 - val_accuracy: 0.2571\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 5.3789 - accuracy: 0.2489 - val_loss: 5.9361 - val_accuracy: 0.2031\n",
            "Epoch 00106: early stopping\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 261ms/step - loss: 1.1514 - accuracy: 0.6799 - val_loss: 31.1057 - val_accuracy: 0.2098\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0954 - accuracy: 0.6995 - val_loss: 26.1283 - val_accuracy: 0.2101\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0904 - accuracy: 0.7138 - val_loss: 23.5067 - val_accuracy: 0.2067\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0738 - accuracy: 0.7237 - val_loss: 30.4362 - val_accuracy: 0.2052\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0409 - accuracy: 0.7306 - val_loss: 31.7386 - val_accuracy: 0.2081\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0653 - accuracy: 0.7160 - val_loss: 29.1680 - val_accuracy: 0.2065\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0426 - accuracy: 0.7234 - val_loss: 28.4264 - val_accuracy: 0.2086\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0384 - accuracy: 0.7360 - val_loss: 27.8821 - val_accuracy: 0.2084\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0347 - accuracy: 0.7398 - val_loss: 26.5325 - val_accuracy: 0.2078\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0284 - accuracy: 0.7362 - val_loss: 27.7200 - val_accuracy: 0.2094\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0310 - accuracy: 0.7341 - val_loss: 26.6544 - val_accuracy: 0.2054\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0333 - accuracy: 0.7118 - val_loss: 26.5346 - val_accuracy: 0.2085\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0211 - accuracy: 0.7315 - val_loss: 31.6141 - val_accuracy: 0.2069\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0445 - accuracy: 0.7406 - val_loss: 27.3236 - val_accuracy: 0.2090\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0528 - accuracy: 0.7480 - val_loss: 25.9802 - val_accuracy: 0.2073\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0142 - accuracy: 0.7625 - val_loss: 26.0284 - val_accuracy: 0.2071\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 1.0539 - accuracy: 0.7256 - val_loss: 25.3547 - val_accuracy: 0.2111\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 1.0324 - accuracy: 0.7456 - val_loss: 28.3029 - val_accuracy: 0.2130\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0385 - accuracy: 0.7150 - val_loss: 35.5219 - val_accuracy: 0.2075\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0498 - accuracy: 0.7190 - val_loss: 25.7927 - val_accuracy: 0.2081\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0329 - accuracy: 0.7445 - val_loss: 25.1134 - val_accuracy: 0.2070\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0418 - accuracy: 0.7135 - val_loss: 25.1381 - val_accuracy: 0.2060\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0271 - accuracy: 0.7251 - val_loss: 29.0632 - val_accuracy: 0.2092\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0324 - accuracy: 0.7331 - val_loss: 30.6880 - val_accuracy: 0.2093\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0239 - accuracy: 0.7328 - val_loss: 24.9943 - val_accuracy: 0.2107\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0296 - accuracy: 0.7132 - val_loss: 31.4004 - val_accuracy: 0.2099\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0317 - accuracy: 0.7432 - val_loss: 33.1539 - val_accuracy: 0.2045\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0211 - accuracy: 0.7217 - val_loss: 28.0415 - val_accuracy: 0.2061\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0146 - accuracy: 0.7221 - val_loss: 23.2830 - val_accuracy: 0.2067\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0284 - accuracy: 0.7205 - val_loss: 26.9443 - val_accuracy: 0.2085\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0265 - accuracy: 0.7427 - val_loss: 41.4850 - val_accuracy: 0.2092\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0294 - accuracy: 0.7012 - val_loss: 25.7281 - val_accuracy: 0.2093\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0174 - accuracy: 0.7368 - val_loss: 28.5942 - val_accuracy: 0.2115\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0129 - accuracy: 0.7276 - val_loss: 40.2359 - val_accuracy: 0.2032\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0323 - accuracy: 0.7331 - val_loss: 28.3301 - val_accuracy: 0.2051\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0118 - accuracy: 0.7422 - val_loss: 29.7781 - val_accuracy: 0.2030\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0138 - accuracy: 0.7178 - val_loss: 35.3238 - val_accuracy: 0.2046\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0263 - accuracy: 0.7091 - val_loss: 36.8526 - val_accuracy: 0.1980\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0215 - accuracy: 0.7239 - val_loss: 134.7704 - val_accuracy: 0.2034\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0041 - accuracy: 0.7291 - val_loss: 31.2256 - val_accuracy: 0.2129\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0010 - accuracy: 0.7129 - val_loss: 24.9568 - val_accuracy: 0.2107\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0274 - accuracy: 0.7019 - val_loss: 87.0241 - val_accuracy: 0.2098\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0261 - accuracy: 0.7428 - val_loss: 344.0115 - val_accuracy: 0.2091\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0251 - accuracy: 0.7167 - val_loss: 46.7169 - val_accuracy: 0.2098\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0200 - accuracy: 0.6788 - val_loss: 63.3610 - val_accuracy: 0.2086\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0179 - accuracy: 0.7363 - val_loss: 63.6499 - val_accuracy: 0.2059\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0301 - accuracy: 0.7029 - val_loss: 34.1072 - val_accuracy: 0.2106\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0059 - accuracy: 0.7065 - val_loss: 30.2047 - val_accuracy: 0.2073\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0131 - accuracy: 0.7289 - val_loss: 42.8233 - val_accuracy: 0.2100\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0215 - accuracy: 0.7142 - val_loss: 39.8443 - val_accuracy: 0.2045\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0097 - accuracy: 0.7041 - val_loss: 64.2735 - val_accuracy: 0.2070\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0052 - accuracy: 0.6843 - val_loss: 30.7099 - val_accuracy: 0.2049\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0330 - accuracy: 0.7242 - val_loss: 30.8481 - val_accuracy: 0.2044\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0201 - accuracy: 0.6810 - val_loss: 41.2340 - val_accuracy: 0.2077\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0049 - accuracy: 0.7463 - val_loss: 467.3768 - val_accuracy: 0.2056\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0046 - accuracy: 0.7003 - val_loss: 51.7079 - val_accuracy: 0.2075\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0080 - accuracy: 0.7167 - val_loss: 3998.4531 - val_accuracy: 0.2055\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0284 - accuracy: 0.6996 - val_loss: 849.5452 - val_accuracy: 0.2046\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0070 - accuracy: 0.6998 - val_loss: 16867.2441 - val_accuracy: 0.2005\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0250 - accuracy: 0.7037 - val_loss: 4078.6340 - val_accuracy: 0.2002\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0123 - accuracy: 0.6966 - val_loss: 713.3966 - val_accuracy: 0.2048\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0138 - accuracy: 0.6978 - val_loss: 1652.9319 - val_accuracy: 0.2034\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0168 - accuracy: 0.7195 - val_loss: 22184.1602 - val_accuracy: 0.2007\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9836 - accuracy: 0.6747 - val_loss: 328.0176 - val_accuracy: 0.2039\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0081 - accuracy: 0.7218 - val_loss: 248.3865 - val_accuracy: 0.2023\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9966 - accuracy: 0.6969 - val_loss: 6917.5972 - val_accuracy: 0.2050\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9968 - accuracy: 0.7069 - val_loss: 10907.5674 - val_accuracy: 0.2040\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0074 - accuracy: 0.6843 - val_loss: 5254.0312 - val_accuracy: 0.2058\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0180 - accuracy: 0.7041 - val_loss: 507.9926 - val_accuracy: 0.2020\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9989 - accuracy: 0.6863 - val_loss: 1626.9248 - val_accuracy: 0.2041\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9887 - accuracy: 0.7066 - val_loss: 2435.9500 - val_accuracy: 0.2048\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9857 - accuracy: 0.7048 - val_loss: 89.1305 - val_accuracy: 0.2057\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9942 - accuracy: 0.7101 - val_loss: 3031.8196 - val_accuracy: 0.2048\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 0.9848 - accuracy: 0.6970 - val_loss: 413.6667 - val_accuracy: 0.2068\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0041 - accuracy: 0.6933 - val_loss: 42.6145 - val_accuracy: 0.2048\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9771 - accuracy: 0.7156 - val_loss: 241.4746 - val_accuracy: 0.2099\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9880 - accuracy: 0.6969 - val_loss: 67.3423 - val_accuracy: 0.2122\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9872 - accuracy: 0.7034 - val_loss: 47.4189 - val_accuracy: 0.2158\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0029 - accuracy: 0.6845 - val_loss: 384.2636 - val_accuracy: 0.2157\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9958 - accuracy: 0.6859 - val_loss: 2344.0989 - val_accuracy: 0.2135\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9975 - accuracy: 0.6850 - val_loss: 95.0949 - val_accuracy: 0.2193\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9899 - accuracy: 0.6906 - val_loss: 115.1968 - val_accuracy: 0.2188\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9937 - accuracy: 0.6897 - val_loss: 256.3484 - val_accuracy: 0.2172\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9899 - accuracy: 0.7010 - val_loss: 1031.4191 - val_accuracy: 0.2090\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9793 - accuracy: 0.7096 - val_loss: 230.8210 - val_accuracy: 0.2020\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0020 - accuracy: 0.6817 - val_loss: 497.7546 - val_accuracy: 0.2115\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9991 - accuracy: 0.6950 - val_loss: 453.5020 - val_accuracy: 0.2084\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9790 - accuracy: 0.6957 - val_loss: 217.1539 - val_accuracy: 0.2089\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9822 - accuracy: 0.6883 - val_loss: 121.2488 - val_accuracy: 0.2006\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9901 - accuracy: 0.6986 - val_loss: 520.4290 - val_accuracy: 0.2000\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9871 - accuracy: 0.6982 - val_loss: 343.1030 - val_accuracy: 0.2022\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0102 - accuracy: 0.6948 - val_loss: 6875.7788 - val_accuracy: 0.1899\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9853 - accuracy: 0.6936 - val_loss: 277.6364 - val_accuracy: 0.1840\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9890 - accuracy: 0.7062 - val_loss: 6409.5269 - val_accuracy: 0.1717\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9976 - accuracy: 0.7077 - val_loss: 31.1488 - val_accuracy: 0.1960\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9937 - accuracy: 0.7023 - val_loss: 33.6174 - val_accuracy: 0.1946\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9857 - accuracy: 0.6972 - val_loss: 71.5943 - val_accuracy: 0.1994\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9844 - accuracy: 0.6950 - val_loss: 39.1853 - val_accuracy: 0.1908\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9749 - accuracy: 0.7066 - val_loss: 38.2036 - val_accuracy: 0.1903\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9673 - accuracy: 0.6935 - val_loss: 34.0146 - val_accuracy: 0.1973\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9852 - accuracy: 0.7089 - val_loss: 38.3233 - val_accuracy: 0.1989\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9771 - accuracy: 0.7094 - val_loss: 39.8872 - val_accuracy: 0.1935\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9742 - accuracy: 0.7067 - val_loss: 67.1959 - val_accuracy: 0.1940\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9764 - accuracy: 0.6945 - val_loss: 91.8585 - val_accuracy: 0.2004\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9923 - accuracy: 0.7003 - val_loss: 341.8253 - val_accuracy: 0.1961\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9799 - accuracy: 0.6977 - val_loss: 330.5425 - val_accuracy: 0.1937\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9850 - accuracy: 0.7064 - val_loss: 524.5082 - val_accuracy: 0.1806\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9804 - accuracy: 0.6915 - val_loss: 463.5335 - val_accuracy: 0.1898\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9958 - accuracy: 0.6893 - val_loss: 1461.5697 - val_accuracy: 0.1951\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9791 - accuracy: 0.6964 - val_loss: 443.1496 - val_accuracy: 0.1951\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9855 - accuracy: 0.6872 - val_loss: 63.5593 - val_accuracy: 0.1919\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0132 - accuracy: 0.7051 - val_loss: 67.8121 - val_accuracy: 0.2021\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9859 - accuracy: 0.7125 - val_loss: 51.3608 - val_accuracy: 0.2075\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9953 - accuracy: 0.6695 - val_loss: 47.6018 - val_accuracy: 0.2037\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9921 - accuracy: 0.6978 - val_loss: 2724.2344 - val_accuracy: 0.1962\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9695 - accuracy: 0.6986 - val_loss: 3278.9819 - val_accuracy: 0.2013\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9743 - accuracy: 0.7016 - val_loss: 2725.6653 - val_accuracy: 0.2024\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9767 - accuracy: 0.7066 - val_loss: 2712.2266 - val_accuracy: 0.2056\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9791 - accuracy: 0.7103 - val_loss: 1438.4084 - val_accuracy: 0.2061\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9660 - accuracy: 0.6993 - val_loss: 2115.9026 - val_accuracy: 0.2106\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9912 - accuracy: 0.7025 - val_loss: 741.7953 - val_accuracy: 0.2056\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9982 - accuracy: 0.7096 - val_loss: 242.1306 - val_accuracy: 0.2057\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9922 - accuracy: 0.6851 - val_loss: 326.6280 - val_accuracy: 0.2036\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9757 - accuracy: 0.7151 - val_loss: 80.1530 - val_accuracy: 0.2072\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9800 - accuracy: 0.6832 - val_loss: 56.8564 - val_accuracy: 0.2052\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9785 - accuracy: 0.6974 - val_loss: 65.5540 - val_accuracy: 0.2061\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9718 - accuracy: 0.7063 - val_loss: 24.6979 - val_accuracy: 0.2123\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9730 - accuracy: 0.7010 - val_loss: 1817.0040 - val_accuracy: 0.2144\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9702 - accuracy: 0.7016 - val_loss: 57.7719 - val_accuracy: 0.2080\n",
            "Epoch 00129: early stopping\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 267ms/step - loss: 1.1985 - accuracy: 0.6713 - val_loss: 1.5039 - val_accuracy: 0.7707\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0752 - accuracy: 0.7124 - val_loss: 1.5670 - val_accuracy: 0.7718\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0689 - accuracy: 0.7180 - val_loss: 1.7425 - val_accuracy: 0.7674\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0626 - accuracy: 0.7066 - val_loss: 1.6136 - val_accuracy: 0.7706\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0512 - accuracy: 0.7153 - val_loss: 1.9794 - val_accuracy: 0.7676\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0490 - accuracy: 0.7097 - val_loss: 1.7762 - val_accuracy: 0.7683\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.0270 - accuracy: 0.7249 - val_loss: 1.6671 - val_accuracy: 0.7702\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0341 - accuracy: 0.7174 - val_loss: 1.9353 - val_accuracy: 0.7675\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0227 - accuracy: 0.7148 - val_loss: 2.1315 - val_accuracy: 0.7667\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0288 - accuracy: 0.7058 - val_loss: 1.7105 - val_accuracy: 0.7723\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0433 - accuracy: 0.7214 - val_loss: 1.4801 - val_accuracy: 0.7714\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0226 - accuracy: 0.7138 - val_loss: 1.8341 - val_accuracy: 0.7683\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0141 - accuracy: 0.7082 - val_loss: 2.0885 - val_accuracy: 0.7673\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0244 - accuracy: 0.7060 - val_loss: 2.2756 - val_accuracy: 0.7680\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.0273 - accuracy: 0.7093 - val_loss: 1.8611 - val_accuracy: 0.7674\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0178 - accuracy: 0.7088 - val_loss: 1.4261 - val_accuracy: 0.7723\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9942 - accuracy: 0.6970 - val_loss: 1.7844 - val_accuracy: 0.7683\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9988 - accuracy: 0.7017 - val_loss: 1.7938 - val_accuracy: 0.7697\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0211 - accuracy: 0.6973 - val_loss: 1.1621 - val_accuracy: 0.7686\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9932 - accuracy: 0.6970 - val_loss: 1.5486 - val_accuracy: 0.7675\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9983 - accuracy: 0.6992 - val_loss: 1.5088 - val_accuracy: 0.7706\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9989 - accuracy: 0.7031 - val_loss: 1.8258 - val_accuracy: 0.7663\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0067 - accuracy: 0.7002 - val_loss: 1.6107 - val_accuracy: 0.7598\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9829 - accuracy: 0.6981 - val_loss: 1.3811 - val_accuracy: 0.7582\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9802 - accuracy: 0.6994 - val_loss: 1.7529 - val_accuracy: 0.7390\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9847 - accuracy: 0.6995 - val_loss: 1.7471 - val_accuracy: 0.7508\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9885 - accuracy: 0.7026 - val_loss: 1.1498 - val_accuracy: 0.7325\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9873 - accuracy: 0.7081 - val_loss: 1.2842 - val_accuracy: 0.7354\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 4s 263ms/step - loss: 0.9810 - accuracy: 0.6963 - val_loss: 1.7325 - val_accuracy: 0.7314\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.9821 - accuracy: 0.7122 - val_loss: 2.0729 - val_accuracy: 0.7280\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.9833 - accuracy: 0.7051 - val_loss: 3.3914 - val_accuracy: 0.7310\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9936 - accuracy: 0.6947 - val_loss: 2.0756 - val_accuracy: 0.7365\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9925 - accuracy: 0.7025 - val_loss: 4.8450 - val_accuracy: 0.7302\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9705 - accuracy: 0.7080 - val_loss: 3.7148 - val_accuracy: 0.7301\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9646 - accuracy: 0.7173 - val_loss: 3.0339 - val_accuracy: 0.7268\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9847 - accuracy: 0.7039 - val_loss: 17.5410 - val_accuracy: 0.7220\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9778 - accuracy: 0.6943 - val_loss: 4.5116 - val_accuracy: 0.7251\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9670 - accuracy: 0.7127 - val_loss: 9.7210 - val_accuracy: 0.7294\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9788 - accuracy: 0.7036 - val_loss: 3.1646 - val_accuracy: 0.7268\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9670 - accuracy: 0.7167 - val_loss: 5.9544 - val_accuracy: 0.7325\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9696 - accuracy: 0.7114 - val_loss: 1310.8828 - val_accuracy: 0.7315\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9511 - accuracy: 0.7090 - val_loss: 36833.9922 - val_accuracy: 0.6991\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9599 - accuracy: 0.7228 - val_loss: 23819.9844 - val_accuracy: 0.6838\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9611 - accuracy: 0.7134 - val_loss: 16668.3594 - val_accuracy: 0.6720\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9596 - accuracy: 0.7236 - val_loss: 46774.6680 - val_accuracy: 0.6546\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9576 - accuracy: 0.7181 - val_loss: 3700.2852 - val_accuracy: 0.4768\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9392 - accuracy: 0.7209 - val_loss: 7808.8271 - val_accuracy: 0.4968\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9435 - accuracy: 0.7186 - val_loss: 399051.7188 - val_accuracy: 0.4496\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9935 - accuracy: 0.7396 - val_loss: 9960.1729 - val_accuracy: 0.4564\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.1053 - accuracy: 0.7312 - val_loss: 37.1209 - val_accuracy: 0.4688\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0712 - accuracy: 0.7146 - val_loss: 1.9497 - val_accuracy: 0.6953\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0765 - accuracy: 0.7546 - val_loss: 1.8736 - val_accuracy: 0.7461\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0692 - accuracy: 0.7303 - val_loss: 1.5995 - val_accuracy: 0.7633\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0640 - accuracy: 0.7915 - val_loss: 2.0434 - val_accuracy: 0.7650\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0523 - accuracy: 0.7350 - val_loss: 1.7304 - val_accuracy: 0.7664\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0485 - accuracy: 0.7439 - val_loss: 1.8405 - val_accuracy: 0.7615\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0448 - accuracy: 0.8051 - val_loss: 1.6780 - val_accuracy: 0.7633\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0329 - accuracy: 0.7751 - val_loss: 1.2516 - val_accuracy: 0.7678\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0275 - accuracy: 0.7967 - val_loss: 1.2537 - val_accuracy: 0.7671\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0552 - accuracy: 0.7421 - val_loss: 1.8428 - val_accuracy: 0.7685\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0431 - accuracy: 0.7062 - val_loss: 2.1802 - val_accuracy: 0.7638\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0260 - accuracy: 0.7611 - val_loss: 1.7897 - val_accuracy: 0.7636\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0358 - accuracy: 0.7502 - val_loss: 1.8388 - val_accuracy: 0.7664\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0360 - accuracy: 0.7683 - val_loss: 1.5915 - val_accuracy: 0.7668\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0185 - accuracy: 0.7750 - val_loss: 2.4274 - val_accuracy: 0.7610\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.0248 - accuracy: 0.7783 - val_loss: 1.3236 - val_accuracy: 0.7715\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0181 - accuracy: 0.7769 - val_loss: 2.2137 - val_accuracy: 0.7632\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0368 - accuracy: 0.7648 - val_loss: 2.6581 - val_accuracy: 0.7614\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0364 - accuracy: 0.7592 - val_loss: 2.7776 - val_accuracy: 0.7651\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0215 - accuracy: 0.7587 - val_loss: 2.6134 - val_accuracy: 0.7623\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0174 - accuracy: 0.7776 - val_loss: 3.5207 - val_accuracy: 0.7608\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0288 - accuracy: 0.7688 - val_loss: 4.8756 - val_accuracy: 0.7637\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0287 - accuracy: 0.7749 - val_loss: 3.5238 - val_accuracy: 0.7624\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0377 - accuracy: 0.7693 - val_loss: 4.9335 - val_accuracy: 0.7634\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0200 - accuracy: 0.7768 - val_loss: 5.5399 - val_accuracy: 0.7643\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0283 - accuracy: 0.7682 - val_loss: 14.3344 - val_accuracy: 0.7621\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0147 - accuracy: 0.7820 - val_loss: 4.1709 - val_accuracy: 0.7636\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0145 - accuracy: 0.7897 - val_loss: 11.5421 - val_accuracy: 0.7673\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0093 - accuracy: 0.7585 - val_loss: 17.3112 - val_accuracy: 0.7606\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0208 - accuracy: 0.7808 - val_loss: 15.8948 - val_accuracy: 0.7596\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0302 - accuracy: 0.7589 - val_loss: 9.9653 - val_accuracy: 0.7503\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0185 - accuracy: 0.7760 - val_loss: 27.4460 - val_accuracy: 0.7604\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.0016 - accuracy: 0.7780 - val_loss: 19.5051 - val_accuracy: 0.7573\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0290 - accuracy: 0.7665 - val_loss: 18.6337 - val_accuracy: 0.7493\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0238 - accuracy: 0.7872 - val_loss: 5.8206 - val_accuracy: 0.7553\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0232 - accuracy: 0.7750 - val_loss: 14.7694 - val_accuracy: 0.7419\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0063 - accuracy: 0.7717 - val_loss: 53.1560 - val_accuracy: 0.7443\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0144 - accuracy: 0.7724 - val_loss: 35.0498 - val_accuracy: 0.7278\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0203 - accuracy: 0.7573 - val_loss: 99.1008 - val_accuracy: 0.7404\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0126 - accuracy: 0.7691 - val_loss: 55.5639 - val_accuracy: 0.7307\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0292 - accuracy: 0.7760 - val_loss: 14.5944 - val_accuracy: 0.6783\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0140 - accuracy: 0.7621 - val_loss: 85.2162 - val_accuracy: 0.6819\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0069 - accuracy: 0.7672 - val_loss: 46.9187 - val_accuracy: 0.6863\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0231 - accuracy: 0.7787 - val_loss: 61.7739 - val_accuracy: 0.6364\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0066 - accuracy: 0.7475 - val_loss: 172.9866 - val_accuracy: 0.6798\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0126 - accuracy: 0.7570 - val_loss: 194.5864 - val_accuracy: 0.4944\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0161 - accuracy: 0.7600 - val_loss: 432.3449 - val_accuracy: 0.4242\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0396 - accuracy: 0.7655 - val_loss: 612.4710 - val_accuracy: 0.6282\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0292 - accuracy: 0.7681 - val_loss: 434.1555 - val_accuracy: 0.5139\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0146 - accuracy: 0.7559 - val_loss: 1182.1732 - val_accuracy: 0.6567\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0093 - accuracy: 0.7632 - val_loss: 1229.7117 - val_accuracy: 0.5985\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0230 - accuracy: 0.7745 - val_loss: 893.9402 - val_accuracy: 0.3003\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0092 - accuracy: 0.7600 - val_loss: 1448.3928 - val_accuracy: 0.6168\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0129 - accuracy: 0.7714 - val_loss: 2135.9805 - val_accuracy: 0.4290\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0001 - accuracy: 0.7737 - val_loss: 3458.2358 - val_accuracy: 0.4125\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0088 - accuracy: 0.7599 - val_loss: 2884.9746 - val_accuracy: 0.5408\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0108 - accuracy: 0.7568 - val_loss: 11725.2188 - val_accuracy: 0.6113\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0117 - accuracy: 0.7535 - val_loss: 9680.0801 - val_accuracy: 0.5654\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0056 - accuracy: 0.7517 - val_loss: 8375.1074 - val_accuracy: 0.5450\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0157 - accuracy: 0.7488 - val_loss: 10283.1787 - val_accuracy: 0.4833\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0070 - accuracy: 0.7657 - val_loss: 10057.9668 - val_accuracy: 0.5016\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0254 - accuracy: 0.7492 - val_loss: 1363.0100 - val_accuracy: 0.5306\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9941 - accuracy: 0.7755 - val_loss: 3099.1858 - val_accuracy: 0.5562\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0061 - accuracy: 0.7348 - val_loss: 1479.5970 - val_accuracy: 0.5803\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0090 - accuracy: 0.7506 - val_loss: 7299.5469 - val_accuracy: 0.5931\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0053 - accuracy: 0.7494 - val_loss: 9473.5957 - val_accuracy: 0.5665\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0047 - accuracy: 0.7546 - val_loss: 19639.8223 - val_accuracy: 0.5396\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0095 - accuracy: 0.7408 - val_loss: 21440.3945 - val_accuracy: 0.5546\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0039 - accuracy: 0.7514 - val_loss: 27629.0977 - val_accuracy: 0.6113\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9983 - accuracy: 0.7619 - val_loss: 15052.4912 - val_accuracy: 0.4925\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0142 - accuracy: 0.7337 - val_loss: 22017.4961 - val_accuracy: 0.5484\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0077 - accuracy: 0.7622 - val_loss: 10177.2236 - val_accuracy: 0.5099\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0018 - accuracy: 0.7407 - val_loss: 8052.1885 - val_accuracy: 0.5405\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9837 - accuracy: 0.7585 - val_loss: 5489.5693 - val_accuracy: 0.5841\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0050 - accuracy: 0.7545 - val_loss: 7547.4834 - val_accuracy: 0.5543\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9955 - accuracy: 0.7323 - val_loss: 5074.2031 - val_accuracy: 0.5767\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9904 - accuracy: 0.7576 - val_loss: 6374.5161 - val_accuracy: 0.5443\n",
            "Epoch 00127: early stopping\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 257ms/step - loss: 1.2750 - accuracy: 0.6786 - val_loss: 2.5572 - val_accuracy: 0.5678\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.1089 - accuracy: 0.7279 - val_loss: 2.4457 - val_accuracy: 0.5675\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0839 - accuracy: 0.7368 - val_loss: 2.5366 - val_accuracy: 0.5707\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0784 - accuracy: 0.7265 - val_loss: 2.4499 - val_accuracy: 0.5714\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.0681 - accuracy: 0.7352 - val_loss: 2.8092 - val_accuracy: 0.5634\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 1.0570 - accuracy: 0.7168 - val_loss: 2.1110 - val_accuracy: 0.5684\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0368 - accuracy: 0.7325 - val_loss: 2.2660 - val_accuracy: 0.5708\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0614 - accuracy: 0.7284 - val_loss: 2.4930 - val_accuracy: 0.5668\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0614 - accuracy: 0.7263 - val_loss: 2.7575 - val_accuracy: 0.5634\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0472 - accuracy: 0.7186 - val_loss: 2.3267 - val_accuracy: 0.5665\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0258 - accuracy: 0.7183 - val_loss: 2.5417 - val_accuracy: 0.5680\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0421 - accuracy: 0.7177 - val_loss: 2.5467 - val_accuracy: 0.5670\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0347 - accuracy: 0.7138 - val_loss: 2.2885 - val_accuracy: 0.5661\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0239 - accuracy: 0.7167 - val_loss: 1.9347 - val_accuracy: 0.5679\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0250 - accuracy: 0.7207 - val_loss: 2.1875 - val_accuracy: 0.5494\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0084 - accuracy: 0.7231 - val_loss: 2.0070 - val_accuracy: 0.5368\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0061 - accuracy: 0.7164 - val_loss: 2.1160 - val_accuracy: 0.5143\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0537 - accuracy: 0.7226 - val_loss: 2.2447 - val_accuracy: 0.5616\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0486 - accuracy: 0.7126 - val_loss: 2.5372 - val_accuracy: 0.5619\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0205 - accuracy: 0.7316 - val_loss: 2.3588 - val_accuracy: 0.5716\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0405 - accuracy: 0.6996 - val_loss: 2.3433 - val_accuracy: 0.5336\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0197 - accuracy: 0.7131 - val_loss: 1.6955 - val_accuracy: 0.5351\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0082 - accuracy: 0.7139 - val_loss: 2.2108 - val_accuracy: 0.5612\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0004 - accuracy: 0.6859 - val_loss: 2.5260 - val_accuracy: 0.4881\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0229 - accuracy: 0.7263 - val_loss: 1.8954 - val_accuracy: 0.4956\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0044 - accuracy: 0.7039 - val_loss: 1.9667 - val_accuracy: 0.5555\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0072 - accuracy: 0.7120 - val_loss: 2.2994 - val_accuracy: 0.5573\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0061 - accuracy: 0.7064 - val_loss: 2.4688 - val_accuracy: 0.5178\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0121 - accuracy: 0.7044 - val_loss: 2.8717 - val_accuracy: 0.4722\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9975 - accuracy: 0.6970 - val_loss: 2.5008 - val_accuracy: 0.4540\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0076 - accuracy: 0.6941 - val_loss: 2.9927 - val_accuracy: 0.4462\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0001 - accuracy: 0.7055 - val_loss: 3.4444 - val_accuracy: 0.4403\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9766 - accuracy: 0.6997 - val_loss: 4.3943 - val_accuracy: 0.4274\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9751 - accuracy: 0.7106 - val_loss: 4.9221 - val_accuracy: 0.4211\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9948 - accuracy: 0.7005 - val_loss: 8.2798 - val_accuracy: 0.4163\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9829 - accuracy: 0.6989 - val_loss: 14.5967 - val_accuracy: 0.4092\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 0.9847 - accuracy: 0.7000 - val_loss: 19.2618 - val_accuracy: 0.4109\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9966 - accuracy: 0.7051 - val_loss: 19.9567 - val_accuracy: 0.4058\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9841 - accuracy: 0.7111 - val_loss: 30.0900 - val_accuracy: 0.4108\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9988 - accuracy: 0.6977 - val_loss: 7.3317 - val_accuracy: 0.4581\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9876 - accuracy: 0.6971 - val_loss: 5.4987 - val_accuracy: 0.4685\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9834 - accuracy: 0.7072 - val_loss: 6.5442 - val_accuracy: 0.4760\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9877 - accuracy: 0.7021 - val_loss: 7.1327 - val_accuracy: 0.4836\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9736 - accuracy: 0.6991 - val_loss: 7.2505 - val_accuracy: 0.4863\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9697 - accuracy: 0.7130 - val_loss: 7.9630 - val_accuracy: 0.4870\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 0.9774 - accuracy: 0.7077 - val_loss: 5.9049 - val_accuracy: 0.4885\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 0.9771 - accuracy: 0.7119 - val_loss: 6.1118 - val_accuracy: 0.4938\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9898 - accuracy: 0.7017 - val_loss: 8.0635 - val_accuracy: 0.4917\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9652 - accuracy: 0.7203 - val_loss: 26.2539 - val_accuracy: 0.4836\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9859 - accuracy: 0.7077 - val_loss: 16.6499 - val_accuracy: 0.4740\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9680 - accuracy: 0.7148 - val_loss: 19.2550 - val_accuracy: 0.4592\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9771 - accuracy: 0.7156 - val_loss: 54.5577 - val_accuracy: 0.4606\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9680 - accuracy: 0.7109 - val_loss: 55.5210 - val_accuracy: 0.4636\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9548 - accuracy: 0.7156 - val_loss: 28.6357 - val_accuracy: 0.4512\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9422 - accuracy: 0.7097 - val_loss: 38.7311 - val_accuracy: 0.4599\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9623 - accuracy: 0.7352 - val_loss: 71.9605 - val_accuracy: 0.4430\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9648 - accuracy: 0.7119 - val_loss: 82.8917 - val_accuracy: 0.4392\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9570 - accuracy: 0.7176 - val_loss: 71.4578 - val_accuracy: 0.4400\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9509 - accuracy: 0.7297 - val_loss: 61.9073 - val_accuracy: 0.4523\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9551 - accuracy: 0.7186 - val_loss: 47.5048 - val_accuracy: 0.4446\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9625 - accuracy: 0.7138 - val_loss: 33.1979 - val_accuracy: 0.4425\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9556 - accuracy: 0.7251 - val_loss: 79.7059 - val_accuracy: 0.4477\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9508 - accuracy: 0.7246 - val_loss: 57.5278 - val_accuracy: 0.4455\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9546 - accuracy: 0.7307 - val_loss: 40.9597 - val_accuracy: 0.4583\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9541 - accuracy: 0.7144 - val_loss: 50.3314 - val_accuracy: 0.4429\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9507 - accuracy: 0.7269 - val_loss: 48.3432 - val_accuracy: 0.4661\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9512 - accuracy: 0.7221 - val_loss: 341.3463 - val_accuracy: 0.4442\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9436 - accuracy: 0.7376 - val_loss: 62.3334 - val_accuracy: 0.4484\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9293 - accuracy: 0.7253 - val_loss: 35.5321 - val_accuracy: 0.4340\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9436 - accuracy: 0.7351 - val_loss: 12.7042 - val_accuracy: 0.4409\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9405 - accuracy: 0.7252 - val_loss: 13.9782 - val_accuracy: 0.4463\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9348 - accuracy: 0.7344 - val_loss: 39.6997 - val_accuracy: 0.4354\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9240 - accuracy: 0.7496 - val_loss: 4.2984 - val_accuracy: 0.4513\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9491 - accuracy: 0.7401 - val_loss: 11.2691 - val_accuracy: 0.4774\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 0.9315 - accuracy: 0.7369 - val_loss: 8.1451 - val_accuracy: 0.3811\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9325 - accuracy: 0.7293 - val_loss: 16.5970 - val_accuracy: 0.4000\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 179ms/step - loss: 0.9198 - accuracy: 0.7507 - val_loss: 5.0887 - val_accuracy: 0.3917\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9155 - accuracy: 0.7459 - val_loss: 7.5361 - val_accuracy: 0.4021\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9161 - accuracy: 0.7452 - val_loss: 12.1305 - val_accuracy: 0.3974\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9110 - accuracy: 0.7481 - val_loss: 23.4293 - val_accuracy: 0.3824\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9209 - accuracy: 0.7419 - val_loss: 14.7888 - val_accuracy: 0.3774\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9131 - accuracy: 0.7615 - val_loss: 5.9854 - val_accuracy: 0.3808\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9033 - accuracy: 0.7447 - val_loss: 9.3158 - val_accuracy: 0.3973\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9222 - accuracy: 0.7493 - val_loss: 14.1220 - val_accuracy: 0.3661\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9187 - accuracy: 0.7531 - val_loss: 11.6002 - val_accuracy: 0.3678\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9046 - accuracy: 0.7520 - val_loss: 14.1861 - val_accuracy: 0.3733\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9169 - accuracy: 0.7545 - val_loss: 10.5299 - val_accuracy: 0.3361\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9062 - accuracy: 0.7569 - val_loss: 8.9079 - val_accuracy: 0.3035\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8952 - accuracy: 0.7614 - val_loss: 10.4786 - val_accuracy: 0.3798\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9112 - accuracy: 0.7466 - val_loss: 6.1515 - val_accuracy: 0.3856\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9141 - accuracy: 0.7597 - val_loss: 10.8150 - val_accuracy: 0.2934\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9180 - accuracy: 0.7566 - val_loss: 11.0012 - val_accuracy: 0.3297\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9170 - accuracy: 0.7471 - val_loss: 21.3644 - val_accuracy: 0.2137\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9093 - accuracy: 0.7612 - val_loss: 11.3596 - val_accuracy: 0.2790\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.8817 - accuracy: 0.7643 - val_loss: 28.1802 - val_accuracy: 0.2241\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.8820 - accuracy: 0.7638 - val_loss: 26.8969 - val_accuracy: 0.2314\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8972 - accuracy: 0.7632 - val_loss: 15.6538 - val_accuracy: 0.2815\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.8787 - accuracy: 0.7632 - val_loss: 28.7071 - val_accuracy: 0.2237\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.8928 - accuracy: 0.7626 - val_loss: 12.1071 - val_accuracy: 0.3212\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8746 - accuracy: 0.7628 - val_loss: 6.1597 - val_accuracy: 0.3975\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8888 - accuracy: 0.7736 - val_loss: 7.8589 - val_accuracy: 0.3700\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.8867 - accuracy: 0.7670 - val_loss: 19.9636 - val_accuracy: 0.3093\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.8999 - accuracy: 0.7595 - val_loss: 13.4833 - val_accuracy: 0.3521\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.8788 - accuracy: 0.7662 - val_loss: 18.2757 - val_accuracy: 0.3579\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.8519 - accuracy: 0.7685 - val_loss: 12.0800 - val_accuracy: 0.3449\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8666 - accuracy: 0.7731 - val_loss: 20.8373 - val_accuracy: 0.3373\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.8487 - accuracy: 0.7727 - val_loss: 12.6401 - val_accuracy: 0.3435\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8536 - accuracy: 0.7739 - val_loss: 7.6087 - val_accuracy: 0.3896\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.8617 - accuracy: 0.7689 - val_loss: 12.1487 - val_accuracy: 0.3433\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.8465 - accuracy: 0.7737 - val_loss: 7.2018 - val_accuracy: 0.3966\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.8452 - accuracy: 0.7748 - val_loss: 4.9416 - val_accuracy: 0.4501\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.8744 - accuracy: 0.7640 - val_loss: 9.5560 - val_accuracy: 0.3796\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.8386 - accuracy: 0.7720 - val_loss: 6.9974 - val_accuracy: 0.3717\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.8531 - accuracy: 0.7731 - val_loss: 7.1247 - val_accuracy: 0.4309\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8398 - accuracy: 0.7751 - val_loss: 4.3775 - val_accuracy: 0.4472\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 181ms/step - loss: 0.8180 - accuracy: 0.7793 - val_loss: 4.3445 - val_accuracy: 0.4881\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8340 - accuracy: 0.7712 - val_loss: 4.9898 - val_accuracy: 0.4657\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8489 - accuracy: 0.7780 - val_loss: 4.8663 - val_accuracy: 0.4648\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.8828 - accuracy: 0.7681 - val_loss: 6.2922 - val_accuracy: 0.4166\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8344 - accuracy: 0.7687 - val_loss: 5.7474 - val_accuracy: 0.4531\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8280 - accuracy: 0.7795 - val_loss: 5.6766 - val_accuracy: 0.4355\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.8584 - accuracy: 0.7715 - val_loss: 6.3510 - val_accuracy: 0.4354\n",
            "Epoch 00122: early stopping\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 247ms/step - loss: 1.1392 - accuracy: 0.6980 - val_loss: 20.0120 - val_accuracy: 0.3839\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0950 - accuracy: 0.7103 - val_loss: 20.8318 - val_accuracy: 0.3864\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0576 - accuracy: 0.7346 - val_loss: 21.3401 - val_accuracy: 0.3825\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0634 - accuracy: 0.7067 - val_loss: 19.5851 - val_accuracy: 0.3825\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0363 - accuracy: 0.7245 - val_loss: 19.9369 - val_accuracy: 0.3871\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0320 - accuracy: 0.7027 - val_loss: 22.4807 - val_accuracy: 0.3857\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0202 - accuracy: 0.7231 - val_loss: 20.6791 - val_accuracy: 0.3874\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0155 - accuracy: 0.7146 - val_loss: 21.2943 - val_accuracy: 0.3857\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0276 - accuracy: 0.7103 - val_loss: 19.8338 - val_accuracy: 0.3894\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0150 - accuracy: 0.7128 - val_loss: 19.8915 - val_accuracy: 0.3837\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0300 - accuracy: 0.7095 - val_loss: 20.8208 - val_accuracy: 0.3833\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0598 - accuracy: 0.7300 - val_loss: 22.4705 - val_accuracy: 0.3851\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1181 - accuracy: 0.7383 - val_loss: 20.2412 - val_accuracy: 0.3826\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0747 - accuracy: 0.7084 - val_loss: 19.0562 - val_accuracy: 0.3833\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0689 - accuracy: 0.7483 - val_loss: 23.2263 - val_accuracy: 0.3832\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0594 - accuracy: 0.6944 - val_loss: 20.9110 - val_accuracy: 0.3832\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0237 - accuracy: 0.7371 - val_loss: 22.0082 - val_accuracy: 0.3804\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0392 - accuracy: 0.7263 - val_loss: 20.0857 - val_accuracy: 0.3846\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0213 - accuracy: 0.7201 - val_loss: 19.9819 - val_accuracy: 0.3837\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0203 - accuracy: 0.7006 - val_loss: 20.2721 - val_accuracy: 0.3835\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0165 - accuracy: 0.7324 - val_loss: 23.9657 - val_accuracy: 0.3853\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0263 - accuracy: 0.6858 - val_loss: 20.6258 - val_accuracy: 0.3842\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0084 - accuracy: 0.7632 - val_loss: 19.6275 - val_accuracy: 0.3834\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0221 - accuracy: 0.7224 - val_loss: 20.1249 - val_accuracy: 0.3833\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0319 - accuracy: 0.7072 - val_loss: 19.9428 - val_accuracy: 0.3830\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0177 - accuracy: 0.7155 - val_loss: 23.7246 - val_accuracy: 0.3820\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0217 - accuracy: 0.7067 - val_loss: 22.6753 - val_accuracy: 0.3810\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0107 - accuracy: 0.7428 - val_loss: 22.1616 - val_accuracy: 0.3812\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0117 - accuracy: 0.7122 - val_loss: 20.9808 - val_accuracy: 0.3868\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0034 - accuracy: 0.7109 - val_loss: 23.9356 - val_accuracy: 0.3788\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0081 - accuracy: 0.7318 - val_loss: 20.6722 - val_accuracy: 0.3778\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0081 - accuracy: 0.7052 - val_loss: 20.0103 - val_accuracy: 0.3812\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0011 - accuracy: 0.7181 - val_loss: 23.4572 - val_accuracy: 0.3748\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0154 - accuracy: 0.7152 - val_loss: 20.1094 - val_accuracy: 0.3684\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0186 - accuracy: 0.7263 - val_loss: 20.0690 - val_accuracy: 0.3352\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9984 - accuracy: 0.7188 - val_loss: 25.7196 - val_accuracy: 0.2953\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 1.0235 - accuracy: 0.7164 - val_loss: 20.3729 - val_accuracy: 0.2468\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9882 - accuracy: 0.7240 - val_loss: 20.1576 - val_accuracy: 0.2140\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9897 - accuracy: 0.7238 - val_loss: 21.4396 - val_accuracy: 0.2417\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0047 - accuracy: 0.7253 - val_loss: 18.9375 - val_accuracy: 0.2501\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0019 - accuracy: 0.7265 - val_loss: 19.2142 - val_accuracy: 0.2516\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9999 - accuracy: 0.7293 - val_loss: 24.2169 - val_accuracy: 0.2547\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9997 - accuracy: 0.7118 - val_loss: 16.8163 - val_accuracy: 0.2409\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9994 - accuracy: 0.7246 - val_loss: 20.3467 - val_accuracy: 0.2379\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0049 - accuracy: 0.7125 - val_loss: 19.2604 - val_accuracy: 0.2700\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0070 - accuracy: 0.7096 - val_loss: 17.7658 - val_accuracy: 0.2701\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 1.0065 - accuracy: 0.7288 - val_loss: 22.8721 - val_accuracy: 0.2603\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0055 - accuracy: 0.6971 - val_loss: 18.6460 - val_accuracy: 0.2890\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 1.0013 - accuracy: 0.7266 - val_loss: 20.1990 - val_accuracy: 0.2612\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0048 - accuracy: 0.7220 - val_loss: 22.4020 - val_accuracy: 0.2746\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9878 - accuracy: 0.7132 - val_loss: 21.0479 - val_accuracy: 0.2736\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9939 - accuracy: 0.7349 - val_loss: 18.2320 - val_accuracy: 0.2814\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0184 - accuracy: 0.7198 - val_loss: 21.5186 - val_accuracy: 0.2860\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9874 - accuracy: 0.7155 - val_loss: 28.5028 - val_accuracy: 0.2648\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9988 - accuracy: 0.7103 - val_loss: 53.7607 - val_accuracy: 0.2644\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 182ms/step - loss: 0.9909 - accuracy: 0.7332 - val_loss: 145.2149 - val_accuracy: 0.2673\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9833 - accuracy: 0.7084 - val_loss: 19.2475 - val_accuracy: 0.2846\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0020 - accuracy: 0.7239 - val_loss: 21.1643 - val_accuracy: 0.2927\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0022 - accuracy: 0.7138 - val_loss: 28.8324 - val_accuracy: 0.2815\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9958 - accuracy: 0.7060 - val_loss: 18.9616 - val_accuracy: 0.2768\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0008 - accuracy: 0.7365 - val_loss: 130.0725 - val_accuracy: 0.3031\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 1.0007 - accuracy: 0.7094 - val_loss: 20.5028 - val_accuracy: 0.3123\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9964 - accuracy: 0.7375 - val_loss: 37.4783 - val_accuracy: 0.3231\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0134 - accuracy: 0.7076 - val_loss: 33.0952 - val_accuracy: 0.2944\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9871 - accuracy: 0.7212 - val_loss: 18.9712 - val_accuracy: 0.3081\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9804 - accuracy: 0.7167 - val_loss: 25.8683 - val_accuracy: 0.3053\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 181ms/step - loss: 0.9873 - accuracy: 0.7195 - val_loss: 149.0996 - val_accuracy: 0.3090\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.9759 - accuracy: 0.7132 - val_loss: 190.2923 - val_accuracy: 0.3034\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 5s 289ms/step - loss: 0.9965 - accuracy: 0.7153 - val_loss: 385.2105 - val_accuracy: 0.3066\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9924 - accuracy: 0.7168 - val_loss: 19.6698 - val_accuracy: 0.3111\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9724 - accuracy: 0.7280 - val_loss: 21.5702 - val_accuracy: 0.3128\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9865 - accuracy: 0.7129 - val_loss: 72.9085 - val_accuracy: 0.3283\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9936 - accuracy: 0.7239 - val_loss: 45.5269 - val_accuracy: 0.3157\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0115 - accuracy: 0.7130 - val_loss: 45.6028 - val_accuracy: 0.2955\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9813 - accuracy: 0.7074 - val_loss: 38.9286 - val_accuracy: 0.3113\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9846 - accuracy: 0.7241 - val_loss: 280.2810 - val_accuracy: 0.3023\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9768 - accuracy: 0.7185 - val_loss: 24.6623 - val_accuracy: 0.2981\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9869 - accuracy: 0.7098 - val_loss: 24.2174 - val_accuracy: 0.3150\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9851 - accuracy: 0.7216 - val_loss: 113.8978 - val_accuracy: 0.3055\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9888 - accuracy: 0.7050 - val_loss: 21.4764 - val_accuracy: 0.3454\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9905 - accuracy: 0.7162 - val_loss: 19.6602 - val_accuracy: 0.3096\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.0001 - accuracy: 0.7114 - val_loss: 37.8878 - val_accuracy: 0.2714\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9871 - accuracy: 0.7097 - val_loss: 22.9044 - val_accuracy: 0.2884\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9728 - accuracy: 0.7133 - val_loss: 37.7238 - val_accuracy: 0.3128\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9809 - accuracy: 0.7265 - val_loss: 130.9149 - val_accuracy: 0.2590\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9794 - accuracy: 0.7054 - val_loss: 42.3492 - val_accuracy: 0.2843\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9701 - accuracy: 0.7179 - val_loss: 271.0384 - val_accuracy: 0.2840\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9824 - accuracy: 0.7137 - val_loss: 530.4095 - val_accuracy: 0.2837\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9835 - accuracy: 0.7105 - val_loss: 32.6492 - val_accuracy: 0.2999\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9848 - accuracy: 0.7272 - val_loss: 233.3203 - val_accuracy: 0.2924\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9735 - accuracy: 0.7094 - val_loss: 159.4727 - val_accuracy: 0.2837\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9946 - accuracy: 0.7151 - val_loss: 1693.9420 - val_accuracy: 0.2843\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9742 - accuracy: 0.7232 - val_loss: 567.0318 - val_accuracy: 0.2842\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9714 - accuracy: 0.7295 - val_loss: 548.2795 - val_accuracy: 0.2789\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9816 - accuracy: 0.7159 - val_loss: 113.4900 - val_accuracy: 0.2884\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9755 - accuracy: 0.7336 - val_loss: 243.3835 - val_accuracy: 0.2750\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9777 - accuracy: 0.7146 - val_loss: 79.8242 - val_accuracy: 0.2939\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9775 - accuracy: 0.7284 - val_loss: 356.1588 - val_accuracy: 0.2836\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9760 - accuracy: 0.7267 - val_loss: 469.0894 - val_accuracy: 0.2924\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9682 - accuracy: 0.7259 - val_loss: 519.0851 - val_accuracy: 0.2874\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9600 - accuracy: 0.7348 - val_loss: 549.5717 - val_accuracy: 0.2900\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9642 - accuracy: 0.7240 - val_loss: 135.1154 - val_accuracy: 0.2778\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9527 - accuracy: 0.7345 - val_loss: 582.4195 - val_accuracy: 0.2937\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9676 - accuracy: 0.7248 - val_loss: 3130.3418 - val_accuracy: 0.3135\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9609 - accuracy: 0.7100 - val_loss: 212.5777 - val_accuracy: 0.3033\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9861 - accuracy: 0.7097 - val_loss: 285.6675 - val_accuracy: 0.3113\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9673 - accuracy: 0.7340 - val_loss: 166.2860 - val_accuracy: 0.3135\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9651 - accuracy: 0.7253 - val_loss: 938.4742 - val_accuracy: 0.3186\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9850 - accuracy: 0.7544 - val_loss: 39.8151 - val_accuracy: 0.3537\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9698 - accuracy: 0.7318 - val_loss: 365.3724 - val_accuracy: 0.2825\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9896 - accuracy: 0.7349 - val_loss: 160.1867 - val_accuracy: 0.2830\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9583 - accuracy: 0.7388 - val_loss: 939.1359 - val_accuracy: 0.2957\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 184ms/step - loss: 0.9584 - accuracy: 0.7408 - val_loss: 959.5307 - val_accuracy: 0.2693\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 180ms/step - loss: 0.9673 - accuracy: 0.7344 - val_loss: 3195.2922 - val_accuracy: 0.2768\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9515 - accuracy: 0.7399 - val_loss: 1452.3411 - val_accuracy: 0.2800\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9647 - accuracy: 0.7294 - val_loss: 124.7140 - val_accuracy: 0.2890\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9516 - accuracy: 0.7374 - val_loss: 264.0960 - val_accuracy: 0.2909\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9573 - accuracy: 0.7311 - val_loss: 256.9382 - val_accuracy: 0.2801\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9639 - accuracy: 0.7266 - val_loss: 236.3282 - val_accuracy: 0.2929\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9407 - accuracy: 0.7352 - val_loss: 75.8714 - val_accuracy: 0.2855\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9477 - accuracy: 0.7241 - val_loss: 87.8269 - val_accuracy: 0.3087\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9677 - accuracy: 0.7367 - val_loss: 87.5486 - val_accuracy: 0.3060\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9542 - accuracy: 0.7305 - val_loss: 237.2121 - val_accuracy: 0.3016\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9474 - accuracy: 0.7399 - val_loss: 79.9262 - val_accuracy: 0.2977\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9407 - accuracy: 0.7296 - val_loss: 3515.9958 - val_accuracy: 0.3026\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9583 - accuracy: 0.7427 - val_loss: 634.7646 - val_accuracy: 0.2942\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9514 - accuracy: 0.7483 - val_loss: 107.2306 - val_accuracy: 0.2881\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9568 - accuracy: 0.7296 - val_loss: 27.0429 - val_accuracy: 0.2802\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9743 - accuracy: 0.7370 - val_loss: 205.6224 - val_accuracy: 0.2816\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9456 - accuracy: 0.7348 - val_loss: 87.2232 - val_accuracy: 0.2955\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9418 - accuracy: 0.7319 - val_loss: 30.9517 - val_accuracy: 0.2859\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9575 - accuracy: 0.7289 - val_loss: 37.0401 - val_accuracy: 0.2763\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.9358 - accuracy: 0.7335 - val_loss: 94.8449 - val_accuracy: 0.2804\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9460 - accuracy: 0.7477 - val_loss: 45.7279 - val_accuracy: 0.2994\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.9509 - accuracy: 0.7385 - val_loss: 19.6169 - val_accuracy: 0.2973\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9460 - accuracy: 0.7418 - val_loss: 67.2692 - val_accuracy: 0.2887\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9483 - accuracy: 0.7335 - val_loss: 77.1403 - val_accuracy: 0.2709\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9512 - accuracy: 0.7315 - val_loss: 92.1597 - val_accuracy: 0.2540\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.9519 - accuracy: 0.7330 - val_loss: 48.2125 - val_accuracy: 0.2680\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 3s 181ms/step - loss: 0.9418 - accuracy: 0.7326 - val_loss: 1958.4998 - val_accuracy: 0.2801\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9488 - accuracy: 0.7296 - val_loss: 11761.2988 - val_accuracy: 0.2690\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 0.9532 - accuracy: 0.7390 - val_loss: 26.8090 - val_accuracy: 0.3153\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9504 - accuracy: 0.7353 - val_loss: 23.1034 - val_accuracy: 0.2918\n",
            "Epoch 00143: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAXpsGg6TeFj",
        "colab_type": "text"
      },
      "source": [
        "# ハイパーパラメータチューニング用の関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHOAs5F7NuEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from keras.callbacks import EarlyStopping \n",
        "\n",
        "DATA_PATH = \"./drive/My Drive/kaggle/m5-forecasting/datas/training_datas_onehot/training_datas\"\n",
        "\n",
        "def objective(hyperparameters, datapath=DATA_PATH, num_samples=30490):\n",
        "    \"\"\"\n",
        "    hyperparameters:\n",
        "    LSTM units\n",
        "    LSTM activation\n",
        "\n",
        "    # ハイパーパラメータは、build_modelの引数に渡す。\n",
        "    後ほど実装。(今は引数なし)\n",
        "\n",
        "    \"\"\"\n",
        "    batch_size = 128\n",
        "    epochs = 500\n",
        "    patience = 10000\n",
        "\n",
        "    \n",
        "    kfold = KFold(n_splits=5)\n",
        "    History = []\n",
        "\n",
        "    for train_cv_idx, valid_cv_idx in kfold.split(np.arange(0, num_samples)):\n",
        "\n",
        "        X_CV_train_gen = ReccurentTrainGenerator(DataPath=datapath, batch_size=128, InputSteps=28, sample_indices=train_cv_idx)\n",
        "        X_CV_valid_gen = ReccurentTrainGenerator(DataPath=datapath, batch_size=128, InputSteps=28, sample_indices=valid_cv_idx)\n",
        "\n",
        "        model = build_model() # 引数にハイパーパラメータを入れられるようにする\n",
        "\n",
        "        early_stopping = EarlyStopping(patience=patience, verbose=1) \n",
        "\n",
        "        history = model.fit_generator(X_CV_train_gen, epochs=epochs, verbose=1, validation_data=X_CV_valid_gen, callbacks=[early_stopping])\n",
        "        History.append(history)\n",
        "\n",
        "    scores = [History[i].history[\"val_loss\"][-1] for i in range(len(History))]\n",
        "    mean_score = np.mean(scores)\n",
        "\n",
        "    return mean_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haQ8RUtAPcZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bcc82f67-4923-46b0-8b4c-55837228f0a2"
      },
      "source": [
        "mean_score = objective(\"hyperparameters\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3447 - accuracy: 0.5629 - val_loss: 3.5539 - val_accuracy: 0.6957\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3145 - accuracy: 0.5606 - val_loss: 2.8256 - val_accuracy: 0.6967\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2825 - accuracy: 0.5599 - val_loss: 2.6238 - val_accuracy: 0.7027\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.2400 - accuracy: 0.5645 - val_loss: 3.1014 - val_accuracy: 0.6978\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2230 - accuracy: 0.5671 - val_loss: 2.9916 - val_accuracy: 0.7033\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.1849 - accuracy: 0.5665 - val_loss: 3.4472 - val_accuracy: 0.7009\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1912 - accuracy: 0.5658 - val_loss: 2.6143 - val_accuracy: 0.6780\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1677 - accuracy: 0.5696 - val_loss: 3.8796 - val_accuracy: 0.6751\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1457 - accuracy: 0.5727 - val_loss: 2.5380 - val_accuracy: 0.6647\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1406 - accuracy: 0.5720 - val_loss: 3.5448 - val_accuracy: 0.6658\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1034 - accuracy: 0.5812 - val_loss: 3.3276 - val_accuracy: 0.6634\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0942 - accuracy: 0.5836 - val_loss: 2.5964 - val_accuracy: 0.6543\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0716 - accuracy: 0.5921 - val_loss: 3.3636 - val_accuracy: 0.6607\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0788 - accuracy: 0.5846 - val_loss: 3.2120 - val_accuracy: 0.6610\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0754 - accuracy: 0.5877 - val_loss: 3.9933 - val_accuracy: 0.6597\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.0556 - accuracy: 0.5894 - val_loss: 2.4481 - val_accuracy: 0.6678\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0528 - accuracy: 0.5925 - val_loss: 2.7866 - val_accuracy: 0.6845\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0360 - accuracy: 0.5951 - val_loss: 3.1662 - val_accuracy: 0.6783\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.0323 - accuracy: 0.5939 - val_loss: 3.2004 - val_accuracy: 0.6886\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0400 - accuracy: 0.5961 - val_loss: 4.8639 - val_accuracy: 0.6819\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.0479 - accuracy: 0.5915 - val_loss: 3.7058 - val_accuracy: 0.6930\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0322 - accuracy: 0.5913 - val_loss: 5.0643 - val_accuracy: 0.6829\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0301 - accuracy: 0.5966 - val_loss: 3.9388 - val_accuracy: 0.6861\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.0275 - accuracy: 0.5976 - val_loss: 6.6375 - val_accuracy: 0.6832\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0229 - accuracy: 0.5959 - val_loss: 3.2681 - val_accuracy: 0.6825\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0137 - accuracy: 0.5952 - val_loss: 3.8916 - val_accuracy: 0.6893\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0253 - accuracy: 0.5945 - val_loss: 2.3185 - val_accuracy: 0.6821\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 1.0251 - accuracy: 0.5938 - val_loss: 3.5249 - val_accuracy: 0.6808\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9929 - accuracy: 0.6031 - val_loss: 6.0348 - val_accuracy: 0.6900\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0098 - accuracy: 0.5963 - val_loss: 2.0271 - val_accuracy: 0.6746\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9958 - accuracy: 0.5979 - val_loss: 2.9650 - val_accuracy: 0.6739\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9971 - accuracy: 0.5990 - val_loss: 6.0087 - val_accuracy: 0.6403\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9946 - accuracy: 0.6008 - val_loss: 3.6985 - val_accuracy: 0.6537\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0008 - accuracy: 0.5974 - val_loss: 17.5073 - val_accuracy: 0.6326\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0005 - accuracy: 0.5991 - val_loss: 81.2919 - val_accuracy: 0.6232\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0057 - accuracy: 0.5965 - val_loss: 3.8645 - val_accuracy: 0.6327\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9906 - accuracy: 0.6019 - val_loss: 5.5773 - val_accuracy: 0.6407\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9954 - accuracy: 0.5981 - val_loss: 2.6384 - val_accuracy: 0.5919\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9749 - accuracy: 0.6077 - val_loss: 256.6933 - val_accuracy: 0.5761\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.9927 - accuracy: 0.6010 - val_loss: 3.4057 - val_accuracy: 0.6157\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.9969 - accuracy: 0.5993 - val_loss: 62.6693 - val_accuracy: 0.6307\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.9920 - accuracy: 0.5991 - val_loss: 1125.2308 - val_accuracy: 0.5029\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9890 - accuracy: 0.5994 - val_loss: 57.2949 - val_accuracy: 0.5234\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9821 - accuracy: 0.6009 - val_loss: 3.5837 - val_accuracy: 0.5447\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9721 - accuracy: 0.6007 - val_loss: 3.2851 - val_accuracy: 0.4893\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9648 - accuracy: 0.6010 - val_loss: 31.5070 - val_accuracy: 0.4794\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9652 - accuracy: 0.6079 - val_loss: 5.8473 - val_accuracy: 0.5186\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9779 - accuracy: 0.5980 - val_loss: 8.1205 - val_accuracy: 0.5536\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9737 - accuracy: 0.6027 - val_loss: 4.2089 - val_accuracy: 0.4907\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9780 - accuracy: 0.6014 - val_loss: 3.4506 - val_accuracy: 0.4652\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.1011 - accuracy: 0.5806 - val_loss: 58.5012 - val_accuracy: 0.3938\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3486 - accuracy: 0.5186 - val_loss: 6.6560 - val_accuracy: 0.1535\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.4314 - accuracy: 0.4935 - val_loss: 17.9412 - val_accuracy: 0.0756\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3441 - accuracy: 0.5235 - val_loss: 3.1999 - val_accuracy: 0.0945\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2054 - accuracy: 0.5382 - val_loss: 3.4502 - val_accuracy: 0.1186\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2647 - accuracy: 0.5429 - val_loss: 2.6215 - val_accuracy: 0.0929\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2365 - accuracy: 0.5463 - val_loss: 3.4794 - val_accuracy: 0.0963\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.1840 - accuracy: 0.5537 - val_loss: 3.6369 - val_accuracy: 0.0945\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1458 - accuracy: 0.5647 - val_loss: 3.3824 - val_accuracy: 0.0941\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1084 - accuracy: 0.5698 - val_loss: 3.3869 - val_accuracy: 0.0914\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0868 - accuracy: 0.5772 - val_loss: 3.2329 - val_accuracy: 0.0906\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0853 - accuracy: 0.5877 - val_loss: 2.9973 - val_accuracy: 0.0896\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0926 - accuracy: 0.5822 - val_loss: 2.5249 - val_accuracy: 0.0944\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0713 - accuracy: 0.5793 - val_loss: 4.2279 - val_accuracy: 0.1018\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0783 - accuracy: 0.5833 - val_loss: 4.5173 - val_accuracy: 0.1102\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0655 - accuracy: 0.5811 - val_loss: 2.8815 - val_accuracy: 0.2257\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0552 - accuracy: 0.5824 - val_loss: 9.7101 - val_accuracy: 0.2683\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0367 - accuracy: 0.5867 - val_loss: 17.7725 - val_accuracy: 0.2767\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0360 - accuracy: 0.5902 - val_loss: 20.1529 - val_accuracy: 0.3639\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0455 - accuracy: 0.5829 - val_loss: 20.7165 - val_accuracy: 0.4042\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0297 - accuracy: 0.5917 - val_loss: 46.6683 - val_accuracy: 0.3428\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0337 - accuracy: 0.5824 - val_loss: 75.7233 - val_accuracy: 0.3651\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0260 - accuracy: 0.5884 - val_loss: 63.5167 - val_accuracy: 0.4399\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0336 - accuracy: 0.5842 - val_loss: 45.4633 - val_accuracy: 0.4132\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0238 - accuracy: 0.5866 - val_loss: 23.9705 - val_accuracy: 0.4655\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0139 - accuracy: 0.5915 - val_loss: 110.0091 - val_accuracy: 0.4655\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0114 - accuracy: 0.5887 - val_loss: 180.6812 - val_accuracy: 0.4498\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0169 - accuracy: 0.5873 - val_loss: 1872.4271 - val_accuracy: 0.4370\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0109 - accuracy: 0.5883 - val_loss: 142.2923 - val_accuracy: 0.4379\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0080 - accuracy: 0.5887 - val_loss: 126.6791 - val_accuracy: 0.4564\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0094 - accuracy: 0.5934 - val_loss: 73.3371 - val_accuracy: 0.4585\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0063 - accuracy: 0.5889 - val_loss: 39.2920 - val_accuracy: 0.4509\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9917 - accuracy: 0.5917 - val_loss: 42.7797 - val_accuracy: 0.4316\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0019 - accuracy: 0.5935 - val_loss: 20.3793 - val_accuracy: 0.3737\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9984 - accuracy: 0.5914 - val_loss: 106.8139 - val_accuracy: 0.3295\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9983 - accuracy: 0.5902 - val_loss: 74.0396 - val_accuracy: 0.3097\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9901 - accuracy: 0.5922 - val_loss: 150.8721 - val_accuracy: 0.2761\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9957 - accuracy: 0.5921 - val_loss: 150.0727 - val_accuracy: 0.2844\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.9859 - accuracy: 0.5942 - val_loss: 15.7813 - val_accuracy: 0.3108\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9708 - accuracy: 0.5959 - val_loss: 177.7628 - val_accuracy: 0.2840\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9819 - accuracy: 0.5995 - val_loss: 129.8249 - val_accuracy: 0.3139\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9885 - accuracy: 0.5939 - val_loss: 119.3301 - val_accuracy: 0.3201\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9819 - accuracy: 0.5955 - val_loss: 100.0091 - val_accuracy: 0.3183\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9818 - accuracy: 0.5946 - val_loss: 21.8923 - val_accuracy: 0.2762\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9836 - accuracy: 0.5965 - val_loss: 86.6399 - val_accuracy: 0.2579\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9802 - accuracy: 0.5927 - val_loss: 28.2397 - val_accuracy: 0.2841\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.9632 - accuracy: 0.6015 - val_loss: 73.9118 - val_accuracy: 0.2987\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 4s 279ms/step - loss: 0.9640 - accuracy: 0.5980 - val_loss: 85.6026 - val_accuracy: 0.2874\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9618 - accuracy: 0.5999 - val_loss: 17.6414 - val_accuracy: 0.3052\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9660 - accuracy: 0.6020 - val_loss: 71.9447 - val_accuracy: 0.3147\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9675 - accuracy: 0.5989 - val_loss: 86.5619 - val_accuracy: 0.2947\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9714 - accuracy: 0.5938 - val_loss: 11.0855 - val_accuracy: 0.2780\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9848 - accuracy: 0.5954 - val_loss: 22.8140 - val_accuracy: 0.2308\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9597 - accuracy: 0.5963 - val_loss: 14.2142 - val_accuracy: 0.2187\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9624 - accuracy: 0.5990 - val_loss: 50.5942 - val_accuracy: 0.1764\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9585 - accuracy: 0.5974 - val_loss: 29.0632 - val_accuracy: 0.1755\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9584 - accuracy: 0.5989 - val_loss: 78.4848 - val_accuracy: 0.2080\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9555 - accuracy: 0.5975 - val_loss: 21.4121 - val_accuracy: 0.2604\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9643 - accuracy: 0.5973 - val_loss: 25.6301 - val_accuracy: 0.2608\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.9616 - accuracy: 0.5960 - val_loss: 12.7374 - val_accuracy: 0.2669\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.9582 - accuracy: 0.6003 - val_loss: 18.5900 - val_accuracy: 0.2736\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9463 - accuracy: 0.5993 - val_loss: 28.6114 - val_accuracy: 0.2908\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9456 - accuracy: 0.6033 - val_loss: 50.6079 - val_accuracy: 0.3342\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9504 - accuracy: 0.6049 - val_loss: 24.4348 - val_accuracy: 0.3037\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9495 - accuracy: 0.5999 - val_loss: 6.7179 - val_accuracy: 0.3209\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9608 - accuracy: 0.5941 - val_loss: 118.4430 - val_accuracy: 0.2660\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9424 - accuracy: 0.6008 - val_loss: 24.7107 - val_accuracy: 0.2968\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9561 - accuracy: 0.5990 - val_loss: 7.4026 - val_accuracy: 0.3402\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9551 - accuracy: 0.6001 - val_loss: 11.3760 - val_accuracy: 0.2775\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9351 - accuracy: 0.5987 - val_loss: 6.4259 - val_accuracy: 0.2717\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9449 - accuracy: 0.6007 - val_loss: 9.9988 - val_accuracy: 0.2104\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.9268 - accuracy: 0.6017 - val_loss: 7.5814 - val_accuracy: 0.2137\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9450 - accuracy: 0.5990 - val_loss: 8.2237 - val_accuracy: 0.1937\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9405 - accuracy: 0.6022 - val_loss: 10.3679 - val_accuracy: 0.1957\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9291 - accuracy: 0.6022 - val_loss: 6.9881 - val_accuracy: 0.2400\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9468 - accuracy: 0.6027 - val_loss: 6.0200 - val_accuracy: 0.2496\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9449 - accuracy: 0.5980 - val_loss: 3.9817 - val_accuracy: 0.3522\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9551 - accuracy: 0.5965 - val_loss: 6.1599 - val_accuracy: 0.2712\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9369 - accuracy: 0.6020 - val_loss: 5.1157 - val_accuracy: 0.2932\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9229 - accuracy: 0.6049 - val_loss: 5.5699 - val_accuracy: 0.2548\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9200 - accuracy: 0.6064 - val_loss: 3.3812 - val_accuracy: 0.2842\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9336 - accuracy: 0.6065 - val_loss: 3.7794 - val_accuracy: 0.2740\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9369 - accuracy: 0.6003 - val_loss: 4.4893 - val_accuracy: 0.2859\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9376 - accuracy: 0.5955 - val_loss: 3.6627 - val_accuracy: 0.2859\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9377 - accuracy: 0.6006 - val_loss: 4.6456 - val_accuracy: 0.2757\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9262 - accuracy: 0.6000 - val_loss: 4.7818 - val_accuracy: 0.2102\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9192 - accuracy: 0.6008 - val_loss: 4.8017 - val_accuracy: 0.2550\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9065 - accuracy: 0.6069 - val_loss: 4.6845 - val_accuracy: 0.2286\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9190 - accuracy: 0.6049 - val_loss: 5.8780 - val_accuracy: 0.2264\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9341 - accuracy: 0.5983 - val_loss: 5.4673 - val_accuracy: 0.2007\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9115 - accuracy: 0.6043 - val_loss: 4.8168 - val_accuracy: 0.2052\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9211 - accuracy: 0.6065 - val_loss: 4.5275 - val_accuracy: 0.2515\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9189 - accuracy: 0.6035 - val_loss: 13.5826 - val_accuracy: 0.2280\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9178 - accuracy: 0.6035 - val_loss: 3.7261 - val_accuracy: 0.2087\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9212 - accuracy: 0.6032 - val_loss: 14.5994 - val_accuracy: 0.2231\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9165 - accuracy: 0.6047 - val_loss: 3.6610 - val_accuracy: 0.2613\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9049 - accuracy: 0.6033 - val_loss: 4.6465 - val_accuracy: 0.2128\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9673 - accuracy: 0.5938 - val_loss: 3.0557 - val_accuracy: 0.2714\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0475 - accuracy: 0.5691 - val_loss: 3.8212 - val_accuracy: 0.1433\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9905 - accuracy: 0.5847 - val_loss: 6.2922 - val_accuracy: 0.1223\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9558 - accuracy: 0.5929 - val_loss: 5.3693 - val_accuracy: 0.1370\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9536 - accuracy: 0.5943 - val_loss: 5.3540 - val_accuracy: 0.1116\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9460 - accuracy: 0.5958 - val_loss: 7.7758 - val_accuracy: 0.1362\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9360 - accuracy: 0.5985 - val_loss: 8.5302 - val_accuracy: 0.1067\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9113 - accuracy: 0.6039 - val_loss: 10.5295 - val_accuracy: 0.0910\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9315 - accuracy: 0.6000 - val_loss: 10.5419 - val_accuracy: 0.0900\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9091 - accuracy: 0.6059 - val_loss: 9.7523 - val_accuracy: 0.0782\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9267 - accuracy: 0.6049 - val_loss: 125.8820 - val_accuracy: 0.0799\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9058 - accuracy: 0.6062 - val_loss: 18.2874 - val_accuracy: 0.0818\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9354 - accuracy: 0.6018 - val_loss: 86.8657 - val_accuracy: 0.0766\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9105 - accuracy: 0.6028 - val_loss: 11.2525 - val_accuracy: 0.0833\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.9117 - accuracy: 0.6076 - val_loss: 10.2481 - val_accuracy: 0.0737\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 0.9162 - accuracy: 0.6024 - val_loss: 13.4477 - val_accuracy: 0.0737\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9239 - accuracy: 0.6088 - val_loss: 12.0863 - val_accuracy: 0.0725\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9108 - accuracy: 0.6026 - val_loss: 17.7294 - val_accuracy: 0.0686\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9060 - accuracy: 0.6047 - val_loss: 69.6207 - val_accuracy: 0.0648\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9078 - accuracy: 0.6051 - val_loss: 414.6410 - val_accuracy: 0.0665\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9138 - accuracy: 0.6029 - val_loss: 21.6152 - val_accuracy: 0.0604\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9034 - accuracy: 0.6066 - val_loss: 13.4748 - val_accuracy: 0.0653\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.9004 - accuracy: 0.6076 - val_loss: 17.3952 - val_accuracy: 0.0624\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8889 - accuracy: 0.6090 - val_loss: 30.9644 - val_accuracy: 0.0664\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9279 - accuracy: 0.6041 - val_loss: 22.4242 - val_accuracy: 0.0650\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9152 - accuracy: 0.5967 - val_loss: 28.2103 - val_accuracy: 0.0626\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9103 - accuracy: 0.6069 - val_loss: 26.4739 - val_accuracy: 0.0635\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8919 - accuracy: 0.6095 - val_loss: 14.1232 - val_accuracy: 0.0661\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8910 - accuracy: 0.6074 - val_loss: 15.5357 - val_accuracy: 0.0673\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9173 - accuracy: 0.6051 - val_loss: 17.0360 - val_accuracy: 0.0637\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9064 - accuracy: 0.6037 - val_loss: 33.3320 - val_accuracy: 0.0639\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8877 - accuracy: 0.6093 - val_loss: 45.9229 - val_accuracy: 0.0526\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8971 - accuracy: 0.6077 - val_loss: 29.2774 - val_accuracy: 0.0662\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.8990 - accuracy: 0.6056 - val_loss: 10.9615 - val_accuracy: 0.0691\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 0.9126 - accuracy: 0.5983 - val_loss: 18.3330 - val_accuracy: 0.0687\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.9088 - accuracy: 0.6029 - val_loss: 21.6790 - val_accuracy: 0.0632\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9011 - accuracy: 0.6067 - val_loss: 17.1429 - val_accuracy: 0.0686\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8801 - accuracy: 0.6132 - val_loss: 26.4220 - val_accuracy: 0.0662\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8790 - accuracy: 0.6082 - val_loss: 24.3308 - val_accuracy: 0.0647\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8861 - accuracy: 0.6094 - val_loss: 30.8139 - val_accuracy: 0.0562\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8886 - accuracy: 0.6102 - val_loss: 24.0509 - val_accuracy: 0.0642\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8995 - accuracy: 0.6038 - val_loss: 20.2523 - val_accuracy: 0.0696\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9048 - accuracy: 0.6050 - val_loss: 11.3871 - val_accuracy: 0.0899\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8985 - accuracy: 0.6036 - val_loss: 15.2122 - val_accuracy: 0.0865\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8790 - accuracy: 0.6053 - val_loss: 28.1453 - val_accuracy: 0.0668\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8872 - accuracy: 0.6054 - val_loss: 18.9013 - val_accuracy: 0.1169\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8790 - accuracy: 0.6096 - val_loss: 19.7348 - val_accuracy: 0.1305\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8740 - accuracy: 0.6069 - val_loss: 25.4873 - val_accuracy: 0.1192\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8872 - accuracy: 0.6090 - val_loss: 20.5005 - val_accuracy: 0.0844\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8779 - accuracy: 0.6128 - val_loss: 30.6098 - val_accuracy: 0.0791\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8832 - accuracy: 0.6077 - val_loss: 18.7039 - val_accuracy: 0.0793\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8900 - accuracy: 0.6068 - val_loss: 17.8233 - val_accuracy: 0.0997\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8882 - accuracy: 0.6109 - val_loss: 26.8504 - val_accuracy: 0.0630\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8896 - accuracy: 0.6098 - val_loss: 21.3090 - val_accuracy: 0.0682\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8696 - accuracy: 0.6109 - val_loss: 53.8986 - val_accuracy: 0.0859\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8769 - accuracy: 0.6085 - val_loss: 39.0487 - val_accuracy: 0.0440\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8782 - accuracy: 0.6071 - val_loss: 34.1547 - val_accuracy: 0.0422\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8755 - accuracy: 0.6117 - val_loss: 46.6101 - val_accuracy: 0.0455\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9129 - accuracy: 0.6007 - val_loss: 24.3346 - val_accuracy: 0.0879\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8861 - accuracy: 0.6091 - val_loss: 28.0579 - val_accuracy: 0.0688\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8721 - accuracy: 0.6073 - val_loss: 23.0932 - val_accuracy: 0.0875\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8638 - accuracy: 0.6118 - val_loss: 16.9649 - val_accuracy: 0.0685\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8599 - accuracy: 0.6115 - val_loss: 17.9943 - val_accuracy: 0.0596\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8669 - accuracy: 0.6133 - val_loss: 16.5820 - val_accuracy: 0.0756\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8643 - accuracy: 0.6139 - val_loss: 35.0614 - val_accuracy: 0.0876\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8768 - accuracy: 0.6118 - val_loss: 31.3041 - val_accuracy: 0.0944\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8571 - accuracy: 0.6154 - val_loss: 31.3478 - val_accuracy: 0.0592\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8824 - accuracy: 0.6100 - val_loss: 38.4457 - val_accuracy: 0.0856\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8672 - accuracy: 0.6127 - val_loss: 30.8432 - val_accuracy: 0.0894\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8613 - accuracy: 0.6085 - val_loss: 22.4351 - val_accuracy: 0.0852\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.8679 - accuracy: 0.6126 - val_loss: 19.0143 - val_accuracy: 0.0794\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8712 - accuracy: 0.6112 - val_loss: 19.5552 - val_accuracy: 0.0970\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8566 - accuracy: 0.6133 - val_loss: 37.1191 - val_accuracy: 0.1044\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8672 - accuracy: 0.6093 - val_loss: 32.0508 - val_accuracy: 0.0970\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8643 - accuracy: 0.6113 - val_loss: 17.1590 - val_accuracy: 0.1328\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8816 - accuracy: 0.6069 - val_loss: 20.0216 - val_accuracy: 0.0995\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8689 - accuracy: 0.6086 - val_loss: 15.5439 - val_accuracy: 0.1292\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8580 - accuracy: 0.6166 - val_loss: 30.7982 - val_accuracy: 0.0949\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8804 - accuracy: 0.6078 - val_loss: 37.6089 - val_accuracy: 0.0645\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.8766 - accuracy: 0.6102 - val_loss: 20.0243 - val_accuracy: 0.0846\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8721 - accuracy: 0.6070 - val_loss: 18.0847 - val_accuracy: 0.1177\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8700 - accuracy: 0.6089 - val_loss: 16.2376 - val_accuracy: 0.1688\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8453 - accuracy: 0.6137 - val_loss: 10.9100 - val_accuracy: 0.1268\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8540 - accuracy: 0.6105 - val_loss: 18.0681 - val_accuracy: 0.0846\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8533 - accuracy: 0.6182 - val_loss: 11.4254 - val_accuracy: 0.1344\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8552 - accuracy: 0.6129 - val_loss: 10.4682 - val_accuracy: 0.1693\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.8581 - accuracy: 0.6133 - val_loss: 22.9901 - val_accuracy: 0.1032\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8553 - accuracy: 0.6130 - val_loss: 23.7675 - val_accuracy: 0.0712\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 0.8479 - accuracy: 0.6116 - val_loss: 31.6939 - val_accuracy: 0.0898\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8483 - accuracy: 0.6152 - val_loss: 15.8289 - val_accuracy: 0.0794\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 4s 256ms/step - loss: 0.8503 - accuracy: 0.6159 - val_loss: 17.5676 - val_accuracy: 0.0881\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8524 - accuracy: 0.6175 - val_loss: 17.5347 - val_accuracy: 0.0886\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.8514 - accuracy: 0.6146 - val_loss: 16.1922 - val_accuracy: 0.1040\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8625 - accuracy: 0.6097 - val_loss: 20.0259 - val_accuracy: 0.1418\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8376 - accuracy: 0.6171 - val_loss: 16.5597 - val_accuracy: 0.1032\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8446 - accuracy: 0.6143 - val_loss: 16.5443 - val_accuracy: 0.0860\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8434 - accuracy: 0.6157 - val_loss: 12.7745 - val_accuracy: 0.1275\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8563 - accuracy: 0.6136 - val_loss: 9.0962 - val_accuracy: 0.1138\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8660 - accuracy: 0.6112 - val_loss: 28.0521 - val_accuracy: 0.1108\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8509 - accuracy: 0.6116 - val_loss: 9.9997 - val_accuracy: 0.1164\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8491 - accuracy: 0.6115 - val_loss: 17.3485 - val_accuracy: 0.0888\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8627 - accuracy: 0.6113 - val_loss: 9.9084 - val_accuracy: 0.1170\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8561 - accuracy: 0.6119 - val_loss: 14.6115 - val_accuracy: 0.0644\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.8489 - accuracy: 0.6110 - val_loss: 16.3404 - val_accuracy: 0.0741\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.8247 - accuracy: 0.6181 - val_loss: 11.0906 - val_accuracy: 0.0675\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.8274 - accuracy: 0.6186 - val_loss: 13.7472 - val_accuracy: 0.0757\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8431 - accuracy: 0.6134 - val_loss: 20.4285 - val_accuracy: 0.0547\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8565 - accuracy: 0.6172 - val_loss: 29.1926 - val_accuracy: 0.0667\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8665 - accuracy: 0.6110 - val_loss: 11.0821 - val_accuracy: 0.0733\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8484 - accuracy: 0.6182 - val_loss: 12.1450 - val_accuracy: 0.0760\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8279 - accuracy: 0.6131 - val_loss: 31.3807 - val_accuracy: 0.0774\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8488 - accuracy: 0.6144 - val_loss: 14.7414 - val_accuracy: 0.0698\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8234 - accuracy: 0.6207 - val_loss: 17.2670 - val_accuracy: 0.0599\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8280 - accuracy: 0.6183 - val_loss: 13.1998 - val_accuracy: 0.0631\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8518 - accuracy: 0.6158 - val_loss: 20.3179 - val_accuracy: 0.0496\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8383 - accuracy: 0.6168 - val_loss: 18.1204 - val_accuracy: 0.0647\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8421 - accuracy: 0.6176 - val_loss: 12.5909 - val_accuracy: 0.0875\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8379 - accuracy: 0.6179 - val_loss: 20.9017 - val_accuracy: 0.0740\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8265 - accuracy: 0.6154 - val_loss: 16.9092 - val_accuracy: 0.0466\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8248 - accuracy: 0.6226 - val_loss: 10.5686 - val_accuracy: 0.0585\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8512 - accuracy: 0.6166 - val_loss: 16.7359 - val_accuracy: 0.0500\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.8442 - accuracy: 0.6127 - val_loss: 13.1630 - val_accuracy: 0.0543\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8387 - accuracy: 0.6105 - val_loss: 17.5039 - val_accuracy: 0.0518\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.8451 - accuracy: 0.6169 - val_loss: 11.3428 - val_accuracy: 0.0671\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8432 - accuracy: 0.6131 - val_loss: 15.9778 - val_accuracy: 0.0522\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8243 - accuracy: 0.6196 - val_loss: 16.7615 - val_accuracy: 0.0520\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8501 - accuracy: 0.6124 - val_loss: 15.0588 - val_accuracy: 0.0642\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8193 - accuracy: 0.6170 - val_loss: 16.3975 - val_accuracy: 0.0586\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8061 - accuracy: 0.6217 - val_loss: 17.9072 - val_accuracy: 0.0519\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8348 - accuracy: 0.6178 - val_loss: 19.5453 - val_accuracy: 0.0461\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8302 - accuracy: 0.6170 - val_loss: 17.4297 - val_accuracy: 0.0572\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8446 - accuracy: 0.6155 - val_loss: 19.9626 - val_accuracy: 0.0556\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8248 - accuracy: 0.6184 - val_loss: 19.2289 - val_accuracy: 0.0539\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8234 - accuracy: 0.6183 - val_loss: 20.2855 - val_accuracy: 0.0502\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8362 - accuracy: 0.6177 - val_loss: 14.4194 - val_accuracy: 0.0707\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.8273 - accuracy: 0.6166 - val_loss: 22.4499 - val_accuracy: 0.0558\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8287 - accuracy: 0.6144 - val_loss: 18.3055 - val_accuracy: 0.0702\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8205 - accuracy: 0.6222 - val_loss: 25.3941 - val_accuracy: 0.0529\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8259 - accuracy: 0.6165 - val_loss: 23.4834 - val_accuracy: 0.0550\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8400 - accuracy: 0.6128 - val_loss: 16.9597 - val_accuracy: 0.0562\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8324 - accuracy: 0.6165 - val_loss: 20.3666 - val_accuracy: 0.0531\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8152 - accuracy: 0.6206 - val_loss: 15.5483 - val_accuracy: 0.0691\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8236 - accuracy: 0.6194 - val_loss: 14.5330 - val_accuracy: 0.0597\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8231 - accuracy: 0.6195 - val_loss: 15.6201 - val_accuracy: 0.0609\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8493 - accuracy: 0.6174 - val_loss: 16.5846 - val_accuracy: 0.0646\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8120 - accuracy: 0.6190 - val_loss: 20.7536 - val_accuracy: 0.0589\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8141 - accuracy: 0.6180 - val_loss: 18.5691 - val_accuracy: 0.0601\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8191 - accuracy: 0.6185 - val_loss: 23.0773 - val_accuracy: 0.0746\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8035 - accuracy: 0.6168 - val_loss: 23.3503 - val_accuracy: 0.0734\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8122 - accuracy: 0.6213 - val_loss: 19.4452 - val_accuracy: 0.0630\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7929 - accuracy: 0.6251 - val_loss: 22.7320 - val_accuracy: 0.0775\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8155 - accuracy: 0.6207 - val_loss: 19.0563 - val_accuracy: 0.0821\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8178 - accuracy: 0.6184 - val_loss: 17.6142 - val_accuracy: 0.0676\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8212 - accuracy: 0.6216 - val_loss: 24.1112 - val_accuracy: 0.0628\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.8209 - accuracy: 0.6187 - val_loss: 15.2530 - val_accuracy: 0.0703\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8033 - accuracy: 0.6226 - val_loss: 23.1096 - val_accuracy: 0.0552\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8096 - accuracy: 0.6268 - val_loss: 23.0014 - val_accuracy: 0.0632\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8273 - accuracy: 0.6191 - val_loss: 25.2295 - val_accuracy: 0.0751\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8105 - accuracy: 0.6210 - val_loss: 47.3350 - val_accuracy: 0.0722\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8320 - accuracy: 0.6164 - val_loss: 24.6076 - val_accuracy: 0.0687\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8130 - accuracy: 0.6228 - val_loss: 21.7778 - val_accuracy: 0.0623\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8124 - accuracy: 0.6164 - val_loss: 30.1054 - val_accuracy: 0.0480\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8078 - accuracy: 0.6201 - val_loss: 26.3522 - val_accuracy: 0.0533\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 3s 185ms/step - loss: 0.8012 - accuracy: 0.6245 - val_loss: 30.2713 - val_accuracy: 0.0473\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.7891 - accuracy: 0.6235 - val_loss: 29.3634 - val_accuracy: 0.0624\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8030 - accuracy: 0.6215 - val_loss: 28.7945 - val_accuracy: 0.0584\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8110 - accuracy: 0.6235 - val_loss: 30.7482 - val_accuracy: 0.0970\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8330 - accuracy: 0.6174 - val_loss: 38.9671 - val_accuracy: 0.0864\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8251 - accuracy: 0.6183 - val_loss: 26.9592 - val_accuracy: 0.0630\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8307 - accuracy: 0.6138 - val_loss: 36.8088 - val_accuracy: 0.0682\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8178 - accuracy: 0.6224 - val_loss: 43.0050 - val_accuracy: 0.0815\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7988 - accuracy: 0.6239 - val_loss: 56.9481 - val_accuracy: 0.0843\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8003 - accuracy: 0.6222 - val_loss: 198.5542 - val_accuracy: 0.1042\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7940 - accuracy: 0.6239 - val_loss: 91.1227 - val_accuracy: 0.1037\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8195 - accuracy: 0.6206 - val_loss: 317.5799 - val_accuracy: 0.1605\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.8060 - accuracy: 0.6203 - val_loss: 263.5008 - val_accuracy: 0.1716\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.8000 - accuracy: 0.6209 - val_loss: 133.5159 - val_accuracy: 0.1726\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.8137 - accuracy: 0.6195 - val_loss: 140.3089 - val_accuracy: 0.1875\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7933 - accuracy: 0.6269 - val_loss: 140.8406 - val_accuracy: 0.1700\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7937 - accuracy: 0.6234 - val_loss: 281.6711 - val_accuracy: 0.1980\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7914 - accuracy: 0.6240 - val_loss: 225.0766 - val_accuracy: 0.1863\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8030 - accuracy: 0.6218 - val_loss: 86.7730 - val_accuracy: 0.1649\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8029 - accuracy: 0.6211 - val_loss: 82.6003 - val_accuracy: 0.1984\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8180 - accuracy: 0.6215 - val_loss: 232.2416 - val_accuracy: 0.1928\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7952 - accuracy: 0.6268 - val_loss: 245.3587 - val_accuracy: 0.1826\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7808 - accuracy: 0.6276 - val_loss: 58.7665 - val_accuracy: 0.1856\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7850 - accuracy: 0.6255 - val_loss: 154.6405 - val_accuracy: 0.1383\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7979 - accuracy: 0.6245 - val_loss: 109.0864 - val_accuracy: 0.1376\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7811 - accuracy: 0.6282 - val_loss: 139.3166 - val_accuracy: 0.1307\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7956 - accuracy: 0.6239 - val_loss: 138.8301 - val_accuracy: 0.1449\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7956 - accuracy: 0.6243 - val_loss: 112.9069 - val_accuracy: 0.1500\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7918 - accuracy: 0.6234 - val_loss: 63.3461 - val_accuracy: 0.1501\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7706 - accuracy: 0.6306 - val_loss: 75.2736 - val_accuracy: 0.2020\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.7875 - accuracy: 0.6257 - val_loss: 119.5701 - val_accuracy: 0.1988\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.7888 - accuracy: 0.6275 - val_loss: 182.8500 - val_accuracy: 0.1483\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7973 - accuracy: 0.6273 - val_loss: 82.0920 - val_accuracy: 0.1149\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7861 - accuracy: 0.6266 - val_loss: 69.4680 - val_accuracy: 0.1489\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7907 - accuracy: 0.6239 - val_loss: 100.0570 - val_accuracy: 0.1377\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7985 - accuracy: 0.6232 - val_loss: 88.6718 - val_accuracy: 0.1414\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8131 - accuracy: 0.6250 - val_loss: 72.0552 - val_accuracy: 0.1249\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7960 - accuracy: 0.6257 - val_loss: 99.7149 - val_accuracy: 0.1054\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7742 - accuracy: 0.6276 - val_loss: 143.1507 - val_accuracy: 0.1060\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7882 - accuracy: 0.6256 - val_loss: 128.3269 - val_accuracy: 0.1065\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.7831 - accuracy: 0.6267 - val_loss: 62.4893 - val_accuracy: 0.1091\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7888 - accuracy: 0.6274 - val_loss: 35.3858 - val_accuracy: 0.1031\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7794 - accuracy: 0.6261 - val_loss: 72.0908 - val_accuracy: 0.1051\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7927 - accuracy: 0.6253 - val_loss: 99.7467 - val_accuracy: 0.1040\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7945 - accuracy: 0.6230 - val_loss: 47.8769 - val_accuracy: 0.0976\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7955 - accuracy: 0.6278 - val_loss: 44.2693 - val_accuracy: 0.1157\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.8021 - accuracy: 0.6236 - val_loss: 79.9778 - val_accuracy: 0.1361\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7849 - accuracy: 0.6240 - val_loss: 66.9985 - val_accuracy: 0.1178\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7745 - accuracy: 0.6275 - val_loss: 31.5981 - val_accuracy: 0.0979\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 4s 231ms/step - loss: 0.8029 - accuracy: 0.6250 - val_loss: 54.0534 - val_accuracy: 0.0902\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7784 - accuracy: 0.6279 - val_loss: 40.4572 - val_accuracy: 0.0973\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7604 - accuracy: 0.6295 - val_loss: 95.4330 - val_accuracy: 0.1146\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7787 - accuracy: 0.6259 - val_loss: 104.7986 - val_accuracy: 0.1274\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7746 - accuracy: 0.6280 - val_loss: 60.8012 - val_accuracy: 0.1335\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.7788 - accuracy: 0.6283 - val_loss: 43.9087 - val_accuracy: 0.1087\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.7796 - accuracy: 0.6271 - val_loss: 60.2817 - val_accuracy: 0.1059\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.7673 - accuracy: 0.6338 - val_loss: 35.0933 - val_accuracy: 0.1013\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7661 - accuracy: 0.6309 - val_loss: 29.5997 - val_accuracy: 0.0963\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7891 - accuracy: 0.6260 - val_loss: 54.0088 - val_accuracy: 0.1072\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7859 - accuracy: 0.6249 - val_loss: 50.8596 - val_accuracy: 0.1225\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 0.7744 - accuracy: 0.6282 - val_loss: 47.4560 - val_accuracy: 0.1133\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.7857 - accuracy: 0.6263 - val_loss: 68.9203 - val_accuracy: 0.1145\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7896 - accuracy: 0.6246 - val_loss: 40.6015 - val_accuracy: 0.1006\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7760 - accuracy: 0.6251 - val_loss: 48.0872 - val_accuracy: 0.1088\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7804 - accuracy: 0.6286 - val_loss: 41.8202 - val_accuracy: 0.0919\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7938 - accuracy: 0.6210 - val_loss: 68.9464 - val_accuracy: 0.0786\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7766 - accuracy: 0.6251 - val_loss: 68.0407 - val_accuracy: 0.1276\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7777 - accuracy: 0.6289 - val_loss: 70.8730 - val_accuracy: 0.1237\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7780 - accuracy: 0.6291 - val_loss: 44.2000 - val_accuracy: 0.1320\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7682 - accuracy: 0.6254 - val_loss: 53.1217 - val_accuracy: 0.1045\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7714 - accuracy: 0.6309 - val_loss: 24.7198 - val_accuracy: 0.0978\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7995 - accuracy: 0.6227 - val_loss: 39.5279 - val_accuracy: 0.0923\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7947 - accuracy: 0.6278 - val_loss: 26.4039 - val_accuracy: 0.1147\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7799 - accuracy: 0.6208 - val_loss: 27.7545 - val_accuracy: 0.1448\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7690 - accuracy: 0.6274 - val_loss: 23.8603 - val_accuracy: 0.1569\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7523 - accuracy: 0.6342 - val_loss: 28.7645 - val_accuracy: 0.1266\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7930 - accuracy: 0.6251 - val_loss: 27.0336 - val_accuracy: 0.1296\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7624 - accuracy: 0.6322 - val_loss: 28.4982 - val_accuracy: 0.1323\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.7713 - accuracy: 0.6319 - val_loss: 79.7246 - val_accuracy: 0.1187\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7646 - accuracy: 0.6298 - val_loss: 32.6302 - val_accuracy: 0.1695\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7798 - accuracy: 0.6263 - val_loss: 81.4766 - val_accuracy: 0.1393\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.7573 - accuracy: 0.6323 - val_loss: 72.0848 - val_accuracy: 0.1093\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.7609 - accuracy: 0.6314 - val_loss: 61.3596 - val_accuracy: 0.1273\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.7749 - accuracy: 0.6307 - val_loss: 42.7381 - val_accuracy: 0.1309\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.7637 - accuracy: 0.6308 - val_loss: 82.1306 - val_accuracy: 0.1302\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.7603 - accuracy: 0.6316 - val_loss: 44.6719 - val_accuracy: 0.1233\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7687 - accuracy: 0.6297 - val_loss: 50.5109 - val_accuracy: 0.1001\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7795 - accuracy: 0.6238 - val_loss: 42.5276 - val_accuracy: 0.0843\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7735 - accuracy: 0.6276 - val_loss: 41.1535 - val_accuracy: 0.0734\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.7597 - accuracy: 0.6293 - val_loss: 41.7127 - val_accuracy: 0.0800\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7551 - accuracy: 0.6301 - val_loss: 55.5544 - val_accuracy: 0.1044\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7630 - accuracy: 0.6286 - val_loss: 38.9436 - val_accuracy: 0.0983\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8037 - accuracy: 0.6288 - val_loss: 37.1178 - val_accuracy: 0.0744\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7805 - accuracy: 0.6286 - val_loss: 36.8184 - val_accuracy: 0.0619\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7739 - accuracy: 0.6265 - val_loss: 56.4972 - val_accuracy: 0.0589\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7426 - accuracy: 0.6346 - val_loss: 30.9124 - val_accuracy: 0.0793\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7625 - accuracy: 0.6272 - val_loss: 38.7293 - val_accuracy: 0.0836\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7550 - accuracy: 0.6317 - val_loss: 45.6735 - val_accuracy: 0.0958\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7389 - accuracy: 0.6307 - val_loss: 35.5601 - val_accuracy: 0.0954\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7594 - accuracy: 0.6336 - val_loss: 30.8542 - val_accuracy: 0.0964\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7635 - accuracy: 0.6319 - val_loss: 43.3779 - val_accuracy: 0.1036\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7653 - accuracy: 0.6293 - val_loss: 36.6906 - val_accuracy: 0.0904\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7356 - accuracy: 0.6320 - val_loss: 70.4615 - val_accuracy: 0.0905\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.7452 - accuracy: 0.6330 - val_loss: 75.4212 - val_accuracy: 0.0995\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7755 - accuracy: 0.6294 - val_loss: 49.9251 - val_accuracy: 0.0827\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7597 - accuracy: 0.6317 - val_loss: 60.4601 - val_accuracy: 0.0762\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7463 - accuracy: 0.6343 - val_loss: 51.5742 - val_accuracy: 0.1112\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7456 - accuracy: 0.6318 - val_loss: 53.1925 - val_accuracy: 0.1252\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7486 - accuracy: 0.6316 - val_loss: 67.4392 - val_accuracy: 0.1035\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7517 - accuracy: 0.6280 - val_loss: 64.3228 - val_accuracy: 0.0982\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7613 - accuracy: 0.6307 - val_loss: 53.9030 - val_accuracy: 0.1072\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7496 - accuracy: 0.6317 - val_loss: 54.9658 - val_accuracy: 0.1127\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7674 - accuracy: 0.6322 - val_loss: 47.5540 - val_accuracy: 0.1380\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7809 - accuracy: 0.6258 - val_loss: 48.8218 - val_accuracy: 0.1480\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7554 - accuracy: 0.6307 - val_loss: 41.2123 - val_accuracy: 0.1340\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7514 - accuracy: 0.6320 - val_loss: 61.8035 - val_accuracy: 0.1049\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7383 - accuracy: 0.6349 - val_loss: 59.6552 - val_accuracy: 0.1016\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7370 - accuracy: 0.6309 - val_loss: 53.9314 - val_accuracy: 0.1035\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7443 - accuracy: 0.6353 - val_loss: 68.4970 - val_accuracy: 0.0918\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7474 - accuracy: 0.6289 - val_loss: 44.9901 - val_accuracy: 0.1176\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7758 - accuracy: 0.6328 - val_loss: 49.3113 - val_accuracy: 0.0867\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7867 - accuracy: 0.6274 - val_loss: 61.6878 - val_accuracy: 0.0762\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7594 - accuracy: 0.6285 - val_loss: 57.2540 - val_accuracy: 0.1036\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7345 - accuracy: 0.6383 - val_loss: 39.9449 - val_accuracy: 0.1138\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7347 - accuracy: 0.6357 - val_loss: 35.3182 - val_accuracy: 0.1319\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7616 - accuracy: 0.6336 - val_loss: 27.3942 - val_accuracy: 0.1333\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7554 - accuracy: 0.6316 - val_loss: 31.8852 - val_accuracy: 0.1287\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.7418 - accuracy: 0.6333 - val_loss: 36.1902 - val_accuracy: 0.1060\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7710 - accuracy: 0.6265 - val_loss: 35.9799 - val_accuracy: 0.1502\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.7556 - accuracy: 0.6349 - val_loss: 33.9586 - val_accuracy: 0.1245\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7435 - accuracy: 0.6374 - val_loss: 52.3597 - val_accuracy: 0.1280\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7802 - accuracy: 0.6271 - val_loss: 62.5577 - val_accuracy: 0.1225\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7436 - accuracy: 0.6319 - val_loss: 47.0743 - val_accuracy: 0.1170\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7432 - accuracy: 0.6324 - val_loss: 47.2947 - val_accuracy: 0.1461\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7423 - accuracy: 0.6331 - val_loss: 45.2464 - val_accuracy: 0.1499\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7592 - accuracy: 0.6315 - val_loss: 42.6610 - val_accuracy: 0.1656\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.7680 - accuracy: 0.6326 - val_loss: 61.6873 - val_accuracy: 0.1447\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.7482 - accuracy: 0.6357 - val_loss: 47.4469 - val_accuracy: 0.1257\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.7400 - accuracy: 0.6341 - val_loss: 35.7829 - val_accuracy: 0.1468\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7566 - accuracy: 0.6271 - val_loss: 59.1370 - val_accuracy: 0.1473\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.7393 - accuracy: 0.6333 - val_loss: 44.7872 - val_accuracy: 0.1579\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7369 - accuracy: 0.6336 - val_loss: 39.8924 - val_accuracy: 0.1744\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.7320 - accuracy: 0.6366 - val_loss: 38.4048 - val_accuracy: 0.1496\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7453 - accuracy: 0.6289 - val_loss: 39.1390 - val_accuracy: 0.1791\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7570 - accuracy: 0.6316 - val_loss: 32.0722 - val_accuracy: 0.1735\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7226 - accuracy: 0.6342 - val_loss: 33.7942 - val_accuracy: 0.1348\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7348 - accuracy: 0.6349 - val_loss: 42.9134 - val_accuracy: 0.1793\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7360 - accuracy: 0.6328 - val_loss: 31.3445 - val_accuracy: 0.1508\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7296 - accuracy: 0.6361 - val_loss: 23.4449 - val_accuracy: 0.1719\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.7357 - accuracy: 0.6350 - val_loss: 54.6831 - val_accuracy: 0.1818\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.7246 - accuracy: 0.6366 - val_loss: 27.5210 - val_accuracy: 0.1689\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7234 - accuracy: 0.6356 - val_loss: 39.1358 - val_accuracy: 0.1906\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7258 - accuracy: 0.6370 - val_loss: 38.5154 - val_accuracy: 0.1680\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7203 - accuracy: 0.6356 - val_loss: 33.5218 - val_accuracy: 0.1790\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7421 - accuracy: 0.6331 - val_loss: 36.6743 - val_accuracy: 0.1831\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7591 - accuracy: 0.6300 - val_loss: 37.9783 - val_accuracy: 0.1861\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7355 - accuracy: 0.6368 - val_loss: 40.3574 - val_accuracy: 0.1866\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7292 - accuracy: 0.6340 - val_loss: 41.4809 - val_accuracy: 0.1654\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.7124 - accuracy: 0.6408 - val_loss: 43.9517 - val_accuracy: 0.2252\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.7252 - accuracy: 0.6398 - val_loss: 66.4500 - val_accuracy: 0.2013\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7285 - accuracy: 0.6355 - val_loss: 44.8240 - val_accuracy: 0.2077\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7314 - accuracy: 0.6352 - val_loss: 46.2595 - val_accuracy: 0.2139\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7495 - accuracy: 0.6358 - val_loss: 40.0091 - val_accuracy: 0.2302\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7390 - accuracy: 0.6349 - val_loss: 47.2715 - val_accuracy: 0.2323\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7277 - accuracy: 0.6357 - val_loss: 36.1907 - val_accuracy: 0.2417\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7217 - accuracy: 0.6379 - val_loss: 37.1649 - val_accuracy: 0.2377\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7410 - accuracy: 0.6391 - val_loss: 39.1631 - val_accuracy: 0.2345\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7465 - accuracy: 0.6343 - val_loss: 37.6198 - val_accuracy: 0.2090\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7393 - accuracy: 0.6341 - val_loss: 34.3609 - val_accuracy: 0.2200\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7511 - accuracy: 0.6320 - val_loss: 36.0692 - val_accuracy: 0.2208\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7299 - accuracy: 0.6380 - val_loss: 30.3707 - val_accuracy: 0.1939\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7321 - accuracy: 0.6321 - val_loss: 37.5212 - val_accuracy: 0.2313\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7255 - accuracy: 0.6369 - val_loss: 34.8422 - val_accuracy: 0.2116\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7025 - accuracy: 0.6417 - val_loss: 28.5172 - val_accuracy: 0.2226\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.7235 - accuracy: 0.6339 - val_loss: 45.3356 - val_accuracy: 0.2262\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7229 - accuracy: 0.6374 - val_loss: 48.1977 - val_accuracy: 0.1974\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7390 - accuracy: 0.6397 - val_loss: 43.7527 - val_accuracy: 0.2073\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7381 - accuracy: 0.6380 - val_loss: 57.0456 - val_accuracy: 0.2140\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7588 - accuracy: 0.6302 - val_loss: 48.5182 - val_accuracy: 0.2036\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7391 - accuracy: 0.6317 - val_loss: 65.0165 - val_accuracy: 0.1796\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7462 - accuracy: 0.6347 - val_loss: 46.5873 - val_accuracy: 0.2100\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7571 - accuracy: 0.6343 - val_loss: 40.8222 - val_accuracy: 0.2178\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7104 - accuracy: 0.6369 - val_loss: 41.5586 - val_accuracy: 0.1808\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7004 - accuracy: 0.6422 - val_loss: 47.9618 - val_accuracy: 0.2027\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.7474 - accuracy: 0.6355 - val_loss: 40.3357 - val_accuracy: 0.1568\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7314 - accuracy: 0.6347 - val_loss: 44.2287 - val_accuracy: 0.1872\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7073 - accuracy: 0.6384 - val_loss: 41.2818 - val_accuracy: 0.1951\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.6978 - accuracy: 0.6379 - val_loss: 34.2421 - val_accuracy: 0.2007\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 276ms/step - loss: 2.6390 - accuracy: 0.5966 - val_loss: 1.6316 - val_accuracy: 0.6157\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2967 - accuracy: 0.6195 - val_loss: 1.8653 - val_accuracy: 0.6104\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.1960 - accuracy: 0.6230 - val_loss: 1.7868 - val_accuracy: 0.6050\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1596 - accuracy: 0.6212 - val_loss: 1.6220 - val_accuracy: 0.2930\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0704 - accuracy: 0.6196 - val_loss: 1.5816 - val_accuracy: 0.1491\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0487 - accuracy: 0.6206 - val_loss: 1.4143 - val_accuracy: 0.1504\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 6s 399ms/step - loss: 2.0234 - accuracy: 0.6220 - val_loss: 1.5402 - val_accuracy: 0.1510\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 4s 256ms/step - loss: 1.9382 - accuracy: 0.6185 - val_loss: 1.6571 - val_accuracy: 0.1548\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.8754 - accuracy: 0.6210 - val_loss: 1.5195 - val_accuracy: 0.1566\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.8367 - accuracy: 0.6225 - val_loss: 1.4836 - val_accuracy: 0.1539\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.8449 - accuracy: 0.6233 - val_loss: 1.6359 - val_accuracy: 0.1398\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.8698 - accuracy: 0.6131 - val_loss: 1.8980 - val_accuracy: 0.1269\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.7635 - accuracy: 0.6244 - val_loss: 1.5235 - val_accuracy: 0.1570\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.8109 - accuracy: 0.6181 - val_loss: 1.4929 - val_accuracy: 0.1485\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.7646 - accuracy: 0.6215 - val_loss: 1.8775 - val_accuracy: 0.1314\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.7988 - accuracy: 0.6196 - val_loss: 1.4274 - val_accuracy: 0.1530\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.7583 - accuracy: 0.6240 - val_loss: 2.0706 - val_accuracy: 0.1270\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.7330 - accuracy: 0.6257 - val_loss: 1.6615 - val_accuracy: 0.1420\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.7808 - accuracy: 0.6214 - val_loss: 1.5525 - val_accuracy: 0.1557\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7455 - accuracy: 0.6256 - val_loss: 2.0638 - val_accuracy: 0.1315\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.6914 - accuracy: 0.6292 - val_loss: 2.2795 - val_accuracy: 0.1249\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.7043 - accuracy: 0.6270 - val_loss: 2.1089 - val_accuracy: 0.1268\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.7238 - accuracy: 0.6275 - val_loss: 15.3214 - val_accuracy: 0.0451\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.8722 - accuracy: 0.6217 - val_loss: 20.7626 - val_accuracy: 0.0447\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.8238 - accuracy: 0.6203 - val_loss: 23.5171 - val_accuracy: 0.0660\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.8137 - accuracy: 0.6224 - val_loss: 1.6564 - val_accuracy: 0.1551\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.7851 - accuracy: 0.6242 - val_loss: 3.3243 - val_accuracy: 0.1833\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.7342 - accuracy: 0.6244 - val_loss: 1.9792 - val_accuracy: 0.1553\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.7048 - accuracy: 0.6279 - val_loss: 2.1598 - val_accuracy: 0.1461\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.7059 - accuracy: 0.6244 - val_loss: 2.3241 - val_accuracy: 0.1243\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6720 - accuracy: 0.6292 - val_loss: 2.2285 - val_accuracy: 0.2072\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.6612 - accuracy: 0.6303 - val_loss: 1.4763 - val_accuracy: 0.2631\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.6559 - accuracy: 0.6236 - val_loss: 4.0402 - val_accuracy: 0.1486\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6420 - accuracy: 0.6304 - val_loss: 2.8583 - val_accuracy: 0.1819\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6250 - accuracy: 0.6332 - val_loss: 5.5993 - val_accuracy: 0.1268\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.6125 - accuracy: 0.6338 - val_loss: 2.9224 - val_accuracy: 0.2149\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6119 - accuracy: 0.6311 - val_loss: 9.6243 - val_accuracy: 0.1805\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7202 - accuracy: 0.6307 - val_loss: 4.4273 - val_accuracy: 0.0919\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.6779 - accuracy: 0.6270 - val_loss: 6.1445 - val_accuracy: 0.1488\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6574 - accuracy: 0.6256 - val_loss: 3.4782 - val_accuracy: 0.1266\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.5981 - accuracy: 0.6317 - val_loss: 6.8283 - val_accuracy: 0.1539\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.6048 - accuracy: 0.6357 - val_loss: 3.1571 - val_accuracy: 0.1719\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6293 - accuracy: 0.6297 - val_loss: 5.1511 - val_accuracy: 0.1659\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5906 - accuracy: 0.6341 - val_loss: 7.0279 - val_accuracy: 0.1646\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.5877 - accuracy: 0.6337 - val_loss: 4.1717 - val_accuracy: 0.1605\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5595 - accuracy: 0.6345 - val_loss: 6.2125 - val_accuracy: 0.1249\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5449 - accuracy: 0.6361 - val_loss: 6.4995 - val_accuracy: 0.1557\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5089 - accuracy: 0.6397 - val_loss: 4.2371 - val_accuracy: 0.1759\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.5332 - accuracy: 0.6392 - val_loss: 5.8450 - val_accuracy: 0.1566\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5360 - accuracy: 0.6428 - val_loss: 5.0138 - val_accuracy: 0.1390\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5454 - accuracy: 0.6356 - val_loss: 4.4142 - val_accuracy: 0.1261\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.5354 - accuracy: 0.6386 - val_loss: 4.0569 - val_accuracy: 0.1219\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.5783 - accuracy: 0.6313 - val_loss: 3.0051 - val_accuracy: 0.1522\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4970 - accuracy: 0.6433 - val_loss: 3.4439 - val_accuracy: 0.1408\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5135 - accuracy: 0.6439 - val_loss: 4.0667 - val_accuracy: 0.1629\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5195 - accuracy: 0.6425 - val_loss: 6.8626 - val_accuracy: 0.0964\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5645 - accuracy: 0.6322 - val_loss: 7.1630 - val_accuracy: 0.1052\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.5834 - accuracy: 0.6440 - val_loss: 2.9496 - val_accuracy: 0.1586\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5751 - accuracy: 0.6401 - val_loss: 5.1994 - val_accuracy: 0.1481\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5129 - accuracy: 0.6412 - val_loss: 5.9029 - val_accuracy: 0.1403\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5230 - accuracy: 0.6447 - val_loss: 9.4210 - val_accuracy: 0.1083\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5231 - accuracy: 0.6396 - val_loss: 9.5791 - val_accuracy: 0.1048\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.4896 - accuracy: 0.6420 - val_loss: 10.4809 - val_accuracy: 0.1100\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.4849 - accuracy: 0.6447 - val_loss: 25.2367 - val_accuracy: 0.0908\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.4705 - accuracy: 0.6501 - val_loss: 12.7237 - val_accuracy: 0.1076\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4908 - accuracy: 0.6437 - val_loss: 27.2628 - val_accuracy: 0.0626\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4525 - accuracy: 0.6497 - val_loss: 34.8686 - val_accuracy: 0.0548\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4458 - accuracy: 0.6494 - val_loss: 31.2839 - val_accuracy: 0.0875\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.4957 - accuracy: 0.6465 - val_loss: 37.9062 - val_accuracy: 0.0748\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.4972 - accuracy: 0.6472 - val_loss: 29.5002 - val_accuracy: 0.1038\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.4812 - accuracy: 0.6466 - val_loss: 77.0348 - val_accuracy: 0.0471\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.4988 - accuracy: 0.6497 - val_loss: 22.1661 - val_accuracy: 0.0592\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.5050 - accuracy: 0.6433 - val_loss: 266.8128 - val_accuracy: 0.0657\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.4737 - accuracy: 0.6490 - val_loss: 126.9428 - val_accuracy: 0.0385\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5578 - accuracy: 0.6496 - val_loss: 130.5169 - val_accuracy: 0.0164\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.6880 - accuracy: 0.6321 - val_loss: 12.3887 - val_accuracy: 0.0757\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.5787 - accuracy: 0.6361 - val_loss: 9.5055 - val_accuracy: 0.0942\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5924 - accuracy: 0.6390 - val_loss: 6.2703 - val_accuracy: 0.1261\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.5421 - accuracy: 0.6362 - val_loss: 9.5036 - val_accuracy: 0.1448\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.4951 - accuracy: 0.6352 - val_loss: 8.4049 - val_accuracy: 0.1228\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4884 - accuracy: 0.6384 - val_loss: 11.7980 - val_accuracy: 0.1458\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4593 - accuracy: 0.6466 - val_loss: 14.5223 - val_accuracy: 0.0936\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4700 - accuracy: 0.6415 - val_loss: 12.1214 - val_accuracy: 0.1202\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4667 - accuracy: 0.6497 - val_loss: 16.4278 - val_accuracy: 0.1227\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5245 - accuracy: 0.6406 - val_loss: 14.7401 - val_accuracy: 0.0751\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4811 - accuracy: 0.6465 - val_loss: 11.6393 - val_accuracy: 0.0930\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4736 - accuracy: 0.6464 - val_loss: 9.4766 - val_accuracy: 0.1037\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4457 - accuracy: 0.6481 - val_loss: 7.8358 - val_accuracy: 0.1058\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.3952 - accuracy: 0.6549 - val_loss: 21.8693 - val_accuracy: 0.1197\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4060 - accuracy: 0.6528 - val_loss: 13.5585 - val_accuracy: 0.0989\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4645 - accuracy: 0.6490 - val_loss: 25.3281 - val_accuracy: 0.1138\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.4235 - accuracy: 0.6528 - val_loss: 12.8068 - val_accuracy: 0.1097\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.3753 - accuracy: 0.6601 - val_loss: 20.2580 - val_accuracy: 0.1176\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3953 - accuracy: 0.6576 - val_loss: 11.5385 - val_accuracy: 0.1023\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4176 - accuracy: 0.6511 - val_loss: 17.0330 - val_accuracy: 0.1241\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3855 - accuracy: 0.6548 - val_loss: 14.3249 - val_accuracy: 0.1015\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3796 - accuracy: 0.6555 - val_loss: 36.5138 - val_accuracy: 0.0908\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4346 - accuracy: 0.6478 - val_loss: 35.9337 - val_accuracy: 0.1191\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.3967 - accuracy: 0.6571 - val_loss: 17.9111 - val_accuracy: 0.1158\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3825 - accuracy: 0.6546 - val_loss: 26.6771 - val_accuracy: 0.0968\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3479 - accuracy: 0.6581 - val_loss: 45.2931 - val_accuracy: 0.1282\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3698 - accuracy: 0.6551 - val_loss: 30.0883 - val_accuracy: 0.0866\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3653 - accuracy: 0.6606 - val_loss: 28.7720 - val_accuracy: 0.1197\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3558 - accuracy: 0.6612 - val_loss: 27.5764 - val_accuracy: 0.1191\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3671 - accuracy: 0.6602 - val_loss: 38.0904 - val_accuracy: 0.0920\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3924 - accuracy: 0.6548 - val_loss: 33.6978 - val_accuracy: 0.0950\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3715 - accuracy: 0.6598 - val_loss: 35.9671 - val_accuracy: 0.0956\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.3378 - accuracy: 0.6571 - val_loss: 28.3228 - val_accuracy: 0.0922\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.3371 - accuracy: 0.6637 - val_loss: 23.6021 - val_accuracy: 0.1326\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3263 - accuracy: 0.6629 - val_loss: 27.6447 - val_accuracy: 0.1164\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3325 - accuracy: 0.6619 - val_loss: 39.3470 - val_accuracy: 0.1147\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3801 - accuracy: 0.6537 - val_loss: 67.2266 - val_accuracy: 0.0539\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4104 - accuracy: 0.6595 - val_loss: 61.7349 - val_accuracy: 0.0996\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3630 - accuracy: 0.6582 - val_loss: 24.4359 - val_accuracy: 0.1187\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3490 - accuracy: 0.6637 - val_loss: 86.1441 - val_accuracy: 0.0874\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3210 - accuracy: 0.6638 - val_loss: 54.1644 - val_accuracy: 0.0993\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2927 - accuracy: 0.6710 - val_loss: 77.4765 - val_accuracy: 0.0925\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3154 - accuracy: 0.6643 - val_loss: 33.6397 - val_accuracy: 0.1034\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.3201 - accuracy: 0.6626 - val_loss: 86.8488 - val_accuracy: 0.0978\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.2721 - accuracy: 0.6661 - val_loss: 46.0924 - val_accuracy: 0.0970\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.2884 - accuracy: 0.6697 - val_loss: 66.7192 - val_accuracy: 0.0643\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3036 - accuracy: 0.6658 - val_loss: 72.6367 - val_accuracy: 0.0572\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.2952 - accuracy: 0.6693 - val_loss: 127.0640 - val_accuracy: 0.0619\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2954 - accuracy: 0.6688 - val_loss: 102.3082 - val_accuracy: 0.1033\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3242 - accuracy: 0.6658 - val_loss: 42.9671 - val_accuracy: 0.0951\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2892 - accuracy: 0.6655 - val_loss: 46.1832 - val_accuracy: 0.0654\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2752 - accuracy: 0.6704 - val_loss: 85.1458 - val_accuracy: 0.0619\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3153 - accuracy: 0.6654 - val_loss: 31.6587 - val_accuracy: 0.1895\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.3546 - accuracy: 0.6633 - val_loss: 49.4990 - val_accuracy: 0.1362\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.3561 - accuracy: 0.6509 - val_loss: 15.2351 - val_accuracy: 0.1232\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3624 - accuracy: 0.6623 - val_loss: 20.6924 - val_accuracy: 0.1525\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4864 - accuracy: 0.6516 - val_loss: 2074.5916 - val_accuracy: 0.1313\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4855 - accuracy: 0.6571 - val_loss: 4166.3120 - val_accuracy: 0.1290\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5260 - accuracy: 0.6551 - val_loss: 19821.0508 - val_accuracy: 0.0892\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5431 - accuracy: 0.6550 - val_loss: 8569.6260 - val_accuracy: 0.0210\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4330 - accuracy: 0.6597 - val_loss: 1993.8732 - val_accuracy: 0.0110\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4227 - accuracy: 0.6472 - val_loss: 645.5900 - val_accuracy: 0.0109\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3350 - accuracy: 0.6591 - val_loss: 500.8604 - val_accuracy: 0.0086\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3452 - accuracy: 0.6622 - val_loss: 704.6860 - val_accuracy: 0.0081\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2942 - accuracy: 0.6594 - val_loss: 632.3255 - val_accuracy: 0.0109\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2898 - accuracy: 0.6662 - val_loss: 686.4457 - val_accuracy: 0.0085\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2797 - accuracy: 0.6678 - val_loss: 540.3590 - val_accuracy: 0.0177\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3559 - accuracy: 0.6593 - val_loss: 1277.5690 - val_accuracy: 0.0131\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2503 - accuracy: 0.6714 - val_loss: 1781.1512 - val_accuracy: 0.0071\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2399 - accuracy: 0.6669 - val_loss: 1126.2400 - val_accuracy: 0.0067\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3078 - accuracy: 0.6721 - val_loss: 962.0472 - val_accuracy: 0.0219\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2899 - accuracy: 0.6675 - val_loss: 611.0142 - val_accuracy: 0.0175\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2000 - accuracy: 0.6741 - val_loss: 1765.4343 - val_accuracy: 0.0211\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2555 - accuracy: 0.6655 - val_loss: 1425.7070 - val_accuracy: 0.0264\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2395 - accuracy: 0.6734 - val_loss: 2477.5371 - val_accuracy: 0.0297\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.2269 - accuracy: 0.6710 - val_loss: 3032.0312 - val_accuracy: 0.0433\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.3930 - accuracy: 0.6701 - val_loss: 428.3853 - val_accuracy: 0.0481\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3131 - accuracy: 0.6712 - val_loss: 1474.9115 - val_accuracy: 0.0297\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2661 - accuracy: 0.6705 - val_loss: 1674.1019 - val_accuracy: 0.0289\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 3s 186ms/step - loss: 1.2573 - accuracy: 0.6743 - val_loss: 816.8817 - val_accuracy: 0.0277\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2523 - accuracy: 0.6713 - val_loss: 679.0137 - val_accuracy: 0.0393\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2454 - accuracy: 0.6729 - val_loss: 1539.3290 - val_accuracy: 0.0381\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2392 - accuracy: 0.6749 - val_loss: 1396.1914 - val_accuracy: 0.0702\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1912 - accuracy: 0.6789 - val_loss: 1340.5310 - val_accuracy: 0.0472\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.2574 - accuracy: 0.6681 - val_loss: 1341.8920 - val_accuracy: 0.0469\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2026 - accuracy: 0.6743 - val_loss: 592.6173 - val_accuracy: 0.0615\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.2003 - accuracy: 0.6792 - val_loss: 243.1049 - val_accuracy: 0.0470\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2053 - accuracy: 0.6760 - val_loss: 597.3732 - val_accuracy: 0.0455\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2574 - accuracy: 0.6734 - val_loss: 344.4361 - val_accuracy: 0.0271\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2223 - accuracy: 0.6757 - val_loss: 244.2242 - val_accuracy: 0.0314\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1956 - accuracy: 0.6765 - val_loss: 84.1479 - val_accuracy: 0.0687\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2340 - accuracy: 0.6759 - val_loss: 269.6064 - val_accuracy: 0.0213\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2052 - accuracy: 0.6776 - val_loss: 135.8757 - val_accuracy: 0.0312\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.2240 - accuracy: 0.6721 - val_loss: 146.4117 - val_accuracy: 0.0342\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1707 - accuracy: 0.6810 - val_loss: 136.8192 - val_accuracy: 0.0435\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2111 - accuracy: 0.6757 - val_loss: 256.9232 - val_accuracy: 0.0404\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1315 - accuracy: 0.6161 - val_loss: 1064.8260 - val_accuracy: 0.0904\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.5360 - accuracy: 0.5945 - val_loss: 91.8835 - val_accuracy: 0.1245\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.7403 - accuracy: 0.4544 - val_loss: 2.2879 - val_accuracy: 0.5014\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 2.5311 - accuracy: 0.4863 - val_loss: 2.0656 - val_accuracy: 0.2444\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.5660 - accuracy: 0.5271 - val_loss: 1.9604 - val_accuracy: 0.3629\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.6456 - accuracy: 0.4823 - val_loss: 1.8505 - val_accuracy: 0.3210\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.5109 - accuracy: 0.4987 - val_loss: 1.7202 - val_accuracy: 0.2277\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.5503 - accuracy: 0.4999 - val_loss: 2.0588 - val_accuracy: 0.4231\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.3309 - accuracy: 0.5399 - val_loss: 1.6598 - val_accuracy: 0.3381\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.2875 - accuracy: 0.5698 - val_loss: 1.7673 - val_accuracy: 0.3000\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1942 - accuracy: 0.5864 - val_loss: 1.6758 - val_accuracy: 0.2838\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.2734 - accuracy: 0.5976 - val_loss: 1.5786 - val_accuracy: 0.2698\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1811 - accuracy: 0.6052 - val_loss: 1.6665 - val_accuracy: 0.2210\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.2210 - accuracy: 0.6050 - val_loss: 1.6799 - val_accuracy: 0.3039\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1903 - accuracy: 0.6078 - val_loss: 1.7113 - val_accuracy: 0.2732\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.2060 - accuracy: 0.6093 - val_loss: 1.4980 - val_accuracy: 0.2261\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.2687 - accuracy: 0.6058 - val_loss: 1.7101 - val_accuracy: 0.2755\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1539 - accuracy: 0.6123 - val_loss: 1.6801 - val_accuracy: 0.2762\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.2112 - accuracy: 0.6002 - val_loss: 1.7406 - val_accuracy: 0.3238\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.2602 - accuracy: 0.6124 - val_loss: 1.6396 - val_accuracy: 0.2721\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2379 - accuracy: 0.6118 - val_loss: 1.7553 - val_accuracy: 0.2146\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.2128 - accuracy: 0.6118 - val_loss: 1.8671 - val_accuracy: 0.1794\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1869 - accuracy: 0.6149 - val_loss: 1.7739 - val_accuracy: 0.1916\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1941 - accuracy: 0.6168 - val_loss: 1.7790 - val_accuracy: 0.1958\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1921 - accuracy: 0.6162 - val_loss: 1.8160 - val_accuracy: 0.1995\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2314 - accuracy: 0.6195 - val_loss: 1.8353 - val_accuracy: 0.2117\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1619 - accuracy: 0.6178 - val_loss: 1.8644 - val_accuracy: 0.2227\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1490 - accuracy: 0.6188 - val_loss: 1.8325 - val_accuracy: 0.2286\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1320 - accuracy: 0.6145 - val_loss: 1.6965 - val_accuracy: 0.2590\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1839 - accuracy: 0.6121 - val_loss: 1.9372 - val_accuracy: 0.2048\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1815 - accuracy: 0.6149 - val_loss: 2.1480 - val_accuracy: 0.1466\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.1037 - accuracy: 0.6216 - val_loss: 2.2713 - val_accuracy: 0.1456\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1943 - accuracy: 0.6190 - val_loss: 2.2337 - val_accuracy: 0.1466\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1900 - accuracy: 0.6147 - val_loss: 2.2158 - val_accuracy: 0.1460\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 4s 241ms/step - loss: 2.2642 - accuracy: 0.6121 - val_loss: 2.0683 - val_accuracy: 0.1495\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1786 - accuracy: 0.6177 - val_loss: 2.1292 - val_accuracy: 0.1503\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1592 - accuracy: 0.6226 - val_loss: 2.0045 - val_accuracy: 0.1565\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0910 - accuracy: 0.6201 - val_loss: 2.0370 - val_accuracy: 0.1587\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1442 - accuracy: 0.6201 - val_loss: 1.9690 - val_accuracy: 0.1580\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 2.2080 - accuracy: 0.6123 - val_loss: 2.0113 - val_accuracy: 0.1567\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.1761 - accuracy: 0.6193 - val_loss: 2.0516 - val_accuracy: 0.1586\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 2.1664 - accuracy: 0.6222 - val_loss: 1.9165 - val_accuracy: 0.1614\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1488 - accuracy: 0.6238 - val_loss: 1.9837 - val_accuracy: 0.1628\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1138 - accuracy: 0.6202 - val_loss: 1.9012 - val_accuracy: 0.1719\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1329 - accuracy: 0.6226 - val_loss: 2.0178 - val_accuracy: 0.1742\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1679 - accuracy: 0.6185 - val_loss: 1.8308 - val_accuracy: 0.1796\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1269 - accuracy: 0.6163 - val_loss: 1.9400 - val_accuracy: 0.1794\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1221 - accuracy: 0.6238 - val_loss: 1.9860 - val_accuracy: 0.1845\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1367 - accuracy: 0.6184 - val_loss: 2.1843 - val_accuracy: 0.1869\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1587 - accuracy: 0.6181 - val_loss: 2.0714 - val_accuracy: 0.1974\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1223 - accuracy: 0.6182 - val_loss: 2.0729 - val_accuracy: 0.2062\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1273 - accuracy: 0.6172 - val_loss: 1.9166 - val_accuracy: 0.2265\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0900 - accuracy: 0.6150 - val_loss: 1.9153 - val_accuracy: 0.2560\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1187 - accuracy: 0.6170 - val_loss: 1.9455 - val_accuracy: 0.2412\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1208 - accuracy: 0.6158 - val_loss: 1.8806 - val_accuracy: 0.2341\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1709 - accuracy: 0.6166 - val_loss: 1.9913 - val_accuracy: 0.2527\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1113 - accuracy: 0.6210 - val_loss: 1.8290 - val_accuracy: 0.2541\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1242 - accuracy: 0.6152 - val_loss: 1.6756 - val_accuracy: 0.3216\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1670 - accuracy: 0.6188 - val_loss: 1.8115 - val_accuracy: 0.3175\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1636 - accuracy: 0.6106 - val_loss: 1.8410 - val_accuracy: 0.3005\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1383 - accuracy: 0.6155 - val_loss: 1.9082 - val_accuracy: 0.2989\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1421 - accuracy: 0.6067 - val_loss: 1.8301 - val_accuracy: 0.2780\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1019 - accuracy: 0.6142 - val_loss: 2.2629 - val_accuracy: 0.3143\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1379 - accuracy: 0.6126 - val_loss: 2.6890 - val_accuracy: 0.2592\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1082 - accuracy: 0.6191 - val_loss: 2.2163 - val_accuracy: 0.2627\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 10s 616ms/step - loss: 2.1183 - accuracy: 0.6176 - val_loss: 2.7005 - val_accuracy: 0.2781\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.1351 - accuracy: 0.6150 - val_loss: 2.0597 - val_accuracy: 0.2829\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1825 - accuracy: 0.6142 - val_loss: 2.3894 - val_accuracy: 0.2725\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 2.1496 - accuracy: 0.6184 - val_loss: 2.6835 - val_accuracy: 0.2675\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1305 - accuracy: 0.6206 - val_loss: 2.1592 - val_accuracy: 0.2604\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1267 - accuracy: 0.6181 - val_loss: 2.9002 - val_accuracy: 0.2548\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1275 - accuracy: 0.6165 - val_loss: 2.4113 - val_accuracy: 0.2570\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1603 - accuracy: 0.6134 - val_loss: 2.7295 - val_accuracy: 0.2736\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1254 - accuracy: 0.6140 - val_loss: 2.9260 - val_accuracy: 0.2780\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1330 - accuracy: 0.6185 - val_loss: 2.6590 - val_accuracy: 0.2576\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 2.1132 - accuracy: 0.6180 - val_loss: 2.5288 - val_accuracy: 0.2439\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0873 - accuracy: 0.6195 - val_loss: 2.6425 - val_accuracy: 0.2330\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0925 - accuracy: 0.6185 - val_loss: 2.4782 - val_accuracy: 0.1964\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0761 - accuracy: 0.6226 - val_loss: 2.6326 - val_accuracy: 0.1875\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1333 - accuracy: 0.6185 - val_loss: 2.4562 - val_accuracy: 0.1824\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0891 - accuracy: 0.6189 - val_loss: 2.1829 - val_accuracy: 0.1908\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1196 - accuracy: 0.6225 - val_loss: 2.3582 - val_accuracy: 0.1959\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0944 - accuracy: 0.6243 - val_loss: 2.4624 - val_accuracy: 0.2176\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1090 - accuracy: 0.6211 - val_loss: 2.1930 - val_accuracy: 0.2179\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0737 - accuracy: 0.6206 - val_loss: 2.1513 - val_accuracy: 0.2471\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1273 - accuracy: 0.6189 - val_loss: 2.2609 - val_accuracy: 0.2763\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1182 - accuracy: 0.6201 - val_loss: 2.2011 - val_accuracy: 0.2383\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1237 - accuracy: 0.6211 - val_loss: 2.3438 - val_accuracy: 0.2321\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1130 - accuracy: 0.6161 - val_loss: 1.9960 - val_accuracy: 0.2591\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1702 - accuracy: 0.6144 - val_loss: 2.3329 - val_accuracy: 0.2383\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0716 - accuracy: 0.6268 - val_loss: 2.3787 - val_accuracy: 0.2330\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0970 - accuracy: 0.6207 - val_loss: 1.9629 - val_accuracy: 0.2628\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0819 - accuracy: 0.6228 - val_loss: 2.2433 - val_accuracy: 0.2469\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2405 - accuracy: 0.6253 - val_loss: 172.6993 - val_accuracy: 0.1499\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.2363 - accuracy: 0.6268 - val_loss: 2.6898 - val_accuracy: 0.1724\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.2108 - accuracy: 0.6175 - val_loss: 2.2128 - val_accuracy: 0.4555\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.2322 - accuracy: 0.6206 - val_loss: 2.0178 - val_accuracy: 0.3414\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.2689 - accuracy: 0.6157 - val_loss: 2.1043 - val_accuracy: 0.5839\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.2346 - accuracy: 0.6122 - val_loss: 1.9866 - val_accuracy: 0.3248\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.2971 - accuracy: 0.5978 - val_loss: 1.6059 - val_accuracy: 0.3684\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1591 - accuracy: 0.6112 - val_loss: 1.5551 - val_accuracy: 0.3503\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.2034 - accuracy: 0.6138 - val_loss: 1.6084 - val_accuracy: 0.3626\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.2051 - accuracy: 0.6187 - val_loss: 1.7943 - val_accuracy: 0.3628\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.2465 - accuracy: 0.6132 - val_loss: 1.7020 - val_accuracy: 0.4823\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1374 - accuracy: 0.6210 - val_loss: 1.7584 - val_accuracy: 0.3645\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1939 - accuracy: 0.6211 - val_loss: 1.6196 - val_accuracy: 0.3661\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.2611 - accuracy: 0.6164 - val_loss: 1.6110 - val_accuracy: 0.3384\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1264 - accuracy: 0.6223 - val_loss: 1.4307 - val_accuracy: 0.3252\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1990 - accuracy: 0.6150 - val_loss: 1.5945 - val_accuracy: 0.3306\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1146 - accuracy: 0.6200 - val_loss: 1.4820 - val_accuracy: 0.3427\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1433 - accuracy: 0.6190 - val_loss: 1.3671 - val_accuracy: 0.3501\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1846 - accuracy: 0.6131 - val_loss: 1.4679 - val_accuracy: 0.3472\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 2.0926 - accuracy: 0.6234 - val_loss: 1.5701 - val_accuracy: 0.3541\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.1637 - accuracy: 0.6151 - val_loss: 1.5967 - val_accuracy: 0.3515\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 2.1653 - accuracy: 0.6154 - val_loss: 1.8493 - val_accuracy: 0.3529\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1942 - accuracy: 0.6162 - val_loss: 1.6207 - val_accuracy: 0.3478\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1163 - accuracy: 0.6210 - val_loss: 1.5942 - val_accuracy: 0.3582\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1966 - accuracy: 0.6160 - val_loss: 1.4944 - val_accuracy: 0.3660\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.2704 - accuracy: 0.6135 - val_loss: 1.7268 - val_accuracy: 0.3665\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0984 - accuracy: 0.6196 - val_loss: 1.9545 - val_accuracy: 0.5480\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1937 - accuracy: 0.6144 - val_loss: 1.6573 - val_accuracy: 0.5701\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1734 - accuracy: 0.6138 - val_loss: 1.8947 - val_accuracy: 0.5337\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1008 - accuracy: 0.6221 - val_loss: 1.8395 - val_accuracy: 0.4948\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1894 - accuracy: 0.6120 - val_loss: 1.7153 - val_accuracy: 0.4685\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1313 - accuracy: 0.6179 - val_loss: 1.6150 - val_accuracy: 0.4405\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1109 - accuracy: 0.6200 - val_loss: 1.5385 - val_accuracy: 0.4243\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1546 - accuracy: 0.6174 - val_loss: 1.5127 - val_accuracy: 0.4207\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1689 - accuracy: 0.6121 - val_loss: 1.3982 - val_accuracy: 0.4149\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1534 - accuracy: 0.6166 - val_loss: 1.6617 - val_accuracy: 0.4054\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1300 - accuracy: 0.6192 - val_loss: 1.2970 - val_accuracy: 0.4125\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1798 - accuracy: 0.6159 - val_loss: 1.3689 - val_accuracy: 0.3995\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0822 - accuracy: 0.6215 - val_loss: 1.5698 - val_accuracy: 0.4054\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1263 - accuracy: 0.6214 - val_loss: 1.7634 - val_accuracy: 0.4054\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1396 - accuracy: 0.6204 - val_loss: 1.4965 - val_accuracy: 0.3948\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1761 - accuracy: 0.6158 - val_loss: 1.6193 - val_accuracy: 0.3777\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1265 - accuracy: 0.6200 - val_loss: 1.4953 - val_accuracy: 0.3879\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.2320 - accuracy: 0.6154 - val_loss: 2.2118 - val_accuracy: 0.6162\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.2897 - accuracy: 0.5949 - val_loss: 2.6057 - val_accuracy: 0.1885\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.2425 - accuracy: 0.5940 - val_loss: 3.4526 - val_accuracy: 0.3757\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.2095 - accuracy: 0.6021 - val_loss: 1.7286 - val_accuracy: 0.3978\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.2169 - accuracy: 0.6145 - val_loss: 1.6803 - val_accuracy: 0.4630\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1882 - accuracy: 0.6181 - val_loss: 1.4698 - val_accuracy: 0.4302\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1979 - accuracy: 0.6177 - val_loss: 1.6970 - val_accuracy: 0.4170\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1717 - accuracy: 0.6227 - val_loss: 1.5417 - val_accuracy: 0.4098\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1696 - accuracy: 0.6181 - val_loss: 1.8443 - val_accuracy: 0.4013\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1632 - accuracy: 0.6184 - val_loss: 1.3245 - val_accuracy: 0.4122\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1871 - accuracy: 0.6183 - val_loss: 1.3982 - val_accuracy: 0.4091\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1350 - accuracy: 0.6246 - val_loss: 1.6070 - val_accuracy: 0.4268\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1293 - accuracy: 0.6221 - val_loss: 1.4603 - val_accuracy: 0.4418\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1213 - accuracy: 0.6249 - val_loss: 1.4215 - val_accuracy: 0.4429\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1568 - accuracy: 0.6273 - val_loss: 1.4264 - val_accuracy: 0.4416\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1186 - accuracy: 0.6217 - val_loss: 1.7226 - val_accuracy: 0.4375\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.2055 - accuracy: 0.6202 - val_loss: 1.3976 - val_accuracy: 0.4436\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2157 - accuracy: 0.6192 - val_loss: 1.4554 - val_accuracy: 0.4362\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1969 - accuracy: 0.6159 - val_loss: 1.5162 - val_accuracy: 0.4268\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1462 - accuracy: 0.6160 - val_loss: 1.3313 - val_accuracy: 0.4263\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.0835 - accuracy: 0.6221 - val_loss: 1.4520 - val_accuracy: 0.4152\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1856 - accuracy: 0.6231 - val_loss: 1.3013 - val_accuracy: 0.4219\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1603 - accuracy: 0.6195 - val_loss: 1.5299 - val_accuracy: 0.4103\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1050 - accuracy: 0.6253 - val_loss: 1.4622 - val_accuracy: 0.4013\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1402 - accuracy: 0.6198 - val_loss: 1.4103 - val_accuracy: 0.4011\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1015 - accuracy: 0.6249 - val_loss: 1.4906 - val_accuracy: 0.4027\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1255 - accuracy: 0.6191 - val_loss: 1.3893 - val_accuracy: 0.3876\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1662 - accuracy: 0.6192 - val_loss: 1.5998 - val_accuracy: 0.3770\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1445 - accuracy: 0.6197 - val_loss: 1.4999 - val_accuracy: 0.3821\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1538 - accuracy: 0.6192 - val_loss: 1.6840 - val_accuracy: 0.3779\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1136 - accuracy: 0.6161 - val_loss: 1.5543 - val_accuracy: 0.3721\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1464 - accuracy: 0.6157 - val_loss: 1.5826 - val_accuracy: 0.3689\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1238 - accuracy: 0.6231 - val_loss: 1.4538 - val_accuracy: 0.3633\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1574 - accuracy: 0.6207 - val_loss: 1.3973 - val_accuracy: 0.3585\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1156 - accuracy: 0.6197 - val_loss: 1.4836 - val_accuracy: 0.3662\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.1075 - accuracy: 0.6186 - val_loss: 1.6806 - val_accuracy: 0.3545\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1816 - accuracy: 0.6204 - val_loss: 1.5571 - val_accuracy: 0.3509\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1261 - accuracy: 0.6189 - val_loss: 1.2968 - val_accuracy: 0.3460\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1179 - accuracy: 0.6243 - val_loss: 1.5137 - val_accuracy: 0.3416\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0596 - accuracy: 0.6234 - val_loss: 1.3788 - val_accuracy: 0.3307\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.0881 - accuracy: 0.6222 - val_loss: 1.7443 - val_accuracy: 0.3276\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 2.0734 - accuracy: 0.6228 - val_loss: 1.5259 - val_accuracy: 0.3245\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1095 - accuracy: 0.6189 - val_loss: 1.3767 - val_accuracy: 0.3069\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1717 - accuracy: 0.6157 - val_loss: 1.5874 - val_accuracy: 0.3012\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.1328 - accuracy: 0.6207 - val_loss: 1.4117 - val_accuracy: 0.3117\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1072 - accuracy: 0.6206 - val_loss: 1.4984 - val_accuracy: 0.2955\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.1506 - accuracy: 0.6217 - val_loss: 1.6079 - val_accuracy: 0.2855\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0934 - accuracy: 0.6185 - val_loss: 1.4176 - val_accuracy: 0.2746\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1515 - accuracy: 0.6226 - val_loss: 1.6338 - val_accuracy: 0.2563\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1039 - accuracy: 0.6176 - val_loss: 1.7095 - val_accuracy: 0.2488\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1268 - accuracy: 0.6185 - val_loss: 1.3251 - val_accuracy: 0.2479\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0864 - accuracy: 0.6202 - val_loss: 1.5522 - val_accuracy: 0.2528\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0972 - accuracy: 0.6199 - val_loss: 1.3966 - val_accuracy: 0.2487\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 2.1400 - accuracy: 0.6196 - val_loss: 1.5738 - val_accuracy: 0.2384\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0842 - accuracy: 0.6232 - val_loss: 1.5848 - val_accuracy: 0.2441\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1002 - accuracy: 0.6200 - val_loss: 1.5368 - val_accuracy: 0.2430\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0798 - accuracy: 0.6247 - val_loss: 1.6196 - val_accuracy: 0.2420\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1275 - accuracy: 0.6178 - val_loss: 1.5702 - val_accuracy: 0.2396\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1280 - accuracy: 0.6188 - val_loss: 1.5397 - val_accuracy: 0.2387\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0875 - accuracy: 0.6183 - val_loss: 1.4637 - val_accuracy: 0.2365\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.1115 - accuracy: 0.6195 - val_loss: 1.4376 - val_accuracy: 0.2333\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 2.1402 - accuracy: 0.6211 - val_loss: 1.4963 - val_accuracy: 0.2351\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0736 - accuracy: 0.6224 - val_loss: 1.4425 - val_accuracy: 0.2314\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1112 - accuracy: 0.6153 - val_loss: 1.5133 - val_accuracy: 0.2239\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0912 - accuracy: 0.6196 - val_loss: 1.5200 - val_accuracy: 0.2235\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0819 - accuracy: 0.6229 - val_loss: 1.4082 - val_accuracy: 0.2335\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0860 - accuracy: 0.6206 - val_loss: 1.3722 - val_accuracy: 0.2323\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0809 - accuracy: 0.6235 - val_loss: 1.2648 - val_accuracy: 0.2264\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0736 - accuracy: 0.6208 - val_loss: 1.5553 - val_accuracy: 0.2287\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0835 - accuracy: 0.6227 - val_loss: 1.5965 - val_accuracy: 0.2279\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0590 - accuracy: 0.6240 - val_loss: 1.4099 - val_accuracy: 0.2257\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0929 - accuracy: 0.6176 - val_loss: 1.4779 - val_accuracy: 0.2242\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1038 - accuracy: 0.6187 - val_loss: 1.5267 - val_accuracy: 0.2225\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0893 - accuracy: 0.6159 - val_loss: 1.4971 - val_accuracy: 0.2242\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0832 - accuracy: 0.6195 - val_loss: 1.5522 - val_accuracy: 0.2235\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0879 - accuracy: 0.6243 - val_loss: 1.5689 - val_accuracy: 0.2374\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0763 - accuracy: 0.6180 - val_loss: 1.4596 - val_accuracy: 0.2272\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0787 - accuracy: 0.6259 - val_loss: 1.5554 - val_accuracy: 0.2334\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0815 - accuracy: 0.6181 - val_loss: 1.5124 - val_accuracy: 0.2278\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0974 - accuracy: 0.6171 - val_loss: 1.5691 - val_accuracy: 0.2308\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0177 - accuracy: 0.6239 - val_loss: 1.6839 - val_accuracy: 0.2353\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1478 - accuracy: 0.6193 - val_loss: 1.6051 - val_accuracy: 0.2261\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0514 - accuracy: 0.6190 - val_loss: 1.4385 - val_accuracy: 0.2283\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0581 - accuracy: 0.6236 - val_loss: 1.4498 - val_accuracy: 0.2319\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0649 - accuracy: 0.6200 - val_loss: 1.6284 - val_accuracy: 0.2317\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0406 - accuracy: 0.6225 - val_loss: 1.5836 - val_accuracy: 0.2332\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0296 - accuracy: 0.6244 - val_loss: 1.5545 - val_accuracy: 0.2310\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0492 - accuracy: 0.6229 - val_loss: 1.5121 - val_accuracy: 0.2326\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.0797 - accuracy: 0.6193 - val_loss: 1.6142 - val_accuracy: 0.2317\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0773 - accuracy: 0.6180 - val_loss: 1.5777 - val_accuracy: 0.2271\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0763 - accuracy: 0.6130 - val_loss: 1.4256 - val_accuracy: 0.2277\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0636 - accuracy: 0.6183 - val_loss: 1.5759 - val_accuracy: 0.2335\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0737 - accuracy: 0.6192 - val_loss: 1.5235 - val_accuracy: 0.2322\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0656 - accuracy: 0.6180 - val_loss: 1.6720 - val_accuracy: 0.2357\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0622 - accuracy: 0.6188 - val_loss: 1.6202 - val_accuracy: 0.2345\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0681 - accuracy: 0.6208 - val_loss: 1.6309 - val_accuracy: 0.2309\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0774 - accuracy: 0.6222 - val_loss: 1.5114 - val_accuracy: 0.2206\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0495 - accuracy: 0.6207 - val_loss: 1.5110 - val_accuracy: 0.2239\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0275 - accuracy: 0.6266 - val_loss: 1.4702 - val_accuracy: 0.2361\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1164 - accuracy: 0.6214 - val_loss: 1.5781 - val_accuracy: 0.2299\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0893 - accuracy: 0.6221 - val_loss: 1.5214 - val_accuracy: 0.2233\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0875 - accuracy: 0.6166 - val_loss: 1.6310 - val_accuracy: 0.2200\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 2.1318 - accuracy: 0.6179 - val_loss: 1.7327 - val_accuracy: 0.2125\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0669 - accuracy: 0.6162 - val_loss: 1.5138 - val_accuracy: 0.2219\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1039 - accuracy: 0.6173 - val_loss: 1.7569 - val_accuracy: 0.2099\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0828 - accuracy: 0.6218 - val_loss: 1.7038 - val_accuracy: 0.2080\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0001 - accuracy: 0.6194 - val_loss: 1.6301 - val_accuracy: 0.2060\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0699 - accuracy: 0.6185 - val_loss: 1.9184 - val_accuracy: 0.2066\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0761 - accuracy: 0.6208 - val_loss: 1.9912 - val_accuracy: 0.1948\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0500 - accuracy: 0.6204 - val_loss: 2.5603 - val_accuracy: 0.2016\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0356 - accuracy: 0.6222 - val_loss: 1.7914 - val_accuracy: 0.1904\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0351 - accuracy: 0.6225 - val_loss: 2.4946 - val_accuracy: 0.1981\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0743 - accuracy: 0.6177 - val_loss: 2.1328 - val_accuracy: 0.1832\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0842 - accuracy: 0.6231 - val_loss: 2.0090 - val_accuracy: 0.1878\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0311 - accuracy: 0.6232 - val_loss: 1.6539 - val_accuracy: 0.1924\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0456 - accuracy: 0.6185 - val_loss: 4.0179 - val_accuracy: 0.1794\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0755 - accuracy: 0.6212 - val_loss: 2.8810 - val_accuracy: 0.1746\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0586 - accuracy: 0.6211 - val_loss: 5.6047 - val_accuracy: 0.1678\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0933 - accuracy: 0.6171 - val_loss: 5.8883 - val_accuracy: 0.1585\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0449 - accuracy: 0.6175 - val_loss: 3.0511 - val_accuracy: 0.1596\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0485 - accuracy: 0.6163 - val_loss: 5.3743 - val_accuracy: 0.1571\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0633 - accuracy: 0.6223 - val_loss: 7.7700 - val_accuracy: 0.1438\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0196 - accuracy: 0.6253 - val_loss: 5.6888 - val_accuracy: 0.1481\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0572 - accuracy: 0.6200 - val_loss: 11.3676 - val_accuracy: 0.1409\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0142 - accuracy: 0.6260 - val_loss: 4.8001 - val_accuracy: 0.1551\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0362 - accuracy: 0.6247 - val_loss: 11.8525 - val_accuracy: 0.1404\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0200 - accuracy: 0.6260 - val_loss: 9.8465 - val_accuracy: 0.1446\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0400 - accuracy: 0.6213 - val_loss: 4.0354 - val_accuracy: 0.1610\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0534 - accuracy: 0.6190 - val_loss: 12.4615 - val_accuracy: 0.1360\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.0508 - accuracy: 0.6233 - val_loss: 9.5167 - val_accuracy: 0.1473\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.0208 - accuracy: 0.6230 - val_loss: 3.0525 - val_accuracy: 0.4342\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0336 - accuracy: 0.6243 - val_loss: 9.4818 - val_accuracy: 0.1531\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1105 - accuracy: 0.6207 - val_loss: 84.2107 - val_accuracy: 0.0837\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0885 - accuracy: 0.6198 - val_loss: 49.4083 - val_accuracy: 0.0733\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0815 - accuracy: 0.6226 - val_loss: 57.4096 - val_accuracy: 0.0741\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0697 - accuracy: 0.6188 - val_loss: 44.6235 - val_accuracy: 0.0933\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0533 - accuracy: 0.6251 - val_loss: 62.6474 - val_accuracy: 0.0807\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0332 - accuracy: 0.6187 - val_loss: 36.6533 - val_accuracy: 0.0861\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0358 - accuracy: 0.6261 - val_loss: 32.5902 - val_accuracy: 0.1188\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0455 - accuracy: 0.6225 - val_loss: 23.6834 - val_accuracy: 0.1128\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.0282 - accuracy: 0.6218 - val_loss: 35.1958 - val_accuracy: 0.0995\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0241 - accuracy: 0.6238 - val_loss: 37.5229 - val_accuracy: 0.1065\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0418 - accuracy: 0.6202 - val_loss: 11.8877 - val_accuracy: 0.1257\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.0361 - accuracy: 0.6236 - val_loss: 26.4598 - val_accuracy: 0.1149\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 2.0213 - accuracy: 0.6269 - val_loss: 13.2515 - val_accuracy: 0.1289\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.0235 - accuracy: 0.6210 - val_loss: 23.3953 - val_accuracy: 0.1217\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0353 - accuracy: 0.6199 - val_loss: 17.3889 - val_accuracy: 0.1214\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.1061 - accuracy: 0.6201 - val_loss: 17.1489 - val_accuracy: 0.1213\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0615 - accuracy: 0.6205 - val_loss: 24.2184 - val_accuracy: 0.1304\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0647 - accuracy: 0.6189 - val_loss: 14.0352 - val_accuracy: 0.1253\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0168 - accuracy: 0.6245 - val_loss: 9.0164 - val_accuracy: 0.1387\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0560 - accuracy: 0.6209 - val_loss: 7.2729 - val_accuracy: 0.1366\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0570 - accuracy: 0.6240 - val_loss: 12.7809 - val_accuracy: 0.1389\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0961 - accuracy: 0.6204 - val_loss: 16.9200 - val_accuracy: 0.1455\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0684 - accuracy: 0.6177 - val_loss: 22.2248 - val_accuracy: 0.1428\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0251 - accuracy: 0.6221 - val_loss: 18.2480 - val_accuracy: 0.1416\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0605 - accuracy: 0.6223 - val_loss: 6.4944 - val_accuracy: 0.1580\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0662 - accuracy: 0.6212 - val_loss: 12.7192 - val_accuracy: 0.1374\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0617 - accuracy: 0.6212 - val_loss: 7.5689 - val_accuracy: 0.1510\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.0567 - accuracy: 0.6219 - val_loss: 15.8067 - val_accuracy: 0.1464\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0311 - accuracy: 0.6195 - val_loss: 10.4278 - val_accuracy: 0.1471\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.9884 - accuracy: 0.6210 - val_loss: 6.8557 - val_accuracy: 0.1578\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0355 - accuracy: 0.6216 - val_loss: 6.7529 - val_accuracy: 0.1522\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0436 - accuracy: 0.6220 - val_loss: 5.1509 - val_accuracy: 0.1549\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0483 - accuracy: 0.6193 - val_loss: 6.3536 - val_accuracy: 0.1565\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0076 - accuracy: 0.6239 - val_loss: 17.7372 - val_accuracy: 0.1564\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0540 - accuracy: 0.6200 - val_loss: 20.5342 - val_accuracy: 0.1430\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0347 - accuracy: 0.6205 - val_loss: 4.6300 - val_accuracy: 0.1578\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0454 - accuracy: 0.6210 - val_loss: 11.5155 - val_accuracy: 0.1438\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0193 - accuracy: 0.6235 - val_loss: 7.7271 - val_accuracy: 0.1682\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0323 - accuracy: 0.6220 - val_loss: 6.7837 - val_accuracy: 0.1877\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0538 - accuracy: 0.6180 - val_loss: 9.9737 - val_accuracy: 0.1554\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0230 - accuracy: 0.6277 - val_loss: 5.4616 - val_accuracy: 0.1735\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0172 - accuracy: 0.6208 - val_loss: 16.5480 - val_accuracy: 0.1443\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0786 - accuracy: 0.6188 - val_loss: 5.3949 - val_accuracy: 0.1699\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0581 - accuracy: 0.6193 - val_loss: 14.7226 - val_accuracy: 0.1466\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0182 - accuracy: 0.6223 - val_loss: 8.2851 - val_accuracy: 0.1701\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0300 - accuracy: 0.6240 - val_loss: 10.5790 - val_accuracy: 0.1392\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0678 - accuracy: 0.6216 - val_loss: 10.7705 - val_accuracy: 0.1393\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.0367 - accuracy: 0.6231 - val_loss: 18.5522 - val_accuracy: 0.1608\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0642 - accuracy: 0.6218 - val_loss: 6.9680 - val_accuracy: 0.1559\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0289 - accuracy: 0.6221 - val_loss: 9.8601 - val_accuracy: 0.1579\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0424 - accuracy: 0.6203 - val_loss: 5.2188 - val_accuracy: 0.1535\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.0145 - accuracy: 0.6228 - val_loss: 6.3835 - val_accuracy: 0.1664\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.9894 - accuracy: 0.6240 - val_loss: 10.0520 - val_accuracy: 0.1609\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0148 - accuracy: 0.6284 - val_loss: 5.0154 - val_accuracy: 0.1553\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0247 - accuracy: 0.6234 - val_loss: 5.0898 - val_accuracy: 0.1563\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 2.0516 - accuracy: 0.6177 - val_loss: 5.3378 - val_accuracy: 0.1666\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0476 - accuracy: 0.6170 - val_loss: 9.5233 - val_accuracy: 0.1459\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0178 - accuracy: 0.6203 - val_loss: 6.8481 - val_accuracy: 0.1541\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0349 - accuracy: 0.6195 - val_loss: 4.5616 - val_accuracy: 0.1549\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.0212 - accuracy: 0.6231 - val_loss: 8.6177 - val_accuracy: 0.1498\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0204 - accuracy: 0.6211 - val_loss: 10.7786 - val_accuracy: 0.1639\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 273ms/step - loss: 2.4410 - accuracy: 0.6113 - val_loss: 15.4737 - val_accuracy: 0.3409\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1958 - accuracy: 0.6143 - val_loss: 16.1462 - val_accuracy: 0.3414\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1726 - accuracy: 0.6112 - val_loss: 15.4422 - val_accuracy: 0.3422\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.0291 - accuracy: 0.6195 - val_loss: 15.6642 - val_accuracy: 0.3428\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.9997 - accuracy: 0.6166 - val_loss: 19.1397 - val_accuracy: 0.3419\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0119 - accuracy: 0.6183 - val_loss: 16.3760 - val_accuracy: 0.3466\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0154 - accuracy: 0.6228 - val_loss: 16.1305 - val_accuracy: 0.3373\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0740 - accuracy: 0.6216 - val_loss: 13.1262 - val_accuracy: 0.3289\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0241 - accuracy: 0.6146 - val_loss: 12.8618 - val_accuracy: 0.3021\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.9894 - accuracy: 0.6172 - val_loss: 11.9756 - val_accuracy: 0.1965\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.9046 - accuracy: 0.6177 - val_loss: 10.4904 - val_accuracy: 0.1892\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.8279 - accuracy: 0.6251 - val_loss: 13.9527 - val_accuracy: 0.1074\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.8343 - accuracy: 0.6196 - val_loss: 12.8492 - val_accuracy: 0.1070\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.7934 - accuracy: 0.6225 - val_loss: 11.6961 - val_accuracy: 0.1076\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.7779 - accuracy: 0.6255 - val_loss: 13.1032 - val_accuracy: 0.1083\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.7764 - accuracy: 0.6228 - val_loss: 12.9890 - val_accuracy: 0.1073\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.7684 - accuracy: 0.6218 - val_loss: 13.3769 - val_accuracy: 0.1106\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.7362 - accuracy: 0.6198 - val_loss: 11.1050 - val_accuracy: 0.1080\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.7603 - accuracy: 0.6219 - val_loss: 12.3379 - val_accuracy: 0.1100\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.7055 - accuracy: 0.6281 - val_loss: 12.8139 - val_accuracy: 0.1085\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6852 - accuracy: 0.6292 - val_loss: 14.2055 - val_accuracy: 0.1068\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.7183 - accuracy: 0.6243 - val_loss: 12.9141 - val_accuracy: 0.1134\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.7279 - accuracy: 0.6223 - val_loss: 11.4122 - val_accuracy: 0.1142\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.6817 - accuracy: 0.6300 - val_loss: 10.9164 - val_accuracy: 0.1131\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.6964 - accuracy: 0.6240 - val_loss: 11.0234 - val_accuracy: 0.1116\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.6789 - accuracy: 0.6290 - val_loss: 12.1382 - val_accuracy: 0.1095\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.6522 - accuracy: 0.6290 - val_loss: 14.0525 - val_accuracy: 0.1082\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.6664 - accuracy: 0.6313 - val_loss: 13.6167 - val_accuracy: 0.1120\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6468 - accuracy: 0.6294 - val_loss: 13.1548 - val_accuracy: 0.1125\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6082 - accuracy: 0.6327 - val_loss: 14.0764 - val_accuracy: 0.1149\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.6175 - accuracy: 0.6324 - val_loss: 12.1008 - val_accuracy: 0.1094\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.6426 - accuracy: 0.6298 - val_loss: 11.3627 - val_accuracy: 0.1090\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.6249 - accuracy: 0.6341 - val_loss: 11.6605 - val_accuracy: 0.1057\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.6187 - accuracy: 0.6331 - val_loss: 13.3842 - val_accuracy: 0.1168\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.5964 - accuracy: 0.6338 - val_loss: 11.6445 - val_accuracy: 0.1040\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.6040 - accuracy: 0.6381 - val_loss: 12.7721 - val_accuracy: 0.1022\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.5937 - accuracy: 0.6363 - val_loss: 11.5026 - val_accuracy: 0.1046\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.6084 - accuracy: 0.6380 - val_loss: 11.2418 - val_accuracy: 0.1077\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5803 - accuracy: 0.6359 - val_loss: 11.3234 - val_accuracy: 0.1232\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5637 - accuracy: 0.6409 - val_loss: 11.1103 - val_accuracy: 0.1923\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5605 - accuracy: 0.6327 - val_loss: 14.0870 - val_accuracy: 0.1555\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5471 - accuracy: 0.6396 - val_loss: 13.9060 - val_accuracy: 0.2018\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5381 - accuracy: 0.6383 - val_loss: 11.0219 - val_accuracy: 0.2361\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.5209 - accuracy: 0.6440 - val_loss: 13.8658 - val_accuracy: 0.2662\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4781 - accuracy: 0.6516 - val_loss: 14.1542 - val_accuracy: 0.3004\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5486 - accuracy: 0.6419 - val_loss: 11.4540 - val_accuracy: 0.3007\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5409 - accuracy: 0.6396 - val_loss: 13.2340 - val_accuracy: 0.3018\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5112 - accuracy: 0.6447 - val_loss: 9.7165 - val_accuracy: 0.2709\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.5644 - accuracy: 0.6429 - val_loss: 14.6354 - val_accuracy: 0.2697\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 4s 274ms/step - loss: 1.5002 - accuracy: 0.6463 - val_loss: 10.2591 - val_accuracy: 0.2591\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 1.4515 - accuracy: 0.6463 - val_loss: 13.1673 - val_accuracy: 0.2983\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 1.4518 - accuracy: 0.6508 - val_loss: 12.5018 - val_accuracy: 0.3146\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4665 - accuracy: 0.6443 - val_loss: 14.1459 - val_accuracy: 0.2823\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4683 - accuracy: 0.6491 - val_loss: 13.9445 - val_accuracy: 0.2979\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.4647 - accuracy: 0.6452 - val_loss: 13.6655 - val_accuracy: 0.3046\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4890 - accuracy: 0.6530 - val_loss: 13.6263 - val_accuracy: 0.3066\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4684 - accuracy: 0.6467 - val_loss: 13.6518 - val_accuracy: 0.2949\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4706 - accuracy: 0.6492 - val_loss: 13.2975 - val_accuracy: 0.3028\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4143 - accuracy: 0.6546 - val_loss: 10.8597 - val_accuracy: 0.2695\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.4460 - accuracy: 0.6536 - val_loss: 11.8898 - val_accuracy: 0.2224\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4547 - accuracy: 0.6533 - val_loss: 13.7531 - val_accuracy: 0.3028\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4379 - accuracy: 0.6526 - val_loss: 13.3043 - val_accuracy: 0.3052\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4419 - accuracy: 0.6559 - val_loss: 13.9241 - val_accuracy: 0.2758\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4493 - accuracy: 0.6543 - val_loss: 13.4894 - val_accuracy: 0.2887\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.4360 - accuracy: 0.6500 - val_loss: 13.7343 - val_accuracy: 0.3055\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4229 - accuracy: 0.6535 - val_loss: 12.4898 - val_accuracy: 0.3176\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.4291 - accuracy: 0.6501 - val_loss: 15.0982 - val_accuracy: 0.3162\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.3991 - accuracy: 0.6579 - val_loss: 13.8025 - val_accuracy: 0.3238\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.4076 - accuracy: 0.6533 - val_loss: 12.1600 - val_accuracy: 0.3255\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 1.3990 - accuracy: 0.6617 - val_loss: 16.3490 - val_accuracy: 0.3153\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4378 - accuracy: 0.6593 - val_loss: 12.3969 - val_accuracy: 0.3156\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3661 - accuracy: 0.6591 - val_loss: 15.9779 - val_accuracy: 0.3138\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3698 - accuracy: 0.6589 - val_loss: 11.8657 - val_accuracy: 0.3208\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3858 - accuracy: 0.6640 - val_loss: 11.4810 - val_accuracy: 0.3252\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.4032 - accuracy: 0.6608 - val_loss: 11.8796 - val_accuracy: 0.3075\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3748 - accuracy: 0.6665 - val_loss: 12.2641 - val_accuracy: 0.3009\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3632 - accuracy: 0.6595 - val_loss: 13.5770 - val_accuracy: 0.3044\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3614 - accuracy: 0.6617 - val_loss: 10.8404 - val_accuracy: 0.3297\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3025 - accuracy: 0.6650 - val_loss: 10.8559 - val_accuracy: 0.3260\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.3499 - accuracy: 0.6662 - val_loss: 11.1352 - val_accuracy: 0.3205\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3233 - accuracy: 0.6640 - val_loss: 11.1460 - val_accuracy: 0.3146\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3102 - accuracy: 0.6656 - val_loss: 11.1835 - val_accuracy: 0.3254\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3526 - accuracy: 0.6653 - val_loss: 11.3219 - val_accuracy: 0.3186\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3206 - accuracy: 0.6680 - val_loss: 11.4400 - val_accuracy: 0.3197\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3383 - accuracy: 0.6646 - val_loss: 11.1782 - val_accuracy: 0.3214\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3124 - accuracy: 0.6668 - val_loss: 12.4526 - val_accuracy: 0.3262\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3110 - accuracy: 0.6651 - val_loss: 10.9996 - val_accuracy: 0.3155\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3271 - accuracy: 0.6680 - val_loss: 10.5618 - val_accuracy: 0.3103\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3381 - accuracy: 0.6616 - val_loss: 12.8655 - val_accuracy: 0.2943\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3619 - accuracy: 0.6650 - val_loss: 10.3844 - val_accuracy: 0.3217\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3841 - accuracy: 0.6610 - val_loss: 10.3660 - val_accuracy: 0.3126\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3250 - accuracy: 0.6660 - val_loss: 10.4503 - val_accuracy: 0.3140\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3018 - accuracy: 0.6674 - val_loss: 10.5969 - val_accuracy: 0.2992\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2982 - accuracy: 0.6705 - val_loss: 9.0867 - val_accuracy: 0.3231\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2745 - accuracy: 0.6683 - val_loss: 9.0974 - val_accuracy: 0.3068\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2881 - accuracy: 0.6687 - val_loss: 11.7490 - val_accuracy: 0.3025\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2865 - accuracy: 0.6720 - val_loss: 11.1589 - val_accuracy: 0.3060\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3344 - accuracy: 0.6663 - val_loss: 10.6625 - val_accuracy: 0.3132\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3557 - accuracy: 0.6633 - val_loss: 10.4634 - val_accuracy: 0.2807\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2651 - accuracy: 0.6724 - val_loss: 9.7841 - val_accuracy: 0.2792\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2655 - accuracy: 0.6765 - val_loss: 11.5210 - val_accuracy: 0.2668\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2899 - accuracy: 0.6721 - val_loss: 10.5426 - val_accuracy: 0.3140\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3279 - accuracy: 0.6729 - val_loss: 11.0570 - val_accuracy: 0.3138\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2519 - accuracy: 0.6719 - val_loss: 10.7531 - val_accuracy: 0.2925\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.2659 - accuracy: 0.6685 - val_loss: 11.6219 - val_accuracy: 0.3007\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2434 - accuracy: 0.6715 - val_loss: 11.3435 - val_accuracy: 0.3055\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.2308 - accuracy: 0.6729 - val_loss: 11.6200 - val_accuracy: 0.3057\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2670 - accuracy: 0.6732 - val_loss: 9.5770 - val_accuracy: 0.3086\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.2475 - accuracy: 0.6720 - val_loss: 9.8803 - val_accuracy: 0.3172\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2301 - accuracy: 0.6725 - val_loss: 11.8121 - val_accuracy: 0.3003\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2256 - accuracy: 0.6759 - val_loss: 11.3344 - val_accuracy: 0.3153\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.3373 - accuracy: 0.6669 - val_loss: 11.7135 - val_accuracy: 0.2468\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2908 - accuracy: 0.6760 - val_loss: 10.1267 - val_accuracy: 0.3038\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2358 - accuracy: 0.6742 - val_loss: 11.0083 - val_accuracy: 0.2980\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2770 - accuracy: 0.6709 - val_loss: 10.3234 - val_accuracy: 0.3078\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2472 - accuracy: 0.6716 - val_loss: 9.8643 - val_accuracy: 0.2736\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2090 - accuracy: 0.6789 - val_loss: 10.3239 - val_accuracy: 0.2815\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2795 - accuracy: 0.6677 - val_loss: 9.4177 - val_accuracy: 0.2799\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.2916 - accuracy: 0.6671 - val_loss: 9.4835 - val_accuracy: 0.2509\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.2814 - accuracy: 0.6681 - val_loss: 9.7168 - val_accuracy: 0.2455\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.2714 - accuracy: 0.6729 - val_loss: 9.6299 - val_accuracy: 0.2680\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2033 - accuracy: 0.6755 - val_loss: 10.0133 - val_accuracy: 0.2717\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2247 - accuracy: 0.6767 - val_loss: 10.7310 - val_accuracy: 0.2230\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2520 - accuracy: 0.6744 - val_loss: 11.2034 - val_accuracy: 0.2305\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3440 - accuracy: 0.6674 - val_loss: 10.3051 - val_accuracy: 0.2605\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2519 - accuracy: 0.6776 - val_loss: 8.9289 - val_accuracy: 0.2971\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2160 - accuracy: 0.6745 - val_loss: 11.3490 - val_accuracy: 0.2160\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2067 - accuracy: 0.6746 - val_loss: 12.0015 - val_accuracy: 0.2519\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1927 - accuracy: 0.6773 - val_loss: 9.8997 - val_accuracy: 0.2565\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.2919 - accuracy: 0.6723 - val_loss: 9.5684 - val_accuracy: 0.2402\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2157 - accuracy: 0.6777 - val_loss: 11.9445 - val_accuracy: 0.1792\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1915 - accuracy: 0.6811 - val_loss: 9.8898 - val_accuracy: 0.2071\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2598 - accuracy: 0.6721 - val_loss: 12.0419 - val_accuracy: 0.2725\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.2692 - accuracy: 0.6731 - val_loss: 11.9532 - val_accuracy: 0.1983\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2111 - accuracy: 0.6747 - val_loss: 10.4323 - val_accuracy: 0.2003\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2107 - accuracy: 0.6735 - val_loss: 10.3202 - val_accuracy: 0.2462\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.2231 - accuracy: 0.6768 - val_loss: 10.4832 - val_accuracy: 0.2390\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1716 - accuracy: 0.6794 - val_loss: 12.0829 - val_accuracy: 0.1643\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2126 - accuracy: 0.6798 - val_loss: 14.2880 - val_accuracy: 0.1625\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2526 - accuracy: 0.6749 - val_loss: 11.9845 - val_accuracy: 0.1587\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2260 - accuracy: 0.6777 - val_loss: 12.7057 - val_accuracy: 0.1629\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1359 - accuracy: 0.6818 - val_loss: 11.7852 - val_accuracy: 0.1597\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2319 - accuracy: 0.6794 - val_loss: 11.2496 - val_accuracy: 0.1555\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2120 - accuracy: 0.6782 - val_loss: 11.6145 - val_accuracy: 0.1608\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2069 - accuracy: 0.6788 - val_loss: 13.1628 - val_accuracy: 0.1633\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2109 - accuracy: 0.6748 - val_loss: 10.4279 - val_accuracy: 0.2008\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2590 - accuracy: 0.6753 - val_loss: 11.2631 - val_accuracy: 0.1841\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2012 - accuracy: 0.6801 - val_loss: 10.9599 - val_accuracy: 0.1598\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.2153 - accuracy: 0.6754 - val_loss: 11.5380 - val_accuracy: 0.1663\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2078 - accuracy: 0.6821 - val_loss: 11.9076 - val_accuracy: 0.1342\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.2356 - accuracy: 0.6715 - val_loss: 9.9532 - val_accuracy: 0.1519\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2329 - accuracy: 0.6743 - val_loss: 10.8980 - val_accuracy: 0.1664\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1657 - accuracy: 0.6795 - val_loss: 11.0531 - val_accuracy: 0.1534\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1673 - accuracy: 0.6782 - val_loss: 10.7681 - val_accuracy: 0.1467\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.1696 - accuracy: 0.6832 - val_loss: 11.6884 - val_accuracy: 0.1407\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.2733 - accuracy: 0.6741 - val_loss: 12.7192 - val_accuracy: 0.1406\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.2190 - accuracy: 0.6754 - val_loss: 12.2236 - val_accuracy: 0.1517\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2342 - accuracy: 0.6795 - val_loss: 12.7767 - val_accuracy: 0.1310\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2314 - accuracy: 0.6782 - val_loss: 11.3093 - val_accuracy: 0.1410\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1921 - accuracy: 0.6727 - val_loss: 11.1055 - val_accuracy: 0.1407\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2101 - accuracy: 0.6765 - val_loss: 11.1241 - val_accuracy: 0.1467\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.1793 - accuracy: 0.6827 - val_loss: 10.2880 - val_accuracy: 0.1560\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2080 - accuracy: 0.6731 - val_loss: 11.2429 - val_accuracy: 0.1410\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.1562 - accuracy: 0.6798 - val_loss: 10.4180 - val_accuracy: 0.1475\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2142 - accuracy: 0.6730 - val_loss: 9.8290 - val_accuracy: 0.1461\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.1882 - accuracy: 0.6830 - val_loss: 12.3862 - val_accuracy: 0.1464\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1637 - accuracy: 0.6825 - val_loss: 11.2204 - val_accuracy: 0.1480\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1645 - accuracy: 0.6787 - val_loss: 13.1357 - val_accuracy: 0.1686\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1600 - accuracy: 0.6768 - val_loss: 10.4962 - val_accuracy: 0.1649\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1742 - accuracy: 0.6794 - val_loss: 11.9947 - val_accuracy: 0.1432\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1259 - accuracy: 0.6807 - val_loss: 10.4274 - val_accuracy: 0.1445\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1751 - accuracy: 0.6820 - val_loss: 12.9726 - val_accuracy: 0.1463\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1336 - accuracy: 0.6878 - val_loss: 11.1855 - val_accuracy: 0.1454\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1175 - accuracy: 0.6877 - val_loss: 10.8154 - val_accuracy: 0.1484\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.1672 - accuracy: 0.6787 - val_loss: 10.7888 - val_accuracy: 0.1705\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1513 - accuracy: 0.6830 - val_loss: 10.8778 - val_accuracy: 0.1610\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.1629 - accuracy: 0.6798 - val_loss: 11.4729 - val_accuracy: 0.1545\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1729 - accuracy: 0.6795 - val_loss: 11.6800 - val_accuracy: 0.1608\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1226 - accuracy: 0.6798 - val_loss: 11.4363 - val_accuracy: 0.1737\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.1321 - accuracy: 0.6840 - val_loss: 10.5130 - val_accuracy: 0.1689\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.1480 - accuracy: 0.6848 - val_loss: 12.2429 - val_accuracy: 0.1632\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.1941 - accuracy: 0.6805 - val_loss: 11.4655 - val_accuracy: 0.1698\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1834 - accuracy: 0.6803 - val_loss: 10.2983 - val_accuracy: 0.1780\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1082 - accuracy: 0.6828 - val_loss: 9.8702 - val_accuracy: 0.1874\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0976 - accuracy: 0.6858 - val_loss: 11.3489 - val_accuracy: 0.1396\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1168 - accuracy: 0.6858 - val_loss: 12.9308 - val_accuracy: 0.1440\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1289 - accuracy: 0.6826 - val_loss: 11.2236 - val_accuracy: 0.1399\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0716 - accuracy: 0.6881 - val_loss: 10.6364 - val_accuracy: 0.1307\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1615 - accuracy: 0.6861 - val_loss: 10.8618 - val_accuracy: 0.1260\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1536 - accuracy: 0.6856 - val_loss: 11.4979 - val_accuracy: 0.1315\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0857 - accuracy: 0.6864 - val_loss: 10.9030 - val_accuracy: 0.1320\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1333 - accuracy: 0.6844 - val_loss: 10.2747 - val_accuracy: 0.1246\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1436 - accuracy: 0.6815 - val_loss: 11.2451 - val_accuracy: 0.1187\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1018 - accuracy: 0.6917 - val_loss: 9.1627 - val_accuracy: 0.1330\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.1564 - accuracy: 0.6831 - val_loss: 13.7718 - val_accuracy: 0.1232\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1776 - accuracy: 0.6798 - val_loss: 10.6556 - val_accuracy: 0.1362\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1482 - accuracy: 0.6820 - val_loss: 12.3354 - val_accuracy: 0.1379\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1018 - accuracy: 0.6853 - val_loss: 11.1770 - val_accuracy: 0.1310\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0755 - accuracy: 0.6871 - val_loss: 12.9248 - val_accuracy: 0.1206\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0982 - accuracy: 0.6900 - val_loss: 12.0785 - val_accuracy: 0.1280\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1692 - accuracy: 0.6831 - val_loss: 11.1981 - val_accuracy: 0.1217\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1894 - accuracy: 0.6859 - val_loss: 12.1184 - val_accuracy: 0.1258\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.1202 - accuracy: 0.6847 - val_loss: 11.8280 - val_accuracy: 0.1190\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1075 - accuracy: 0.6840 - val_loss: 11.7949 - val_accuracy: 0.1244\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1176 - accuracy: 0.6833 - val_loss: 15.0799 - val_accuracy: 0.1322\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0750 - accuracy: 0.6891 - val_loss: 9.8117 - val_accuracy: 0.1425\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0907 - accuracy: 0.6871 - val_loss: 10.7189 - val_accuracy: 0.1234\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0993 - accuracy: 0.6941 - val_loss: 10.9617 - val_accuracy: 0.1268\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1038 - accuracy: 0.6850 - val_loss: 10.5723 - val_accuracy: 0.1206\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 4s 253ms/step - loss: 1.1913 - accuracy: 0.6816 - val_loss: 12.6674 - val_accuracy: 0.1179\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.1041 - accuracy: 0.6846 - val_loss: 16.8912 - val_accuracy: 0.1136\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.0575 - accuracy: 0.6860 - val_loss: 11.7521 - val_accuracy: 0.1111\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0730 - accuracy: 0.6893 - val_loss: 9.8821 - val_accuracy: 0.1156\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0482 - accuracy: 0.6904 - val_loss: 11.7249 - val_accuracy: 0.1137\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1533 - accuracy: 0.6823 - val_loss: 12.0547 - val_accuracy: 0.1122\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1628 - accuracy: 0.6815 - val_loss: 12.2038 - val_accuracy: 0.1080\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1308 - accuracy: 0.6847 - val_loss: 13.3346 - val_accuracy: 0.1136\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1122 - accuracy: 0.6883 - val_loss: 12.2114 - val_accuracy: 0.1093\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0935 - accuracy: 0.6875 - val_loss: 12.5558 - val_accuracy: 0.1095\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1173 - accuracy: 0.6868 - val_loss: 11.3374 - val_accuracy: 0.1147\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0582 - accuracy: 0.6897 - val_loss: 12.4178 - val_accuracy: 0.1156\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0948 - accuracy: 0.6877 - val_loss: 12.0842 - val_accuracy: 0.1129\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1072 - accuracy: 0.6841 - val_loss: 13.5007 - val_accuracy: 0.1101\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1282 - accuracy: 0.6866 - val_loss: 15.8352 - val_accuracy: 0.1098\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0919 - accuracy: 0.6892 - val_loss: 13.2160 - val_accuracy: 0.1129\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.0794 - accuracy: 0.6844 - val_loss: 14.5711 - val_accuracy: 0.1076\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0839 - accuracy: 0.6907 - val_loss: 16.0863 - val_accuracy: 0.1080\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.1014 - accuracy: 0.6871 - val_loss: 13.9488 - val_accuracy: 0.1033\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0588 - accuracy: 0.6941 - val_loss: 14.4294 - val_accuracy: 0.0988\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.0838 - accuracy: 0.6835 - val_loss: 12.3771 - val_accuracy: 0.1112\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.0790 - accuracy: 0.6890 - val_loss: 14.0412 - val_accuracy: 0.1056\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0946 - accuracy: 0.6909 - val_loss: 13.7969 - val_accuracy: 0.1079\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0884 - accuracy: 0.6923 - val_loss: 12.4029 - val_accuracy: 0.1092\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0795 - accuracy: 0.6923 - val_loss: 13.0974 - val_accuracy: 0.1096\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0904 - accuracy: 0.6886 - val_loss: 12.0956 - val_accuracy: 0.1112\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0981 - accuracy: 0.6843 - val_loss: 12.3608 - val_accuracy: 0.1053\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0270 - accuracy: 0.6924 - val_loss: 13.1105 - val_accuracy: 0.1053\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0538 - accuracy: 0.6881 - val_loss: 10.9684 - val_accuracy: 0.1122\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2076 - accuracy: 0.6780 - val_loss: 11.9698 - val_accuracy: 0.1149\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.1676 - accuracy: 0.6848 - val_loss: 17.0727 - val_accuracy: 0.1074\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.1373 - accuracy: 0.6839 - val_loss: 13.2486 - val_accuracy: 0.1128\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0725 - accuracy: 0.6869 - val_loss: 13.1286 - val_accuracy: 0.1135\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0958 - accuracy: 0.6841 - val_loss: 14.8231 - val_accuracy: 0.1152\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0824 - accuracy: 0.6837 - val_loss: 12.3142 - val_accuracy: 0.1135\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.1119 - accuracy: 0.6897 - val_loss: 12.9213 - val_accuracy: 0.1136\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.1020 - accuracy: 0.6883 - val_loss: 13.9474 - val_accuracy: 0.1146\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0565 - accuracy: 0.6899 - val_loss: 13.4740 - val_accuracy: 0.1128\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.0559 - accuracy: 0.6905 - val_loss: 14.2310 - val_accuracy: 0.1110\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0970 - accuracy: 0.6918 - val_loss: 13.4629 - val_accuracy: 0.1120\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0213 - accuracy: 0.6921 - val_loss: 15.5581 - val_accuracy: 0.1069\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1031 - accuracy: 0.6939 - val_loss: 13.4029 - val_accuracy: 0.1083\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1015 - accuracy: 0.6906 - val_loss: 13.8204 - val_accuracy: 0.1101\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0636 - accuracy: 0.6902 - val_loss: 13.6144 - val_accuracy: 0.1103\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0601 - accuracy: 0.6919 - val_loss: 14.8092 - val_accuracy: 0.1064\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0330 - accuracy: 0.6937 - val_loss: 14.3059 - val_accuracy: 0.1149\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0817 - accuracy: 0.6897 - val_loss: 12.7106 - val_accuracy: 0.1096\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0233 - accuracy: 0.6927 - val_loss: 12.9610 - val_accuracy: 0.1095\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0166 - accuracy: 0.6962 - val_loss: 13.1724 - val_accuracy: 0.1084\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0359 - accuracy: 0.6926 - val_loss: 12.5112 - val_accuracy: 0.1092\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0135 - accuracy: 0.6946 - val_loss: 13.1990 - val_accuracy: 0.1080\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0263 - accuracy: 0.6960 - val_loss: 13.2747 - val_accuracy: 0.1107\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9802 - accuracy: 0.6917 - val_loss: 15.9623 - val_accuracy: 0.1084\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0072 - accuracy: 0.6961 - val_loss: 12.8862 - val_accuracy: 0.1109\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0131 - accuracy: 0.6948 - val_loss: 13.3994 - val_accuracy: 0.1097\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0687 - accuracy: 0.6959 - val_loss: 12.2062 - val_accuracy: 0.1087\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0172 - accuracy: 0.6946 - val_loss: 10.9433 - val_accuracy: 0.1136\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9910 - accuracy: 0.6970 - val_loss: 12.3264 - val_accuracy: 0.1095\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0430 - accuracy: 0.6926 - val_loss: 11.6478 - val_accuracy: 0.1113\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0619 - accuracy: 0.6959 - val_loss: 12.9312 - val_accuracy: 0.1113\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0139 - accuracy: 0.6921 - val_loss: 13.5683 - val_accuracy: 0.1126\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9921 - accuracy: 0.6976 - val_loss: 13.2421 - val_accuracy: 0.1105\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9782 - accuracy: 0.6975 - val_loss: 15.0253 - val_accuracy: 0.1046\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0381 - accuracy: 0.6906 - val_loss: 12.4803 - val_accuracy: 0.1099\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1036 - accuracy: 0.6890 - val_loss: 12.3860 - val_accuracy: 0.1108\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0745 - accuracy: 0.6863 - val_loss: 11.4779 - val_accuracy: 0.1148\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.0587 - accuracy: 0.6947 - val_loss: 14.1515 - val_accuracy: 0.1092\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0085 - accuracy: 0.6925 - val_loss: 14.1090 - val_accuracy: 0.1106\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.0731 - accuracy: 0.6893 - val_loss: 12.8378 - val_accuracy: 0.1118\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0178 - accuracy: 0.6937 - val_loss: 13.2306 - val_accuracy: 0.1071\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9492 - accuracy: 0.7010 - val_loss: 12.8148 - val_accuracy: 0.1058\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9589 - accuracy: 0.6974 - val_loss: 13.6200 - val_accuracy: 0.1057\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9808 - accuracy: 0.6980 - val_loss: 15.0051 - val_accuracy: 0.1056\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0247 - accuracy: 0.6929 - val_loss: 14.4123 - val_accuracy: 0.1046\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0196 - accuracy: 0.6933 - val_loss: 12.5748 - val_accuracy: 0.1041\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9781 - accuracy: 0.6961 - val_loss: 15.2250 - val_accuracy: 0.1087\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0017 - accuracy: 0.6931 - val_loss: 12.8101 - val_accuracy: 0.1107\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0080 - accuracy: 0.6915 - val_loss: 12.6302 - val_accuracy: 0.1079\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9693 - accuracy: 0.6966 - val_loss: 15.4374 - val_accuracy: 0.1073\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9734 - accuracy: 0.6983 - val_loss: 13.2201 - val_accuracy: 0.1086\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0965 - accuracy: 0.6888 - val_loss: 13.8278 - val_accuracy: 0.1085\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0482 - accuracy: 0.6919 - val_loss: 13.1438 - val_accuracy: 0.1089\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0008 - accuracy: 0.6960 - val_loss: 12.5758 - val_accuracy: 0.1097\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0533 - accuracy: 0.6972 - val_loss: 12.2856 - val_accuracy: 0.1083\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 1.0519 - accuracy: 0.6898 - val_loss: 14.5429 - val_accuracy: 0.1120\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0001 - accuracy: 0.6934 - val_loss: 14.2453 - val_accuracy: 0.1105\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9392 - accuracy: 0.7031 - val_loss: 14.4656 - val_accuracy: 0.1089\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9553 - accuracy: 0.7041 - val_loss: 14.1285 - val_accuracy: 0.1086\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.0481 - accuracy: 0.6904 - val_loss: 12.6003 - val_accuracy: 0.1090\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0016 - accuracy: 0.6970 - val_loss: 13.7488 - val_accuracy: 0.1061\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9831 - accuracy: 0.6934 - val_loss: 14.4027 - val_accuracy: 0.1068\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0151 - accuracy: 0.6906 - val_loss: 12.2331 - val_accuracy: 0.1055\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9646 - accuracy: 0.7009 - val_loss: 14.8010 - val_accuracy: 0.1007\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0120 - accuracy: 0.6999 - val_loss: 11.6367 - val_accuracy: 0.1064\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9948 - accuracy: 0.6998 - val_loss: 12.9897 - val_accuracy: 0.1057\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9726 - accuracy: 0.6988 - val_loss: 13.6865 - val_accuracy: 0.1036\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9797 - accuracy: 0.6966 - val_loss: 12.3538 - val_accuracy: 0.1064\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0374 - accuracy: 0.6951 - val_loss: 14.1742 - val_accuracy: 0.1072\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9735 - accuracy: 0.6984 - val_loss: 11.9903 - val_accuracy: 0.1045\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9736 - accuracy: 0.6986 - val_loss: 11.3123 - val_accuracy: 0.1100\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9870 - accuracy: 0.6976 - val_loss: 14.1066 - val_accuracy: 0.1077\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0045 - accuracy: 0.6980 - val_loss: 12.8409 - val_accuracy: 0.1052\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.0256 - accuracy: 0.6994 - val_loss: 14.5655 - val_accuracy: 0.1052\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.9726 - accuracy: 0.6976 - val_loss: 12.1596 - val_accuracy: 0.1036\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9548 - accuracy: 0.7012 - val_loss: 17.0589 - val_accuracy: 0.1039\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9323 - accuracy: 0.6997 - val_loss: 12.1030 - val_accuracy: 0.1065\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0539 - accuracy: 0.6938 - val_loss: 11.6639 - val_accuracy: 0.1053\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0182 - accuracy: 0.6972 - val_loss: 14.0286 - val_accuracy: 0.1063\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9642 - accuracy: 0.6981 - val_loss: 11.9018 - val_accuracy: 0.1043\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0032 - accuracy: 0.6982 - val_loss: 12.3319 - val_accuracy: 0.1094\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0304 - accuracy: 0.6969 - val_loss: 12.6728 - val_accuracy: 0.1016\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9612 - accuracy: 0.6954 - val_loss: 12.6972 - val_accuracy: 0.1037\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9190 - accuracy: 0.7033 - val_loss: 13.4975 - val_accuracy: 0.1075\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9742 - accuracy: 0.6995 - val_loss: 11.3944 - val_accuracy: 0.1094\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9912 - accuracy: 0.6959 - val_loss: 10.9709 - val_accuracy: 0.1042\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 1.0148 - accuracy: 0.6990 - val_loss: 12.5246 - val_accuracy: 0.1042\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9864 - accuracy: 0.6937 - val_loss: 11.9221 - val_accuracy: 0.1046\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9619 - accuracy: 0.6999 - val_loss: 12.1030 - val_accuracy: 0.1005\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9744 - accuracy: 0.7012 - val_loss: 12.0573 - val_accuracy: 0.1038\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9373 - accuracy: 0.7009 - val_loss: 12.6545 - val_accuracy: 0.1052\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9418 - accuracy: 0.7015 - val_loss: 11.6482 - val_accuracy: 0.1052\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0288 - accuracy: 0.6985 - val_loss: 12.4356 - val_accuracy: 0.1027\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0050 - accuracy: 0.6972 - val_loss: 13.5230 - val_accuracy: 0.1064\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9576 - accuracy: 0.6940 - val_loss: 12.0023 - val_accuracy: 0.1051\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9487 - accuracy: 0.7055 - val_loss: 13.6359 - val_accuracy: 0.1035\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9259 - accuracy: 0.7070 - val_loss: 11.4885 - val_accuracy: 0.1052\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9746 - accuracy: 0.7001 - val_loss: 13.1229 - val_accuracy: 0.1007\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9771 - accuracy: 0.6993 - val_loss: 11.9173 - val_accuracy: 0.1035\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9810 - accuracy: 0.6973 - val_loss: 13.7784 - val_accuracy: 0.1054\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9701 - accuracy: 0.6990 - val_loss: 14.9661 - val_accuracy: 0.1060\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9502 - accuracy: 0.7005 - val_loss: 13.2116 - val_accuracy: 0.1050\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9376 - accuracy: 0.6983 - val_loss: 13.5685 - val_accuracy: 0.1061\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9629 - accuracy: 0.7036 - val_loss: 11.8934 - val_accuracy: 0.1093\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9775 - accuracy: 0.7025 - val_loss: 13.4022 - val_accuracy: 0.1041\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9638 - accuracy: 0.7069 - val_loss: 13.1113 - val_accuracy: 0.1048\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.9833 - accuracy: 0.7002 - val_loss: 11.8508 - val_accuracy: 0.1048\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9873 - accuracy: 0.6978 - val_loss: 12.8805 - val_accuracy: 0.1044\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9098 - accuracy: 0.7005 - val_loss: 12.0018 - val_accuracy: 0.1078\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8834 - accuracy: 0.7029 - val_loss: 12.1895 - val_accuracy: 0.1063\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8633 - accuracy: 0.7080 - val_loss: 12.1994 - val_accuracy: 0.1037\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8968 - accuracy: 0.7056 - val_loss: 13.4222 - val_accuracy: 0.1046\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9289 - accuracy: 0.7029 - val_loss: 13.8402 - val_accuracy: 0.1065\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0325 - accuracy: 0.6999 - val_loss: 12.4297 - val_accuracy: 0.1023\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0179 - accuracy: 0.6983 - val_loss: 12.0033 - val_accuracy: 0.1043\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.9344 - accuracy: 0.7033 - val_loss: 14.7255 - val_accuracy: 0.1052\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9439 - accuracy: 0.7038 - val_loss: 12.7588 - val_accuracy: 0.1046\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9185 - accuracy: 0.7038 - val_loss: 11.9289 - val_accuracy: 0.1042\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9110 - accuracy: 0.7017 - val_loss: 13.0895 - val_accuracy: 0.1059\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8841 - accuracy: 0.7042 - val_loss: 12.9384 - val_accuracy: 0.1031\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.9081 - accuracy: 0.7035 - val_loss: 13.5797 - val_accuracy: 0.1049\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 0.9000 - accuracy: 0.7026 - val_loss: 11.5615 - val_accuracy: 0.1059\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.9115 - accuracy: 0.7048 - val_loss: 13.5620 - val_accuracy: 0.1045\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9240 - accuracy: 0.7002 - val_loss: 12.1272 - val_accuracy: 0.1053\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9021 - accuracy: 0.7039 - val_loss: 12.2225 - val_accuracy: 0.1046\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9096 - accuracy: 0.7069 - val_loss: 11.8984 - val_accuracy: 0.1077\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9046 - accuracy: 0.7047 - val_loss: 11.9764 - val_accuracy: 0.1034\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9800 - accuracy: 0.7005 - val_loss: 11.8794 - val_accuracy: 0.1041\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.8999 - accuracy: 0.7029 - val_loss: 10.9258 - val_accuracy: 0.1043\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9496 - accuracy: 0.7079 - val_loss: 11.3338 - val_accuracy: 0.1060\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9388 - accuracy: 0.7019 - val_loss: 11.6855 - val_accuracy: 0.1081\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8750 - accuracy: 0.7081 - val_loss: 12.4506 - val_accuracy: 0.1040\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9214 - accuracy: 0.7051 - val_loss: 11.5495 - val_accuracy: 0.1071\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8655 - accuracy: 0.7053 - val_loss: 13.2058 - val_accuracy: 0.1055\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8692 - accuracy: 0.7057 - val_loss: 11.5682 - val_accuracy: 0.1050\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9056 - accuracy: 0.7067 - val_loss: 13.9014 - val_accuracy: 0.1057\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9285 - accuracy: 0.7056 - val_loss: 13.0365 - val_accuracy: 0.1064\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9531 - accuracy: 0.7016 - val_loss: 12.7087 - val_accuracy: 0.1043\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9558 - accuracy: 0.7045 - val_loss: 11.9908 - val_accuracy: 0.1076\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9855 - accuracy: 0.7045 - val_loss: 12.6427 - val_accuracy: 0.1030\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9031 - accuracy: 0.7043 - val_loss: 11.9438 - val_accuracy: 0.1049\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8590 - accuracy: 0.7106 - val_loss: 12.9568 - val_accuracy: 0.1047\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9680 - accuracy: 0.7072 - val_loss: 12.4704 - val_accuracy: 0.1075\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9694 - accuracy: 0.6975 - val_loss: 11.3601 - val_accuracy: 0.1040\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8793 - accuracy: 0.7072 - val_loss: 11.8020 - val_accuracy: 0.1048\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8991 - accuracy: 0.7063 - val_loss: 11.3884 - val_accuracy: 0.1086\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8822 - accuracy: 0.7080 - val_loss: 12.8413 - val_accuracy: 0.1064\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8189 - accuracy: 0.7113 - val_loss: 13.6587 - val_accuracy: 0.1043\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8530 - accuracy: 0.7079 - val_loss: 12.2260 - val_accuracy: 0.1050\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9111 - accuracy: 0.7013 - val_loss: 13.6795 - val_accuracy: 0.1074\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8622 - accuracy: 0.7080 - val_loss: 11.9791 - val_accuracy: 0.1046\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9158 - accuracy: 0.7071 - val_loss: 12.5775 - val_accuracy: 0.1039\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9528 - accuracy: 0.7013 - val_loss: 11.8646 - val_accuracy: 0.1048\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9083 - accuracy: 0.7060 - val_loss: 12.4094 - val_accuracy: 0.1024\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9391 - accuracy: 0.7042 - val_loss: 12.9538 - val_accuracy: 0.1036\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.9215 - accuracy: 0.7036 - val_loss: 12.3228 - val_accuracy: 0.1045\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9431 - accuracy: 0.7059 - val_loss: 11.0616 - val_accuracy: 0.1069\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9429 - accuracy: 0.7027 - val_loss: 12.9194 - val_accuracy: 0.1061\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9738 - accuracy: 0.7000 - val_loss: 11.6054 - val_accuracy: 0.1044\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9816 - accuracy: 0.7022 - val_loss: 12.6050 - val_accuracy: 0.1074\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9300 - accuracy: 0.7053 - val_loss: 13.4911 - val_accuracy: 0.1069\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9173 - accuracy: 0.7024 - val_loss: 11.8955 - val_accuracy: 0.1076\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9449 - accuracy: 0.7057 - val_loss: 13.8070 - val_accuracy: 0.1036\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8963 - accuracy: 0.7126 - val_loss: 13.3317 - val_accuracy: 0.1036\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9046 - accuracy: 0.7133 - val_loss: 11.8985 - val_accuracy: 0.1086\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.9275 - accuracy: 0.7043 - val_loss: 13.7074 - val_accuracy: 0.1055\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8987 - accuracy: 0.7037 - val_loss: 13.8005 - val_accuracy: 0.1060\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8725 - accuracy: 0.7058 - val_loss: 11.9850 - val_accuracy: 0.1061\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8799 - accuracy: 0.7106 - val_loss: 12.3575 - val_accuracy: 0.1008\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8886 - accuracy: 0.7087 - val_loss: 13.5763 - val_accuracy: 0.1029\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8621 - accuracy: 0.7094 - val_loss: 14.2565 - val_accuracy: 0.1047\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8781 - accuracy: 0.7092 - val_loss: 14.1246 - val_accuracy: 0.1016\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8491 - accuracy: 0.7040 - val_loss: 11.6144 - val_accuracy: 0.1008\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8022 - accuracy: 0.7098 - val_loss: 13.0779 - val_accuracy: 0.1055\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8252 - accuracy: 0.7108 - val_loss: 12.2281 - val_accuracy: 0.1034\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8689 - accuracy: 0.7065 - val_loss: 10.8007 - val_accuracy: 0.1040\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8719 - accuracy: 0.7100 - val_loss: 12.2813 - val_accuracy: 0.1059\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8507 - accuracy: 0.7116 - val_loss: 12.0300 - val_accuracy: 0.1054\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8318 - accuracy: 0.7093 - val_loss: 15.0000 - val_accuracy: 0.1046\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8170 - accuracy: 0.7075 - val_loss: 13.7227 - val_accuracy: 0.1015\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7946 - accuracy: 0.7129 - val_loss: 12.5613 - val_accuracy: 0.1070\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8434 - accuracy: 0.7067 - val_loss: 13.9228 - val_accuracy: 0.1048\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8986 - accuracy: 0.7076 - val_loss: 12.0745 - val_accuracy: 0.1041\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8916 - accuracy: 0.7092 - val_loss: 12.2549 - val_accuracy: 0.1033\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8023 - accuracy: 0.7119 - val_loss: 13.7234 - val_accuracy: 0.1038\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8269 - accuracy: 0.7167 - val_loss: 11.2834 - val_accuracy: 0.1035\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8861 - accuracy: 0.7119 - val_loss: 14.0488 - val_accuracy: 0.1026\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8826 - accuracy: 0.7050 - val_loss: 13.0548 - val_accuracy: 0.1027\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8615 - accuracy: 0.7078 - val_loss: 14.0972 - val_accuracy: 0.1025\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9213 - accuracy: 0.7086 - val_loss: 12.3151 - val_accuracy: 0.1030\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.9642 - accuracy: 0.7018 - val_loss: 13.1624 - val_accuracy: 0.1027\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9328 - accuracy: 0.7065 - val_loss: 13.3706 - val_accuracy: 0.1026\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8021 - accuracy: 0.7146 - val_loss: 12.1532 - val_accuracy: 0.1032\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8057 - accuracy: 0.7159 - val_loss: 11.5805 - val_accuracy: 0.1058\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8346 - accuracy: 0.7174 - val_loss: 12.0005 - val_accuracy: 0.1032\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8210 - accuracy: 0.7110 - val_loss: 12.8397 - val_accuracy: 0.0998\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7991 - accuracy: 0.7150 - val_loss: 12.6531 - val_accuracy: 0.1024\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8694 - accuracy: 0.7093 - val_loss: 11.2183 - val_accuracy: 0.1017\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8351 - accuracy: 0.7154 - val_loss: 12.9277 - val_accuracy: 0.1008\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8722 - accuracy: 0.7061 - val_loss: 14.0188 - val_accuracy: 0.1029\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8393 - accuracy: 0.7136 - val_loss: 12.0229 - val_accuracy: 0.1023\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8264 - accuracy: 0.7115 - val_loss: 11.7258 - val_accuracy: 0.1043\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8732 - accuracy: 0.7128 - val_loss: 11.6450 - val_accuracy: 0.1016\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.9324 - accuracy: 0.7075 - val_loss: 12.0614 - val_accuracy: 0.1046\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.8941 - accuracy: 0.7061 - val_loss: 11.2327 - val_accuracy: 0.1053\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 0.8823 - accuracy: 0.7074 - val_loss: 11.8915 - val_accuracy: 0.1046\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9495 - accuracy: 0.7085 - val_loss: 13.1256 - val_accuracy: 0.1021\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0042 - accuracy: 0.7030 - val_loss: 11.5817 - val_accuracy: 0.1022\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9442 - accuracy: 0.7059 - val_loss: 12.4446 - val_accuracy: 0.1012\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8154 - accuracy: 0.7104 - val_loss: 12.9933 - val_accuracy: 0.1019\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8567 - accuracy: 0.7125 - val_loss: 14.1679 - val_accuracy: 0.0981\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8275 - accuracy: 0.7138 - val_loss: 11.4282 - val_accuracy: 0.1033\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8680 - accuracy: 0.7083 - val_loss: 12.9376 - val_accuracy: 0.1046\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8533 - accuracy: 0.7127 - val_loss: 12.0266 - val_accuracy: 0.1017\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8507 - accuracy: 0.7072 - val_loss: 12.5226 - val_accuracy: 0.0982\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7626 - accuracy: 0.7186 - val_loss: 12.7659 - val_accuracy: 0.1007\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8098 - accuracy: 0.7128 - val_loss: 12.5840 - val_accuracy: 0.1038\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8475 - accuracy: 0.7139 - val_loss: 13.6701 - val_accuracy: 0.1003\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8024 - accuracy: 0.7067 - val_loss: 12.8228 - val_accuracy: 0.0998\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8505 - accuracy: 0.7125 - val_loss: 12.7437 - val_accuracy: 0.1019\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8987 - accuracy: 0.7096 - val_loss: 12.2137 - val_accuracy: 0.1015\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8138 - accuracy: 0.7130 - val_loss: 13.4727 - val_accuracy: 0.1007\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7749 - accuracy: 0.7146 - val_loss: 13.0375 - val_accuracy: 0.0998\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7886 - accuracy: 0.7152 - val_loss: 13.5170 - val_accuracy: 0.1000\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7810 - accuracy: 0.7219 - val_loss: 12.2461 - val_accuracy: 0.1025\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8078 - accuracy: 0.7104 - val_loss: 12.5708 - val_accuracy: 0.1014\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8720 - accuracy: 0.7141 - val_loss: 11.9150 - val_accuracy: 0.1007\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8489 - accuracy: 0.7154 - val_loss: 11.2242 - val_accuracy: 0.1053\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8281 - accuracy: 0.7107 - val_loss: 13.4857 - val_accuracy: 0.1074\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.8402 - accuracy: 0.7180 - val_loss: 12.3313 - val_accuracy: 0.1017\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9636 - accuracy: 0.7066 - val_loss: 11.0878 - val_accuracy: 0.1039\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8877 - accuracy: 0.7120 - val_loss: 11.5136 - val_accuracy: 0.1027\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 4s 246ms/step - loss: 0.9449 - accuracy: 0.7087 - val_loss: 11.5576 - val_accuracy: 0.1030\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9050 - accuracy: 0.7064 - val_loss: 12.3878 - val_accuracy: 0.1007\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.8441 - accuracy: 0.7116 - val_loss: 13.7229 - val_accuracy: 0.1054\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7968 - accuracy: 0.7139 - val_loss: 12.3026 - val_accuracy: 0.1045\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.7646 - accuracy: 0.7226 - val_loss: 12.8631 - val_accuracy: 0.1037\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8248 - accuracy: 0.7162 - val_loss: 12.8021 - val_accuracy: 0.1022\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8660 - accuracy: 0.7089 - val_loss: 11.7630 - val_accuracy: 0.1020\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8597 - accuracy: 0.7072 - val_loss: 13.6551 - val_accuracy: 0.0999\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8186 - accuracy: 0.7100 - val_loss: 14.3149 - val_accuracy: 0.1015\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0087 - accuracy: 0.7063 - val_loss: 13.2653 - val_accuracy: 0.1044\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9480 - accuracy: 0.7060 - val_loss: 12.9800 - val_accuracy: 0.1042\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8034 - accuracy: 0.7155 - val_loss: 14.3032 - val_accuracy: 0.1038\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8231 - accuracy: 0.7143 - val_loss: 12.8374 - val_accuracy: 0.1031\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8894 - accuracy: 0.7109 - val_loss: 13.3510 - val_accuracy: 0.1051\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8630 - accuracy: 0.7114 - val_loss: 11.7836 - val_accuracy: 0.1053\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.7990 - accuracy: 0.7204 - val_loss: 11.7847 - val_accuracy: 0.1063\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8419 - accuracy: 0.7154 - val_loss: 12.0819 - val_accuracy: 0.1029\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8165 - accuracy: 0.7167 - val_loss: 13.1159 - val_accuracy: 0.1050\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7892 - accuracy: 0.7140 - val_loss: 12.7493 - val_accuracy: 0.1020\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8274 - accuracy: 0.7177 - val_loss: 12.0274 - val_accuracy: 0.1004\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8602 - accuracy: 0.7100 - val_loss: 10.9835 - val_accuracy: 0.1047\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7802 - accuracy: 0.7174 - val_loss: 12.1068 - val_accuracy: 0.0997\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8307 - accuracy: 0.7159 - val_loss: 11.1121 - val_accuracy: 0.1010\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8209 - accuracy: 0.7159 - val_loss: 12.0241 - val_accuracy: 0.1064\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.7915 - accuracy: 0.7149 - val_loss: 13.2134 - val_accuracy: 0.1039\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7971 - accuracy: 0.7164 - val_loss: 11.9112 - val_accuracy: 0.1047\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7354 - accuracy: 0.7194 - val_loss: 13.2731 - val_accuracy: 0.1040\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7765 - accuracy: 0.7130 - val_loss: 13.3848 - val_accuracy: 0.1034\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8528 - accuracy: 0.7104 - val_loss: 13.5092 - val_accuracy: 0.1001\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7936 - accuracy: 0.7159 - val_loss: 10.8142 - val_accuracy: 0.1040\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 279ms/step - loss: 2.4557 - accuracy: 0.6121 - val_loss: 0.5018 - val_accuracy: 0.8143\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.2193 - accuracy: 0.6121 - val_loss: 0.5354 - val_accuracy: 0.8175\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0677 - accuracy: 0.6184 - val_loss: 0.5520 - val_accuracy: 0.8147\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.0084 - accuracy: 0.6178 - val_loss: 0.6448 - val_accuracy: 0.6751\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.9203 - accuracy: 0.6258 - val_loss: 0.5383 - val_accuracy: 0.7153\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.8742 - accuracy: 0.6256 - val_loss: 0.5713 - val_accuracy: 0.6870\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8261 - accuracy: 0.6251 - val_loss: 0.5195 - val_accuracy: 0.6537\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7755 - accuracy: 0.6272 - val_loss: 0.6287 - val_accuracy: 0.5283\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.7504 - accuracy: 0.6323 - val_loss: 0.4943 - val_accuracy: 0.5643\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.7526 - accuracy: 0.6309 - val_loss: 0.6205 - val_accuracy: 0.5317\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7366 - accuracy: 0.6275 - val_loss: 0.5901 - val_accuracy: 0.5187\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.7267 - accuracy: 0.6324 - val_loss: 0.6491 - val_accuracy: 0.5081\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.6888 - accuracy: 0.6287 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.7692 - accuracy: 0.6259 - val_loss: 0.9355 - val_accuracy: 0.4865\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6571 - accuracy: 0.6407 - val_loss: 0.8937 - val_accuracy: 0.5298\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.7027 - accuracy: 0.6306 - val_loss: 0.8659 - val_accuracy: 0.5223\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.7053 - accuracy: 0.6311 - val_loss: 0.8169 - val_accuracy: 0.4999\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.6633 - accuracy: 0.6351 - val_loss: 1.0474 - val_accuracy: 0.4775\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6379 - accuracy: 0.6347 - val_loss: 1.3191 - val_accuracy: 0.4632\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.6602 - accuracy: 0.6305 - val_loss: 1.3711 - val_accuracy: 0.4277\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.6034 - accuracy: 0.6332 - val_loss: 1.4182 - val_accuracy: 0.3716\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.5867 - accuracy: 0.6396 - val_loss: 4.5992 - val_accuracy: 0.2945\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6067 - accuracy: 0.6422 - val_loss: 2.6968 - val_accuracy: 0.3962\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.5882 - accuracy: 0.6396 - val_loss: 3.4314 - val_accuracy: 0.3428\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.5527 - accuracy: 0.6433 - val_loss: 11.5315 - val_accuracy: 0.2806\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.6083 - accuracy: 0.6330 - val_loss: 20.9731 - val_accuracy: 0.2536\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.6315 - accuracy: 0.6349 - val_loss: 196.3050 - val_accuracy: 0.2218\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.5620 - accuracy: 0.6397 - val_loss: 116.5178 - val_accuracy: 0.2284\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.6173 - accuracy: 0.6288 - val_loss: 275.0684 - val_accuracy: 0.2163\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5789 - accuracy: 0.6396 - val_loss: 162.6279 - val_accuracy: 0.2517\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5637 - accuracy: 0.6407 - val_loss: 16.8908 - val_accuracy: 0.2450\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5143 - accuracy: 0.6417 - val_loss: 7.6948 - val_accuracy: 0.2771\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5253 - accuracy: 0.6444 - val_loss: 13.6559 - val_accuracy: 0.2471\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.5405 - accuracy: 0.6393 - val_loss: 22.3032 - val_accuracy: 0.2348\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5366 - accuracy: 0.6409 - val_loss: 70.6125 - val_accuracy: 0.2744\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5247 - accuracy: 0.6410 - val_loss: 56.9582 - val_accuracy: 0.5101\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5105 - accuracy: 0.6452 - val_loss: 46.6689 - val_accuracy: 0.2562\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.5175 - accuracy: 0.6350 - val_loss: 29.6535 - val_accuracy: 0.2596\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5131 - accuracy: 0.6417 - val_loss: 72.9033 - val_accuracy: 0.3057\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.5581 - accuracy: 0.6427 - val_loss: 78.2975 - val_accuracy: 0.2376\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4910 - accuracy: 0.6394 - val_loss: 126.0349 - val_accuracy: 0.2525\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5499 - accuracy: 0.6407 - val_loss: 18.8169 - val_accuracy: 0.3115\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4676 - accuracy: 0.6448 - val_loss: 165.3836 - val_accuracy: 0.3167\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4632 - accuracy: 0.6445 - val_loss: 62.5530 - val_accuracy: 0.3082\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4876 - accuracy: 0.6397 - val_loss: 72.3789 - val_accuracy: 0.2463\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4501 - accuracy: 0.6449 - val_loss: 430.1825 - val_accuracy: 0.3012\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4721 - accuracy: 0.6432 - val_loss: 1277.1039 - val_accuracy: 0.3108\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4346 - accuracy: 0.6478 - val_loss: 105.5225 - val_accuracy: 0.2981\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.4058 - accuracy: 0.6481 - val_loss: 25.1878 - val_accuracy: 0.2966\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3969 - accuracy: 0.6548 - val_loss: 159.2748 - val_accuracy: 0.2850\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4414 - accuracy: 0.6519 - val_loss: 26.9677 - val_accuracy: 0.2905\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4390 - accuracy: 0.6491 - val_loss: 29.1003 - val_accuracy: 0.2681\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.4170 - accuracy: 0.6505 - val_loss: 1545.1632 - val_accuracy: 0.2428\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4194 - accuracy: 0.6478 - val_loss: 3470.0139 - val_accuracy: 0.2422\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4061 - accuracy: 0.6503 - val_loss: 4047.6038 - val_accuracy: 0.2553\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4106 - accuracy: 0.6520 - val_loss: 2824.4448 - val_accuracy: 0.2609\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4049 - accuracy: 0.6536 - val_loss: 1504.6992 - val_accuracy: 0.2652\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3835 - accuracy: 0.6528 - val_loss: 3303.5505 - val_accuracy: 0.2732\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4023 - accuracy: 0.6514 - val_loss: 561.5343 - val_accuracy: 0.3018\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4424 - accuracy: 0.6538 - val_loss: 6262.3003 - val_accuracy: 0.2584\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3700 - accuracy: 0.6602 - val_loss: 4979.0835 - val_accuracy: 0.2541\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4471 - accuracy: 0.6487 - val_loss: 1204.0529 - val_accuracy: 0.2606\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4105 - accuracy: 0.6532 - val_loss: 54.8789 - val_accuracy: 0.2970\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3335 - accuracy: 0.6625 - val_loss: 355.8527 - val_accuracy: 0.3180\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3326 - accuracy: 0.6631 - val_loss: 2521.5737 - val_accuracy: 0.2802\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3135 - accuracy: 0.6612 - val_loss: 3451.6021 - val_accuracy: 0.2947\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3439 - accuracy: 0.6544 - val_loss: 1641.9119 - val_accuracy: 0.3087\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3896 - accuracy: 0.6545 - val_loss: 1063.6967 - val_accuracy: 0.2847\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3405 - accuracy: 0.6599 - val_loss: 1889.5208 - val_accuracy: 0.2813\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3814 - accuracy: 0.6619 - val_loss: 1195.0848 - val_accuracy: 0.2966\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3757 - accuracy: 0.6504 - val_loss: 1126.1533 - val_accuracy: 0.3259\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3324 - accuracy: 0.6643 - val_loss: 3911.0325 - val_accuracy: 0.3225\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3339 - accuracy: 0.6572 - val_loss: 426.7691 - val_accuracy: 0.3237\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3203 - accuracy: 0.6634 - val_loss: 175.0635 - val_accuracy: 0.3278\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3341 - accuracy: 0.6607 - val_loss: 10380.0137 - val_accuracy: 0.3225\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3309 - accuracy: 0.6642 - val_loss: 253.9808 - val_accuracy: 0.3153\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3219 - accuracy: 0.6648 - val_loss: 162.4840 - val_accuracy: 0.3040\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.2961 - accuracy: 0.6689 - val_loss: 1607.2059 - val_accuracy: 0.3025\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3014 - accuracy: 0.6680 - val_loss: 122.7831 - val_accuracy: 0.3017\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3054 - accuracy: 0.6646 - val_loss: 132.2783 - val_accuracy: 0.3303\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2806 - accuracy: 0.6682 - val_loss: 121.0814 - val_accuracy: 0.3219\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3457 - accuracy: 0.6603 - val_loss: 46.5403 - val_accuracy: 0.3481\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3045 - accuracy: 0.6714 - val_loss: 39.6250 - val_accuracy: 0.3585\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3359 - accuracy: 0.6678 - val_loss: 125.6133 - val_accuracy: 0.3480\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.3180 - accuracy: 0.6661 - val_loss: 34.8655 - val_accuracy: 0.3781\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3313 - accuracy: 0.6589 - val_loss: 27.1544 - val_accuracy: 0.4318\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3022 - accuracy: 0.6597 - val_loss: 46.0828 - val_accuracy: 0.3318\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3185 - accuracy: 0.6629 - val_loss: 111.9864 - val_accuracy: 0.3437\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3143 - accuracy: 0.6610 - val_loss: 58.6220 - val_accuracy: 0.3555\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2715 - accuracy: 0.6708 - val_loss: 8.8848 - val_accuracy: 0.4109\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2962 - accuracy: 0.6688 - val_loss: 27.0985 - val_accuracy: 0.3432\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3158 - accuracy: 0.6643 - val_loss: 55.0595 - val_accuracy: 0.3214\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2839 - accuracy: 0.6639 - val_loss: 17.3968 - val_accuracy: 0.3471\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2710 - accuracy: 0.6735 - val_loss: 12.7710 - val_accuracy: 0.3690\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.2428 - accuracy: 0.6739 - val_loss: 17.9189 - val_accuracy: 0.3253\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2663 - accuracy: 0.6730 - val_loss: 55.3743 - val_accuracy: 0.3088\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.2926 - accuracy: 0.6616 - val_loss: 156.1533 - val_accuracy: 0.3719\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2981 - accuracy: 0.6686 - val_loss: 8.0142 - val_accuracy: 0.3773\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2919 - accuracy: 0.6698 - val_loss: 140.6422 - val_accuracy: 0.3473\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3262 - accuracy: 0.6730 - val_loss: 23.0067 - val_accuracy: 0.3231\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3075 - accuracy: 0.6662 - val_loss: 11.6652 - val_accuracy: 0.3587\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2511 - accuracy: 0.6739 - val_loss: 17.3447 - val_accuracy: 0.3228\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.2674 - accuracy: 0.6730 - val_loss: 30.6236 - val_accuracy: 0.3226\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2993 - accuracy: 0.6756 - val_loss: 31.5538 - val_accuracy: 0.3543\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2397 - accuracy: 0.6729 - val_loss: 40.3114 - val_accuracy: 0.3694\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.2441 - accuracy: 0.6771 - val_loss: 15.9535 - val_accuracy: 0.3759\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2297 - accuracy: 0.6826 - val_loss: 14.8178 - val_accuracy: 0.3273\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2189 - accuracy: 0.6750 - val_loss: 28.7546 - val_accuracy: 0.3317\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.2278 - accuracy: 0.6749 - val_loss: 13.4012 - val_accuracy: 0.3300\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.2436 - accuracy: 0.6709 - val_loss: 25.4029 - val_accuracy: 0.3278\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.1916 - accuracy: 0.6780 - val_loss: 10.1390 - val_accuracy: 0.3334\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.2206 - accuracy: 0.6787 - val_loss: 16.2042 - val_accuracy: 0.3610\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.2195 - accuracy: 0.6789 - val_loss: 27.1365 - val_accuracy: 0.3702\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.2023 - accuracy: 0.6778 - val_loss: 14.6590 - val_accuracy: 0.3357\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1976 - accuracy: 0.6747 - val_loss: 32.2528 - val_accuracy: 0.3265\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1508 - accuracy: 0.6788 - val_loss: 18.7153 - val_accuracy: 0.3206\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.2218 - accuracy: 0.6799 - val_loss: 9.3133 - val_accuracy: 0.3417\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.2089 - accuracy: 0.6775 - val_loss: 11.6043 - val_accuracy: 0.3027\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1984 - accuracy: 0.6795 - val_loss: 16.6590 - val_accuracy: 0.3020\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1634 - accuracy: 0.6799 - val_loss: 19.9053 - val_accuracy: 0.2927\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1946 - accuracy: 0.6828 - val_loss: 27.4728 - val_accuracy: 0.3502\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2121 - accuracy: 0.6788 - val_loss: 30.8837 - val_accuracy: 0.3915\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1951 - accuracy: 0.6806 - val_loss: 28.5698 - val_accuracy: 0.3276\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1268 - accuracy: 0.6843 - val_loss: 21.8026 - val_accuracy: 0.3678\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1766 - accuracy: 0.6827 - val_loss: 20.1203 - val_accuracy: 0.3685\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1952 - accuracy: 0.6782 - val_loss: 22.7482 - val_accuracy: 0.2816\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1463 - accuracy: 0.6859 - val_loss: 25.9366 - val_accuracy: 0.2908\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1640 - accuracy: 0.6827 - val_loss: 14.2668 - val_accuracy: 0.2998\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.1791 - accuracy: 0.6802 - val_loss: 46.8702 - val_accuracy: 0.2998\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1663 - accuracy: 0.6778 - val_loss: 20.2876 - val_accuracy: 0.3045\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1755 - accuracy: 0.6766 - val_loss: 40.4954 - val_accuracy: 0.3045\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.1672 - accuracy: 0.6844 - val_loss: 23.1034 - val_accuracy: 0.2886\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1621 - accuracy: 0.6841 - val_loss: 43.9052 - val_accuracy: 0.2932\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.1429 - accuracy: 0.6861 - val_loss: 97.6001 - val_accuracy: 0.2856\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1550 - accuracy: 0.6862 - val_loss: 55.4516 - val_accuracy: 0.2867\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1666 - accuracy: 0.6848 - val_loss: 53.2712 - val_accuracy: 0.3386\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1527 - accuracy: 0.6876 - val_loss: 68.4054 - val_accuracy: 0.2689\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.2050 - accuracy: 0.6794 - val_loss: 85.3251 - val_accuracy: 0.2786\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1376 - accuracy: 0.6839 - val_loss: 29.6988 - val_accuracy: 0.2665\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1215 - accuracy: 0.6857 - val_loss: 47.2797 - val_accuracy: 0.2810\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1673 - accuracy: 0.6883 - val_loss: 117.3809 - val_accuracy: 0.2776\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1211 - accuracy: 0.6890 - val_loss: 79.5773 - val_accuracy: 0.2962\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1284 - accuracy: 0.6831 - val_loss: 88.0685 - val_accuracy: 0.2814\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1335 - accuracy: 0.6814 - val_loss: 49.4699 - val_accuracy: 0.2878\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0973 - accuracy: 0.6896 - val_loss: 35.9426 - val_accuracy: 0.2996\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1071 - accuracy: 0.6869 - val_loss: 97.5308 - val_accuracy: 0.2587\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0706 - accuracy: 0.6914 - val_loss: 48.8575 - val_accuracy: 0.2574\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 4s 237ms/step - loss: 1.1150 - accuracy: 0.6895 - val_loss: 24.0685 - val_accuracy: 0.2841\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1592 - accuracy: 0.6841 - val_loss: 57.7364 - val_accuracy: 0.2720\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.2156 - accuracy: 0.6803 - val_loss: 142.8360 - val_accuracy: 0.2601\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1977 - accuracy: 0.6820 - val_loss: 71.0586 - val_accuracy: 0.2960\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.1542 - accuracy: 0.6881 - val_loss: 54.2319 - val_accuracy: 0.3028\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.1545 - accuracy: 0.6824 - val_loss: 12.2851 - val_accuracy: 0.3389\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1051 - accuracy: 0.6893 - val_loss: 44.5219 - val_accuracy: 0.2819\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1092 - accuracy: 0.6849 - val_loss: 10.7262 - val_accuracy: 0.2974\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1331 - accuracy: 0.6843 - val_loss: 31.8540 - val_accuracy: 0.2689\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1564 - accuracy: 0.6850 - val_loss: 18.0352 - val_accuracy: 0.2667\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1575 - accuracy: 0.6859 - val_loss: 24.9312 - val_accuracy: 0.2648\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1382 - accuracy: 0.6859 - val_loss: 69.0250 - val_accuracy: 0.2872\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.1502 - accuracy: 0.6871 - val_loss: 26.8975 - val_accuracy: 0.2588\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1202 - accuracy: 0.6862 - val_loss: 66.3876 - val_accuracy: 0.2731\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1067 - accuracy: 0.6853 - val_loss: 53.3229 - val_accuracy: 0.2666\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0961 - accuracy: 0.6891 - val_loss: 98.1538 - val_accuracy: 0.2765\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1303 - accuracy: 0.6867 - val_loss: 41.2809 - val_accuracy: 0.2456\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.1375 - accuracy: 0.6859 - val_loss: 50.8733 - val_accuracy: 0.2951\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1557 - accuracy: 0.6845 - val_loss: 28.6510 - val_accuracy: 0.2578\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.1382 - accuracy: 0.6842 - val_loss: 51.1188 - val_accuracy: 0.3340\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0793 - accuracy: 0.6937 - val_loss: 53.8114 - val_accuracy: 0.2494\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0593 - accuracy: 0.6899 - val_loss: 42.4436 - val_accuracy: 0.3170\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0791 - accuracy: 0.6896 - val_loss: 71.8407 - val_accuracy: 0.3333\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1183 - accuracy: 0.6878 - val_loss: 36.6343 - val_accuracy: 0.3396\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0708 - accuracy: 0.6934 - val_loss: 55.0730 - val_accuracy: 0.3128\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1007 - accuracy: 0.6900 - val_loss: 81.3101 - val_accuracy: 0.2780\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0888 - accuracy: 0.6964 - val_loss: 22.6458 - val_accuracy: 0.3205\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1115 - accuracy: 0.6896 - val_loss: 24.7435 - val_accuracy: 0.2638\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1100 - accuracy: 0.6936 - val_loss: 25.2971 - val_accuracy: 0.3251\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0861 - accuracy: 0.6930 - val_loss: 56.9451 - val_accuracy: 0.2648\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0687 - accuracy: 0.6943 - val_loss: 37.6292 - val_accuracy: 0.2752\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0646 - accuracy: 0.6917 - val_loss: 37.8567 - val_accuracy: 0.2451\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0942 - accuracy: 0.6921 - val_loss: 28.1654 - val_accuracy: 0.2807\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1072 - accuracy: 0.6903 - val_loss: 51.5529 - val_accuracy: 0.2620\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1192 - accuracy: 0.6873 - val_loss: 69.4063 - val_accuracy: 0.2816\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0791 - accuracy: 0.6952 - val_loss: 46.5986 - val_accuracy: 0.2893\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0698 - accuracy: 0.6930 - val_loss: 64.2105 - val_accuracy: 0.3376\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.0456 - accuracy: 0.6937 - val_loss: 43.6966 - val_accuracy: 0.3057\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.0523 - accuracy: 0.6944 - val_loss: 18.6568 - val_accuracy: 0.3455\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.1375 - accuracy: 0.6884 - val_loss: 27.2928 - val_accuracy: 0.3059\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.1723 - accuracy: 0.6825 - val_loss: 30.8058 - val_accuracy: 0.3007\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0622 - accuracy: 0.6924 - val_loss: 37.4306 - val_accuracy: 0.3068\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0391 - accuracy: 0.6967 - val_loss: 33.7057 - val_accuracy: 0.3086\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0147 - accuracy: 0.6921 - val_loss: 25.7279 - val_accuracy: 0.3351\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1025 - accuracy: 0.6953 - val_loss: 21.9176 - val_accuracy: 0.3091\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.1236 - accuracy: 0.6854 - val_loss: 16.4879 - val_accuracy: 0.3687\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0957 - accuracy: 0.6912 - val_loss: 33.2758 - val_accuracy: 0.3182\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0390 - accuracy: 0.6950 - val_loss: 30.5072 - val_accuracy: 0.3343\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0223 - accuracy: 0.6955 - val_loss: 31.0352 - val_accuracy: 0.3576\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0333 - accuracy: 0.6971 - val_loss: 44.2121 - val_accuracy: 0.3571\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0253 - accuracy: 0.6963 - val_loss: 28.2166 - val_accuracy: 0.2881\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0377 - accuracy: 0.6992 - val_loss: 29.1814 - val_accuracy: 0.3161\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.1072 - accuracy: 0.6920 - val_loss: 21.4324 - val_accuracy: 0.3698\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0488 - accuracy: 0.6955 - val_loss: 43.1133 - val_accuracy: 0.3311\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0429 - accuracy: 0.6955 - val_loss: 27.6965 - val_accuracy: 0.3594\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0539 - accuracy: 0.6957 - val_loss: 36.6036 - val_accuracy: 0.3651\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0352 - accuracy: 0.7000 - val_loss: 26.0580 - val_accuracy: 0.3643\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0555 - accuracy: 0.7006 - val_loss: 36.0398 - val_accuracy: 0.3528\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.1154 - accuracy: 0.6958 - val_loss: 14.9136 - val_accuracy: 0.3561\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0522 - accuracy: 0.6902 - val_loss: 25.6545 - val_accuracy: 0.3756\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0278 - accuracy: 0.6937 - val_loss: 34.3293 - val_accuracy: 0.3448\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0022 - accuracy: 0.6964 - val_loss: 14.3816 - val_accuracy: 0.3506\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0199 - accuracy: 0.6948 - val_loss: 25.1249 - val_accuracy: 0.3349\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0307 - accuracy: 0.6975 - val_loss: 20.3103 - val_accuracy: 0.2752\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.0583 - accuracy: 0.6954 - val_loss: 37.8894 - val_accuracy: 0.3723\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.0367 - accuracy: 0.6967 - val_loss: 5.6998 - val_accuracy: 0.3175\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.0761 - accuracy: 0.6944 - val_loss: 17.5279 - val_accuracy: 0.3764\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.0624 - accuracy: 0.6972 - val_loss: 15.5046 - val_accuracy: 0.3100\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0141 - accuracy: 0.6986 - val_loss: 13.7654 - val_accuracy: 0.2783\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9912 - accuracy: 0.6983 - val_loss: 11.8762 - val_accuracy: 0.3085\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0305 - accuracy: 0.6931 - val_loss: 11.8451 - val_accuracy: 0.3006\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.0107 - accuracy: 0.6957 - val_loss: 12.1077 - val_accuracy: 0.3237\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0240 - accuracy: 0.6941 - val_loss: 15.8332 - val_accuracy: 0.3164\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0010 - accuracy: 0.6994 - val_loss: 8.1182 - val_accuracy: 0.3534\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0141 - accuracy: 0.6985 - val_loss: 16.2719 - val_accuracy: 0.3004\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.1816 - accuracy: 0.6946 - val_loss: 17.5208 - val_accuracy: 0.2591\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0642 - accuracy: 0.6924 - val_loss: 22.1503 - val_accuracy: 0.2881\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0939 - accuracy: 0.6937 - val_loss: 17.7314 - val_accuracy: 0.2777\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0317 - accuracy: 0.6966 - val_loss: 19.9614 - val_accuracy: 0.2924\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9684 - accuracy: 0.7011 - val_loss: 22.0193 - val_accuracy: 0.3023\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0344 - accuracy: 0.6967 - val_loss: 11.6905 - val_accuracy: 0.3240\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0260 - accuracy: 0.6982 - val_loss: 15.2330 - val_accuracy: 0.3043\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0471 - accuracy: 0.6985 - val_loss: 24.0071 - val_accuracy: 0.3022\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.0184 - accuracy: 0.6992 - val_loss: 15.4393 - val_accuracy: 0.3603\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9799 - accuracy: 0.6990 - val_loss: 13.6502 - val_accuracy: 0.2882\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0500 - accuracy: 0.6956 - val_loss: 14.9437 - val_accuracy: 0.2896\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0175 - accuracy: 0.6970 - val_loss: 18.6743 - val_accuracy: 0.2847\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9793 - accuracy: 0.7019 - val_loss: 21.5282 - val_accuracy: 0.2722\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9445 - accuracy: 0.7036 - val_loss: 25.3042 - val_accuracy: 0.2906\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9649 - accuracy: 0.7024 - val_loss: 33.7316 - val_accuracy: 0.3001\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9997 - accuracy: 0.7007 - val_loss: 15.4258 - val_accuracy: 0.3001\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0140 - accuracy: 0.6964 - val_loss: 22.8836 - val_accuracy: 0.2853\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9560 - accuracy: 0.7023 - val_loss: 17.9423 - val_accuracy: 0.2900\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9499 - accuracy: 0.7036 - val_loss: 18.8803 - val_accuracy: 0.2975\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9621 - accuracy: 0.7046 - val_loss: 12.6299 - val_accuracy: 0.2878\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9421 - accuracy: 0.7071 - val_loss: 10.8078 - val_accuracy: 0.3089\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9951 - accuracy: 0.6983 - val_loss: 16.4725 - val_accuracy: 0.2784\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9612 - accuracy: 0.7028 - val_loss: 15.1635 - val_accuracy: 0.2935\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9936 - accuracy: 0.7009 - val_loss: 12.6934 - val_accuracy: 0.2425\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9876 - accuracy: 0.7042 - val_loss: 11.7747 - val_accuracy: 0.2864\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0395 - accuracy: 0.6973 - val_loss: 13.6679 - val_accuracy: 0.2914\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.9971 - accuracy: 0.7006 - val_loss: 10.7277 - val_accuracy: 0.2927\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.0598 - accuracy: 0.6990 - val_loss: 10.2439 - val_accuracy: 0.2839\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9991 - accuracy: 0.6964 - val_loss: 10.8860 - val_accuracy: 0.3349\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9510 - accuracy: 0.7020 - val_loss: 9.2417 - val_accuracy: 0.3057\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9465 - accuracy: 0.6992 - val_loss: 12.3149 - val_accuracy: 0.3211\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9624 - accuracy: 0.7014 - val_loss: 10.9569 - val_accuracy: 0.3417\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9261 - accuracy: 0.6979 - val_loss: 15.0069 - val_accuracy: 0.3384\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9620 - accuracy: 0.7017 - val_loss: 8.8567 - val_accuracy: 0.3231\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9631 - accuracy: 0.7010 - val_loss: 13.1905 - val_accuracy: 0.2942\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.0451 - accuracy: 0.6980 - val_loss: 9.0940 - val_accuracy: 0.2991\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.0136 - accuracy: 0.6972 - val_loss: 10.4118 - val_accuracy: 0.2790\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0057 - accuracy: 0.6969 - val_loss: 9.6683 - val_accuracy: 0.2610\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9628 - accuracy: 0.6996 - val_loss: 10.5526 - val_accuracy: 0.2938\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9731 - accuracy: 0.7053 - val_loss: 11.6403 - val_accuracy: 0.3218\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9839 - accuracy: 0.6990 - val_loss: 15.5432 - val_accuracy: 0.2774\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9795 - accuracy: 0.6997 - val_loss: 9.3785 - val_accuracy: 0.2991\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9318 - accuracy: 0.7068 - val_loss: 11.1968 - val_accuracy: 0.2640\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9495 - accuracy: 0.7013 - val_loss: 10.3977 - val_accuracy: 0.3179\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.9569 - accuracy: 0.7037 - val_loss: 8.0779 - val_accuracy: 0.2915\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.9467 - accuracy: 0.7021 - val_loss: 22.3574 - val_accuracy: 0.2383\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.9485 - accuracy: 0.7070 - val_loss: 11.5138 - val_accuracy: 0.2905\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.9619 - accuracy: 0.6978 - val_loss: 9.6434 - val_accuracy: 0.2957\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9662 - accuracy: 0.7026 - val_loss: 6.3235 - val_accuracy: 0.3525\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9400 - accuracy: 0.7006 - val_loss: 12.0344 - val_accuracy: 0.3267\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9252 - accuracy: 0.7027 - val_loss: 7.4812 - val_accuracy: 0.3251\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.9906 - accuracy: 0.7032 - val_loss: 6.2082 - val_accuracy: 0.3154\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.0286 - accuracy: 0.6964 - val_loss: 8.2009 - val_accuracy: 0.2991\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9344 - accuracy: 0.7046 - val_loss: 8.6317 - val_accuracy: 0.3657\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9254 - accuracy: 0.7026 - val_loss: 7.7664 - val_accuracy: 0.2680\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8829 - accuracy: 0.7076 - val_loss: 8.3966 - val_accuracy: 0.3389\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9087 - accuracy: 0.7042 - val_loss: 20.1423 - val_accuracy: 0.2768\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8987 - accuracy: 0.7062 - val_loss: 7.6937 - val_accuracy: 0.3191\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9202 - accuracy: 0.7062 - val_loss: 11.8892 - val_accuracy: 0.3150\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9609 - accuracy: 0.7114 - val_loss: 9.5606 - val_accuracy: 0.2953\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9391 - accuracy: 0.7022 - val_loss: 13.1579 - val_accuracy: 0.2712\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9109 - accuracy: 0.7097 - val_loss: 11.7835 - val_accuracy: 0.2971\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8960 - accuracy: 0.7051 - val_loss: 11.6593 - val_accuracy: 0.2840\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9034 - accuracy: 0.7056 - val_loss: 15.4227 - val_accuracy: 0.2960\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8978 - accuracy: 0.7079 - val_loss: 5.8908 - val_accuracy: 0.2931\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9420 - accuracy: 0.6989 - val_loss: 5.8257 - val_accuracy: 0.3283\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9338 - accuracy: 0.7060 - val_loss: 8.7219 - val_accuracy: 0.3024\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9197 - accuracy: 0.7055 - val_loss: 7.1302 - val_accuracy: 0.2900\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.0346 - accuracy: 0.7012 - val_loss: 5.2410 - val_accuracy: 0.2947\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.0001 - accuracy: 0.7016 - val_loss: 3.6444 - val_accuracy: 0.3408\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9390 - accuracy: 0.7051 - val_loss: 9.3028 - val_accuracy: 0.2769\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9603 - accuracy: 0.7059 - val_loss: 12.1883 - val_accuracy: 0.2496\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9505 - accuracy: 0.7022 - val_loss: 8.2041 - val_accuracy: 0.2821\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.0286 - accuracy: 0.7007 - val_loss: 8.8872 - val_accuracy: 0.2758\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.9841 - accuracy: 0.7003 - val_loss: 5.9732 - val_accuracy: 0.3132\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9161 - accuracy: 0.7084 - val_loss: 8.3439 - val_accuracy: 0.3140\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9232 - accuracy: 0.7016 - val_loss: 6.3648 - val_accuracy: 0.3020\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9052 - accuracy: 0.7042 - val_loss: 7.9926 - val_accuracy: 0.2882\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8938 - accuracy: 0.7051 - val_loss: 7.5283 - val_accuracy: 0.3090\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.8336 - accuracy: 0.7125 - val_loss: 8.8456 - val_accuracy: 0.3543\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.8458 - accuracy: 0.7129 - val_loss: 9.4619 - val_accuracy: 0.2829\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8414 - accuracy: 0.7082 - val_loss: 8.7390 - val_accuracy: 0.3419\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8920 - accuracy: 0.7104 - val_loss: 11.1030 - val_accuracy: 0.3013\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.9904 - accuracy: 0.7053 - val_loss: 9.5407 - val_accuracy: 0.3160\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9333 - accuracy: 0.7040 - val_loss: 6.1364 - val_accuracy: 0.3696\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9439 - accuracy: 0.7069 - val_loss: 5.8917 - val_accuracy: 0.3198\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9784 - accuracy: 0.7025 - val_loss: 8.4510 - val_accuracy: 0.2427\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8992 - accuracy: 0.7020 - val_loss: 8.6665 - val_accuracy: 0.2851\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8831 - accuracy: 0.7085 - val_loss: 8.2481 - val_accuracy: 0.3108\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9011 - accuracy: 0.7067 - val_loss: 6.7675 - val_accuracy: 0.3147\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9152 - accuracy: 0.7108 - val_loss: 5.3401 - val_accuracy: 0.3461\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9521 - accuracy: 0.7034 - val_loss: 6.9102 - val_accuracy: 0.3311\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9268 - accuracy: 0.7015 - val_loss: 7.5675 - val_accuracy: 0.3367\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8598 - accuracy: 0.7122 - val_loss: 6.2777 - val_accuracy: 0.3035\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8556 - accuracy: 0.7111 - val_loss: 7.5303 - val_accuracy: 0.3138\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9009 - accuracy: 0.7102 - val_loss: 7.8065 - val_accuracy: 0.2839\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 0.9704 - accuracy: 0.6978 - val_loss: 6.0515 - val_accuracy: 0.3115\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9517 - accuracy: 0.7089 - val_loss: 5.1326 - val_accuracy: 0.3478\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9661 - accuracy: 0.7027 - val_loss: 5.3928 - val_accuracy: 0.3546\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8936 - accuracy: 0.7079 - val_loss: 6.8792 - val_accuracy: 0.3838\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8737 - accuracy: 0.7115 - val_loss: 8.8951 - val_accuracy: 0.3137\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9457 - accuracy: 0.7055 - val_loss: 8.0726 - val_accuracy: 0.2862\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.9001 - accuracy: 0.7087 - val_loss: 7.1479 - val_accuracy: 0.2940\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8964 - accuracy: 0.7087 - val_loss: 7.0850 - val_accuracy: 0.3108\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8887 - accuracy: 0.7059 - val_loss: 8.4678 - val_accuracy: 0.3510\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8853 - accuracy: 0.7116 - val_loss: 7.2243 - val_accuracy: 0.3016\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9027 - accuracy: 0.7111 - val_loss: 5.4572 - val_accuracy: 0.3578\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.9348 - accuracy: 0.7106 - val_loss: 6.2521 - val_accuracy: 0.3069\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9169 - accuracy: 0.7060 - val_loss: 7.8533 - val_accuracy: 0.2826\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.9193 - accuracy: 0.7050 - val_loss: 8.3722 - val_accuracy: 0.2928\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8911 - accuracy: 0.7074 - val_loss: 6.8430 - val_accuracy: 0.3107\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0456 - accuracy: 0.7025 - val_loss: 6.7585 - val_accuracy: 0.3178\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9791 - accuracy: 0.7016 - val_loss: 6.2148 - val_accuracy: 0.3119\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8801 - accuracy: 0.7106 - val_loss: 8.7630 - val_accuracy: 0.3458\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9099 - accuracy: 0.7100 - val_loss: 7.7107 - val_accuracy: 0.3392\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.0474 - accuracy: 0.7031 - val_loss: 7.9584 - val_accuracy: 0.3172\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0069 - accuracy: 0.6998 - val_loss: 7.0776 - val_accuracy: 0.2779\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9469 - accuracy: 0.7053 - val_loss: 5.9296 - val_accuracy: 0.3683\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9041 - accuracy: 0.7041 - val_loss: 7.3097 - val_accuracy: 0.3119\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9299 - accuracy: 0.7063 - val_loss: 4.2701 - val_accuracy: 0.4360\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9525 - accuracy: 0.7074 - val_loss: 7.0661 - val_accuracy: 0.3402\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.9284 - accuracy: 0.7032 - val_loss: 5.7329 - val_accuracy: 0.3490\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.9225 - accuracy: 0.7105 - val_loss: 6.1734 - val_accuracy: 0.3651\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.8602 - accuracy: 0.7096 - val_loss: 7.3537 - val_accuracy: 0.3420\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.9939 - accuracy: 0.7049 - val_loss: 7.0684 - val_accuracy: 0.3289\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9524 - accuracy: 0.7036 - val_loss: 8.1573 - val_accuracy: 0.3254\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8964 - accuracy: 0.7107 - val_loss: 6.3621 - val_accuracy: 0.3724\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9117 - accuracy: 0.7089 - val_loss: 7.0041 - val_accuracy: 0.3481\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.8785 - accuracy: 0.7123 - val_loss: 6.0374 - val_accuracy: 0.4107\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.8524 - accuracy: 0.7105 - val_loss: 5.7713 - val_accuracy: 0.3538\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.8806 - accuracy: 0.7070 - val_loss: 8.0078 - val_accuracy: 0.3264\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9046 - accuracy: 0.7135 - val_loss: 7.2344 - val_accuracy: 0.3449\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9181 - accuracy: 0.7089 - val_loss: 6.6512 - val_accuracy: 0.3233\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8672 - accuracy: 0.7124 - val_loss: 8.3923 - val_accuracy: 0.3738\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8774 - accuracy: 0.7130 - val_loss: 5.2708 - val_accuracy: 0.3281\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8817 - accuracy: 0.7111 - val_loss: 9.1316 - val_accuracy: 0.3560\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9123 - accuracy: 0.7076 - val_loss: 8.1999 - val_accuracy: 0.3192\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.9012 - accuracy: 0.7116 - val_loss: 7.8728 - val_accuracy: 0.3231\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9252 - accuracy: 0.7088 - val_loss: 9.4299 - val_accuracy: 0.2991\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.9243 - accuracy: 0.7096 - val_loss: 9.1300 - val_accuracy: 0.2529\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8905 - accuracy: 0.7110 - val_loss: 7.9199 - val_accuracy: 0.2690\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8632 - accuracy: 0.7165 - val_loss: 7.5180 - val_accuracy: 0.2900\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8184 - accuracy: 0.7147 - val_loss: 7.8029 - val_accuracy: 0.3369\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8377 - accuracy: 0.7161 - val_loss: 8.0692 - val_accuracy: 0.3067\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8594 - accuracy: 0.7117 - val_loss: 5.8051 - val_accuracy: 0.3337\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8711 - accuracy: 0.7150 - val_loss: 8.1474 - val_accuracy: 0.3386\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8140 - accuracy: 0.7174 - val_loss: 7.1010 - val_accuracy: 0.3318\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 4s 258ms/step - loss: 0.8059 - accuracy: 0.7156 - val_loss: 10.8319 - val_accuracy: 0.3540\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8007 - accuracy: 0.7120 - val_loss: 6.8658 - val_accuracy: 0.3535\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.9204 - accuracy: 0.7115 - val_loss: 4.6120 - val_accuracy: 0.3772\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9976 - accuracy: 0.7124 - val_loss: 6.2626 - val_accuracy: 0.3512\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.9275 - accuracy: 0.7084 - val_loss: 6.2027 - val_accuracy: 0.3196\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8730 - accuracy: 0.7114 - val_loss: 8.3886 - val_accuracy: 0.3347\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8588 - accuracy: 0.7124 - val_loss: 9.5085 - val_accuracy: 0.3617\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8831 - accuracy: 0.7079 - val_loss: 12.0494 - val_accuracy: 0.2931\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.9134 - accuracy: 0.7113 - val_loss: 10.9726 - val_accuracy: 0.3372\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8544 - accuracy: 0.7130 - val_loss: 8.3228 - val_accuracy: 0.2698\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8544 - accuracy: 0.7142 - val_loss: 8.0530 - val_accuracy: 0.2842\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8984 - accuracy: 0.7113 - val_loss: 7.9180 - val_accuracy: 0.3263\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8620 - accuracy: 0.7117 - val_loss: 8.5681 - val_accuracy: 0.3007\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8629 - accuracy: 0.7159 - val_loss: 7.8276 - val_accuracy: 0.2566\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8358 - accuracy: 0.7102 - val_loss: 8.4755 - val_accuracy: 0.2650\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8613 - accuracy: 0.7097 - val_loss: 9.4725 - val_accuracy: 0.3160\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8632 - accuracy: 0.7146 - val_loss: 7.5203 - val_accuracy: 0.3255\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8916 - accuracy: 0.7148 - val_loss: 8.0007 - val_accuracy: 0.2858\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8720 - accuracy: 0.7127 - val_loss: 6.2589 - val_accuracy: 0.3490\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8052 - accuracy: 0.7191 - val_loss: 11.1814 - val_accuracy: 0.2677\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 0.8315 - accuracy: 0.7128 - val_loss: 9.5723 - val_accuracy: 0.2842\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8570 - accuracy: 0.7115 - val_loss: 7.5818 - val_accuracy: 0.3049\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8586 - accuracy: 0.7068 - val_loss: 11.3327 - val_accuracy: 0.2893\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8259 - accuracy: 0.7163 - val_loss: 10.0341 - val_accuracy: 0.3065\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9145 - accuracy: 0.7106 - val_loss: 6.8656 - val_accuracy: 0.3444\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8913 - accuracy: 0.7072 - val_loss: 8.1153 - val_accuracy: 0.3058\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8862 - accuracy: 0.7117 - val_loss: 7.7177 - val_accuracy: 0.3413\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8538 - accuracy: 0.7136 - val_loss: 6.6201 - val_accuracy: 0.3747\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8416 - accuracy: 0.7143 - val_loss: 7.9447 - val_accuracy: 0.2908\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8307 - accuracy: 0.7104 - val_loss: 8.3413 - val_accuracy: 0.3151\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.7830 - accuracy: 0.7186 - val_loss: 6.9942 - val_accuracy: 0.3799\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8078 - accuracy: 0.7155 - val_loss: 9.1517 - val_accuracy: 0.2916\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8399 - accuracy: 0.7146 - val_loss: 7.6503 - val_accuracy: 0.3672\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8432 - accuracy: 0.7178 - val_loss: 6.1971 - val_accuracy: 0.3589\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8665 - accuracy: 0.7115 - val_loss: 7.9542 - val_accuracy: 0.3287\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8680 - accuracy: 0.7096 - val_loss: 6.4004 - val_accuracy: 0.3966\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7871 - accuracy: 0.7170 - val_loss: 7.2545 - val_accuracy: 0.3832\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8477 - accuracy: 0.7148 - val_loss: 9.3891 - val_accuracy: 0.3415\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8233 - accuracy: 0.7143 - val_loss: 8.8437 - val_accuracy: 0.3407\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7957 - accuracy: 0.7171 - val_loss: 6.6940 - val_accuracy: 0.3727\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.9161 - accuracy: 0.7117 - val_loss: 6.6207 - val_accuracy: 0.3706\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8584 - accuracy: 0.7086 - val_loss: 5.7679 - val_accuracy: 0.3801\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8116 - accuracy: 0.7151 - val_loss: 6.3755 - val_accuracy: 0.3578\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.9378 - accuracy: 0.7098 - val_loss: 6.1915 - val_accuracy: 0.3871\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.8643 - accuracy: 0.7140 - val_loss: 8.7722 - val_accuracy: 0.3957\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8271 - accuracy: 0.7134 - val_loss: 7.4651 - val_accuracy: 0.3517\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.8898 - accuracy: 0.7134 - val_loss: 5.7023 - val_accuracy: 0.3276\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8541 - accuracy: 0.7144 - val_loss: 6.4080 - val_accuracy: 0.3675\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8841 - accuracy: 0.7113 - val_loss: 6.9932 - val_accuracy: 0.3931\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8411 - accuracy: 0.7155 - val_loss: 10.4397 - val_accuracy: 0.2785\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8159 - accuracy: 0.7138 - val_loss: 9.9942 - val_accuracy: 0.3440\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8402 - accuracy: 0.7136 - val_loss: 5.7396 - val_accuracy: 0.4576\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8686 - accuracy: 0.7138 - val_loss: 5.8527 - val_accuracy: 0.3781\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8362 - accuracy: 0.7127 - val_loss: 11.9306 - val_accuracy: 0.4109\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8486 - accuracy: 0.7116 - val_loss: 9.9386 - val_accuracy: 0.3206\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8333 - accuracy: 0.7162 - val_loss: 8.5785 - val_accuracy: 0.3737\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.8138 - accuracy: 0.7152 - val_loss: 8.0951 - val_accuracy: 0.3319\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.8317 - accuracy: 0.7166 - val_loss: 6.0580 - val_accuracy: 0.3883\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.8475 - accuracy: 0.7163 - val_loss: 7.9452 - val_accuracy: 0.3926\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9006 - accuracy: 0.7177 - val_loss: 7.1048 - val_accuracy: 0.3491\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.8144 - accuracy: 0.7164 - val_loss: 5.2150 - val_accuracy: 0.4139\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7895 - accuracy: 0.7183 - val_loss: 7.4107 - val_accuracy: 0.3853\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7848 - accuracy: 0.7193 - val_loss: 7.0573 - val_accuracy: 0.4054\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7763 - accuracy: 0.7222 - val_loss: 7.3432 - val_accuracy: 0.3578\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.8075 - accuracy: 0.7170 - val_loss: 5.6981 - val_accuracy: 0.4386\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 0.7778 - accuracy: 0.7233 - val_loss: 6.2801 - val_accuracy: 0.3991\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8076 - accuracy: 0.7171 - val_loss: 5.7158 - val_accuracy: 0.4222\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8079 - accuracy: 0.7166 - val_loss: 7.4515 - val_accuracy: 0.3636\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7511 - accuracy: 0.7242 - val_loss: 6.7110 - val_accuracy: 0.4052\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.7706 - accuracy: 0.7234 - val_loss: 7.3984 - val_accuracy: 0.3863\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8127 - accuracy: 0.7178 - val_loss: 9.7382 - val_accuracy: 0.3885\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.8282 - accuracy: 0.7180 - val_loss: 8.1801 - val_accuracy: 0.3473\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.8625 - accuracy: 0.7180 - val_loss: 7.4464 - val_accuracy: 0.3590\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8102 - accuracy: 0.7191 - val_loss: 7.5719 - val_accuracy: 0.3771\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8316 - accuracy: 0.7196 - val_loss: 10.1513 - val_accuracy: 0.3471\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.8387 - accuracy: 0.7130 - val_loss: 7.2096 - val_accuracy: 0.4238\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7885 - accuracy: 0.7159 - val_loss: 5.4107 - val_accuracy: 0.4210\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.7704 - accuracy: 0.7231 - val_loss: 6.6001 - val_accuracy: 0.4287\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.8085 - accuracy: 0.7220 - val_loss: 11.3986 - val_accuracy: 0.3590\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.7972 - accuracy: 0.7203 - val_loss: 6.7957 - val_accuracy: 0.3730\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 7s 407ms/step - loss: 0.8112 - accuracy: 0.7211 - val_loss: 10.3428 - val_accuracy: 0.3472\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.7440 - accuracy: 0.7202 - val_loss: 7.2834 - val_accuracy: 0.4054\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8381 - accuracy: 0.7174 - val_loss: 6.7277 - val_accuracy: 0.3516\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.8364 - accuracy: 0.7153 - val_loss: 6.5857 - val_accuracy: 0.3456\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.8151 - accuracy: 0.7165 - val_loss: 6.7498 - val_accuracy: 0.3490\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8215 - accuracy: 0.7157 - val_loss: 9.3778 - val_accuracy: 0.3290\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.7518 - accuracy: 0.7216 - val_loss: 7.4666 - val_accuracy: 0.3800\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7597 - accuracy: 0.7216 - val_loss: 8.7024 - val_accuracy: 0.3987\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.8985 - accuracy: 0.7161 - val_loss: 9.0486 - val_accuracy: 0.3542\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.9005 - accuracy: 0.7126 - val_loss: 7.7639 - val_accuracy: 0.3808\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8866 - accuracy: 0.7127 - val_loss: 5.8228 - val_accuracy: 0.3889\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8170 - accuracy: 0.7191 - val_loss: 4.4605 - val_accuracy: 0.4145\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.7344 - accuracy: 0.7295 - val_loss: 6.0495 - val_accuracy: 0.4186\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.7712 - accuracy: 0.7158 - val_loss: 6.1469 - val_accuracy: 0.4262\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.8593 - accuracy: 0.7145 - val_loss: 5.9890 - val_accuracy: 0.3903\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8498 - accuracy: 0.7144 - val_loss: 7.7809 - val_accuracy: 0.3918\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.8339 - accuracy: 0.7146 - val_loss: 6.0994 - val_accuracy: 0.3964\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.7838 - accuracy: 0.7155 - val_loss: 6.0281 - val_accuracy: 0.3836\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8508 - accuracy: 0.7195 - val_loss: 6.0343 - val_accuracy: 0.3733\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8741 - accuracy: 0.7072 - val_loss: 9.6841 - val_accuracy: 0.3075\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7626 - accuracy: 0.7230 - val_loss: 6.4432 - val_accuracy: 0.3567\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.7816 - accuracy: 0.7197 - val_loss: 6.4337 - val_accuracy: 0.4258\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7212 - accuracy: 0.7275 - val_loss: 7.0349 - val_accuracy: 0.3685\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7866 - accuracy: 0.7222 - val_loss: 5.7064 - val_accuracy: 0.3909\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0534 - accuracy: 0.7070 - val_loss: 6.1156 - val_accuracy: 0.3696\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0159 - accuracy: 0.7012 - val_loss: 10.9054 - val_accuracy: 0.3199\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.0431 - accuracy: 0.6990 - val_loss: 10.2905 - val_accuracy: 0.4212\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.9747 - accuracy: 0.7070 - val_loss: 6.8144 - val_accuracy: 0.4321\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.9514 - accuracy: 0.7107 - val_loss: 7.7835 - val_accuracy: 0.4519\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8710 - accuracy: 0.7159 - val_loss: 6.8543 - val_accuracy: 0.4310\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 0.8397 - accuracy: 0.7129 - val_loss: 6.0085 - val_accuracy: 0.4624\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8559 - accuracy: 0.7174 - val_loss: 5.8297 - val_accuracy: 0.4109\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.8978 - accuracy: 0.7208 - val_loss: 5.0439 - val_accuracy: 0.4815\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.8463 - accuracy: 0.7174 - val_loss: 7.5648 - val_accuracy: 0.3669\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7874 - accuracy: 0.7219 - val_loss: 5.6032 - val_accuracy: 0.3932\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8175 - accuracy: 0.7193 - val_loss: 6.0122 - val_accuracy: 0.4541\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.8356 - accuracy: 0.7195 - val_loss: 6.3184 - val_accuracy: 0.4234\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.7712 - accuracy: 0.7231 - val_loss: 7.0940 - val_accuracy: 0.3683\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.8225 - accuracy: 0.7178 - val_loss: 5.7984 - val_accuracy: 0.4136\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.8307 - accuracy: 0.7172 - val_loss: 9.0941 - val_accuracy: 0.3599\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.8207 - accuracy: 0.7224 - val_loss: 5.1755 - val_accuracy: 0.4765\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.7893 - accuracy: 0.7186 - val_loss: 6.0517 - val_accuracy: 0.3782\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8693 - accuracy: 0.7136 - val_loss: 5.8849 - val_accuracy: 0.4265\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.8069 - accuracy: 0.7178 - val_loss: 5.9987 - val_accuracy: 0.3919\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7390 - accuracy: 0.7232 - val_loss: 6.6499 - val_accuracy: 0.4225\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.7408 - accuracy: 0.7266 - val_loss: 5.1143 - val_accuracy: 0.4258\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7671 - accuracy: 0.7224 - val_loss: 5.3504 - val_accuracy: 0.4070\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.7907 - accuracy: 0.7187 - val_loss: 6.3524 - val_accuracy: 0.3816\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.7936 - accuracy: 0.7216 - val_loss: 6.9630 - val_accuracy: 0.3660\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.7702 - accuracy: 0.7194 - val_loss: 5.1946 - val_accuracy: 0.4431\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.7494 - accuracy: 0.7235 - val_loss: 5.0908 - val_accuracy: 0.4668\n",
            "(1969, 68)\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 279ms/step - loss: 2.7474 - accuracy: 0.5835 - val_loss: 21.7525 - val_accuracy: 0.1561\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.3570 - accuracy: 0.6078 - val_loss: 21.9987 - val_accuracy: 0.1601\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 2.2673 - accuracy: 0.6155 - val_loss: 16.6866 - val_accuracy: 0.1691\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.3277 - accuracy: 0.6041 - val_loss: 34.9061 - val_accuracy: 0.1747\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.3705 - accuracy: 0.6171 - val_loss: 47.6874 - val_accuracy: 0.1294\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.7037 - accuracy: 0.6156 - val_loss: 161.8979 - val_accuracy: 0.1184\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 2.7007 - accuracy: 0.6051 - val_loss: 2240.7686 - val_accuracy: 0.0762\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.5136 - accuracy: 0.5998 - val_loss: 26.7263 - val_accuracy: 0.0963\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.3671 - accuracy: 0.6078 - val_loss: 19.8052 - val_accuracy: 0.1028\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.2606 - accuracy: 0.6086 - val_loss: 21.3760 - val_accuracy: 0.1147\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2855 - accuracy: 0.6167 - val_loss: 21.9166 - val_accuracy: 0.1398\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.2699 - accuracy: 0.6184 - val_loss: 20.0329 - val_accuracy: 0.1181\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 2.3060 - accuracy: 0.6116 - val_loss: 27.3569 - val_accuracy: 0.1318\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.2682 - accuracy: 0.6140 - val_loss: 16.6325 - val_accuracy: 0.1294\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 2.1609 - accuracy: 0.6175 - val_loss: 16.8352 - val_accuracy: 0.1750\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 2.2093 - accuracy: 0.6128 - val_loss: 12.6077 - val_accuracy: 0.1411\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1198 - accuracy: 0.6202 - val_loss: 12.9571 - val_accuracy: 0.1697\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1621 - accuracy: 0.6142 - val_loss: 13.9743 - val_accuracy: 0.1729\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 2.1407 - accuracy: 0.6210 - val_loss: 17.4819 - val_accuracy: 0.1586\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1028 - accuracy: 0.6176 - val_loss: 14.9829 - val_accuracy: 0.1724\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0624 - accuracy: 0.6242 - val_loss: 17.1859 - val_accuracy: 0.1650\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0466 - accuracy: 0.6231 - val_loss: 20.9269 - val_accuracy: 0.1555\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.0902 - accuracy: 0.6215 - val_loss: 20.5154 - val_accuracy: 0.1080\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.0841 - accuracy: 0.6178 - val_loss: 20.2194 - val_accuracy: 0.1032\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0991 - accuracy: 0.6170 - val_loss: 21.7351 - val_accuracy: 0.1035\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0265 - accuracy: 0.6183 - val_loss: 22.0280 - val_accuracy: 0.1452\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0944 - accuracy: 0.6194 - val_loss: 18.4656 - val_accuracy: 0.1462\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0243 - accuracy: 0.6233 - val_loss: 19.9069 - val_accuracy: 0.1007\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 2.1088 - accuracy: 0.6165 - val_loss: 31.5796 - val_accuracy: 0.0838\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1240 - accuracy: 0.6156 - val_loss: 19.1845 - val_accuracy: 0.1122\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0914 - accuracy: 0.6206 - val_loss: 19.0675 - val_accuracy: 0.1059\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0402 - accuracy: 0.6192 - val_loss: 17.2755 - val_accuracy: 0.1054\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0235 - accuracy: 0.6233 - val_loss: 11.8688 - val_accuracy: 0.1392\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0687 - accuracy: 0.6167 - val_loss: 17.0885 - val_accuracy: 0.1053\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0254 - accuracy: 0.6178 - val_loss: 25.4655 - val_accuracy: 0.0826\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.9990 - accuracy: 0.6177 - val_loss: 36.7682 - val_accuracy: 0.0705\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 2.0038 - accuracy: 0.6211 - val_loss: 68.5363 - val_accuracy: 0.0678\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.9811 - accuracy: 0.6260 - val_loss: 141.9491 - val_accuracy: 0.0197\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.9673 - accuracy: 0.6195 - val_loss: 93.3294 - val_accuracy: 0.0623\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.9586 - accuracy: 0.6221 - val_loss: 47.0826 - val_accuracy: 0.0720\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.0002 - accuracy: 0.6232 - val_loss: 106.7266 - val_accuracy: 0.0596\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.9614 - accuracy: 0.6171 - val_loss: 62.6320 - val_accuracy: 0.0687\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.9237 - accuracy: 0.6204 - val_loss: 80.5562 - val_accuracy: 0.0550\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.9052 - accuracy: 0.6226 - val_loss: 46.1048 - val_accuracy: 0.0615\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.9114 - accuracy: 0.6254 - val_loss: 46.9617 - val_accuracy: 0.0708\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.9511 - accuracy: 0.6187 - val_loss: 48.2531 - val_accuracy: 0.0810\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 1.9249 - accuracy: 0.6205 - val_loss: 43.2209 - val_accuracy: 0.0740\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.9496 - accuracy: 0.6167 - val_loss: 67.1584 - val_accuracy: 0.0570\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.9083 - accuracy: 0.6147 - val_loss: 150.3161 - val_accuracy: 0.0560\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8830 - accuracy: 0.6190 - val_loss: 81.1472 - val_accuracy: 0.0599\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.9486 - accuracy: 0.6191 - val_loss: 205.1544 - val_accuracy: 0.0422\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.8854 - accuracy: 0.6202 - val_loss: 126.3826 - val_accuracy: 0.0524\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8122 - accuracy: 0.6221 - val_loss: 101.0523 - val_accuracy: 0.0486\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8464 - accuracy: 0.6180 - val_loss: 121.4504 - val_accuracy: 0.0502\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.8052 - accuracy: 0.6212 - val_loss: 167.3867 - val_accuracy: 0.0431\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.8358 - accuracy: 0.6178 - val_loss: 216.3366 - val_accuracy: 0.0137\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8230 - accuracy: 0.6219 - val_loss: 303.5394 - val_accuracy: 0.0201\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.8111 - accuracy: 0.6231 - val_loss: 161.5829 - val_accuracy: 0.0235\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.8531 - accuracy: 0.6162 - val_loss: 178.1315 - val_accuracy: 0.0304\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.8512 - accuracy: 0.6203 - val_loss: 80.7674 - val_accuracy: 0.0317\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.7898 - accuracy: 0.6240 - val_loss: 62.0627 - val_accuracy: 0.0365\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 1.8260 - accuracy: 0.6184 - val_loss: 122.3125 - val_accuracy: 0.0301\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7898 - accuracy: 0.6249 - val_loss: 79.0203 - val_accuracy: 0.0369\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.8079 - accuracy: 0.6233 - val_loss: 70.8329 - val_accuracy: 0.0359\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.7992 - accuracy: 0.6246 - val_loss: 69.9657 - val_accuracy: 0.0399\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.7980 - accuracy: 0.6221 - val_loss: 4019553536.0000 - val_accuracy: 0.0277\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.5501 - accuracy: 0.5812 - val_loss: 116853.8750 - val_accuracy: 0.0755\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.3668 - accuracy: 0.6072 - val_loss: 283.1472 - val_accuracy: 0.0179\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.2835 - accuracy: 0.6118 - val_loss: 15.9600 - val_accuracy: 0.0988\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.2312 - accuracy: 0.6148 - val_loss: 9.9499 - val_accuracy: 0.1243\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1967 - accuracy: 0.6186 - val_loss: 10.4147 - val_accuracy: 0.1302\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1643 - accuracy: 0.6214 - val_loss: 12.3590 - val_accuracy: 0.1293\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.1535 - accuracy: 0.6220 - val_loss: 10.7851 - val_accuracy: 0.1262\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.1902 - accuracy: 0.6240 - val_loss: 12.3975 - val_accuracy: 0.1301\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.2460 - accuracy: 0.6160 - val_loss: 12.6027 - val_accuracy: 0.1297\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1834 - accuracy: 0.6151 - val_loss: 12.4823 - val_accuracy: 0.1265\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0960 - accuracy: 0.6219 - val_loss: 13.5595 - val_accuracy: 0.1276\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 2.1426 - accuracy: 0.6170 - val_loss: 10.7091 - val_accuracy: 0.1271\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1190 - accuracy: 0.6196 - val_loss: 10.9651 - val_accuracy: 0.1305\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 2.2170 - accuracy: 0.6193 - val_loss: 11.5545 - val_accuracy: 0.1277\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1542 - accuracy: 0.6209 - val_loss: 11.0360 - val_accuracy: 0.1266\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1079 - accuracy: 0.6201 - val_loss: 11.3415 - val_accuracy: 0.1253\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1335 - accuracy: 0.6211 - val_loss: 12.2985 - val_accuracy: 0.1187\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0924 - accuracy: 0.6177 - val_loss: 13.2129 - val_accuracy: 0.1212\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0955 - accuracy: 0.6241 - val_loss: 10.8433 - val_accuracy: 0.1131\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0995 - accuracy: 0.6233 - val_loss: 12.3964 - val_accuracy: 0.1091\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.0818 - accuracy: 0.6218 - val_loss: 13.2752 - val_accuracy: 0.1048\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.0830 - accuracy: 0.6147 - val_loss: 10.9509 - val_accuracy: 0.1101\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0262 - accuracy: 0.6186 - val_loss: 14.0262 - val_accuracy: 0.1096\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 2.0201 - accuracy: 0.6173 - val_loss: 12.0022 - val_accuracy: 0.1009\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 2.0245 - accuracy: 0.6209 - val_loss: 13.6581 - val_accuracy: 0.0966\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0100 - accuracy: 0.6220 - val_loss: 9.5128 - val_accuracy: 0.1387\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 2.0136 - accuracy: 0.6163 - val_loss: 12.2660 - val_accuracy: 0.1313\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 4s 234ms/step - loss: 1.9664 - accuracy: 0.6212 - val_loss: 12.6759 - val_accuracy: 0.1284\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.9599 - accuracy: 0.6226 - val_loss: 10.5866 - val_accuracy: 0.1247\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.9646 - accuracy: 0.6175 - val_loss: 12.0982 - val_accuracy: 0.1280\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.9277 - accuracy: 0.6227 - val_loss: 11.7639 - val_accuracy: 0.1328\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.9334 - accuracy: 0.6213 - val_loss: 11.5681 - val_accuracy: 0.1311\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.9832 - accuracy: 0.6116 - val_loss: 10.1176 - val_accuracy: 0.1357\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.9138 - accuracy: 0.6203 - val_loss: 12.2141 - val_accuracy: 0.1346\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.9711 - accuracy: 0.6171 - val_loss: 12.7346 - val_accuracy: 0.1327\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.9663 - accuracy: 0.6192 - val_loss: 11.7509 - val_accuracy: 0.1311\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.9797 - accuracy: 0.6140 - val_loss: 13.5402 - val_accuracy: 0.1204\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.9627 - accuracy: 0.6180 - val_loss: 14.8597 - val_accuracy: 0.1198\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.9157 - accuracy: 0.6223 - val_loss: 14.1455 - val_accuracy: 0.1205\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.9291 - accuracy: 0.6208 - val_loss: 15.9992 - val_accuracy: 0.1355\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0091 - accuracy: 0.6133 - val_loss: 12.5215 - val_accuracy: 0.1322\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.9090 - accuracy: 0.6160 - val_loss: 13.2502 - val_accuracy: 0.1411\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.9254 - accuracy: 0.6206 - val_loss: 13.3971 - val_accuracy: 0.1357\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.9120 - accuracy: 0.6197 - val_loss: 14.1574 - val_accuracy: 0.1351\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.9212 - accuracy: 0.6186 - val_loss: 12.8797 - val_accuracy: 0.1410\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.9079 - accuracy: 0.6186 - val_loss: 13.8884 - val_accuracy: 0.1353\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.9083 - accuracy: 0.6242 - val_loss: 12.2096 - val_accuracy: 0.1438\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8867 - accuracy: 0.6184 - val_loss: 13.6833 - val_accuracy: 0.1402\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.8979 - accuracy: 0.6193 - val_loss: 15.1789 - val_accuracy: 0.1368\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.8322 - accuracy: 0.6260 - val_loss: 12.1954 - val_accuracy: 0.1441\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.8773 - accuracy: 0.6217 - val_loss: 14.6631 - val_accuracy: 0.1389\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.8454 - accuracy: 0.6237 - val_loss: 13.0080 - val_accuracy: 0.1401\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.8597 - accuracy: 0.6233 - val_loss: 15.8782 - val_accuracy: 0.1391\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.8747 - accuracy: 0.6226 - val_loss: 16.2796 - val_accuracy: 0.1410\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.8589 - accuracy: 0.6169 - val_loss: 12.3352 - val_accuracy: 0.1435\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.8606 - accuracy: 0.6160 - val_loss: 13.7177 - val_accuracy: 0.1459\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.8453 - accuracy: 0.6150 - val_loss: 15.8310 - val_accuracy: 0.1446\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.8532 - accuracy: 0.6194 - val_loss: 10.7734 - val_accuracy: 0.1423\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.9637 - accuracy: 0.6140 - val_loss: 20.5074 - val_accuracy: 0.1423\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.8924 - accuracy: 0.6251 - val_loss: 18.4216 - val_accuracy: 0.1396\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.8651 - accuracy: 0.6238 - val_loss: 14.0864 - val_accuracy: 0.1556\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.8372 - accuracy: 0.6249 - val_loss: 16.1637 - val_accuracy: 0.1500\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.8351 - accuracy: 0.6201 - val_loss: 14.0504 - val_accuracy: 0.1542\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.7966 - accuracy: 0.6218 - val_loss: 17.0136 - val_accuracy: 0.1522\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.8283 - accuracy: 0.6207 - val_loss: 15.7264 - val_accuracy: 0.1486\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.8054 - accuracy: 0.6223 - val_loss: 14.8889 - val_accuracy: 0.1465\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.7893 - accuracy: 0.6243 - val_loss: 10.5044 - val_accuracy: 0.1607\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.7945 - accuracy: 0.6165 - val_loss: 12.6504 - val_accuracy: 0.1527\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.8242 - accuracy: 0.6237 - val_loss: 15.7817 - val_accuracy: 0.1467\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.7667 - accuracy: 0.6274 - val_loss: 14.4622 - val_accuracy: 0.1474\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.7650 - accuracy: 0.6233 - val_loss: 11.7798 - val_accuracy: 0.1480\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.7191 - accuracy: 0.6220 - val_loss: 11.1144 - val_accuracy: 0.1364\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.8078 - accuracy: 0.6170 - val_loss: 14.7426 - val_accuracy: 0.1477\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.8025 - accuracy: 0.6155 - val_loss: 11.8013 - val_accuracy: 0.1488\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7523 - accuracy: 0.6235 - val_loss: 15.8421 - val_accuracy: 0.1397\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.7175 - accuracy: 0.6285 - val_loss: 14.6906 - val_accuracy: 0.1405\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.7331 - accuracy: 0.6236 - val_loss: 14.6398 - val_accuracy: 0.1430\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.7214 - accuracy: 0.6217 - val_loss: 14.8144 - val_accuracy: 0.1385\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.6958 - accuracy: 0.6250 - val_loss: 14.0625 - val_accuracy: 0.1435\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6768 - accuracy: 0.6241 - val_loss: 16.9098 - val_accuracy: 0.1424\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.7265 - accuracy: 0.6184 - val_loss: 12.3156 - val_accuracy: 0.1526\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.7086 - accuracy: 0.6227 - val_loss: 12.8423 - val_accuracy: 0.1472\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.7501 - accuracy: 0.6248 - val_loss: 13.7041 - val_accuracy: 0.1529\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.7265 - accuracy: 0.6211 - val_loss: 15.2267 - val_accuracy: 0.1363\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.7225 - accuracy: 0.6238 - val_loss: 13.4793 - val_accuracy: 0.1519\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.6906 - accuracy: 0.6291 - val_loss: 12.7031 - val_accuracy: 0.1667\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.6978 - accuracy: 0.6227 - val_loss: 13.8508 - val_accuracy: 0.1636\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.6842 - accuracy: 0.6237 - val_loss: 16.0770 - val_accuracy: 0.1526\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.6968 - accuracy: 0.6222 - val_loss: 11.5129 - val_accuracy: 0.1696\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.6939 - accuracy: 0.6228 - val_loss: 13.2335 - val_accuracy: 0.1538\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.6715 - accuracy: 0.6297 - val_loss: 11.5213 - val_accuracy: 0.1554\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.6815 - accuracy: 0.6252 - val_loss: 15.0340 - val_accuracy: 0.1529\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.6877 - accuracy: 0.6223 - val_loss: 14.0900 - val_accuracy: 0.1540\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.7005 - accuracy: 0.6286 - val_loss: 15.1697 - val_accuracy: 0.1502\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.6978 - accuracy: 0.6227 - val_loss: 14.6111 - val_accuracy: 0.1458\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.7152 - accuracy: 0.6211 - val_loss: 11.2358 - val_accuracy: 0.1559\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6792 - accuracy: 0.6265 - val_loss: 22.5307 - val_accuracy: 0.1445\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.6626 - accuracy: 0.6289 - val_loss: 13.5012 - val_accuracy: 0.1531\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.6503 - accuracy: 0.6314 - val_loss: 29.7355 - val_accuracy: 0.1536\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6051 - accuracy: 0.6350 - val_loss: 14.8868 - val_accuracy: 0.1509\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.6278 - accuracy: 0.6296 - val_loss: 10.5392 - val_accuracy: 0.1587\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6175 - accuracy: 0.6298 - val_loss: 13.3729 - val_accuracy: 0.1555\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.6170 - accuracy: 0.6336 - val_loss: 43.7917 - val_accuracy: 0.1416\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6284 - accuracy: 0.6324 - val_loss: 16.6140 - val_accuracy: 0.1580\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.6430 - accuracy: 0.6292 - val_loss: 12.8781 - val_accuracy: 0.1532\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.6524 - accuracy: 0.6290 - val_loss: 12.0009 - val_accuracy: 0.1614\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.6526 - accuracy: 0.6315 - val_loss: 11.5009 - val_accuracy: 0.1608\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.6018 - accuracy: 0.6338 - val_loss: 12.5715 - val_accuracy: 0.1521\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.6181 - accuracy: 0.6337 - val_loss: 12.8250 - val_accuracy: 0.1551\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.6328 - accuracy: 0.6266 - val_loss: 10.9965 - val_accuracy: 0.1648\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.6064 - accuracy: 0.6367 - val_loss: 29.6651 - val_accuracy: 0.1584\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6469 - accuracy: 0.6306 - val_loss: 13.4169 - val_accuracy: 0.1440\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.6400 - accuracy: 0.6331 - val_loss: 20.5765 - val_accuracy: 0.1613\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.6096 - accuracy: 0.6326 - val_loss: 11.4275 - val_accuracy: 0.1528\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6029 - accuracy: 0.6332 - val_loss: 10.5932 - val_accuracy: 0.1618\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6400 - accuracy: 0.6305 - val_loss: 11.7391 - val_accuracy: 0.1518\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.6413 - accuracy: 0.6278 - val_loss: 12.3640 - val_accuracy: 0.1504\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.6057 - accuracy: 0.6359 - val_loss: 11.7753 - val_accuracy: 0.1546\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.6087 - accuracy: 0.6349 - val_loss: 11.9938 - val_accuracy: 0.1624\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5912 - accuracy: 0.6349 - val_loss: 20.6085 - val_accuracy: 0.1603\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6090 - accuracy: 0.6305 - val_loss: 22.6742 - val_accuracy: 0.1549\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.6236 - accuracy: 0.6316 - val_loss: 16.0710 - val_accuracy: 0.1460\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5785 - accuracy: 0.6368 - val_loss: 10.4884 - val_accuracy: 0.1558\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5741 - accuracy: 0.6361 - val_loss: 11.9570 - val_accuracy: 0.1509\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.5550 - accuracy: 0.6401 - val_loss: 12.2282 - val_accuracy: 0.1432\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.6205 - accuracy: 0.6311 - val_loss: 14.2827 - val_accuracy: 0.1411\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.6452 - accuracy: 0.6349 - val_loss: 12.4677 - val_accuracy: 0.1449\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5974 - accuracy: 0.6375 - val_loss: 13.5136 - val_accuracy: 0.1492\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.6007 - accuracy: 0.6306 - val_loss: 10.4233 - val_accuracy: 0.1441\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5438 - accuracy: 0.6428 - val_loss: 11.6243 - val_accuracy: 0.1530\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.6144 - accuracy: 0.6364 - val_loss: 12.3889 - val_accuracy: 0.1436\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.5512 - accuracy: 0.6436 - val_loss: 72.0086 - val_accuracy: 0.1457\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.5572 - accuracy: 0.6399 - val_loss: 12.7815 - val_accuracy: 0.1458\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6124 - accuracy: 0.6326 - val_loss: 13.5361 - val_accuracy: 0.1525\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.5638 - accuracy: 0.6381 - val_loss: 11.2621 - val_accuracy: 0.1437\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.5772 - accuracy: 0.6387 - val_loss: 12.6650 - val_accuracy: 0.1512\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5920 - accuracy: 0.6313 - val_loss: 18.9802 - val_accuracy: 0.1362\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.5693 - accuracy: 0.6380 - val_loss: 10.5031 - val_accuracy: 0.1487\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.5171 - accuracy: 0.6435 - val_loss: 11.9568 - val_accuracy: 0.1463\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5440 - accuracy: 0.6412 - val_loss: 13.0831 - val_accuracy: 0.1427\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.5163 - accuracy: 0.6463 - val_loss: 12.4350 - val_accuracy: 0.1414\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.5296 - accuracy: 0.6413 - val_loss: 11.2499 - val_accuracy: 0.1466\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5351 - accuracy: 0.6364 - val_loss: 10.9546 - val_accuracy: 0.1438\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5268 - accuracy: 0.6425 - val_loss: 15.0648 - val_accuracy: 0.1366\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5312 - accuracy: 0.6390 - val_loss: 11.0612 - val_accuracy: 0.1443\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.6854 - accuracy: 0.6337 - val_loss: 29.3235 - val_accuracy: 0.1338\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.7249 - accuracy: 0.6345 - val_loss: 21.1404 - val_accuracy: 0.1324\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.6798 - accuracy: 0.6284 - val_loss: 13.2246 - val_accuracy: 0.1410\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.6179 - accuracy: 0.6357 - val_loss: 10.8149 - val_accuracy: 0.1426\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5844 - accuracy: 0.6356 - val_loss: 13.7353 - val_accuracy: 0.1419\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5884 - accuracy: 0.6325 - val_loss: 12.7111 - val_accuracy: 0.1395\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5529 - accuracy: 0.6364 - val_loss: 11.3374 - val_accuracy: 0.1446\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5420 - accuracy: 0.6404 - val_loss: 11.7946 - val_accuracy: 0.1417\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5605 - accuracy: 0.6399 - val_loss: 12.0695 - val_accuracy: 0.1483\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.5636 - accuracy: 0.6343 - val_loss: 14.8720 - val_accuracy: 0.1388\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5436 - accuracy: 0.6410 - val_loss: 14.7818 - val_accuracy: 0.1395\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5378 - accuracy: 0.6395 - val_loss: 14.5702 - val_accuracy: 0.1443\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.5718 - accuracy: 0.6409 - val_loss: 17.5956 - val_accuracy: 0.1349\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5441 - accuracy: 0.6394 - val_loss: 17.0921 - val_accuracy: 0.1336\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.5531 - accuracy: 0.6361 - val_loss: 15.6742 - val_accuracy: 0.1368\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5261 - accuracy: 0.6369 - val_loss: 14.9459 - val_accuracy: 0.1406\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.5224 - accuracy: 0.6415 - val_loss: 18.8252 - val_accuracy: 0.1358\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.5289 - accuracy: 0.6421 - val_loss: 20.8074 - val_accuracy: 0.1384\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.5570 - accuracy: 0.6364 - val_loss: 18.2920 - val_accuracy: 0.1390\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5165 - accuracy: 0.6419 - val_loss: 22.8614 - val_accuracy: 0.1331\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5340 - accuracy: 0.6429 - val_loss: 16.9619 - val_accuracy: 0.1341\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.5165 - accuracy: 0.6412 - val_loss: 13.1296 - val_accuracy: 0.1406\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.5149 - accuracy: 0.6431 - val_loss: 20.1386 - val_accuracy: 0.1377\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5562 - accuracy: 0.6433 - val_loss: 23.7659 - val_accuracy: 0.1346\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5658 - accuracy: 0.6401 - val_loss: 14.4674 - val_accuracy: 0.1415\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5351 - accuracy: 0.6433 - val_loss: 18.5072 - val_accuracy: 0.1453\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4897 - accuracy: 0.6443 - val_loss: 21.0971 - val_accuracy: 0.1310\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.5417 - accuracy: 0.6477 - val_loss: 17.9425 - val_accuracy: 0.1349\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.5377 - accuracy: 0.6430 - val_loss: 24.5315 - val_accuracy: 0.1462\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5107 - accuracy: 0.6447 - val_loss: 19.5426 - val_accuracy: 0.1405\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.5128 - accuracy: 0.6368 - val_loss: 15.6389 - val_accuracy: 0.1444\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5594 - accuracy: 0.6415 - val_loss: 14.9577 - val_accuracy: 0.1428\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5199 - accuracy: 0.6353 - val_loss: 12.8384 - val_accuracy: 0.1516\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4861 - accuracy: 0.6445 - val_loss: 19.9469 - val_accuracy: 0.1429\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.5112 - accuracy: 0.6460 - val_loss: 13.6231 - val_accuracy: 0.1480\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.5417 - accuracy: 0.6369 - val_loss: 10.2242 - val_accuracy: 0.1515\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4922 - accuracy: 0.6490 - val_loss: 13.8895 - val_accuracy: 0.1481\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4996 - accuracy: 0.6457 - val_loss: 15.8737 - val_accuracy: 0.1459\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4998 - accuracy: 0.6445 - val_loss: 17.5451 - val_accuracy: 0.1484\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.4525 - accuracy: 0.6478 - val_loss: 31.9956 - val_accuracy: 0.1392\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.4673 - accuracy: 0.6414 - val_loss: 26.3705 - val_accuracy: 0.1479\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4745 - accuracy: 0.6463 - val_loss: 36.9913 - val_accuracy: 0.1392\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4419 - accuracy: 0.6444 - val_loss: 15.2193 - val_accuracy: 0.1473\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4644 - accuracy: 0.6473 - val_loss: 20.1541 - val_accuracy: 0.1432\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4739 - accuracy: 0.6415 - val_loss: 19.1593 - val_accuracy: 0.1487\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.4929 - accuracy: 0.6419 - val_loss: 11.7476 - val_accuracy: 0.1530\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.4590 - accuracy: 0.6524 - val_loss: 13.6703 - val_accuracy: 0.1509\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.4588 - accuracy: 0.6518 - val_loss: 17.2795 - val_accuracy: 0.1472\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.4493 - accuracy: 0.6495 - val_loss: 18.9128 - val_accuracy: 0.1480\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4224 - accuracy: 0.6521 - val_loss: 12.8172 - val_accuracy: 0.1548\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4618 - accuracy: 0.6520 - val_loss: 14.9792 - val_accuracy: 0.1498\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4689 - accuracy: 0.6445 - val_loss: 14.8627 - val_accuracy: 0.1507\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.5385 - accuracy: 0.6486 - val_loss: 14.3163 - val_accuracy: 0.1645\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4705 - accuracy: 0.6450 - val_loss: 10.7631 - val_accuracy: 0.1664\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4479 - accuracy: 0.6530 - val_loss: 10.4169 - val_accuracy: 0.1578\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4601 - accuracy: 0.6467 - val_loss: 13.6987 - val_accuracy: 0.1568\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.4304 - accuracy: 0.6492 - val_loss: 16.8411 - val_accuracy: 0.1518\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.4584 - accuracy: 0.6507 - val_loss: 16.4867 - val_accuracy: 0.1537\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.4408 - accuracy: 0.6489 - val_loss: 13.2363 - val_accuracy: 0.1562\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4942 - accuracy: 0.6404 - val_loss: 16.1027 - val_accuracy: 0.1428\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4530 - accuracy: 0.6516 - val_loss: 26.5064 - val_accuracy: 0.1302\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.4551 - accuracy: 0.6461 - val_loss: 24.4013 - val_accuracy: 0.1360\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4262 - accuracy: 0.6502 - val_loss: 23.7075 - val_accuracy: 0.1394\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.4707 - accuracy: 0.6477 - val_loss: 20.7752 - val_accuracy: 0.1432\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4645 - accuracy: 0.6459 - val_loss: 32.9502 - val_accuracy: 0.1373\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.4726 - accuracy: 0.6460 - val_loss: 39.2863 - val_accuracy: 0.1379\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.4369 - accuracy: 0.6498 - val_loss: 39.8875 - val_accuracy: 0.1385\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.5027 - accuracy: 0.6441 - val_loss: 19.2065 - val_accuracy: 0.1413\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4510 - accuracy: 0.6425 - val_loss: 57.5874 - val_accuracy: 0.1380\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4374 - accuracy: 0.6542 - val_loss: 27.8408 - val_accuracy: 0.1394\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4625 - accuracy: 0.6428 - val_loss: 31.4793 - val_accuracy: 0.1330\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4198 - accuracy: 0.6546 - val_loss: 23.5491 - val_accuracy: 0.1400\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4489 - accuracy: 0.6460 - val_loss: 26.7082 - val_accuracy: 0.1361\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4523 - accuracy: 0.6482 - val_loss: 28.6944 - val_accuracy: 0.1432\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4323 - accuracy: 0.6474 - val_loss: 17.2283 - val_accuracy: 0.1465\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.4637 - accuracy: 0.6453 - val_loss: 22.6294 - val_accuracy: 0.1525\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4145 - accuracy: 0.6507 - val_loss: 16.1355 - val_accuracy: 0.1469\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.4307 - accuracy: 0.6523 - val_loss: 22.9462 - val_accuracy: 0.1374\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4903 - accuracy: 0.6418 - val_loss: 26.0871 - val_accuracy: 0.1414\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.4295 - accuracy: 0.6505 - val_loss: 18.0902 - val_accuracy: 0.1400\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 4s 231ms/step - loss: 1.4331 - accuracy: 0.6454 - val_loss: 18.9977 - val_accuracy: 0.1376\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.4498 - accuracy: 0.6452 - val_loss: 21.2197 - val_accuracy: 0.1366\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 4s 231ms/step - loss: 1.4375 - accuracy: 0.6493 - val_loss: 20.9420 - val_accuracy: 0.1396\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 1.4244 - accuracy: 0.6480 - val_loss: 25.8400 - val_accuracy: 0.1250\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.4373 - accuracy: 0.6517 - val_loss: 26.9555 - val_accuracy: 0.1312\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.3934 - accuracy: 0.6552 - val_loss: 19.1979 - val_accuracy: 0.1451\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.4624 - accuracy: 0.6491 - val_loss: 34.4375 - val_accuracy: 0.1289\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.5054 - accuracy: 0.6484 - val_loss: 17.5678 - val_accuracy: 0.1408\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4850 - accuracy: 0.6484 - val_loss: 18.1562 - val_accuracy: 0.1437\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4482 - accuracy: 0.6524 - val_loss: 18.2797 - val_accuracy: 0.1324\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4687 - accuracy: 0.6464 - val_loss: 15.7734 - val_accuracy: 0.1374\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4616 - accuracy: 0.6469 - val_loss: 17.3907 - val_accuracy: 0.1383\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4459 - accuracy: 0.6497 - val_loss: 19.3101 - val_accuracy: 0.1321\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4251 - accuracy: 0.6550 - val_loss: 18.5323 - val_accuracy: 0.1363\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3970 - accuracy: 0.6535 - val_loss: 22.0406 - val_accuracy: 0.1289\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4295 - accuracy: 0.6481 - val_loss: 38.0301 - val_accuracy: 0.1323\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.4038 - accuracy: 0.6524 - val_loss: 45.0803 - val_accuracy: 0.1281\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4143 - accuracy: 0.6550 - val_loss: 24.6456 - val_accuracy: 0.1334\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4813 - accuracy: 0.6456 - val_loss: 19.7455 - val_accuracy: 0.1308\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4571 - accuracy: 0.6497 - val_loss: 14.8302 - val_accuracy: 0.1441\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4237 - accuracy: 0.6513 - val_loss: 15.9242 - val_accuracy: 0.1408\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4200 - accuracy: 0.6493 - val_loss: 29.7655 - val_accuracy: 0.1265\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4470 - accuracy: 0.6482 - val_loss: 10.5812 - val_accuracy: 0.1552\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.4367 - accuracy: 0.6493 - val_loss: 19.2363 - val_accuracy: 0.1334\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4555 - accuracy: 0.6487 - val_loss: 12.9759 - val_accuracy: 0.1441\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.3984 - accuracy: 0.6546 - val_loss: 15.0486 - val_accuracy: 0.1389\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3920 - accuracy: 0.6517 - val_loss: 25.1241 - val_accuracy: 0.1305\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4111 - accuracy: 0.6541 - val_loss: 28.6699 - val_accuracy: 0.1272\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.4077 - accuracy: 0.6519 - val_loss: 22.9515 - val_accuracy: 0.1367\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3509 - accuracy: 0.6595 - val_loss: 26.9077 - val_accuracy: 0.1322\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3582 - accuracy: 0.6574 - val_loss: 14.8826 - val_accuracy: 0.1422\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.4000 - accuracy: 0.6515 - val_loss: 15.8119 - val_accuracy: 0.1413\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.4120 - accuracy: 0.6537 - val_loss: 18.3059 - val_accuracy: 0.1349\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3992 - accuracy: 0.6552 - val_loss: 16.6904 - val_accuracy: 0.1332\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4168 - accuracy: 0.6508 - val_loss: 20.7273 - val_accuracy: 0.1307\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3769 - accuracy: 0.6556 - val_loss: 26.9727 - val_accuracy: 0.1340\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3745 - accuracy: 0.6546 - val_loss: 29.8345 - val_accuracy: 0.1355\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3808 - accuracy: 0.6559 - val_loss: 39.4490 - val_accuracy: 0.1284\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4077 - accuracy: 0.6539 - val_loss: 17.4696 - val_accuracy: 0.1388\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.3776 - accuracy: 0.6583 - val_loss: 27.7167 - val_accuracy: 0.1326\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3760 - accuracy: 0.6566 - val_loss: 33.7068 - val_accuracy: 0.1390\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4332 - accuracy: 0.6488 - val_loss: 20.7322 - val_accuracy: 0.1409\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.4025 - accuracy: 0.6502 - val_loss: 16.5350 - val_accuracy: 0.1448\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3749 - accuracy: 0.6573 - val_loss: 20.6126 - val_accuracy: 0.1413\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3694 - accuracy: 0.6565 - val_loss: 40.6908 - val_accuracy: 0.1338\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3934 - accuracy: 0.6595 - val_loss: 17.6915 - val_accuracy: 0.1421\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.3877 - accuracy: 0.6519 - val_loss: 17.3931 - val_accuracy: 0.1348\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.3822 - accuracy: 0.6539 - val_loss: 19.0364 - val_accuracy: 0.1353\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.3487 - accuracy: 0.6612 - val_loss: 14.6406 - val_accuracy: 0.1458\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.4131 - accuracy: 0.6498 - val_loss: 19.9173 - val_accuracy: 0.1391\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4382 - accuracy: 0.6537 - val_loss: 12.6698 - val_accuracy: 0.1518\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3641 - accuracy: 0.6585 - val_loss: 14.6159 - val_accuracy: 0.1366\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.4020 - accuracy: 0.6503 - val_loss: 17.5673 - val_accuracy: 0.1434\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3747 - accuracy: 0.6551 - val_loss: 19.9030 - val_accuracy: 0.1410\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3977 - accuracy: 0.6505 - val_loss: 12.2969 - val_accuracy: 0.1464\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3924 - accuracy: 0.6531 - val_loss: 15.0331 - val_accuracy: 0.1494\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3446 - accuracy: 0.6580 - val_loss: 15.3519 - val_accuracy: 0.1464\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3369 - accuracy: 0.6611 - val_loss: 12.3361 - val_accuracy: 0.1415\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3970 - accuracy: 0.6532 - val_loss: 16.0631 - val_accuracy: 0.1393\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3914 - accuracy: 0.6565 - val_loss: 15.6136 - val_accuracy: 0.1436\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3526 - accuracy: 0.6551 - val_loss: 18.6315 - val_accuracy: 0.1385\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3467 - accuracy: 0.6581 - val_loss: 26.1462 - val_accuracy: 0.1343\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3545 - accuracy: 0.6542 - val_loss: 19.5647 - val_accuracy: 0.1454\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3927 - accuracy: 0.6566 - val_loss: 13.3825 - val_accuracy: 0.1513\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3339 - accuracy: 0.6600 - val_loss: 33.7001 - val_accuracy: 0.1372\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3462 - accuracy: 0.6599 - val_loss: 16.8901 - val_accuracy: 0.1405\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 9s 575ms/step - loss: 1.4336 - accuracy: 0.6536 - val_loss: 13.4543 - val_accuracy: 0.1380\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3777 - accuracy: 0.6580 - val_loss: 21.1541 - val_accuracy: 0.1421\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.3399 - accuracy: 0.6577 - val_loss: 20.4165 - val_accuracy: 0.1328\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3088 - accuracy: 0.6665 - val_loss: 19.4536 - val_accuracy: 0.1305\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3470 - accuracy: 0.6588 - val_loss: 22.8719 - val_accuracy: 0.1348\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3395 - accuracy: 0.6612 - val_loss: 18.1798 - val_accuracy: 0.1466\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3405 - accuracy: 0.6600 - val_loss: 18.4085 - val_accuracy: 0.1385\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.4007 - accuracy: 0.6536 - val_loss: 15.6220 - val_accuracy: 0.1463\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3290 - accuracy: 0.6594 - val_loss: 19.4394 - val_accuracy: 0.1401\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.3363 - accuracy: 0.6651 - val_loss: 18.9579 - val_accuracy: 0.1363\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.3426 - accuracy: 0.6605 - val_loss: 21.3096 - val_accuracy: 0.1361\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3655 - accuracy: 0.6573 - val_loss: 20.6546 - val_accuracy: 0.1391\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3425 - accuracy: 0.6580 - val_loss: 17.9797 - val_accuracy: 0.1398\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3611 - accuracy: 0.6631 - val_loss: 16.7882 - val_accuracy: 0.1404\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3463 - accuracy: 0.6624 - val_loss: 16.7784 - val_accuracy: 0.1462\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3516 - accuracy: 0.6566 - val_loss: 18.1690 - val_accuracy: 0.1460\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3783 - accuracy: 0.6540 - val_loss: 20.6230 - val_accuracy: 0.1451\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3523 - accuracy: 0.6598 - val_loss: 18.7094 - val_accuracy: 0.1432\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3365 - accuracy: 0.6587 - val_loss: 15.1069 - val_accuracy: 0.1468\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3397 - accuracy: 0.6607 - val_loss: 15.9966 - val_accuracy: 0.1456\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 1.3616 - accuracy: 0.6549 - val_loss: 15.8202 - val_accuracy: 0.1382\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3591 - accuracy: 0.6597 - val_loss: 16.1357 - val_accuracy: 0.1427\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3487 - accuracy: 0.6591 - val_loss: 17.2529 - val_accuracy: 0.1393\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3141 - accuracy: 0.6657 - val_loss: 20.8251 - val_accuracy: 0.1430\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3258 - accuracy: 0.6617 - val_loss: 19.1353 - val_accuracy: 0.1387\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3194 - accuracy: 0.6565 - val_loss: 16.3722 - val_accuracy: 0.1447\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3497 - accuracy: 0.6605 - val_loss: 13.6695 - val_accuracy: 0.1572\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3735 - accuracy: 0.6604 - val_loss: 13.0004 - val_accuracy: 0.1504\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3645 - accuracy: 0.6601 - val_loss: 17.5243 - val_accuracy: 0.1379\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3728 - accuracy: 0.6571 - val_loss: 12.8202 - val_accuracy: 0.1563\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3513 - accuracy: 0.6587 - val_loss: 13.2444 - val_accuracy: 0.1466\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3348 - accuracy: 0.6626 - val_loss: 22.4225 - val_accuracy: 0.1411\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3140 - accuracy: 0.6599 - val_loss: 34.9305 - val_accuracy: 0.1363\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3456 - accuracy: 0.6579 - val_loss: 18.2673 - val_accuracy: 0.1456\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 1.3502 - accuracy: 0.6558 - val_loss: 21.0826 - val_accuracy: 0.1450\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3390 - accuracy: 0.6578 - val_loss: 18.7844 - val_accuracy: 0.1341\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 1.3331 - accuracy: 0.6588 - val_loss: 17.5245 - val_accuracy: 0.1439\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3626 - accuracy: 0.6564 - val_loss: 20.7583 - val_accuracy: 0.1490\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3519 - accuracy: 0.6581 - val_loss: 25.3146 - val_accuracy: 0.1421\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 1.3300 - accuracy: 0.6635 - val_loss: 16.9850 - val_accuracy: 0.1493\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.3114 - accuracy: 0.6636 - val_loss: 19.4247 - val_accuracy: 0.1377\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3051 - accuracy: 0.6609 - val_loss: 19.8374 - val_accuracy: 0.1428\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3267 - accuracy: 0.6635 - val_loss: 21.7322 - val_accuracy: 0.1333\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3140 - accuracy: 0.6651 - val_loss: 28.8938 - val_accuracy: 0.1353\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.3005 - accuracy: 0.6641 - val_loss: 17.0148 - val_accuracy: 0.1493\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3239 - accuracy: 0.6629 - val_loss: 41.7571 - val_accuracy: 0.1309\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.3438 - accuracy: 0.6619 - val_loss: 24.4249 - val_accuracy: 0.1357\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3343 - accuracy: 0.6577 - val_loss: 33.1935 - val_accuracy: 0.1318\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3208 - accuracy: 0.6585 - val_loss: 31.5296 - val_accuracy: 0.1302\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.2995 - accuracy: 0.6661 - val_loss: 65.2039 - val_accuracy: 0.1316\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 1.3384 - accuracy: 0.6634 - val_loss: 49.4422 - val_accuracy: 0.1259\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 1.3296 - accuracy: 0.6601 - val_loss: 45.0652 - val_accuracy: 0.1334\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 1.5173 - accuracy: 0.6400 - val_loss: 20.1187 - val_accuracy: 0.1391\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.5770 - accuracy: 0.5020 - val_loss: 109706768.0000 - val_accuracy: 0.0994\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.9029 - accuracy: 0.4878 - val_loss: 3846.0938 - val_accuracy: 0.1028\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.5029 - accuracy: 0.5126 - val_loss: 23.7797 - val_accuracy: 0.0872\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.3105 - accuracy: 0.5672 - val_loss: 13.4584 - val_accuracy: 0.1231\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.3045 - accuracy: 0.5908 - val_loss: 14.1115 - val_accuracy: 0.1250\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.2612 - accuracy: 0.5927 - val_loss: 13.4691 - val_accuracy: 0.1230\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2135 - accuracy: 0.5999 - val_loss: 13.5897 - val_accuracy: 0.1159\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1710 - accuracy: 0.6057 - val_loss: 14.5312 - val_accuracy: 0.1116\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2364 - accuracy: 0.6092 - val_loss: 13.4256 - val_accuracy: 0.1173\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.2419 - accuracy: 0.6099 - val_loss: 12.9490 - val_accuracy: 0.1169\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1641 - accuracy: 0.6114 - val_loss: 14.7746 - val_accuracy: 0.1160\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 2.2103 - accuracy: 0.6120 - val_loss: 13.7300 - val_accuracy: 0.1197\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 2.1949 - accuracy: 0.6116 - val_loss: 12.9308 - val_accuracy: 0.1235\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.2035 - accuracy: 0.6163 - val_loss: 13.3144 - val_accuracy: 0.1257\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1566 - accuracy: 0.6168 - val_loss: 13.0757 - val_accuracy: 0.1220\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1453 - accuracy: 0.6184 - val_loss: 12.5460 - val_accuracy: 0.1266\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1491 - accuracy: 0.6181 - val_loss: 12.8930 - val_accuracy: 0.1262\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1859 - accuracy: 0.6144 - val_loss: 12.2700 - val_accuracy: 0.1249\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1537 - accuracy: 0.6166 - val_loss: 11.5478 - val_accuracy: 0.1275\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.1886 - accuracy: 0.6203 - val_loss: 12.2159 - val_accuracy: 0.1229\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1554 - accuracy: 0.6218 - val_loss: 14.1669 - val_accuracy: 0.1282\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1169 - accuracy: 0.6196 - val_loss: 15.1996 - val_accuracy: 0.1281\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1427 - accuracy: 0.6160 - val_loss: 14.3911 - val_accuracy: 0.1230\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1346 - accuracy: 0.6166 - val_loss: 14.5812 - val_accuracy: 0.1256\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.2276 - accuracy: 0.6135 - val_loss: 14.8740 - val_accuracy: 0.1355\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.1226 - accuracy: 0.6194 - val_loss: 13.9955 - val_accuracy: 0.1327\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1071 - accuracy: 0.6185 - val_loss: 16.7948 - val_accuracy: 0.1369\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.1586 - accuracy: 0.6198 - val_loss: 15.8342 - val_accuracy: 0.1383\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.1428 - accuracy: 0.6149 - val_loss: 15.6588 - val_accuracy: 0.1357\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.1541 - accuracy: 0.6134 - val_loss: 15.0437 - val_accuracy: 0.1372\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.1053 - accuracy: 0.6195 - val_loss: 15.9931 - val_accuracy: 0.1401\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1362 - accuracy: 0.6195 - val_loss: 18.9852 - val_accuracy: 0.1427\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1803 - accuracy: 0.6181 - val_loss: 17.4495 - val_accuracy: 0.1446\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0992 - accuracy: 0.6200 - val_loss: 16.0756 - val_accuracy: 0.1434\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1873 - accuracy: 0.6149 - val_loss: 15.8950 - val_accuracy: 0.1409\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 12s 733ms/step - loss: 2.1294 - accuracy: 0.6218 - val_loss: 20.5295 - val_accuracy: 0.1426\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1379 - accuracy: 0.6206 - val_loss: 20.1311 - val_accuracy: 0.1447\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.2147 - accuracy: 0.6155 - val_loss: 19.6760 - val_accuracy: 0.1455\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.1303 - accuracy: 0.6177 - val_loss: 138.0018 - val_accuracy: 0.1476\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1721 - accuracy: 0.6051 - val_loss: 67.1684 - val_accuracy: 0.1414\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.2550 - accuracy: 0.5982 - val_loss: 17.9001 - val_accuracy: 0.1562\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.2937 - accuracy: 0.6147 - val_loss: 26.3877 - val_accuracy: 0.1406\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.2545 - accuracy: 0.6030 - val_loss: 22.2777 - val_accuracy: 0.1515\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.2109 - accuracy: 0.6081 - val_loss: 22.2268 - val_accuracy: 0.1483\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 2.2080 - accuracy: 0.6136 - val_loss: 18.3491 - val_accuracy: 0.1475\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1842 - accuracy: 0.6133 - val_loss: 18.9506 - val_accuracy: 0.1442\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.2072 - accuracy: 0.6126 - val_loss: 18.0752 - val_accuracy: 0.1465\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1566 - accuracy: 0.6144 - val_loss: 19.3183 - val_accuracy: 0.1486\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0861 - accuracy: 0.6201 - val_loss: 19.9121 - val_accuracy: 0.1483\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 2.1768 - accuracy: 0.6116 - val_loss: 18.2587 - val_accuracy: 0.1489\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1665 - accuracy: 0.6130 - val_loss: 18.3300 - val_accuracy: 0.1516\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1536 - accuracy: 0.6148 - val_loss: 20.6270 - val_accuracy: 0.1532\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 2.1226 - accuracy: 0.6148 - val_loss: 20.4115 - val_accuracy: 0.1507\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 2.1253 - accuracy: 0.6172 - val_loss: 21.3138 - val_accuracy: 0.1546\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1569 - accuracy: 0.6146 - val_loss: 19.8439 - val_accuracy: 0.1552\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1040 - accuracy: 0.6169 - val_loss: 26.5070 - val_accuracy: 0.1500\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1329 - accuracy: 0.6170 - val_loss: 30.5068 - val_accuracy: 0.1496\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1517 - accuracy: 0.6136 - val_loss: 18.3319 - val_accuracy: 0.1571\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1061 - accuracy: 0.6139 - val_loss: 20.1191 - val_accuracy: 0.1543\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1670 - accuracy: 0.6173 - val_loss: 19.4424 - val_accuracy: 0.1526\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1072 - accuracy: 0.6121 - val_loss: 19.2373 - val_accuracy: 0.1570\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0831 - accuracy: 0.6173 - val_loss: 18.9830 - val_accuracy: 0.1538\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.1559 - accuracy: 0.6063 - val_loss: 22.4466 - val_accuracy: 0.1566\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 2.1407 - accuracy: 0.6174 - val_loss: 20.8574 - val_accuracy: 0.1545\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.1522 - accuracy: 0.6168 - val_loss: 18.2751 - val_accuracy: 0.1536\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1383 - accuracy: 0.6156 - val_loss: 18.7701 - val_accuracy: 0.1595\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.1555 - accuracy: 0.6135 - val_loss: 20.9517 - val_accuracy: 0.1545\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.1387 - accuracy: 0.6159 - val_loss: 20.1277 - val_accuracy: 0.1527\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0455 - accuracy: 0.6180 - val_loss: 18.5054 - val_accuracy: 0.1555\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 2.1182 - accuracy: 0.6155 - val_loss: 19.7594 - val_accuracy: 0.1551\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0840 - accuracy: 0.6187 - val_loss: 19.6916 - val_accuracy: 0.1552\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0538 - accuracy: 0.6222 - val_loss: 23.3660 - val_accuracy: 0.1544\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.1051 - accuracy: 0.6166 - val_loss: 18.7972 - val_accuracy: 0.1547\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0649 - accuracy: 0.6163 - val_loss: 19.9680 - val_accuracy: 0.1539\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.1113 - accuracy: 0.6118 - val_loss: 21.5837 - val_accuracy: 0.1549\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0526 - accuracy: 0.6230 - val_loss: 20.2720 - val_accuracy: 0.1535\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.1464 - accuracy: 0.6139 - val_loss: 23.1011 - val_accuracy: 0.1567\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0856 - accuracy: 0.6179 - val_loss: 22.4245 - val_accuracy: 0.1514\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.0502 - accuracy: 0.6203 - val_loss: 55.5131 - val_accuracy: 0.1523\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0596 - accuracy: 0.6168 - val_loss: 21.9474 - val_accuracy: 0.1539\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0980 - accuracy: 0.6081 - val_loss: 31.1374 - val_accuracy: 0.1543\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.1187 - accuracy: 0.6135 - val_loss: 22.2040 - val_accuracy: 0.1547\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0492 - accuracy: 0.6192 - val_loss: 20.8892 - val_accuracy: 0.1565\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 2.0925 - accuracy: 0.6161 - val_loss: 26.2205 - val_accuracy: 0.1528\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 2.0847 - accuracy: 0.6179 - val_loss: 19.6894 - val_accuracy: 0.1551\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 2.0096 - accuracy: 0.6234 - val_loss: 22.0821 - val_accuracy: 0.1545\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 2.0220 - accuracy: 0.6167 - val_loss: 20.7016 - val_accuracy: 0.1556\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 2.0716 - accuracy: 0.6203 - val_loss: 18.7602 - val_accuracy: 0.1561\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 2.0686 - accuracy: 0.6189 - val_loss: 79.4149 - val_accuracy: 0.1544\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 2.0079 - accuracy: 0.6241 - val_loss: 25.7367 - val_accuracy: 0.1545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xwz6XVxTCbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}