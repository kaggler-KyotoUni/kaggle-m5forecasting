# kaggle-m5forecasting
<br />
2020/06/15 Todo <br />

やるべきことリスト<br />
・Colaboratoryに定期アクセスする仕組みづくり(JavaScript??)<br />
・特徴量に週・月くらいの移動平均のデータを盛り込む。<br />
・Encodingを変化させる(one-hot 他)<br />
・~クロスバリデーションやる。~(6/14実施済)<br />
・カテゴリ(食品・生活必需品・嗜好品)ごとに個別のモデルを学習する。<br />
・LightGBMも使う。<br />
・可能なら、ARモデルとか、SVMとかもやってみる。そして最後にアンサンブル。<br />
・Loss を自作する(RMSSEをLossとした学習を行う)。<br />
<br />
※ 参考 RMSSE(Root Mean Squared Scaled Error)の式<br />
$$
\begin{eqnarrray}
RMSSE = \sqrt{\frac{1}{h}\frac{\sum_{t=n+1}^{n+h}(Y_t -\hat{Y}_t)^2}{\frac{1}{n-1}{\sum_{t=2}^{n}(Y_t - Y_{t-1})^2}}}
\end{eqnarray}
$$<br />
<br />
h: 予測のステップ数(今回では28日分=28step)<br />
n: 観測されている(入力に使える？)ステップ数(今回は1969日分＝1969step??)<br />
<br />
この式から読み取れること<br />
・予測結果に効いてくるのは分子のみ。その意味では単なる二乗誤差で学習しても大差はない<br />
・分母は過去の系列=入力データがステップごとに大きく変動している(高周波)と大きな値、あまり変動していない(低周波)と小さな値になり、それぞれRMSSEの値が小さく/大きくなる。つまり、極端に変動する値(=外れ値/ボラティリティ項のような一瞬の変動)を外す分にはあまりペナルティが乗らず、大域的な変動(=トレンド項のような一定の傾向・バイアス)を外すと大きなペナルティが乗ることになる。<br />
したがって、移動平均のような特徴量を作成し、大域的な傾向を外さないことが高評価のための要件と考えられる。

<br />
<br />
<br />

Todo(old)
-EDA周りを整える
-LightGBMで予測
-LSTM

